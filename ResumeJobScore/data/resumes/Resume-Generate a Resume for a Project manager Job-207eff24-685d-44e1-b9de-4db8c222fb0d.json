{
    "clean_data": "Job Seeker Data Analyst Python Developer Chicago IL Work Experience Banking and Financial January 2018 to Present Skills used Python Numpy Pandas seaborn Kmeans RandomForestClassifier HTML CSS for presentations AWS Helped the project analyse the HMDA historical data for the given period giving many insights to the Change leaders to make strategic decisions to enter the market in a particular location gains profit or loss Used the metadata to know the datatype of the attributes and made quality suggestions on the incoming data from the users directly using a quality check analysis Handled multiple records by combining multiple files using Pandas dataframes in Python and used them for further analysis Predictive analysis Clustered the data using KMeans clustering and classified them accordingly using RandomForest Classifier and predicted the accuracy of my test cases and results Plotted the visualizations using Seaborn in Python to make the change leaders understand the importance of their competitors in that location and the offers along the gain profit percentage Python Developer Twitter API December 2017 to January 2018 Skills used Python Numpy Pandas collections Itertools matplotlib Networkx TwitterAPI Pickle Scipy ScikitLearn Girvan_Newman algorithms AWS NLTK packages Helped the project understand the importance of the network in a social hub Implemented a Community detection using BreadthFirst search and Girvan Newman Algorithms to find the communities each person belonged and to find the exisiting relationship between resources Developed NLP programs for twitter analysis using NLTK Implemented LinkPrediction using Jaccard similarity and Pearsons Coefficient to understand the link between two nodes if there is no exisiting relationship already Calculated the path score and accuracy for consistency Implemented Sentiment analysis classification Built a text classifier to determine whether a text is expressing positive or negative sentiment Removed outliers Built a prediction model and vectorized the testing and training data fitting Logistic regression on the training set Writing and injecting service classes to the components and posting and fetching JSON data Developed Python based API to track sales and perform sales analysis Used and enhanced HMM model and Girvan Newman method algorithms in order to find the communities in complex applications Used Networkx Algorithms in Python for the analysis of community structure based on the iterative elimination of edges with the highest number of shortest paths that go through them Used Scipy for scientific computing and used modules for optimization linear regression integration and special functions for existing applications Used PANDAS for ease data structures in data manipulation and analysis in criticial applications Technology Analyst Infosys Ltd Minneapolis MN January 2014 to April 2014 Wrote Requirement Analysis and prepared program specifications Worked with the business partners in defining requirements for system applications Created database Model APIs and Views utilizing Python in order to build an interactive web based application Used Python to place data into JSON files for testing applications Resolved complex problems in computer systems by developing and modifying the existing process Involved in defects tracking and prevented postprod issues Handled high volumes of data where a group of transactions is collected over a period of time using Batch data processing and Online processing Updated and manipulated content and files by using python scripts Project experience with agile development Worked in version control tools like Github and involved in peer reviews Senior Software Engineer Mindtree Ltd July 2012 to January 2013 Prepared Design documents review of the code and ensuring quality assurance of the code Designed and developed the UI of the website using HTML CSS and JavaScript Developed entire backend modules using Python Designed and developed data management system using MySQL Involved in coding and developingenhancing software projects depending on the requirements from the client and prepared various test cases and design reports that required technical assistance Developed and modified Python programs based on user requirements with an extensive Python infrastructure Wrote scripts in Python for automation of testing jobs Performed advanced procedures like text analytics and processing using the inmemory computing capabilities Application Developer IBM India Pvt Ltd Novato CA March 2010 to July 2012 Involved in Design Coding and testing of all phases of the requirements prepared requirement analysis for few of the projects that required technical assistance in developing the software Developed UNIX scripts which helped in automating the insurance data loads thus reducing the manual effort Collaborated with clients and built integrated solutions with other dynamic data Created project test plans and detailed test cases for all the regions UT SIT UAT and Production Designed developed and executed automated tests in all the user acceptance region and reviewed codes of various projects by peers Tracked quality metrics through development and postrelease via tracking tools like ServiceNow HP Quality center Assisted developers and project team during design and development phase to ensure zerodefect postproduction code Developed new applications end to end to support the daily maintenance activities Primary person in production releases and signingoff User Acceptance test cases and results Formatted reports based on criteria from client and triggered them via mail to clients if there was any error using Python scripts Ensured compliance with SDLC process from the requirement phase until production support Rewrite existing applications in Python module to deliver certain format of data and ease access of data Education Masters in Computer Science in Computer Science Illinois Institute of technology August 2015 to December 2017 Bachelor of Engineering in Electronics and Communication Engineering in Electronics and Communication Engineering Anna University August 2005 to May 2009 Skills CSS Less than 1 year HTML Less than 1 year Python 3 years SDLC 2 years UNIX 2 years Additional Information TECHNICAL SKILL SET Languages Python Hadoop R Unix C IMSDB DB2 CoreJava Web Technologies HTML CSS Cloud and Visualization AWS Docker Jenkins Databases MySQL DB2Sql Operating Systems Servers UNIXLinux Ubuntu Windows Utilities Git MS Visio MS Office Methodologies Waterfall SDLC Agile Other tools Weka Eclipse Netbeans IntelliJ IDEA 131",
    "entities": [
        "Technology Analyst Infosys Ltd",
        "Pandas",
        "HTML CSS",
        "Developed",
        "RandomForest Classifier",
        "Jaccard",
        "Itertools",
        "API",
        "MN",
        "ServiceNow HP Quality center Assisted",
        "Windows Utilities",
        "AWS NLTK",
        "Performed",
        "Software Engineer Mindtree Ltd",
        "Communication Engineering in Electronics and",
        "Application Developer IBM India Pvt Ltd",
        "Additional Information TECHNICAL SKILL SET Languages Python Hadoop R Unix C",
        "Developer Chicago IL Work Experience Banking and",
        "IDEA",
        "BreadthFirst",
        "HMDA",
        "MS Visio MS Office Methodologies Waterfall SDLC",
        "Developed NLP",
        "Minneapolis",
        "Collaborated",
        "Present Skills",
        "Skills CSS Less than 1 year",
        "CoreJava Web Technologies HTML CSS Cloud",
        "Github",
        "HMM",
        "Views",
        "NLTK Implemented LinkPrediction"
    ],
    "experience": "Experience Banking and Financial January 2018 to Present Skills used Python Numpy Pandas seaborn Kmeans RandomForestClassifier HTML CSS for presentations AWS Helped the project analyse the HMDA historical data for the given period giving many insights to the Change leaders to make strategic decisions to enter the market in a particular location gains profit or loss Used the metadata to know the datatype of the attributes and made quality suggestions on the incoming data from the users directly using a quality check analysis Handled multiple records by combining multiple files using Pandas dataframes in Python and used them for further analysis Predictive analysis Clustered the data using KMeans clustering and classified them accordingly using RandomForest Classifier and predicted the accuracy of my test cases and results Plotted the visualizations using Seaborn in Python to make the change leaders understand the importance of their competitors in that location and the offers along the gain profit percentage Python Developer Twitter API December 2017 to January 2018 Skills used Python Numpy Pandas collections Itertools matplotlib Networkx TwitterAPI Pickle Scipy ScikitLearn Girvan_Newman algorithms AWS NLTK packages Helped the project understand the importance of the network in a social hub Implemented a Community detection using BreadthFirst search and Girvan Newman Algorithms to find the communities each person belonged and to find the exisiting relationship between resources Developed NLP programs for twitter analysis using NLTK Implemented LinkPrediction using Jaccard similarity and Pearsons Coefficient to understand the link between two nodes if there is no exisiting relationship already Calculated the path score and accuracy for consistency Implemented Sentiment analysis classification Built a text classifier to determine whether a text is expressing positive or negative sentiment Removed outliers Built a prediction model and vectorized the testing and training data fitting Logistic regression on the training set Writing and injecting service classes to the components and posting and fetching JSON data Developed Python based API to track sales and perform sales analysis Used and enhanced HMM model and Girvan Newman method algorithms in order to find the communities in complex applications Used Networkx Algorithms in Python for the analysis of community structure based on the iterative elimination of edges with the highest number of shortest paths that go through them Used Scipy for scientific computing and used modules for optimization linear regression integration and special functions for existing applications Used PANDAS for ease data structures in data manipulation and analysis in criticial applications Technology Analyst Infosys Ltd Minneapolis MN January 2014 to April 2014 Wrote Requirement Analysis and prepared program specifications Worked with the business partners in defining requirements for system applications Created database Model APIs and Views utilizing Python in order to build an interactive web based application Used Python to place data into JSON files for testing applications Resolved complex problems in computer systems by developing and modifying the existing process Involved in defects tracking and prevented postprod issues Handled high volumes of data where a group of transactions is collected over a period of time using Batch data processing and Online processing Updated and manipulated content and files by using python scripts Project experience with agile development Worked in version control tools like Github and involved in peer reviews Senior Software Engineer Mindtree Ltd July 2012 to January 2013 Prepared Design documents review of the code and ensuring quality assurance of the code Designed and developed the UI of the website using HTML CSS and JavaScript Developed entire backend modules using Python Designed and developed data management system using MySQL Involved in coding and developingenhancing software projects depending on the requirements from the client and prepared various test cases and design reports that required technical assistance Developed and modified Python programs based on user requirements with an extensive Python infrastructure Wrote scripts in Python for automation of testing jobs Performed advanced procedures like text analytics and processing using the inmemory computing capabilities Application Developer IBM India Pvt Ltd Novato CA March 2010 to July 2012 Involved in Design Coding and testing of all phases of the requirements prepared requirement analysis for few of the projects that required technical assistance in developing the software Developed UNIX scripts which helped in automating the insurance data loads thus reducing the manual effort Collaborated with clients and built integrated solutions with other dynamic data Created project test plans and detailed test cases for all the regions UT SIT UAT and Production Designed developed and executed automated tests in all the user acceptance region and reviewed codes of various projects by peers Tracked quality metrics through development and postrelease via tracking tools like ServiceNow HP Quality center Assisted developers and project team during design and development phase to ensure zerodefect postproduction code Developed new applications end to end to support the daily maintenance activities Primary person in production releases and signingoff User Acceptance test cases and results Formatted reports based on criteria from client and triggered them via mail to clients if there was any error using Python scripts Ensured compliance with SDLC process from the requirement phase until production support Rewrite existing applications in Python module to deliver certain format of data and ease access of data Education Masters in Computer Science in Computer Science Illinois Institute of technology August 2015 to December 2017 Bachelor of Engineering in Electronics and Communication Engineering in Electronics and Communication Engineering Anna University August 2005 to May 2009 Skills CSS Less than 1 year HTML Less than 1 year Python 3 years SDLC 2 years UNIX 2 years Additional Information TECHNICAL SKILL SET Languages Python Hadoop R Unix C IMSDB DB2 CoreJava Web Technologies HTML CSS Cloud and Visualization AWS Docker Jenkins Databases MySQL DB2Sql Operating Systems Servers UNIXLinux Ubuntu Windows Utilities Git MS Visio MS Office Methodologies Waterfall SDLC Agile Other tools Weka Eclipse Netbeans IntelliJ IDEA 131",
    "extracted_keywords": [
        "Job",
        "Seeker",
        "Data",
        "Analyst",
        "Python",
        "Developer",
        "Chicago",
        "IL",
        "Work",
        "Experience",
        "Banking",
        "Financial",
        "January",
        "Present",
        "Skills",
        "Python",
        "Numpy",
        "Pandas",
        "Kmeans",
        "HTML",
        "CSS",
        "presentations",
        "AWS",
        "project",
        "analyse",
        "HMDA",
        "data",
        "period",
        "insights",
        "Change",
        "leaders",
        "decisions",
        "market",
        "location",
        "gains",
        "profit",
        "loss",
        "metadata",
        "datatype",
        "attributes",
        "quality",
        "suggestions",
        "data",
        "users",
        "quality",
        "check",
        "analysis",
        "records",
        "files",
        "Pandas",
        "dataframes",
        "Python",
        "analysis",
        "analysis",
        "data",
        "KMeans",
        "RandomForest",
        "Classifier",
        "accuracy",
        "test",
        "cases",
        "results",
        "visualizations",
        "Seaborn",
        "Python",
        "change",
        "leaders",
        "importance",
        "competitors",
        "location",
        "offers",
        "gain",
        "profit",
        "percentage",
        "Python",
        "Developer",
        "Twitter",
        "API",
        "December",
        "January",
        "Skills",
        "Python",
        "Numpy",
        "Pandas",
        "collections",
        "Itertools",
        "matplotlib",
        "Networkx",
        "TwitterAPI",
        "Pickle",
        "Scipy",
        "ScikitLearn",
        "Girvan_Newman",
        "AWS",
        "NLTK",
        "packages",
        "project",
        "importance",
        "network",
        "hub",
        "Community",
        "detection",
        "BreadthFirst",
        "search",
        "Girvan",
        "Newman",
        "Algorithms",
        "communities",
        "person",
        "relationship",
        "resources",
        "NLP",
        "programs",
        "twitter",
        "analysis",
        "NLTK",
        "LinkPrediction",
        "Jaccard",
        "similarity",
        "Pearsons",
        "Coefficient",
        "link",
        "nodes",
        "relationship",
        "path",
        "score",
        "accuracy",
        "consistency",
        "Sentiment",
        "analysis",
        "classification",
        "text",
        "classifier",
        "text",
        "sentiment",
        "Removed",
        "outliers",
        "prediction",
        "model",
        "testing",
        "training",
        "data",
        "regression",
        "training",
        "Writing",
        "service",
        "classes",
        "components",
        "JSON",
        "data",
        "Python",
        "API",
        "sales",
        "sales",
        "analysis",
        "HMM",
        "model",
        "Girvan",
        "Newman",
        "method",
        "order",
        "communities",
        "applications",
        "Networkx",
        "Algorithms",
        "Python",
        "analysis",
        "community",
        "structure",
        "elimination",
        "edges",
        "number",
        "paths",
        "Scipy",
        "computing",
        "modules",
        "optimization",
        "linear",
        "regression",
        "integration",
        "functions",
        "applications",
        "PANDAS",
        "ease",
        "data",
        "structures",
        "data",
        "manipulation",
        "analysis",
        "applications",
        "Technology",
        "Analyst",
        "Infosys",
        "Ltd",
        "Minneapolis",
        "MN",
        "January",
        "April",
        "Wrote",
        "Requirement",
        "Analysis",
        "program",
        "specifications",
        "business",
        "partners",
        "requirements",
        "system",
        "applications",
        "database",
        "Model",
        "APIs",
        "Views",
        "Python",
        "order",
        "web",
        "application",
        "Python",
        "data",
        "files",
        "testing",
        "applications",
        "problems",
        "computer",
        "systems",
        "process",
        "defects",
        "postprod",
        "issues",
        "volumes",
        "data",
        "group",
        "transactions",
        "period",
        "time",
        "Batch",
        "data",
        "processing",
        "processing",
        "content",
        "files",
        "scripts",
        "Project",
        "experience",
        "development",
        "version",
        "control",
        "tools",
        "Github",
        "peer",
        "reviews",
        "Senior",
        "Software",
        "Engineer",
        "Mindtree",
        "Ltd",
        "July",
        "January",
        "Prepared",
        "Design",
        "documents",
        "review",
        "code",
        "quality",
        "assurance",
        "code",
        "UI",
        "website",
        "HTML",
        "CSS",
        "JavaScript",
        "modules",
        "Python",
        "data",
        "management",
        "system",
        "MySQL",
        "software",
        "projects",
        "requirements",
        "client",
        "test",
        "cases",
        "design",
        "reports",
        "assistance",
        "Developed",
        "Python",
        "programs",
        "user",
        "requirements",
        "Python",
        "infrastructure",
        "Wrote",
        "scripts",
        "Python",
        "automation",
        "testing",
        "jobs",
        "procedures",
        "text",
        "analytics",
        "processing",
        "inmemory",
        "computing",
        "capabilities",
        "Application",
        "Developer",
        "IBM",
        "India",
        "Pvt",
        "Ltd",
        "Novato",
        "CA",
        "March",
        "July",
        "Design",
        "Coding",
        "testing",
        "phases",
        "requirements",
        "requirement",
        "analysis",
        "projects",
        "assistance",
        "software",
        "UNIX",
        "scripts",
        "insurance",
        "data",
        "loads",
        "effort",
        "clients",
        "solutions",
        "data",
        "project",
        "test",
        "plans",
        "test",
        "cases",
        "regions",
        "UT",
        "SIT",
        "UAT",
        "Production",
        "tests",
        "user",
        "acceptance",
        "region",
        "codes",
        "projects",
        "peers",
        "quality",
        "metrics",
        "development",
        "postrelease",
        "tools",
        "ServiceNow",
        "HP",
        "Quality",
        "center",
        "Assisted",
        "developers",
        "project",
        "team",
        "design",
        "development",
        "phase",
        "zerodefect",
        "postproduction",
        "code",
        "applications",
        "maintenance",
        "activities",
        "person",
        "production",
        "releases",
        "signingoff",
        "User",
        "Acceptance",
        "test",
        "cases",
        "reports",
        "criteria",
        "client",
        "mail",
        "clients",
        "error",
        "Python",
        "scripts",
        "compliance",
        "SDLC",
        "process",
        "requirement",
        "phase",
        "production",
        "support",
        "Rewrite",
        "applications",
        "Python",
        "module",
        "format",
        "data",
        "ease",
        "access",
        "data",
        "Education",
        "Masters",
        "Computer",
        "Science",
        "Computer",
        "Science",
        "Illinois",
        "Institute",
        "technology",
        "August",
        "December",
        "Bachelor",
        "Engineering",
        "Electronics",
        "Communication",
        "Engineering",
        "Electronics",
        "Communication",
        "Engineering",
        "Anna",
        "University",
        "August",
        "May",
        "Skills",
        "CSS",
        "year",
        "HTML",
        "year",
        "Python",
        "years",
        "SDLC",
        "years",
        "UNIX",
        "years",
        "Additional",
        "Information",
        "TECHNICAL",
        "SKILL",
        "SET",
        "Languages",
        "Python",
        "Hadoop",
        "R",
        "Unix",
        "C",
        "DB2",
        "CoreJava",
        "Web",
        "Technologies",
        "HTML",
        "CSS",
        "Cloud",
        "Visualization",
        "AWS",
        "Docker",
        "Jenkins",
        "Databases",
        "MySQL",
        "Operating",
        "Systems",
        "Servers",
        "UNIXLinux",
        "Ubuntu",
        "Windows",
        "Utilities",
        "Git",
        "MS",
        "Visio",
        "MS",
        "Office",
        "Methodologies",
        "Waterfall",
        "SDLC",
        "tools",
        "Weka",
        "Eclipse",
        "Netbeans",
        "IntelliJ",
        "IDEA"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:40:18.709046",
    "resume_data": "Job Seeker Data Analyst Python Developer Chicago IL Work Experience Banking and Financial January 2018 to Present Skills used Python Numpy Pandas seaborn Kmeans RandomForestClassifier HTML CSS for presentations AWS Helped the project analyse the HMDA historical data for the given period giving many insights to the Change leaders to make strategic decisions to enter the market in a particular location gains profit or loss Used the metadata to know the datatype of the attributes and made quality suggestions on the incoming data from the users directly using a quality check analysis Handled multiple records by combining multiple files using Pandas dataframes in Python and used them for further analysis Predictive analysis Clustered the data using KMeans clustering and classified them accordingly using RandomForest Classifier and predicted the accuracy of my test cases and results Plotted the visualizations using Seaborn in Python to make the change leaders understand the importance of their competitors in that location and the offers along the gain profit percentage Python Developer Twitter API December 2017 to January 2018 Skills used Python Numpy Pandas collections Itertools matplotlib Networkx TwitterAPI Pickle Scipy ScikitLearn Girvan_Newman algorithms AWS NLTK packages Helped the project understand the importance of the network in a social hub Implemented a Community detection using BreadthFirst search and Girvan Newman Algorithms to find the communities each person belonged and to find the exisiting relationship between resources Developed NLP programs for twitter analysis using NLTK Implemented LinkPrediction using Jaccard similarity and Pearsons Coefficient to understand the link between two nodes if there is no exisiting relationship already Calculated the path score and accuracy for consistency Implemented Sentiment analysis classification Built a text classifier to determine whether a text is expressing positive or negative sentiment Removed outliers Built a prediction model and vectorized the testing and training data fitting Logistic regression on the training set Writing and injecting service classes to the components and posting and fetching JSON data Developed Python based API to track sales and perform sales analysis Used and enhanced HMM model and Girvan Newman method algorithms in order to find the communities in complex applications Used Networkx Algorithms in Python for the analysis of community structure based on the iterative elimination of edges with the highest number of shortest paths that go through them Used Scipy for scientific computing and used modules for optimization linear regression integration and special functions for existing applications Used PANDAS for ease data structures in data manipulation and analysis in criticial applications Technology Analyst Infosys Ltd Minneapolis MN January 2014 to April 2014 Wrote Requirement Analysis and prepared program specifications Worked with the business partners in defining requirements for system applications Created database Model APIs and Views utilizing Python in order to build an interactive web based application Used Python to place data into JSON files for testing applications Resolved complex problems in computer systems by developing and modifying the existing process Involved in defects tracking and prevented postprod issues Handled high volumes of data where a group of transactions is collected over a period of time using Batch data processing and Online processing Updated and manipulated content and files by using python scripts Project experience with agile development Worked in version control tools like Github and involved in peer reviews Senior Software Engineer Mindtree Ltd July 2012 to January 2013 Prepared Design documents review of the code and ensuring quality assurance of the code Designed and developed the UI of the website using HTML CSS and JavaScript Developed entire backend modules using Python Designed and developed data management system using MySQL Involved in coding and developingenhancing software projects depending on the requirements from the client and prepared various test cases and design reports that required technical assistance Developed and modified Python programs based on user requirements with an extensive Python infrastructure Wrote scripts in Python for automation of testing jobs Performed advanced procedures like text analytics and processing using the inmemory computing capabilities Application Developer IBM India Pvt Ltd Novato CA March 2010 to July 2012 Involved in Design Coding and testing of all phases of the requirements prepared requirement analysis for few of the projects that required technical assistance in developing the software Developed UNIX scripts which helped in automating the insurance data loads thus reducing the manual effort Collaborated with clients and built integrated solutions with other dynamic data Created project test plans and detailed test cases for all the regions UT SIT UAT and Production Designed developed and executed automated tests in all the user acceptance region and reviewed codes of various projects by peers Tracked quality metrics through development and postrelease via tracking tools like ServiceNow HP Quality center Assisted developers and project team during design and development phase to ensure zerodefect postproduction code Developed new applications end to end to support the daily maintenance activities Primary person in production releases and signingoff User Acceptance test cases and results Formatted reports based on criteria from client and triggered them via mail to clients if there was any error using Python scripts Ensured compliance with SDLC process from the requirement phase until production support Rewrite existing applications in Python module to deliver certain format of data and ease access of data Education Masters in Computer Science in Computer Science Illinois Institute of technology August 2015 to December 2017 Bachelor of Engineering in Electronics and Communication Engineering in Electronics and Communication Engineering Anna University August 2005 to May 2009 Skills CSS Less than 1 year HTML Less than 1 year Python 3 years SDLC 2 years UNIX 2 years Additional Information TECHNICAL SKILL SET Languages Python Hadoop R Unix C IMSDB DB2 CoreJava Web Technologies HTML CSS Cloud and Visualization AWS Docker Jenkins Databases MySQL DB2Sql Operating Systems Servers UNIXLinux Ubuntu Windows Utilities Git MS Visio MS Office Methodologies Waterfall SDLC Agile Other tools Weka Eclipse Netbeans IntelliJ IDEA 131",
    "unique_id": "207eff24-685d-44e1-b9de-4db8c222fb0d"
}