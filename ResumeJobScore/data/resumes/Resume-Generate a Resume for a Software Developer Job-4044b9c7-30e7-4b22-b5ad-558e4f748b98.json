{
    "clean_data": "Programmer Analyst Programmer Analyst Programmer Analyst PepsiCo Inc Around 11 yrs of IT experience in Software Analysis Development and Implementation of Data Warehousing and Mainframe Applications for Insurance Finance and Retail verticals Proficient in Informatica Power Center 101918x7x 62 51 Informatica Data QualityIDQ 951 Informatica Power Mart 51 47 Having strong application development skills and mainframe and DW technical experience in Informatica COBOL DB2 CICS VSAM JCL Maestro CA7 Experience working in OnsiteOffshore model Extensive experience in Dimensional Data modelling using Star and Snow Flake schema Expertise in working with relational databases such as Oracle Teradata IBM UDB DB2 Extensive experience in developing Stored Procedures Functions Views and Triggers Complex SQL queries using Oracle PLSQL Experience in writing UNIX shell scripting and automation of the ETL processes using UNIX shell scripting Good in understanding Business processrequirements and translating them into technical requirements Performed all dimensions of development including Extraction Transformation and Loading ETL data from various sources into Data Warehouses and Data Marts using Informatica Power Center Designer Workflow Manager and Workflow Monitor Experience in integration of various data sources like SQL Server MS Access Oracle DB2 Cobol Files and Flat files Extensively used Power exchange to import source files from Mainframe systems Experience in PLSQL stored procedures along with tools like TOAD Rapid SQL Well versed in developing the complex SQL queries unions and multiple table joins and experience with Views Extensively used Teradata BTEQ FLOAD MLOADTPT Extensively used Bteq scripts to update the status and loading Landing zone tables of the load for Audit purposes Good understanding of Teradata parallel architecture and its physical implementation Sound knowledge in understanding of Star Schema Snowflake Schema using Data Modeling Tool Erwin Knowledge in Teradata and its utilities Extensively Used Scheduling tools like MaestroWLMCA7 Proficient in all phases of the System Development Lifecycle SDLC Analysis Design and Modeling System Implementation System Testing Acceptance and Maintenance Ability to work with team as well as independently Team player with Analytical ProblemSolving and Excellent Communication Skills Good Learn ability A fast learner with an open mind to learning new technologies High level of SelfMotivation and an ability to motivate others Work Experience Programmer Analyst PepsiCo Inc November 2017 to Present PepsiCo is a global food and beverage leader with a product portfolio including 22 brands that generate more than 1 billion each in annual retail sales Quaker Tropicana Gatorade FritoLay and PepsiCola make hundreds of enjoyable foods and beverages that are loved throughout the world The main objective of the project is to make selling data available for Walmart which can be used in analytical tools like tableau so that insights can be gathered to allow more products to be sold Responsibilities Gathering requirements and data mart designs from Business user and Analytical teams and translating the same into useable blueprint Determine structural requirements by analyzing the requirements Develop database design and architecture documentation for the teams Participate in modeling discussions and share the inputs Extensively used Teradata Sql Assistant 150 to analyze the data to build views and validation of data in Dev QA and PROD Created Views Joining different Sources based on Requirement in Teradata for Tableau to access and create dashboards Perform business functional analysis for project requirements Coordinate gather and evaluate the process requirements of PepsiCo to Implement the Software Solutions Conduct Design Review and other related Meetings for Master Data Management projects Translate business objectives design documents into clear Technical functional requirements To interact with the client on critical issues manage customer expectations and align customer business goal with Cognizant Responsible to develop and maintain code using tools Informatica power center UNIX Controlm schedulerTeradata Responsible for technical design development unitsystem testing of ETL mappings and scripts Conduct peer reviews with the team for design coding integration and system testing to ensure 100 accuracy Environment Informatica 101 SQL Teradata SQL Assistant 150 UNIX SSH ControlM Informatica Developer StateFarmInsurance Richardson TX July 2015 to September 2017 As part of new CDE Customer Driven Evolution strategy OM Opportunity Management has established several marketing initiatives One of which is to create NAR Need Analysis and Recommendation marketing database for campaign management application SAS to operates Worked in Multiple projects and Loaded consolidated data into EDW Responsibilities Designing developing informatica mappings and jobs Performing code migration from lower environment to higher Analyzing the data anomalies and defect fixes Created UNIX scripts to perform operations like gun zip remove and touch files and SecureFTP file to business user Worked with PreSession and PostSession UNIX scripts for automation of ETL jobs Also involved in migrationconversion of ETL processes from development to production Developed tested Stored Procedures Cursors Functions and Packages using PLSQL for Data ETL Extensively used Trac to log the Incidents and tracking Fix the Incident Experience working with customers and peers to develop solutions to complex business problems Extensively worked on loading and extracting data from OracleDB2 database Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Migration and supported the data migration from current system to IBM Unica for Campaign management Created Test Data and executed SQL queries in SQL loader to validate and test the data Unit Testing has been extensively done at development level Responsible for Unit Testing and Integration testing of mappings and workflows Extensively Used Controlm scheduling tool to schedule daily weekly and monthly jobs Environment Informatica 96101  TOAD IBM Control Center IBM UnicaUNIXIpswitchWS_FTP12FileZilla Informatica Developer Allegis Group Services Inc Hanover MD February 2014 to June 2015 Allegis Group is the largest privately held staffing company in the United States and serves a wide variety of industries Allegis Global Solutions represents the union of Allegis Group Services a subsidiary of Allegis Group Inc the largest privately held staffing and recruiting services company in the US and Australianbased Talent2 RMS the leading HR and recruitment provider in Asia Pacific The goal of this project is to cleanse the report data from the Vendor Management Systems like Field Glass Beeline IQN etc and store in a data repository and generate invoice in PDF files for each client and supplier separately Responsibilities Interacting with SFDC salesforcecom to retrieve the parameter required in Informatica Worked on SFDC objects Worked on generating invoices for different clients like Microsoft TD Bank Alere Rackspace Amgen Fanniemae and Experian based on their different business requirements Worked on data cleansing and standardization using the cleanse functions in IDQ 951 Worked with Informatica Data Quality IDQ 951 DeveloperAnalyst Tools to remove the noise of data using different transformations like Standardization Merge and Match Case Conversion Consolidation Parser Labeler Address Validator Created ReferenceMaster data for profiling using IDQ Analyst tools Used the Address Doctor Geocoding table to validate the address and performed exception handling reporting and monitoring the data Performed matchmerge and ran match rules to check the effectiveness of IDQ process on data Configured Address Doctor which can cleanse address Data and enhanced by making some modifications during installation Executed scheduled workflows using Informatica Cloud tool to load data from Source to Target Extensively used B2B data transformation studio to develop DT services to convert Excel to CSV and to PDF Generated Self bills for Microsoft Sweden Microsoft Norway and Microsoft Netherlands in PDF format using Macros and Informatica Extensively Used Labeler and Standardizer for Data cleansing and Data standardization and Data harmonization Understanding of source systems thoroughly by going through the Integration specification documents and onetoone interaction Used transformations like Unstructured Data transformation Aggregator Filter Router Sequence Generator lookup Expression update strategy and Union Transaction Control to meet business logic in the mappings Created workflows to run sessions sequentially one after the other and concurrent worklets to start all the sessions in the workflow at once Extracted data from Source files transformed and loaded into the target using Informatica Loaded the data into XML targets using XML target Definition Developed various Mappings with the collection of all Sources Targets and Transformations using Designer Used Debugger to monitor data movement identified and fixed the bugsissues Worked on Xcel file Source file convert Xcel file to CSV using VBA Macros Data Transformation Created target CSV flat files and converted to PDF using Macro Responsible for the implementation of ETL processes Develop and maintain technical documentation relating to ETL processes Work with BI technical lead to design ETL solutions and improvements Ensure timely completion of nightly data load process and provide analysis of load delays or failures Created UNIX shell scripts to run the Informatica workflows and controlling the ETL flow Participate in data modeling and data design with BI technical lead Create and support ETL development standards Work with manager BI technical lead and analysts to review and assess business requirements relating to data loads Perform Informatica administration and performance tuning of ETL processes Optimize processes programs and functions to improve data quality data security and data consistency Prepare test strategies test scripts and conduct system tests Assist coordinate and mentor ETL development staff Other responsibilities as assigned Environment Informatica 95196 Informatica Data Quality 951 Salesforce SQLTOAD FileZilla3602 IDQ Data Analyst Database Developer UNIX IpswitchWS_FTP12 Team Lead Informatica Developer StateFarmInsurance Bloomington IL September 2012 to March 2013 As part of new CDE Customer Driven Evolution strategy OM Opportunity Management has established several marketing initiatives One of which is to create NAR Need Analysis and Recommendation marketing database for campaign management application SAS to operates Worked in Multiple projects and Loaded consolidated data into EDW Responsibilities Designing developing informatica mappings and jobs Performing code migration from lower environment to higher Analyzing the data anomalies and defect fixes Performing supervisory activities for the team members Created UNIX scripts to perform operations like gun zip remove and touch files and SecureFTP file to business user Worked with PreSession and PostSession UNIX scripts for automation of ETL jobs Also involved in migrationconversion of ETL processes from development to production Extensively used Trac to log the Incidents and tracking Fix the Incident Experience working with customers and peers to develop solutions to complex business problems Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Created Test Data and executed SQL queries in IBM DB2 to validate and test the data Unit Testing has been extensively done at development level Responsible for Unit Testing and Integration testing of mappings and workflows Extensively Used CA7 scheduling Environment Informatica 86191 CA7SQL TOAD Embarcadero Rapid IBM Control Center UNIXSAP IpswitchWS_FTP12 Team Lead Informatica Developer WellPoint INC Richmond VA August 2011 to July 2012 AHR Fully Insured Project is to expand the delivery of flexible and consistent incentive offerings to Anthems customers This will be achieved through the rollout of a new incentive product offering to the FullyInsured market AHR as well as to continue to support the current GenC and Comprehensive Health Solutions CHS supported incentives Hallmark as a vendor is processing the incentives for WellPoint WLP It would send a Monthly file to WLP for gift card disbursement EDWard would process this feed and send out file to different billing systems WGS STAR ACES FACETS CHIPS VA Data for Fully Insured Members will start coming in the source file source file sent from Hallmark from Feb2012 onwards Responsibilities Schedule meetings with WellPoint business teams to gather WellPoint Data warehousing Business requirements for Maintenance requirements Schedule meetings with Technical reference architecture teamsDBAInformatica admin to finalize on the design aspects of the project Preparing design documents and Technical design documents for the extract transform and loading data portion of the Project Meetings with Offshore team to provide details of the design and project requirements Reviewing the test case documents test plans coding and deliverables from offshore team to ensure they meet the project requirements and are delivered on time Reviewing the ETL design documents prepared by offshore teams reviewing Informatica and Teradata components to load the data to Data warehouse for reporting purposes Extensively used Transformation to load the data into Landing zone and dat files Extensively used Teradata SQL Assistant Created scripts using Fast Load MultiLoad to load data into the Teradata data warehouse Used utilities of FLOAD MLOAD of Teradata and created batch jobs using BTEQ Extensively used IpswitchWS_FTP12 for file transfer Extensively Used Work Load Manager WLM scheduler to load the data to Landing zone table and to create dat files for different source systems Responsible for Unit Testing and Integration testing of mappings and workflows Bteq and Unix Scripts Write Shell script running workflows in UNIX environment Extensively used Bteq scripts to update the status and loading Landing zone tables of the load for Audit purposes Utilizing a host of Cognizants internal tools that include MCAT To validate the components between source and target environments It will generate a report in a spread sheet indicating if the migration is successful or done with errors QView for quality assurance and QSmart to automate quality assurance through powerful built in workflow mechanisms Environment Informatica 861901 WLM scheduler SQL TOAD XML IBM Rapid Sql UNIX Erwin 80 Teradata IpswitchWS_FTP12TeradataSqlAssistant Team Lead Informatica Developer BlueCross BlueShield Eagan MN September 2010 to July 2011 The Enterprise Data Warehouse EDW is much more than a typical data warehouse It comprises all the data and infrastructure necessary to support reporting analysis data extracts and data services for the enterprise It includes the IDW comprising of general data which is comprehensive and historical The EDW also includes optimized and dimensional data which is organized to meet specific business data requirements Responsibilities Worked on OnsiteOffshore Model Worked on Power Center Designer client tools like Source Analyzer Warehouse Designer Mapping Designer Mapplet Designer and Transformations Developer Responsible for testing and validating the Informatica mappings against the predefined ETL design standards Extensively used Power exchange to import source files from Mainframe systems Worked on flat file and mainframe sources Developed Slowly Changing Dimension Mappings for Type 1 SCD and Type 2 SCD Extensively used Power Exchange to convert mainframe source Extensively worked with History and Incremental Loading using Parameter Files Mapping Variables and Mapping Parameters Developed Informatica parameter files to filter the daily data from the source system Extensively used PLSQL stored procedures Extensively worked with the Debugger for handling the data errors in the mapping designer Responsible for determining the bottlenecks and fixing the bottlenecks with performance tuning Responsible for error handling using Session Logs Reject Files and Session Logs in the Workflow Monitor Worked with Shortcuts across Shared and Non Shared Folders Performance tuning on sources targets mappings and SQL queries in the transformations Worked on flat files as sources targets and lookups Extensively used SQL tool TOAD RapidSql to execute SQL queries Extensively used ClearQuest to log the Incidents and tracking Fix the Incident Experience working with customers and peers to develop solutions to complex business problems Involved in SQL Performance Tuning Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Created Test Data and executed SQL queries in IBM DB2 to validate and test the data Unit Testing has been extensively done at development level Responsible for Unit Testing and Integration testing of mappings and workflows Involved in writing UNIX shell scripts to automate ETL jobs Extensively Used CA7 scheduling Environment Informatica 861901 IMS CA7 Oracle 11g DB2 SQL TOAD IBM Rapid Sql SQL Server UNIX Erwin 80 Teradata ETLInformatica Developer Country Insurance and Financial Bloomington IL April 2010 to August 2010 Country Insurance and Financial Services is a corporate firm broadly engaged in providing Solutions for Financial and Insurance applications Worked as Informatica Developer in Sales Work Station Phase2 Project Automated Scrubbing Automatic Load vendor Leads Schedule vendor email and mail Activities Responsibilities Involved in meetings with Business System Analysts to understand the functionality Worked on Power Center Designer client tools like Source Analyzer Warehouse Designer Mapping Designer Mapplet Designer and Transformations Developer Responsible for testing and validating the Informatica mappings against the Predefined ETL design standards Responsible for mapping and transforming existing feeds into the new data structures and standards utilizing Router Lookups Connected UnconnectedExpressionAggregatorUpdatestrategystoredprocedure transformations Developed ETL mappings in Informatica Power Center Designer using various transformations like Source Qualifier Normalizer Expression Connected and Unconnected Lookup Update Strategy Java Transformation Joiner etc Developed SQLs to extract the data from Siebel as per requirements Developed Java Transformation to send email to call Java and Siebel web services Developed Java Transformation to create Unique ID instead of Sequence generator Developed complex mapping for Scrubbing the data based on contact method ieemailphoneaddress and used web service to get Request and Response from Siebel Developed ETL scripts using BTEQ MLOAD and UNIX Extensively used Web service to call Siebel and to Update the Siebel based on the Requirements Extensively used PLSQL and SQL Extensively used Informatica 861 to load data from source tables ie DB2oracle and then loaded the data into target table ie flat filesDB2oracle Involved in source code management using Version Control option in Informatica ETL experience using Informatica 861 Power Center Power Mart Designer Workflow Manager Workflow Monitor and Server Manager Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Created reusable transformations and Mapplet and used them to reduce the development time and complexity of mappings and better maintenance Created Test Data and executed SQL queries in SQL Squirrel to validate and test Siebel data Unit and Integration testing has been extensively done at development level Involved in SQL Performance Tuning Responsible for developing Reports using Cognos 10 in Report Studio Tuned performance of Informatica mappings using components using Parameter files Variables and Dynamic Cache Environment Informatica 851861Oracle DB2 ControlM Windows XP Sql Squirrel Siebel Cognos 10 XML Java Informatica Developer MassMutual Financial Group Springfield MA February 2008 to March 2010 The EB PRP COLIBOLI conversion project is one of the most complex modernization projects inflight at MassMutual today This initiative includes converting 60000 policies and all of the history the standing up of a new admin platform ALP the development of a new data hub EBIF and related downstream feeds Responsibilities Performed requirements analysis design coding and testing of mainframe programs including maintaining the existing programs ETL experience using Informatica 851861 Power Center Power Mart Designer Workflow Manager Workflow Monitor and Server Manager Created new JCLs and Modified existing JCLs Created new and modified existing programs using COBOL CICS DB2 and VSAM Worked on File Aid Endeavor Worked on Quality center 92 to Track the status Verified defects and Perform database functional integration and regression testing as needed to minimize defects Extensively used Power Exchange Created and executed SQL queries in Embarcadero Rapid SQL 742 to validate and test data Created mappings workflows and Shell Scripts to extract validate transform data according to the business rules Worked on Maestro scheduling UNIX Scripting Performed Unit Functional and System Testing Developed several Mappings and Mapplet using corresponding Sources Targets and Transformations Designed and developed UNIX shell scripts as part of the ETL process automate the process of loading pulling the data Responsible for testing and validating the Informatica mappings against the predefined ETL design standards ETL experience using Informatica 851861 Power Center Power Mart Designer Workflow Manager Workflow Monitor and Server Manager Involved in performance testing functional testing and integration testing Retrieve the latest version of programs from ENDEVOR Which was the change management tool Used Maestro for Informatica batch scheduling Environment COBOL VSAM DB2 JCL Maestro UNIX Shell scripting Embarcadero RapidSql Quality Center 92 CICS FileAid Endeavor Cognos 83 Informatica 851 Software Engineer Accenture IN November 2006 to January 2008 BCBSM Blue Cross Blue Shield of Michigan is a nonprofit corporation It provides health care Benefits to 48 million members through a variety of plans The objective of the MOS Michigan Operating System project is to unify BCBSM processing systems on a single NASCO platform for Benefit Administration Membership Billing Claims and Servicing The expectation is to achieve the following Increased speed and flexibility in delivery of BCBSM products and services to market Reduced Administrative costs improved provider satisfaction through common practices Enhancing operating functionality given current BCBSM system capabilities Responsibilities Gathering user Requirement Specification Involved in all phases of SDLC from requirement design development testing training and rollout to the field user and support for production environment Prepared the ETL Design Documents as per the Business Specifications Translated business requirements into Informatica mappingsworkflows Created reusable transformations and Mapplet Created High leveldetailed level design documents and also involved in creating ETL specifications Created mappings workflows and Shell Scripts to extract validate transform data according to the business rules Involved in writing the PLSQL Packages Stored Procedures Functions to accomplish the business rules and tuning the SQL queries using EXPLAIN Plan in Toad Designed and developed the sessions for the relevant mappings or Informatica jobs and organized as sequential concurrent Scheduled the main workflows as per the business rules using the Informatica scheduler using UNIX shell scriptinging for some of the existing data jobs Used Informatica to extract and transform the data from existing new and modified sources and finally loaded into the Staging area Data Mart Target databases and Data warehouse depending upon the requirements Informatica will be used for job scheduling and sessionjob level monitoring and Notification Created Unix script to automate the process Used Informatica debugger for Unit Testing the mappings Performed Unit Systems and Regression testing of the mappings Involved in writing the test cases and also assisted the users in performing UAT Environment Informatica Power Center 6 UNIX shell scripting Oracle 8i SQL PLSQL Toad Windows NT Software Engineer Microline Infosystems IN August 2005 to October 2006 The Objective of this Program is to create various data marts like the Individual Sales Mart which caters to specific requirements for the policyholders and the agents This system helps to analyze and grow their business The source data which includes Types of Policies Information about the policy holder Policy covered item details Premium payment details Involved in all phases of SDLC from requirement design development testing training and rollout to the field user and support for production environment Worked with Informatica Power Mart client tools like Source Analyzer Warehouse Designer and Mapping Designer Developed ETL mappings in Informatica Power Center Designer using various transformations like Source Qualifier Normalizer Expression Connected and Unconnected Lookup Update Strategy Sequence Generator etc Implemented Slowly Changing Dimensions using Power Center to insertupdate the dimensions Implemented delta loading for data loading from source to target Created Mapplet and used them in different Mappings for maintaining the standards Developed the Test Scripts and performed the Unit Tests on the ETL mappings Developed and scheduled Workflows using workflow designer in Workflow manager Involved in analyzing source systems and designing the processes for Extracting Transforming and Loading the data to Data marts Scheduled sessions for pulling the data from transactional databases in order to maintain the Daily and weekly based loads Created UNIX script for scheduling the informatica workflows Environment Informatica Power Center 6 UNIX shell scripting Oracle 8i SQL PLSQL Education Bachelors Degree in Information Technology in Information Technology JNTU 2004 Skills Db2 Etl Informatica Teradata Ms access",
    "entities": [
        "Informatica Developer in Sales Work Station Phase2",
        "Hallmark",
        "Informatica Worked",
        "Perform Informatica",
        "QSmart",
        "DB2 SQL TOAD IBM",
        "Informatica",
        "Informatica Power Center",
        "Expression",
        "Feb2012",
        "MN",
        "Power Exchange",
        "Request",
        "Informatica Data Quality IDQ",
        "Reduced Administrative",
        "Informatica Power Mart",
        "Meetings for Master Data Management",
        "BI",
        "UNIX",
        "Participate",
        "Norway",
        "Informatica Loaded",
        "WellPoint",
        "PostSession",
        "Allegis Group",
        "WGS",
        "Oracle Teradata IBM UDB",
        "Springfield",
        "Programmer Analyst",
        "IBM",
        "Landing",
        "Bteq",
        "Requirements",
        "QView",
        "Informatica 851861 Power Center Power Mart",
        "XML",
        "Macro Responsible",
        "EXPLAIN Plan in Toad Designed",
        "WLP",
        "MassMutual Financial Group",
        "Stored Procedures Functions Views",
        "BTEQ",
        "VBA Macros Data Transformation Created",
        "MA",
        "Shell",
        "Predefined",
        "MaestroWLMCA7 Proficient",
        "Present PepsiCo",
        "Responsibilities Worked on OnsiteOffshore Model Worked on Power Center Designer",
        "Target",
        "Labeler",
        "Country Insurance and Financial Services",
        "AHR Fully Insured Project",
        "ClearQuest",
        "Cognizants",
        "TOAD IBM Control Center IBM",
        "TOAD Rapid",
        "Developed",
        "Version Control",
        "PDF Generated Self",
        "SecureFTP",
        "Microsoft Netherlands",
        "Cognizant Responsible",
        "OM Opportunity Management",
        "BCBSM",
        "Responsibilities Schedule",
        "Microsoft TD Bank",
        "ReferenceMaster",
        "Analytical ProblemSolving and Excellent Communication Skills Good Learn",
        "Response",
        "Sequence",
        "PreSession",
        "Types of Policies Information",
        "EDW Responsibilities Designing",
        "Maestro",
        "Develop",
        "Translate",
        "Informatica Power Center Designer",
        "Informatica Cloud",
        "Unconnected Lookup Update Strategy",
        "GenC",
        "SDLC",
        "Unstructured Data",
        "Workflow Monitor",
        "Dimensional Data",
        "Created Test Data",
        "Performed Unit Systems",
        "Informatica Developer Allegis Group Services Inc",
        "Views",
        "BCBSM Blue Cross Blue Shield",
        "Information Technology in Information Technology",
        "PepsiCo to Implement the Software Solutions Conduct Design Review",
        "Informatica 95196",
        "SQL TOAD",
        "Power Exchange Created",
        "IDQ 951 Worked",
        "Standardization Merge",
        "Sweden",
        "Embarcadero Rapid",
        "Michigan",
        "CSV",
        "NASCO",
        "the MOS Michigan Operating System",
        "US",
        "Perform",
        "PDF",
        "Walmart",
        "ENDEVOR Which",
        "Created Mapplet",
        "Oracle PLSQL Experience",
        "Created",
        "Server",
        "MCAT",
        "PepsiCo Inc",
        "DW",
        "DT",
        "IDQ Analyst",
        "UAT Environment Informatica Power Center",
        "Workflows",
        "Responsible for Unit Testing and Integration",
        "Unique",
        "NAR Need Analysis and Recommendation",
        "SAS",
        "Created UNIX",
        "IDQ",
        "Mapplet Created",
        "WellPoint Data",
        "the Project Meetings with Offshore",
        "WLM",
        "AHR",
        "Mapplet",
        "CICS VSAM",
        "the Vendor Management Systems",
        "SQL",
        "FullyInsured",
        "MD",
        "Transformation",
        "Informatica 861 Power Center Power Mart",
        "Optimize",
        "Notification Created",
        "Informatica Data",
        "the United States",
        "Worked on Power Center Designer",
        "Union Transaction Control",
        "Workflow",
        "Informatica Power Center Designer Workflow",
        "Oracle 8i SQL",
        "SQL Server MS Access Oracle DB2 Cobol Files",
        "Mappings",
        "Allegis Group Inc",
        "CDE",
        "Allegis Group Services",
        "ETL",
        "Business System Analysts",
        "Update the Siebel",
        "Worked in Multiple",
        "PepsiCola",
        "MassMutual",
        "Standardizer for Data",
        "Microsoft",
        "PROD Created Views Joining",
        "Quaker Tropicana Gatorade FritoLay",
        "Sessions Created Test Data",
        "Extraction Transformation",
        "Transformations Developer Responsible",
        "Retrieve",
        "Software Analysis Development and Implementation of Data Warehousing",
        "WellPoint WLP",
        "EDW",
        "Data",
        "JCL Maestro",
        "DeveloperAnalyst Tools",
        "Responsibilities Interacting",
        "Team",
        "Tableau",
        "Data Mart Target",
        "Integration",
        "Teradata",
        "Responsibilities Performed",
        "Data Warehouses",
        "the Individual Sales Mart"
    ],
    "experience": "Experience working in OnsiteOffshore model Extensive experience in Dimensional Data modelling using Star and Snow Flake schema Expertise in working with relational databases such as Oracle Teradata IBM UDB DB2 Extensive experience in developing Stored Procedures Functions Views and Triggers Complex SQL queries using Oracle PLSQL Experience in writing UNIX shell scripting and automation of the ETL processes using UNIX shell scripting Good in understanding Business processrequirements and translating them into technical requirements Performed all dimensions of development including Extraction Transformation and Loading ETL data from various sources into Data Warehouses and Data Marts using Informatica Power Center Designer Workflow Manager and Workflow Monitor Experience in integration of various data sources like SQL Server MS Access Oracle DB2 Cobol Files and Flat files Extensively used Power exchange to import source files from Mainframe systems Experience in PLSQL stored procedures along with tools like TOAD Rapid SQL Well versed in developing the complex SQL queries unions and multiple table joins and experience with Views Extensively used Teradata BTEQ FLOAD MLOADTPT Extensively used Bteq scripts to update the status and loading Landing zone tables of the load for Audit purposes Good understanding of Teradata parallel architecture and its physical implementation Sound knowledge in understanding of Star Schema Snowflake Schema using Data Modeling Tool Erwin Knowledge in Teradata and its utilities Extensively Used Scheduling tools like MaestroWLMCA7 Proficient in all phases of the System Development Lifecycle SDLC Analysis Design and Modeling System Implementation System Testing Acceptance and Maintenance Ability to work with team as well as independently Team player with Analytical ProblemSolving and Excellent Communication Skills Good Learn ability A fast learner with an open mind to learning new technologies High level of SelfMotivation and an ability to motivate others Work Experience Programmer Analyst PepsiCo Inc November 2017 to Present PepsiCo is a global food and beverage leader with a product portfolio including 22 brands that generate more than 1 billion each in annual retail sales Quaker Tropicana Gatorade FritoLay and PepsiCola make hundreds of enjoyable foods and beverages that are loved throughout the world The main objective of the project is to make selling data available for Walmart which can be used in analytical tools like tableau so that insights can be gathered to allow more products to be sold Responsibilities Gathering requirements and data mart designs from Business user and Analytical teams and translating the same into useable blueprint Determine structural requirements by analyzing the requirements Develop database design and architecture documentation for the teams Participate in modeling discussions and share the inputs Extensively used Teradata Sql Assistant 150 to analyze the data to build views and validation of data in Dev QA and PROD Created Views Joining different Sources based on Requirement in Teradata for Tableau to access and create dashboards Perform business functional analysis for project requirements Coordinate gather and evaluate the process requirements of PepsiCo to Implement the Software Solutions Conduct Design Review and other related Meetings for Master Data Management projects Translate business objectives design documents into clear Technical functional requirements To interact with the client on critical issues manage customer expectations and align customer business goal with Cognizant Responsible to develop and maintain code using tools Informatica power center UNIX Controlm schedulerTeradata Responsible for technical design development unitsystem testing of ETL mappings and scripts Conduct peer reviews with the team for design coding integration and system testing to ensure 100 accuracy Environment Informatica 101 SQL Teradata SQL Assistant 150 UNIX SSH ControlM Informatica Developer StateFarmInsurance Richardson TX July 2015 to September 2017 As part of new CDE Customer Driven Evolution strategy OM Opportunity Management has established several marketing initiatives One of which is to create NAR Need Analysis and Recommendation marketing database for campaign management application SAS to operates Worked in Multiple projects and Loaded consolidated data into EDW Responsibilities Designing developing informatica mappings and jobs Performing code migration from lower environment to higher Analyzing the data anomalies and defect fixes Created UNIX scripts to perform operations like gun zip remove and touch files and SecureFTP file to business user Worked with PreSession and PostSession UNIX scripts for automation of ETL jobs Also involved in migrationconversion of ETL processes from development to production Developed tested Stored Procedures Cursors Functions and Packages using PLSQL for Data ETL Extensively used Trac to log the Incidents and tracking Fix the Incident Experience working with customers and peers to develop solutions to complex business problems Extensively worked on loading and extracting data from OracleDB2 database Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Migration and supported the data migration from current system to IBM Unica for Campaign management Created Test Data and executed SQL queries in SQL loader to validate and test the data Unit Testing has been extensively done at development level Responsible for Unit Testing and Integration testing of mappings and workflows Extensively Used Controlm scheduling tool to schedule daily weekly and monthly jobs Environment Informatica 96101   TOAD IBM Control Center IBM UnicaUNIXIpswitchWS_FTP12FileZilla Informatica Developer Allegis Group Services Inc Hanover MD February 2014 to June 2015 Allegis Group is the largest privately held staffing company in the United States and serves a wide variety of industries Allegis Global Solutions represents the union of Allegis Group Services a subsidiary of Allegis Group Inc the largest privately held staffing and recruiting services company in the US and Australianbased Talent2 RMS the leading HR and recruitment provider in Asia Pacific The goal of this project is to cleanse the report data from the Vendor Management Systems like Field Glass Beeline IQN etc and store in a data repository and generate invoice in PDF files for each client and supplier separately Responsibilities Interacting with SFDC salesforcecom to retrieve the parameter required in Informatica Worked on SFDC objects Worked on generating invoices for different clients like Microsoft TD Bank Alere Rackspace Amgen Fanniemae and Experian based on their different business requirements Worked on data cleansing and standardization using the cleanse functions in IDQ 951 Worked with Informatica Data Quality IDQ 951 DeveloperAnalyst Tools to remove the noise of data using different transformations like Standardization Merge and Match Case Conversion Consolidation Parser Labeler Address Validator Created ReferenceMaster data for profiling using IDQ Analyst tools Used the Address Doctor Geocoding table to validate the address and performed exception handling reporting and monitoring the data Performed matchmerge and ran match rules to check the effectiveness of IDQ process on data Configured Address Doctor which can cleanse address Data and enhanced by making some modifications during installation Executed scheduled workflows using Informatica Cloud tool to load data from Source to Target Extensively used B2B data transformation studio to develop DT services to convert Excel to CSV and to PDF Generated Self bills for Microsoft Sweden Microsoft Norway and Microsoft Netherlands in PDF format using Macros and Informatica Extensively Used Labeler and Standardizer for Data cleansing and Data standardization and Data harmonization Understanding of source systems thoroughly by going through the Integration specification documents and onetoone interaction Used transformations like Unstructured Data transformation Aggregator Filter Router Sequence Generator lookup Expression update strategy and Union Transaction Control to meet business logic in the mappings Created workflows to run sessions sequentially one after the other and concurrent worklets to start all the sessions in the workflow at once Extracted data from Source files transformed and loaded into the target using Informatica Loaded the data into XML targets using XML target Definition Developed various Mappings with the collection of all Sources Targets and Transformations using Designer Used Debugger to monitor data movement identified and fixed the bugsissues Worked on Xcel file Source file convert Xcel file to CSV using VBA Macros Data Transformation Created target CSV flat files and converted to PDF using Macro Responsible for the implementation of ETL processes Develop and maintain technical documentation relating to ETL processes Work with BI technical lead to design ETL solutions and improvements Ensure timely completion of nightly data load process and provide analysis of load delays or failures Created UNIX shell scripts to run the Informatica workflows and controlling the ETL flow Participate in data modeling and data design with BI technical lead Create and support ETL development standards Work with manager BI technical lead and analysts to review and assess business requirements relating to data loads Perform Informatica administration and performance tuning of ETL processes Optimize processes programs and functions to improve data quality data security and data consistency Prepare test strategies test scripts and conduct system tests Assist coordinate and mentor ETL development staff Other responsibilities as assigned Environment Informatica 95196 Informatica Data Quality 951 Salesforce SQLTOAD FileZilla3602 IDQ Data Analyst Database Developer UNIX IpswitchWS_FTP12 Team Lead Informatica Developer StateFarmInsurance Bloomington IL September 2012 to March 2013 As part of new CDE Customer Driven Evolution strategy OM Opportunity Management has established several marketing initiatives One of which is to create NAR Need Analysis and Recommendation marketing database for campaign management application SAS to operates Worked in Multiple projects and Loaded consolidated data into EDW Responsibilities Designing developing informatica mappings and jobs Performing code migration from lower environment to higher Analyzing the data anomalies and defect fixes Performing supervisory activities for the team members Created UNIX scripts to perform operations like gun zip remove and touch files and SecureFTP file to business user Worked with PreSession and PostSession UNIX scripts for automation of ETL jobs Also involved in migrationconversion of ETL processes from development to production Extensively used Trac to log the Incidents and tracking Fix the Incident Experience working with customers and peers to develop solutions to complex business problems Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Created Test Data and executed SQL queries in IBM DB2 to validate and test the data Unit Testing has been extensively done at development level Responsible for Unit Testing and Integration testing of mappings and workflows Extensively Used CA7 scheduling Environment Informatica 86191 CA7SQL TOAD Embarcadero Rapid IBM Control Center UNIXSAP IpswitchWS_FTP12 Team Lead Informatica Developer WellPoint INC Richmond VA August 2011 to July 2012 AHR Fully Insured Project is to expand the delivery of flexible and consistent incentive offerings to Anthems customers This will be achieved through the rollout of a new incentive product offering to the FullyInsured market AHR as well as to continue to support the current GenC and Comprehensive Health Solutions CHS supported incentives Hallmark as a vendor is processing the incentives for WellPoint WLP It would send a Monthly file to WLP for gift card disbursement EDWard would process this feed and send out file to different billing systems WGS STAR ACES FACETS CHIPS VA Data for Fully Insured Members will start coming in the source file source file sent from Hallmark from Feb2012 onwards Responsibilities Schedule meetings with WellPoint business teams to gather WellPoint Data warehousing Business requirements for Maintenance requirements Schedule meetings with Technical reference architecture teamsDBAInformatica admin to finalize on the design aspects of the project Preparing design documents and Technical design documents for the extract transform and loading data portion of the Project Meetings with Offshore team to provide details of the design and project requirements Reviewing the test case documents test plans coding and deliverables from offshore team to ensure they meet the project requirements and are delivered on time Reviewing the ETL design documents prepared by offshore teams reviewing Informatica and Teradata components to load the data to Data warehouse for reporting purposes Extensively used Transformation to load the data into Landing zone and dat files Extensively used Teradata SQL Assistant Created scripts using Fast Load MultiLoad to load data into the Teradata data warehouse Used utilities of FLOAD MLOAD of Teradata and created batch jobs using BTEQ Extensively used IpswitchWS_FTP12 for file transfer Extensively Used Work Load Manager WLM scheduler to load the data to Landing zone table and to create dat files for different source systems Responsible for Unit Testing and Integration testing of mappings and workflows Bteq and Unix Scripts Write Shell script running workflows in UNIX environment Extensively used Bteq scripts to update the status and loading Landing zone tables of the load for Audit purposes Utilizing a host of Cognizants internal tools that include MCAT To validate the components between source and target environments It will generate a report in a spread sheet indicating if the migration is successful or done with errors QView for quality assurance and QSmart to automate quality assurance through powerful built in workflow mechanisms Environment Informatica 861901 WLM scheduler SQL TOAD XML IBM Rapid Sql UNIX Erwin 80 Teradata IpswitchWS_FTP12TeradataSqlAssistant Team Lead Informatica Developer BlueCross BlueShield Eagan MN September 2010 to July 2011 The Enterprise Data Warehouse EDW is much more than a typical data warehouse It comprises all the data and infrastructure necessary to support reporting analysis data extracts and data services for the enterprise It includes the IDW comprising of general data which is comprehensive and historical The EDW also includes optimized and dimensional data which is organized to meet specific business data requirements Responsibilities Worked on OnsiteOffshore Model Worked on Power Center Designer client tools like Source Analyzer Warehouse Designer Mapping Designer Mapplet Designer and Transformations Developer Responsible for testing and validating the Informatica mappings against the predefined ETL design standards Extensively used Power exchange to import source files from Mainframe systems Worked on flat file and mainframe sources Developed Slowly Changing Dimension Mappings for Type 1 SCD and Type 2 SCD Extensively used Power Exchange to convert mainframe source Extensively worked with History and Incremental Loading using Parameter Files Mapping Variables and Mapping Parameters Developed Informatica parameter files to filter the daily data from the source system Extensively used PLSQL stored procedures Extensively worked with the Debugger for handling the data errors in the mapping designer Responsible for determining the bottlenecks and fixing the bottlenecks with performance tuning Responsible for error handling using Session Logs Reject Files and Session Logs in the Workflow Monitor Worked with Shortcuts across Shared and Non Shared Folders Performance tuning on sources targets mappings and SQL queries in the transformations Worked on flat files as sources targets and lookups Extensively used SQL tool TOAD RapidSql to execute SQL queries Extensively used ClearQuest to log the Incidents and tracking Fix the Incident Experience working with customers and peers to develop solutions to complex business problems Involved in SQL Performance Tuning Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Created Test Data and executed SQL queries in IBM DB2 to validate and test the data Unit Testing has been extensively done at development level Responsible for Unit Testing and Integration testing of mappings and workflows Involved in writing UNIX shell scripts to automate ETL jobs Extensively Used CA7 scheduling Environment Informatica 861901 IMS CA7 Oracle 11 g DB2 SQL TOAD IBM Rapid Sql SQL Server UNIX Erwin 80 Teradata ETLInformatica Developer Country Insurance and Financial Bloomington IL April 2010 to August 2010 Country Insurance and Financial Services is a corporate firm broadly engaged in providing Solutions for Financial and Insurance applications Worked as Informatica Developer in Sales Work Station Phase2 Project Automated Scrubbing Automatic Load vendor Leads Schedule vendor email and mail Activities Responsibilities Involved in meetings with Business System Analysts to understand the functionality Worked on Power Center Designer client tools like Source Analyzer Warehouse Designer Mapping Designer Mapplet Designer and Transformations Developer Responsible for testing and validating the Informatica mappings against the Predefined ETL design standards Responsible for mapping and transforming existing feeds into the new data structures and standards utilizing Router Lookups Connected UnconnectedExpressionAggregatorUpdatestrategystoredprocedure transformations Developed ETL mappings in Informatica Power Center Designer using various transformations like Source Qualifier Normalizer Expression Connected and Unconnected Lookup Update Strategy Java Transformation Joiner etc Developed SQLs to extract the data from Siebel as per requirements Developed Java Transformation to send email to call Java and Siebel web services Developed Java Transformation to create Unique ID instead of Sequence generator Developed complex mapping for Scrubbing the data based on contact method ieemailphoneaddress and used web service to get Request and Response from Siebel Developed ETL scripts using BTEQ MLOAD and UNIX Extensively used Web service to call Siebel and to Update the Siebel based on the Requirements Extensively used PLSQL and SQL Extensively used Informatica 861 to load data from source tables ie DB2oracle and then loaded the data into target table ie flat filesDB2oracle Involved in source code management using Version Control option in Informatica ETL experience using Informatica 861 Power Center Power Mart Designer Workflow Manager Workflow Monitor and Server Manager Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Created reusable transformations and Mapplet and used them to reduce the development time and complexity of mappings and better maintenance Created Test Data and executed SQL queries in SQL Squirrel to validate and test Siebel data Unit and Integration testing has been extensively done at development level Involved in SQL Performance Tuning Responsible for developing Reports using Cognos 10 in Report Studio Tuned performance of Informatica mappings using components using Parameter files Variables and Dynamic Cache Environment Informatica 851861Oracle DB2 ControlM Windows XP Sql Squirrel Siebel Cognos 10 XML Java Informatica Developer MassMutual Financial Group Springfield MA February 2008 to March 2010 The EB PRP COLIBOLI conversion project is one of the most complex modernization projects inflight at MassMutual today This initiative includes converting 60000 policies and all of the history the standing up of a new admin platform ALP the development of a new data hub EBIF and related downstream feeds Responsibilities Performed requirements analysis design coding and testing of mainframe programs including maintaining the existing programs ETL experience using Informatica 851861 Power Center Power Mart Designer Workflow Manager Workflow Monitor and Server Manager Created new JCLs and Modified existing JCLs Created new and modified existing programs using COBOL CICS DB2 and VSAM Worked on File Aid Endeavor Worked on Quality center 92 to Track the status Verified defects and Perform database functional integration and regression testing as needed to minimize defects Extensively used Power Exchange Created and executed SQL queries in Embarcadero Rapid SQL 742 to validate and test data Created mappings workflows and Shell Scripts to extract validate transform data according to the business rules Worked on Maestro scheduling UNIX Scripting Performed Unit Functional and System Testing Developed several Mappings and Mapplet using corresponding Sources Targets and Transformations Designed and developed UNIX shell scripts as part of the ETL process automate the process of loading pulling the data Responsible for testing and validating the Informatica mappings against the predefined ETL design standards ETL experience using Informatica 851861 Power Center Power Mart Designer Workflow Manager Workflow Monitor and Server Manager Involved in performance testing functional testing and integration testing Retrieve the latest version of programs from ENDEVOR Which was the change management tool Used Maestro for Informatica batch scheduling Environment COBOL VSAM DB2 JCL Maestro UNIX Shell scripting Embarcadero RapidSql Quality Center 92 CICS FileAid Endeavor Cognos 83 Informatica 851 Software Engineer Accenture IN November 2006 to January 2008 BCBSM Blue Cross Blue Shield of Michigan is a nonprofit corporation It provides health care Benefits to 48 million members through a variety of plans The objective of the MOS Michigan Operating System project is to unify BCBSM processing systems on a single NASCO platform for Benefit Administration Membership Billing Claims and Servicing The expectation is to achieve the following Increased speed and flexibility in delivery of BCBSM products and services to market Reduced Administrative costs improved provider satisfaction through common practices Enhancing operating functionality given current BCBSM system capabilities Responsibilities Gathering user Requirement Specification Involved in all phases of SDLC from requirement design development testing training and rollout to the field user and support for production environment Prepared the ETL Design Documents as per the Business Specifications Translated business requirements into Informatica mappingsworkflows Created reusable transformations and Mapplet Created High leveldetailed level design documents and also involved in creating ETL specifications Created mappings workflows and Shell Scripts to extract validate transform data according to the business rules Involved in writing the PLSQL Packages Stored Procedures Functions to accomplish the business rules and tuning the SQL queries using EXPLAIN Plan in Toad Designed and developed the sessions for the relevant mappings or Informatica jobs and organized as sequential concurrent Scheduled the main workflows as per the business rules using the Informatica scheduler using UNIX shell scriptinging for some of the existing data jobs Used Informatica to extract and transform the data from existing new and modified sources and finally loaded into the Staging area Data Mart Target databases and Data warehouse depending upon the requirements Informatica will be used for job scheduling and sessionjob level monitoring and Notification Created Unix script to automate the process Used Informatica debugger for Unit Testing the mappings Performed Unit Systems and Regression testing of the mappings Involved in writing the test cases and also assisted the users in performing UAT Environment Informatica Power Center 6 UNIX shell scripting Oracle 8i SQL PLSQL Toad Windows NT Software Engineer Microline Infosystems IN August 2005 to October 2006 The Objective of this Program is to create various data marts like the Individual Sales Mart which caters to specific requirements for the policyholders and the agents This system helps to analyze and grow their business The source data which includes Types of Policies Information about the policy holder Policy covered item details Premium payment details Involved in all phases of SDLC from requirement design development testing training and rollout to the field user and support for production environment Worked with Informatica Power Mart client tools like Source Analyzer Warehouse Designer and Mapping Designer Developed ETL mappings in Informatica Power Center Designer using various transformations like Source Qualifier Normalizer Expression Connected and Unconnected Lookup Update Strategy Sequence Generator etc Implemented Slowly Changing Dimensions using Power Center to insertupdate the dimensions Implemented delta loading for data loading from source to target Created Mapplet and used them in different Mappings for maintaining the standards Developed the Test Scripts and performed the Unit Tests on the ETL mappings Developed and scheduled Workflows using workflow designer in Workflow manager Involved in analyzing source systems and designing the processes for Extracting Transforming and Loading the data to Data marts Scheduled sessions for pulling the data from transactional databases in order to maintain the Daily and weekly based loads Created UNIX script for scheduling the informatica workflows Environment Informatica Power Center 6 UNIX shell scripting Oracle 8i SQL PLSQL Education Bachelors Degree in Information Technology in Information Technology JNTU 2004 Skills Db2 Etl Informatica Teradata Ms access",
    "extracted_keywords": [
        "Programmer",
        "Analyst",
        "Programmer",
        "Analyst",
        "Programmer",
        "Analyst",
        "PepsiCo",
        "Inc",
        "yrs",
        "IT",
        "experience",
        "Software",
        "Analysis",
        "Development",
        "Implementation",
        "Data",
        "Warehousing",
        "Mainframe",
        "Applications",
        "Insurance",
        "Finance",
        "Retail",
        "verticals",
        "Proficient",
        "Informatica",
        "Power",
        "Center",
        "101918x7x",
        "Informatica",
        "Data",
        "QualityIDQ",
        "Informatica",
        "Power",
        "Mart",
        "application",
        "development",
        "skills",
        "mainframe",
        "DW",
        "experience",
        "Informatica",
        "COBOL",
        "DB2",
        "CICS",
        "VSAM",
        "JCL",
        "Maestro",
        "CA7",
        "Experience",
        "OnsiteOffshore",
        "model",
        "experience",
        "Dimensional",
        "Data",
        "modelling",
        "Star",
        "Snow",
        "Flake",
        "schema",
        "Expertise",
        "databases",
        "Oracle",
        "Teradata",
        "IBM",
        "UDB",
        "DB2",
        "experience",
        "Stored",
        "Procedures",
        "Functions",
        "Views",
        "Triggers",
        "Complex",
        "SQL",
        "Oracle",
        "PLSQL",
        "Experience",
        "UNIX",
        "shell",
        "scripting",
        "automation",
        "ETL",
        "processes",
        "UNIX",
        "shell",
        "Good",
        "Business",
        "processrequirements",
        "requirements",
        "dimensions",
        "development",
        "Extraction",
        "Transformation",
        "Loading",
        "ETL",
        "data",
        "sources",
        "Data",
        "Warehouses",
        "Data",
        "Marts",
        "Informatica",
        "Power",
        "Center",
        "Designer",
        "Workflow",
        "Manager",
        "Workflow",
        "Monitor",
        "Experience",
        "integration",
        "data",
        "sources",
        "SQL",
        "Server",
        "MS",
        "Access",
        "Oracle",
        "DB2",
        "Cobol",
        "Files",
        "files",
        "Power",
        "exchange",
        "source",
        "files",
        "Mainframe",
        "systems",
        "Experience",
        "procedures",
        "tools",
        "TOAD",
        "Rapid",
        "SQL",
        "SQL",
        "unions",
        "table",
        "experience",
        "Views",
        "Teradata",
        "BTEQ",
        "MLOADTPT",
        "Bteq",
        "scripts",
        "status",
        "Landing",
        "zone",
        "tables",
        "load",
        "Audit",
        "purposes",
        "understanding",
        "architecture",
        "implementation",
        "knowledge",
        "understanding",
        "Star",
        "Schema",
        "Snowflake",
        "Schema",
        "Data",
        "Modeling",
        "Tool",
        "Erwin",
        "Knowledge",
        "Teradata",
        "utilities",
        "Scheduling",
        "tools",
        "MaestroWLMCA7",
        "Proficient",
        "phases",
        "System",
        "Development",
        "Lifecycle",
        "SDLC",
        "Analysis",
        "Design",
        "Modeling",
        "System",
        "Implementation",
        "System",
        "Testing",
        "Acceptance",
        "Maintenance",
        "Ability",
        "team",
        "Team",
        "player",
        "Analytical",
        "ProblemSolving",
        "Excellent",
        "Communication",
        "Skills",
        "Good",
        "Learn",
        "ability",
        "learner",
        "mind",
        "technologies",
        "level",
        "SelfMotivation",
        "ability",
        "others",
        "Work",
        "Experience",
        "Programmer",
        "Analyst",
        "PepsiCo",
        "Inc",
        "November",
        "Present",
        "PepsiCo",
        "food",
        "beverage",
        "leader",
        "product",
        "portfolio",
        "brands",
        "sales",
        "Quaker",
        "Tropicana",
        "Gatorade",
        "FritoLay",
        "PepsiCola",
        "hundreds",
        "foods",
        "beverages",
        "world",
        "objective",
        "project",
        "selling",
        "data",
        "Walmart",
        "tools",
        "tableau",
        "insights",
        "products",
        "Responsibilities",
        "requirements",
        "data",
        "mart",
        "designs",
        "Business",
        "user",
        "teams",
        "blueprint",
        "requirements",
        "requirements",
        "Develop",
        "database",
        "design",
        "architecture",
        "documentation",
        "teams",
        "discussions",
        "inputs",
        "Teradata",
        "Sql",
        "Assistant",
        "data",
        "views",
        "validation",
        "data",
        "Dev",
        "QA",
        "PROD",
        "Created",
        "Views",
        "Sources",
        "Requirement",
        "Teradata",
        "Tableau",
        "dashboards",
        "Perform",
        "business",
        "analysis",
        "project",
        "requirements",
        "Coordinate",
        "process",
        "requirements",
        "PepsiCo",
        "Software",
        "Solutions",
        "Conduct",
        "Design",
        "Review",
        "Meetings",
        "Master",
        "Data",
        "Management",
        "projects",
        "business",
        "objectives",
        "documents",
        "requirements",
        "client",
        "issues",
        "customer",
        "expectations",
        "customer",
        "business",
        "goal",
        "Cognizant",
        "Responsible",
        "code",
        "tools",
        "Informatica",
        "power",
        "center",
        "UNIX",
        "Controlm",
        "schedulerTeradata",
        "design",
        "development",
        "unitsystem",
        "testing",
        "ETL",
        "mappings",
        "Conduct",
        "peer",
        "reviews",
        "team",
        "design",
        "integration",
        "system",
        "testing",
        "accuracy",
        "Environment",
        "Informatica",
        "SQL",
        "Teradata",
        "SQL",
        "Assistant",
        "UNIX",
        "SSH",
        "ControlM",
        "Informatica",
        "Developer",
        "StateFarmInsurance",
        "Richardson",
        "TX",
        "July",
        "September",
        "part",
        "CDE",
        "Customer",
        "Driven",
        "Evolution",
        "strategy",
        "OM",
        "Opportunity",
        "Management",
        "marketing",
        "initiatives",
        "NAR",
        "Analysis",
        "Recommendation",
        "marketing",
        "database",
        "campaign",
        "management",
        "application",
        "SAS",
        "operates",
        "projects",
        "data",
        "EDW",
        "Responsibilities",
        "Designing",
        "informatica",
        "mappings",
        "jobs",
        "code",
        "migration",
        "environment",
        "data",
        "anomalies",
        "fixes",
        "UNIX",
        "scripts",
        "operations",
        "gun",
        "zip",
        "remove",
        "files",
        "file",
        "business",
        "user",
        "PreSession",
        "PostSession",
        "UNIX",
        "scripts",
        "automation",
        "ETL",
        "jobs",
        "migrationconversion",
        "ETL",
        "processes",
        "development",
        "production",
        "Stored",
        "Procedures",
        "Cursors",
        "Functions",
        "Packages",
        "PLSQL",
        "Data",
        "ETL",
        "Trac",
        "Incidents",
        "Fix",
        "Incident",
        "Experience",
        "customers",
        "peers",
        "solutions",
        "business",
        "problems",
        "loading",
        "data",
        "OracleDB2",
        "database",
        "manager",
        "Validating",
        "Testing",
        "Batches",
        "Sessions",
        "Migration",
        "data",
        "migration",
        "system",
        "IBM",
        "Unica",
        "Campaign",
        "management",
        "Created",
        "Test",
        "Data",
        "SQL",
        "queries",
        "SQL",
        "loader",
        "data",
        "Unit",
        "Testing",
        "development",
        "level",
        "Unit",
        "Testing",
        "Integration",
        "testing",
        "mappings",
        "workflows",
        "Controlm",
        "scheduling",
        "tool",
        "jobs",
        "Environment",
        "Informatica",
        "TOAD",
        "IBM",
        "Control",
        "Center",
        "IBM",
        "UnicaUNIXIpswitchWS_FTP12FileZilla",
        "Informatica",
        "Developer",
        "Allegis",
        "Group",
        "Services",
        "Inc",
        "Hanover",
        "MD",
        "February",
        "June",
        "Allegis",
        "Group",
        "staffing",
        "company",
        "United",
        "States",
        "variety",
        "industries",
        "Allegis",
        "Global",
        "Solutions",
        "union",
        "Allegis",
        "Group",
        "Services",
        "subsidiary",
        "Allegis",
        "Group",
        "Inc",
        "staffing",
        "recruiting",
        "services",
        "company",
        "US",
        "Australianbased",
        "Talent2",
        "RMS",
        "HR",
        "recruitment",
        "provider",
        "Asia",
        "Pacific",
        "goal",
        "project",
        "report",
        "data",
        "Vendor",
        "Management",
        "Systems",
        "Field",
        "Glass",
        "Beeline",
        "IQN",
        "etc",
        "data",
        "repository",
        "invoice",
        "PDF",
        "files",
        "client",
        "supplier",
        "Responsibilities",
        "SFDC",
        "salesforcecom",
        "parameter",
        "Informatica",
        "Worked",
        "SFDC",
        "invoices",
        "clients",
        "Microsoft",
        "TD",
        "Bank",
        "Alere",
        "Rackspace",
        "Amgen",
        "Fanniemae",
        "Experian",
        "business",
        "requirements",
        "data",
        "cleansing",
        "standardization",
        "cleanse",
        "functions",
        "IDQ",
        "Informatica",
        "Data",
        "Quality",
        "IDQ",
        "DeveloperAnalyst",
        "Tools",
        "noise",
        "data",
        "transformations",
        "Standardization",
        "Merge",
        "Match",
        "Case",
        "Conversion",
        "Consolidation",
        "Parser",
        "Labeler",
        "Address",
        "Validator",
        "Created",
        "ReferenceMaster",
        "data",
        "profiling",
        "IDQ",
        "Analyst",
        "tools",
        "Address",
        "Doctor",
        "Geocoding",
        "table",
        "address",
        "exception",
        "reporting",
        "data",
        "matchmerge",
        "match",
        "rules",
        "effectiveness",
        "IDQ",
        "process",
        "data",
        "Configured",
        "Address",
        "Doctor",
        "Data",
        "modifications",
        "installation",
        "workflows",
        "Informatica",
        "Cloud",
        "tool",
        "data",
        "Source",
        "Target",
        "B2B",
        "data",
        "transformation",
        "studio",
        "DT",
        "services",
        "Excel",
        "CSV",
        "PDF",
        "Self",
        "bills",
        "Microsoft",
        "Sweden",
        "Microsoft",
        "Norway",
        "Microsoft",
        "Netherlands",
        "PDF",
        "format",
        "Macros",
        "Informatica",
        "Labeler",
        "Standardizer",
        "Data",
        "cleansing",
        "Data",
        "standardization",
        "Data",
        "harmonization",
        "Understanding",
        "source",
        "systems",
        "Integration",
        "specification",
        "documents",
        "interaction",
        "transformations",
        "Unstructured",
        "Data",
        "transformation",
        "Aggregator",
        "Filter",
        "Router",
        "Sequence",
        "Generator",
        "Expression",
        "update",
        "strategy",
        "Union",
        "Transaction",
        "Control",
        "business",
        "logic",
        "mappings",
        "workflows",
        "sessions",
        "worklets",
        "sessions",
        "workflow",
        "data",
        "Source",
        "files",
        "target",
        "Informatica",
        "Loaded",
        "data",
        "XML",
        "targets",
        "XML",
        "target",
        "Definition",
        "Mappings",
        "collection",
        "Sources",
        "Targets",
        "Transformations",
        "Designer",
        "Debugger",
        "data",
        "movement",
        "bugsissues",
        "Xcel",
        "file",
        "Source",
        "file",
        "convert",
        "Xcel",
        "file",
        "CSV",
        "VBA",
        "Macros",
        "Data",
        "Transformation",
        "target",
        "CSV",
        "files",
        "PDF",
        "Macro",
        "Responsible",
        "implementation",
        "ETL",
        "Develop",
        "documentation",
        "ETL",
        "processes",
        "Work",
        "BI",
        "lead",
        "design",
        "ETL",
        "solutions",
        "improvements",
        "completion",
        "data",
        "load",
        "process",
        "analysis",
        "load",
        "delays",
        "failures",
        "UNIX",
        "shell",
        "scripts",
        "Informatica",
        "workflows",
        "ETL",
        "flow",
        "Participate",
        "data",
        "modeling",
        "data",
        "design",
        "BI",
        "lead",
        "ETL",
        "development",
        "standards",
        "manager",
        "BI",
        "lead",
        "analysts",
        "business",
        "requirements",
        "data",
        "loads",
        "Perform",
        "Informatica",
        "administration",
        "performance",
        "tuning",
        "ETL",
        "processes",
        "Optimize",
        "programs",
        "functions",
        "data",
        "quality",
        "data",
        "security",
        "data",
        "consistency",
        "Prepare",
        "test",
        "strategies",
        "scripts",
        "conduct",
        "system",
        "tests",
        "coordinate",
        "mentor",
        "ETL",
        "development",
        "staff",
        "responsibilities",
        "Environment",
        "Informatica",
        "Informatica",
        "Data",
        "Quality",
        "Salesforce",
        "SQLTOAD",
        "IDQ",
        "Data",
        "Analyst",
        "Database",
        "Developer",
        "UNIX",
        "IpswitchWS_FTP12",
        "Team",
        "Lead",
        "Informatica",
        "Developer",
        "StateFarmInsurance",
        "Bloomington",
        "IL",
        "September",
        "March",
        "part",
        "CDE",
        "Customer",
        "Driven",
        "Evolution",
        "strategy",
        "OM",
        "Opportunity",
        "Management",
        "marketing",
        "initiatives",
        "NAR",
        "Analysis",
        "Recommendation",
        "marketing",
        "database",
        "campaign",
        "management",
        "application",
        "SAS",
        "operates",
        "projects",
        "data",
        "EDW",
        "Responsibilities",
        "Designing",
        "informatica",
        "mappings",
        "jobs",
        "code",
        "migration",
        "environment",
        "data",
        "anomalies",
        "fixes",
        "activities",
        "team",
        "members",
        "UNIX",
        "scripts",
        "operations",
        "gun",
        "zip",
        "remove",
        "files",
        "file",
        "business",
        "user",
        "PreSession",
        "PostSession",
        "UNIX",
        "scripts",
        "automation",
        "ETL",
        "jobs",
        "migrationconversion",
        "ETL",
        "processes",
        "development",
        "production",
        "Trac",
        "Incidents",
        "Fix",
        "Incident",
        "Experience",
        "customers",
        "peers",
        "solutions",
        "business",
        "problems",
        "manager",
        "Validating",
        "Testing",
        "Batches",
        "Sessions",
        "Created",
        "Test",
        "Data",
        "SQL",
        "queries",
        "IBM",
        "DB2",
        "data",
        "Unit",
        "Testing",
        "development",
        "level",
        "Unit",
        "Testing",
        "Integration",
        "testing",
        "mappings",
        "workflows",
        "CA7",
        "scheduling",
        "Environment",
        "Informatica",
        "CA7SQL",
        "TOAD",
        "Embarcadero",
        "Rapid",
        "IBM",
        "Control",
        "Center",
        "UNIXSAP",
        "IpswitchWS_FTP12",
        "Team",
        "Lead",
        "Informatica",
        "Developer",
        "WellPoint",
        "INC",
        "Richmond",
        "VA",
        "August",
        "July",
        "AHR",
        "Project",
        "delivery",
        "incentive",
        "offerings",
        "Anthems",
        "customers",
        "rollout",
        "incentive",
        "product",
        "FullyInsured",
        "market",
        "AHR",
        "GenC",
        "Comprehensive",
        "Health",
        "Solutions",
        "CHS",
        "incentives",
        "Hallmark",
        "vendor",
        "incentives",
        "WellPoint",
        "WLP",
        "file",
        "WLP",
        "gift",
        "card",
        "disbursement",
        "EDWard",
        "feed",
        "file",
        "billing",
        "systems",
        "WGS",
        "STAR",
        "ACES",
        "FACETS",
        "CHIPS",
        "VA",
        "Data",
        "Members",
        "source",
        "file",
        "source",
        "file",
        "Hallmark",
        "Feb2012",
        "onwards",
        "Responsibilities",
        "Schedule",
        "meetings",
        "WellPoint",
        "business",
        "teams",
        "WellPoint",
        "Data",
        "warehousing",
        "Business",
        "requirements",
        "Maintenance",
        "requirements",
        "Schedule",
        "meetings",
        "reference",
        "architecture",
        "teamsDBAInformatica",
        "admin",
        "design",
        "aspects",
        "project",
        "design",
        "documents",
        "design",
        "documents",
        "extract",
        "transform",
        "loading",
        "data",
        "portion",
        "Project",
        "Meetings",
        "Offshore",
        "team",
        "details",
        "design",
        "project",
        "requirements",
        "test",
        "case",
        "documents",
        "plans",
        "deliverables",
        "team",
        "project",
        "requirements",
        "time",
        "ETL",
        "design",
        "documents",
        "teams",
        "Informatica",
        "Teradata",
        "components",
        "data",
        "Data",
        "warehouse",
        "purposes",
        "Transformation",
        "data",
        "Landing",
        "zone",
        "files",
        "Teradata",
        "SQL",
        "Assistant",
        "scripts",
        "Fast",
        "Load",
        "MultiLoad",
        "data",
        "Teradata",
        "data",
        "warehouse",
        "utilities",
        "FLOAD",
        "MLOAD",
        "Teradata",
        "batch",
        "jobs",
        "BTEQ",
        "IpswitchWS_FTP12",
        "file",
        "transfer",
        "Work",
        "Load",
        "Manager",
        "WLM",
        "scheduler",
        "data",
        "zone",
        "table",
        "files",
        "source",
        "systems",
        "Unit",
        "Testing",
        "Integration",
        "testing",
        "mappings",
        "workflows",
        "Bteq",
        "Unix",
        "Scripts",
        "Write",
        "Shell",
        "script",
        "workflows",
        "UNIX",
        "environment",
        "Bteq",
        "scripts",
        "status",
        "Landing",
        "zone",
        "tables",
        "load",
        "Audit",
        "purposes",
        "host",
        "Cognizants",
        "tools",
        "MCAT",
        "components",
        "source",
        "target",
        "environments",
        "report",
        "sheet",
        "migration",
        "errors",
        "QView",
        "quality",
        "assurance",
        "QSmart",
        "quality",
        "assurance",
        "mechanisms",
        "Environment",
        "Informatica",
        "WLM",
        "scheduler",
        "SQL",
        "TOAD",
        "XML",
        "IBM",
        "Rapid",
        "Sql",
        "UNIX",
        "Erwin",
        "Teradata",
        "Team",
        "Lead",
        "Informatica",
        "Developer",
        "BlueCross",
        "BlueShield",
        "Eagan",
        "MN",
        "September",
        "July",
        "Enterprise",
        "Data",
        "Warehouse",
        "EDW",
        "data",
        "warehouse",
        "data",
        "infrastructure",
        "analysis",
        "data",
        "extracts",
        "data",
        "services",
        "enterprise",
        "IDW",
        "comprising",
        "data",
        "EDW",
        "data",
        "business",
        "data",
        "requirements",
        "Responsibilities",
        "OnsiteOffshore",
        "Model",
        "Worked",
        "Power",
        "Center",
        "Designer",
        "client",
        "tools",
        "Source",
        "Analyzer",
        "Warehouse",
        "Designer",
        "Mapping",
        "Designer",
        "Mapplet",
        "Designer",
        "Transformations",
        "Developer",
        "Informatica",
        "mappings",
        "ETL",
        "design",
        "standards",
        "Power",
        "exchange",
        "source",
        "files",
        "Mainframe",
        "systems",
        "file",
        "mainframe",
        "sources",
        "Dimension",
        "Mappings",
        "Type",
        "SCD",
        "Type",
        "SCD",
        "Power",
        "Exchange",
        "mainframe",
        "source",
        "History",
        "Incremental",
        "Loading",
        "Parameter",
        "Files",
        "Mapping",
        "Variables",
        "Mapping",
        "Parameters",
        "Developed",
        "Informatica",
        "parameter",
        "files",
        "data",
        "source",
        "system",
        "procedures",
        "Debugger",
        "data",
        "errors",
        "mapping",
        "designer",
        "bottlenecks",
        "bottlenecks",
        "performance",
        "error",
        "handling",
        "Session",
        "Logs",
        "Reject",
        "Files",
        "Session",
        "Logs",
        "Workflow",
        "Monitor",
        "Shortcuts",
        "Shared",
        "Non",
        "Shared",
        "Folders",
        "Performance",
        "sources",
        "targets",
        "mappings",
        "SQL",
        "transformations",
        "files",
        "sources",
        "targets",
        "lookups",
        "SQL",
        "tool",
        "TOAD",
        "RapidSql",
        "SQL",
        "queries",
        "ClearQuest",
        "Incidents",
        "Fix",
        "Incident",
        "Experience",
        "customers",
        "peers",
        "solutions",
        "business",
        "problems",
        "SQL",
        "Performance",
        "manager",
        "Validating",
        "Testing",
        "Batches",
        "Sessions",
        "Created",
        "Test",
        "Data",
        "SQL",
        "queries",
        "IBM",
        "DB2",
        "data",
        "Unit",
        "Testing",
        "development",
        "level",
        "Unit",
        "Testing",
        "Integration",
        "testing",
        "mappings",
        "workflows",
        "UNIX",
        "shell",
        "scripts",
        "ETL",
        "jobs",
        "CA7",
        "scheduling",
        "Environment",
        "Informatica",
        "IMS",
        "CA7",
        "Oracle",
        "g",
        "DB2",
        "SQL",
        "TOAD",
        "IBM",
        "Rapid",
        "Sql",
        "SQL",
        "Server",
        "UNIX",
        "Erwin",
        "Teradata",
        "ETLInformatica",
        "Developer",
        "Country",
        "Insurance",
        "Financial",
        "Bloomington",
        "IL",
        "April",
        "August",
        "Country",
        "Insurance",
        "Financial",
        "Services",
        "firm",
        "Solutions",
        "Financial",
        "Insurance",
        "applications",
        "Informatica",
        "Developer",
        "Sales",
        "Work",
        "Station",
        "Phase2",
        "Project",
        "Automated",
        "Scrubbing",
        "Automatic",
        "Load",
        "vendor",
        "Schedule",
        "vendor",
        "email",
        "mail",
        "Activities",
        "Responsibilities",
        "meetings",
        "Business",
        "System",
        "Analysts",
        "functionality",
        "Power",
        "Center",
        "Designer",
        "client",
        "tools",
        "Source",
        "Analyzer",
        "Warehouse",
        "Designer",
        "Mapping",
        "Designer",
        "Mapplet",
        "Designer",
        "Transformations",
        "Developer",
        "Informatica",
        "mappings",
        "ETL",
        "design",
        "standards",
        "mapping",
        "feeds",
        "data",
        "structures",
        "standards",
        "Router",
        "Lookups",
        "Connected",
        "UnconnectedExpressionAggregatorUpdatestrategystoredprocedure",
        "transformations",
        "ETL",
        "mappings",
        "Informatica",
        "Power",
        "Center",
        "Designer",
        "transformations",
        "Source",
        "Qualifier",
        "Normalizer",
        "Expression",
        "Connected",
        "Unconnected",
        "Lookup",
        "Update",
        "Strategy",
        "Java",
        "Transformation",
        "Joiner",
        "SQLs",
        "data",
        "Siebel",
        "requirements",
        "Java",
        "Transformation",
        "email",
        "Java",
        "Siebel",
        "web",
        "services",
        "Java",
        "Transformation",
        "Unique",
        "ID",
        "Sequence",
        "generator",
        "mapping",
        "data",
        "contact",
        "method",
        "ieemailphoneaddress",
        "web",
        "service",
        "Request",
        "Response",
        "Siebel",
        "Developed",
        "ETL",
        "scripts",
        "BTEQ",
        "MLOAD",
        "UNIX",
        "Web",
        "service",
        "Siebel",
        "Siebel",
        "Requirements",
        "PLSQL",
        "SQL",
        "Informatica",
        "data",
        "source",
        "tables",
        "DB2oracle",
        "data",
        "target",
        "table",
        "filesDB2oracle",
        "source",
        "code",
        "management",
        "Version",
        "Control",
        "option",
        "Informatica",
        "ETL",
        "experience",
        "Informatica",
        "Power",
        "Center",
        "Power",
        "Mart",
        "Designer",
        "Workflow",
        "Manager",
        "Workflow",
        "Monitor",
        "Server",
        "Manager",
        "manager",
        "Validating",
        "Testing",
        "Batches",
        "Sessions",
        "transformations",
        "Mapplet",
        "development",
        "time",
        "complexity",
        "mappings",
        "maintenance",
        "Created",
        "Test",
        "Data",
        "SQL",
        "queries",
        "SQL",
        "Squirrel",
        "Siebel",
        "data",
        "Unit",
        "Integration",
        "testing",
        "development",
        "level",
        "SQL",
        "Performance",
        "Reports",
        "Cognos",
        "Report",
        "Studio",
        "performance",
        "Informatica",
        "mappings",
        "components",
        "Parameter",
        "files",
        "Variables",
        "Dynamic",
        "Cache",
        "Environment",
        "Informatica",
        "DB2",
        "Windows",
        "XP",
        "Sql",
        "Squirrel",
        "Siebel",
        "Cognos",
        "XML",
        "Java",
        "Informatica",
        "Developer",
        "MassMutual",
        "Financial",
        "Group",
        "Springfield",
        "MA",
        "February",
        "March",
        "EB",
        "PRP",
        "COLIBOLI",
        "conversion",
        "project",
        "modernization",
        "projects",
        "MassMutual",
        "today",
        "initiative",
        "policies",
        "history",
        "standing",
        "admin",
        "platform",
        "ALP",
        "development",
        "data",
        "hub",
        "EBIF",
        "Responsibilities",
        "requirements",
        "analysis",
        "design",
        "testing",
        "mainframe",
        "programs",
        "programs",
        "ETL",
        "experience",
        "Informatica",
        "Power",
        "Center",
        "Power",
        "Mart",
        "Designer",
        "Workflow",
        "Manager",
        "Workflow",
        "Monitor",
        "Server",
        "Manager",
        "JCLs",
        "Modified",
        "JCLs",
        "programs",
        "COBOL",
        "CICS",
        "DB2",
        "VSAM",
        "File",
        "Aid",
        "Endeavor",
        "Quality",
        "center",
        "status",
        "defects",
        "database",
        "integration",
        "regression",
        "testing",
        "defects",
        "Power",
        "Exchange",
        "Created",
        "SQL",
        "queries",
        "Embarcadero",
        "Rapid",
        "SQL",
        "test",
        "data",
        "mappings",
        "workflows",
        "Shell",
        "Scripts",
        "validate",
        "transform",
        "data",
        "business",
        "rules",
        "Maestro",
        "UNIX",
        "Scripting",
        "Performed",
        "Unit",
        "Functional",
        "System",
        "Testing",
        "Mappings",
        "Mapplet",
        "Sources",
        "Targets",
        "Transformations",
        "UNIX",
        "shell",
        "scripts",
        "part",
        "ETL",
        "process",
        "process",
        "loading",
        "data",
        "Informatica",
        "mappings",
        "ETL",
        "design",
        "standards",
        "ETL",
        "experience",
        "Informatica",
        "Power",
        "Center",
        "Power",
        "Mart",
        "Designer",
        "Workflow",
        "Manager",
        "Workflow",
        "Monitor",
        "Server",
        "Manager",
        "performance",
        "testing",
        "testing",
        "integration",
        "testing",
        "Retrieve",
        "version",
        "programs",
        "ENDEVOR",
        "change",
        "management",
        "tool",
        "Maestro",
        "Informatica",
        "batch",
        "scheduling",
        "Environment",
        "COBOL",
        "VSAM",
        "DB2",
        "JCL",
        "Maestro",
        "UNIX",
        "Shell",
        "Embarcadero",
        "RapidSql",
        "Quality",
        "Center",
        "CICS",
        "FileAid",
        "Endeavor",
        "Cognos",
        "Informatica",
        "Software",
        "Engineer",
        "Accenture",
        "November",
        "January",
        "BCBSM",
        "Blue",
        "Cross",
        "Blue",
        "Shield",
        "Michigan",
        "corporation",
        "health",
        "care",
        "Benefits",
        "members",
        "variety",
        "plans",
        "objective",
        "MOS",
        "Michigan",
        "Operating",
        "System",
        "project",
        "BCBSM",
        "processing",
        "systems",
        "NASCO",
        "platform",
        "Benefit",
        "Administration",
        "Membership",
        "Billing",
        "Claims",
        "Servicing",
        "expectation",
        "speed",
        "flexibility",
        "delivery",
        "BCBSM",
        "products",
        "services",
        "Reduced",
        "Administrative",
        "costs",
        "provider",
        "satisfaction",
        "practices",
        "functionality",
        "BCBSM",
        "system",
        "capabilities",
        "Responsibilities",
        "user",
        "Requirement",
        "Specification",
        "phases",
        "SDLC",
        "requirement",
        "design",
        "development",
        "testing",
        "training",
        "rollout",
        "field",
        "user",
        "support",
        "production",
        "environment",
        "ETL",
        "Design",
        "Documents",
        "Business",
        "Specifications",
        "Translated",
        "business",
        "requirements",
        "Informatica",
        "mappingsworkflows",
        "transformations",
        "Mapplet",
        "Created",
        "High",
        "level",
        "design",
        "documents",
        "ETL",
        "specifications",
        "mappings",
        "workflows",
        "Shell",
        "Scripts",
        "validate",
        "transform",
        "data",
        "business",
        "rules",
        "PLSQL",
        "Packages",
        "Stored",
        "Procedures",
        "Functions",
        "business",
        "rules",
        "SQL",
        "queries",
        "EXPLAIN",
        "Plan",
        "Toad",
        "sessions",
        "mappings",
        "Informatica",
        "jobs",
        "concurrent",
        "workflows",
        "business",
        "rules",
        "Informatica",
        "scheduler",
        "UNIX",
        "shell",
        "scriptinging",
        "data",
        "jobs",
        "Informatica",
        "data",
        "sources",
        "Staging",
        "area",
        "Data",
        "Mart",
        "Target",
        "databases",
        "Data",
        "warehouse",
        "requirements",
        "Informatica",
        "job",
        "scheduling",
        "sessionjob",
        "level",
        "monitoring",
        "Notification",
        "Created",
        "Unix",
        "script",
        "process",
        "Informatica",
        "debugger",
        "Unit",
        "mappings",
        "Performed",
        "Unit",
        "Systems",
        "Regression",
        "testing",
        "mappings",
        "test",
        "cases",
        "users",
        "UAT",
        "Environment",
        "Informatica",
        "Power",
        "Center",
        "UNIX",
        "shell",
        "scripting",
        "Oracle",
        "SQL",
        "PLSQL",
        "Toad",
        "Windows",
        "NT",
        "Software",
        "Engineer",
        "Microline",
        "Infosystems",
        "August",
        "October",
        "Objective",
        "Program",
        "data",
        "marts",
        "Individual",
        "Sales",
        "Mart",
        "requirements",
        "policyholders",
        "agents",
        "system",
        "business",
        "source",
        "data",
        "Types",
        "Policies",
        "Information",
        "policy",
        "holder",
        "Policy",
        "item",
        "details",
        "payment",
        "details",
        "phases",
        "SDLC",
        "requirement",
        "design",
        "development",
        "testing",
        "training",
        "rollout",
        "field",
        "user",
        "support",
        "production",
        "environment",
        "Informatica",
        "Power",
        "Mart",
        "client",
        "tools",
        "Source",
        "Analyzer",
        "Warehouse",
        "Designer",
        "Mapping",
        "Designer",
        "ETL",
        "mappings",
        "Informatica",
        "Power",
        "Center",
        "Designer",
        "transformations",
        "Source",
        "Qualifier",
        "Normalizer",
        "Expression",
        "Connected",
        "Unconnected",
        "Lookup",
        "Update",
        "Strategy",
        "Sequence",
        "Generator",
        "Dimensions",
        "Power",
        "Center",
        "dimensions",
        "delta",
        "loading",
        "data",
        "source",
        "Created",
        "Mapplet",
        "Mappings",
        "standards",
        "Test",
        "Scripts",
        "Unit",
        "Tests",
        "ETL",
        "mappings",
        "Workflows",
        "workflow",
        "designer",
        "manager",
        "source",
        "systems",
        "processes",
        "Transforming",
        "data",
        "Data",
        "sessions",
        "data",
        "databases",
        "order",
        "Daily",
        "loads",
        "UNIX",
        "script",
        "informatica",
        "workflows",
        "Environment",
        "Informatica",
        "Power",
        "Center",
        "UNIX",
        "shell",
        "scripting",
        "Oracle",
        "SQL",
        "PLSQL",
        "Education",
        "Bachelors",
        "Degree",
        "Information",
        "Technology",
        "Information",
        "Technology",
        "JNTU",
        "Skills",
        "Etl",
        "Informatica",
        "Teradata",
        "Ms",
        "access"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T22:03:32.590634",
    "resume_data": "Programmer Analyst Programmer Analyst Programmer Analyst PepsiCo Inc Around 11 yrs of IT experience in Software Analysis Development and Implementation of Data Warehousing and Mainframe Applications for Insurance Finance and Retail verticals Proficient in Informatica Power Center 101918x7x 62 51 Informatica Data QualityIDQ 951 Informatica Power Mart 51 47 Having strong application development skills and mainframe and DW technical experience in Informatica COBOL DB2 CICS VSAM JCL Maestro CA7 Experience working in OnsiteOffshore model Extensive experience in Dimensional Data modelling using Star and Snow Flake schema Expertise in working with relational databases such as Oracle Teradata IBM UDB DB2 Extensive experience in developing Stored Procedures Functions Views and Triggers Complex SQL queries using Oracle PLSQL Experience in writing UNIX shell scripting and automation of the ETL processes using UNIX shell scripting Good in understanding Business processrequirements and translating them into technical requirements Performed all dimensions of development including Extraction Transformation and Loading ETL data from various sources into Data Warehouses and Data Marts using Informatica Power Center Designer Workflow Manager and Workflow Monitor Experience in integration of various data sources like SQL Server MS Access Oracle DB2 Cobol Files and Flat files Extensively used Power exchange to import source files from Mainframe systems Experience in PLSQL stored procedures along with tools like TOAD Rapid SQL Well versed in developing the complex SQL queries unions and multiple table joins and experience with Views Extensively used Teradata BTEQ FLOAD MLOADTPT Extensively used Bteq scripts to update the status and loading Landing zone tables of the load for Audit purposes Good understanding of Teradata parallel architecture and its physical implementation Sound knowledge in understanding of Star Schema Snowflake Schema using Data Modeling Tool Erwin Knowledge in Teradata and its utilities Extensively Used Scheduling tools like MaestroWLMCA7 Proficient in all phases of the System Development Lifecycle SDLC Analysis Design and Modeling System Implementation System Testing Acceptance and Maintenance Ability to work with team as well as independently Team player with Analytical ProblemSolving and Excellent Communication Skills Good Learn ability A fast learner with an open mind to learning new technologies High level of SelfMotivation and an ability to motivate others Work Experience Programmer Analyst PepsiCo Inc November 2017 to Present PepsiCo is a global food and beverage leader with a product portfolio including 22 brands that generate more than 1 billion each in annual retail sales Quaker Tropicana Gatorade FritoLay and PepsiCola make hundreds of enjoyable foods and beverages that are loved throughout the world The main objective of the project is to make selling data available for Walmart which can be used in analytical tools like tableau so that insights can be gathered to allow more products to be sold Responsibilities Gathering requirements and data mart designs from Business user and Analytical teams and translating the same into useable blueprint Determine structural requirements by analyzing the requirements Develop database design and architecture documentation for the teams Participate in modeling discussions and share the inputs Extensively used Teradata Sql Assistant 150 to analyze the data to build views and validation of data in Dev QA and PROD Created Views Joining different Sources based on Requirement in Teradata for Tableau to access and create dashboards Perform business functional analysis for project requirements Coordinate gather and evaluate the process requirements of PepsiCo to Implement the Software Solutions Conduct Design Review and other related Meetings for Master Data Management projects Translate business objectives design documents into clear Technical functional requirements To interact with the client on critical issues manage customer expectations and align customer business goal with Cognizant Responsible to develop and maintain code using tools Informatica power center UNIX Controlm schedulerTeradata Responsible for technical design development unitsystem testing of ETL mappings and scripts Conduct peer reviews with the team for design coding integration and system testing to ensure 100 accuracy Environment Informatica 101 SQL Teradata SQL Assistant 150 UNIX SSH ControlM Informatica Developer StateFarmInsurance Richardson TX July 2015 to September 2017 As part of new CDE Customer Driven Evolution strategy OM Opportunity Management has established several marketing initiatives One of which is to create NAR Need Analysis and Recommendation marketing database for campaign management application SAS to operates Worked in Multiple projects and Loaded consolidated data into EDW Responsibilities Designing developing informatica mappings and jobs Performing code migration from lower environment to higher Analyzing the data anomalies and defect fixes Created UNIX scripts to perform operations like gun zip remove and touch files and SecureFTP file to business user Worked with PreSession and PostSession UNIX scripts for automation of ETL jobs Also involved in migrationconversion of ETL processes from development to production Developed tested Stored Procedures Cursors Functions and Packages using PLSQL for Data ETL Extensively used Trac to log the Incidents and tracking Fix the Incident Experience working with customers and peers to develop solutions to complex business problems Extensively worked on loading and extracting data from OracleDB2 database Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Migration and supported the data migration from current system to IBM Unica for Campaign management Created Test Data and executed SQL queries in SQL loader to validate and test the data Unit Testing has been extensively done at development level Responsible for Unit Testing and Integration testing of mappings and workflows Extensively Used Controlm scheduling tool to schedule daily weekly and monthly jobs Environment Informatica 96101 CA7SQLOracle TOAD IBM Control Center IBM UnicaUNIXIpswitchWS_FTP12FileZilla Informatica Developer Allegis Group Services Inc Hanover MD February 2014 to June 2015 Allegis Group is the largest privately held staffing company in the United States and serves a wide variety of industries Allegis Global Solutions represents the union of Allegis Group Services a subsidiary of Allegis Group Inc the largest privately held staffing and recruiting services company in the US and Australianbased Talent2 RMS the leading HR and recruitment provider in Asia Pacific The goal of this project is to cleanse the report data from the Vendor Management Systems like Field Glass Beeline IQN etc and store in a data repository and generate invoice in PDF files for each client and supplier separately Responsibilities Interacting with SFDC salesforcecom to retrieve the parameter required in Informatica Worked on SFDC objects Worked on generating invoices for different clients like Microsoft TD Bank Alere Rackspace Amgen Fanniemae and Experian based on their different business requirements Worked on data cleansing and standardization using the cleanse functions in IDQ 951 Worked with Informatica Data Quality IDQ 951 DeveloperAnalyst Tools to remove the noise of data using different transformations like Standardization Merge and Match Case Conversion Consolidation Parser Labeler Address Validator Created ReferenceMaster data for profiling using IDQ Analyst tools Used the Address Doctor Geocoding table to validate the address and performed exception handling reporting and monitoring the data Performed matchmerge and ran match rules to check the effectiveness of IDQ process on data Configured Address Doctor which can cleanse address Data and enhanced by making some modifications during installation Executed scheduled workflows using Informatica Cloud tool to load data from Source to Target Extensively used B2B data transformation studio to develop DT services to convert Excel to CSV and to PDF Generated Self bills for Microsoft Sweden Microsoft Norway and Microsoft Netherlands in PDF format using Macros and Informatica Extensively Used Labeler and Standardizer for Data cleansing and Data standardization and Data harmonization Understanding of source systems thoroughly by going through the Integration specification documents and onetoone interaction Used transformations like Unstructured Data transformation Aggregator Filter Router Sequence Generator lookup Expression update strategy and Union Transaction Control to meet business logic in the mappings Created workflows to run sessions sequentially one after the other and concurrent worklets to start all the sessions in the workflow at once Extracted data from Source files transformed and loaded into the target using Informatica Loaded the data into XML targets using XML target Definition Developed various Mappings with the collection of all Sources Targets and Transformations using Designer Used Debugger to monitor data movement identified and fixed the bugsissues Worked on Xcel file Source file convert Xcel file to CSV using VBA Macros Data Transformation Created target CSV flat files and converted to PDF using Macro Responsible for the implementation of ETL processes Develop and maintain technical documentation relating to ETL processes Work with BI technical lead to design ETL solutions and improvements Ensure timely completion of nightly data load process and provide analysis of load delays or failures Created UNIX shell scripts to run the Informatica workflows and controlling the ETL flow Participate in data modeling and data design with BI technical lead Create and support ETL development standards Work with manager BI technical lead and analysts to review and assess business requirements relating to data loads Perform Informatica administration and performance tuning of ETL processes Optimize processes programs and functions to improve data quality data security and data consistency Prepare test strategies test scripts and conduct system tests Assist coordinate and mentor ETL development staff Other responsibilities as assigned Environment Informatica 95196 Informatica Data Quality 951 Salesforce SQLTOAD FileZilla3602 IDQ Data Analyst Database Developer UNIX IpswitchWS_FTP12 Team Lead Informatica Developer StateFarmInsurance Bloomington IL September 2012 to March 2013 As part of new CDE Customer Driven Evolution strategy OM Opportunity Management has established several marketing initiatives One of which is to create NAR Need Analysis and Recommendation marketing database for campaign management application SAS to operates Worked in Multiple projects and Loaded consolidated data into EDW Responsibilities Designing developing informatica mappings and jobs Performing code migration from lower environment to higher Analyzing the data anomalies and defect fixes Performing supervisory activities for the team members Created UNIX scripts to perform operations like gun zip remove and touch files and SecureFTP file to business user Worked with PreSession and PostSession UNIX scripts for automation of ETL jobs Also involved in migrationconversion of ETL processes from development to production Extensively used Trac to log the Incidents and tracking Fix the Incident Experience working with customers and peers to develop solutions to complex business problems Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Created Test Data and executed SQL queries in IBM DB2 to validate and test the data Unit Testing has been extensively done at development level Responsible for Unit Testing and Integration testing of mappings and workflows Extensively Used CA7 scheduling Environment Informatica 86191 CA7SQL TOAD Embarcadero Rapid IBM Control Center UNIXSAP IpswitchWS_FTP12 Team Lead Informatica Developer WellPoint INC Richmond VA August 2011 to July 2012 AHR Fully Insured Project is to expand the delivery of flexible and consistent incentive offerings to Anthems customers This will be achieved through the rollout of a new incentive product offering to the FullyInsured market AHR as well as to continue to support the current GenC and Comprehensive Health Solutions CHS supported incentives Hallmark as a vendor is processing the incentives for WellPoint WLP It would send a Monthly file to WLP for gift card disbursement EDWard would process this feed and send out file to different billing systems WGS STAR ACES FACETS CHIPS VA Data for Fully Insured Members will start coming in the source file source file sent from Hallmark from Feb2012 onwards Responsibilities Schedule meetings with WellPoint business teams to gather WellPoint Data warehousing Business requirements for Maintenance requirements Schedule meetings with Technical reference architecture teamsDBAInformatica admin to finalize on the design aspects of the project Preparing design documents and Technical design documents for the extract transform and loading data portion of the Project Meetings with Offshore team to provide details of the design and project requirements Reviewing the test case documents test plans coding and deliverables from offshore team to ensure they meet the project requirements and are delivered on time Reviewing the ETL design documents prepared by offshore teams reviewing Informatica and Teradata components to load the data to Data warehouse for reporting purposes Extensively used Transformation to load the data into Landing zone and dat files Extensively used Teradata SQL Assistant Created scripts using Fast Load MultiLoad to load data into the Teradata data warehouse Used utilities of FLOAD MLOAD of Teradata and created batch jobs using BTEQ Extensively used IpswitchWS_FTP12 for file transfer Extensively Used Work Load Manager WLM scheduler to load the data to Landing zone table and to create dat files for different source systems Responsible for Unit Testing and Integration testing of mappings and workflows Bteq and Unix Scripts Write Shell script running workflows in UNIX environment Extensively used Bteq scripts to update the status and loading Landing zone tables of the load for Audit purposes Utilizing a host of Cognizants internal tools that include MCAT To validate the components between source and target environments It will generate a report in a spread sheet indicating if the migration is successful or done with errors QView for quality assurance and QSmart to automate quality assurance through powerful built in workflow mechanisms Environment Informatica 861901 WLM scheduler SQL TOAD XML IBM Rapid Sql UNIX Erwin 80 Teradata IpswitchWS_FTP12TeradataSqlAssistant Team Lead Informatica Developer BlueCross BlueShield Eagan MN September 2010 to July 2011 The Enterprise Data Warehouse EDW is much more than a typical data warehouse It comprises all the data and infrastructure necessary to support reporting analysis data extracts and data services for the enterprise It includes the IDW comprising of general data which is comprehensive and historical The EDW also includes optimized and dimensional data which is organized to meet specific business data requirements Responsibilities Worked on OnsiteOffshore Model Worked on Power Center Designer client tools like Source Analyzer Warehouse Designer Mapping Designer Mapplet Designer and Transformations Developer Responsible for testing and validating the Informatica mappings against the predefined ETL design standards Extensively used Power exchange to import source files from Mainframe systems Worked on flat file and mainframe sources Developed Slowly Changing Dimension Mappings for Type 1 SCD and Type 2 SCD Extensively used Power Exchange to convert mainframe source Extensively worked with History and Incremental Loading using Parameter Files Mapping Variables and Mapping Parameters Developed Informatica parameter files to filter the daily data from the source system Extensively used PLSQL stored procedures Extensively worked with the Debugger for handling the data errors in the mapping designer Responsible for determining the bottlenecks and fixing the bottlenecks with performance tuning Responsible for error handling using Session Logs Reject Files and Session Logs in the Workflow Monitor Worked with Shortcuts across Shared and Non Shared Folders Performance tuning on sources targets mappings and SQL queries in the transformations Worked on flat files as sources targets and lookups Extensively used SQL tool TOAD RapidSql to execute SQL queries Extensively used ClearQuest to log the Incidents and tracking Fix the Incident Experience working with customers and peers to develop solutions to complex business problems Involved in SQL Performance Tuning Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Created Test Data and executed SQL queries in IBM DB2 to validate and test the data Unit Testing has been extensively done at development level Responsible for Unit Testing and Integration testing of mappings and workflows Involved in writing UNIX shell scripts to automate ETL jobs Extensively Used CA7 scheduling Environment Informatica 861901 IMS CA7 Oracle 11g DB2 SQL TOAD IBM Rapid Sql SQL Server UNIX Erwin 80 Teradata ETLInformatica Developer Country Insurance and Financial Bloomington IL April 2010 to August 2010 Country Insurance and Financial Services is a corporate firm broadly engaged in providing Solutions for Financial and Insurance applications Worked as Informatica Developer in Sales Work Station Phase2 Project Automated Scrubbing Automatic Load vendor Leads Schedule vendor email and mail Activities Responsibilities Involved in meetings with Business System Analysts to understand the functionality Worked on Power Center Designer client tools like Source Analyzer Warehouse Designer Mapping Designer Mapplet Designer and Transformations Developer Responsible for testing and validating the Informatica mappings against the Predefined ETL design standards Responsible for mapping and transforming existing feeds into the new data structures and standards utilizing Router Lookups Connected UnconnectedExpressionAggregatorUpdatestrategystoredprocedure transformations Developed ETL mappings in Informatica Power Center Designer using various transformations like Source Qualifier Normalizer Expression Connected and Unconnected Lookup Update Strategy Java Transformation Joiner etc Developed SQLs to extract the data from Siebel as per requirements Developed Java Transformation to send email to call Java and Siebel web services Developed Java Transformation to create Unique ID instead of Sequence generator Developed complex mapping for Scrubbing the data based on contact method ieemailphoneaddress and used web service to get Request and Response from Siebel Developed ETL scripts using BTEQ MLOAD and UNIX Extensively used Web service to call Siebel and to Update the Siebel based on the Requirements Extensively used PLSQL and SQL Extensively used Informatica 861 to load data from source tables ie DB2oracle and then loaded the data into target table ie flat filesDB2oracle Involved in source code management using Version Control option in Informatica ETL experience using Informatica 861 Power Center Power Mart Designer Workflow Manager Workflow Monitor and Server Manager Used Workflow manager for Creating Validating Testing and running the sequential and concurrent Batches and Sessions Created reusable transformations and Mapplet and used them to reduce the development time and complexity of mappings and better maintenance Created Test Data and executed SQL queries in SQL Squirrel to validate and test Siebel data Unit and Integration testing has been extensively done at development level Involved in SQL Performance Tuning Responsible for developing Reports using Cognos 10 in Report Studio Tuned performance of Informatica mappings using components using Parameter files Variables and Dynamic Cache Environment Informatica 851861Oracle DB2 ControlM Windows XP Sql Squirrel Siebel Cognos 10 XML Java Informatica Developer MassMutual Financial Group Springfield MA February 2008 to March 2010 The EB PRP COLIBOLI conversion project is one of the most complex modernization projects inflight at MassMutual today This initiative includes converting 60000 policies and all of the history the standing up of a new admin platform ALP the development of a new data hub EBIF and related downstream feeds Responsibilities Performed requirements analysis design coding and testing of mainframe programs including maintaining the existing programs ETL experience using Informatica 851861 Power Center Power Mart Designer Workflow Manager Workflow Monitor and Server Manager Created new JCLs and Modified existing JCLs Created new and modified existing programs using COBOL CICS DB2 and VSAM Worked on File Aid Endeavor Worked on Quality center 92 to Track the status Verified defects and Perform database functional integration and regression testing as needed to minimize defects Extensively used Power Exchange Created and executed SQL queries in Embarcadero Rapid SQL 742 to validate and test data Created mappings workflows and Shell Scripts to extract validate transform data according to the business rules Worked on Maestro scheduling UNIX Scripting Performed Unit Functional and System Testing Developed several Mappings and Mapplet using corresponding Sources Targets and Transformations Designed and developed UNIX shell scripts as part of the ETL process automate the process of loading pulling the data Responsible for testing and validating the Informatica mappings against the predefined ETL design standards ETL experience using Informatica 851861 Power Center Power Mart Designer Workflow Manager Workflow Monitor and Server Manager Involved in performance testing functional testing and integration testing Retrieve the latest version of programs from ENDEVOR Which was the change management tool Used Maestro for Informatica batch scheduling Environment COBOL VSAM DB2 JCL Maestro UNIX Shell scripting Embarcadero RapidSql Quality Center 92 CICS FileAid Endeavor Cognos 83 Informatica 851 Software Engineer Accenture IN November 2006 to January 2008 BCBSM Blue Cross Blue Shield of Michigan is a nonprofit corporation It provides health care Benefits to 48 million members through a variety of plans The objective of the MOS Michigan Operating System project is to unify BCBSM processing systems on a single NASCO platform for Benefit Administration Membership Billing Claims and Servicing The expectation is to achieve the following Increased speed and flexibility in delivery of BCBSM products and services to market Reduced Administrative costs improved provider satisfaction through common practices Enhancing operating functionality given current BCBSM system capabilities Responsibilities Gathering user Requirement Specification Involved in all phases of SDLC from requirement design development testing training and rollout to the field user and support for production environment Prepared the ETL Design Documents as per the Business Specifications Translated business requirements into Informatica mappingsworkflows Created reusable transformations and Mapplet Created High leveldetailed level design documents and also involved in creating ETL specifications Created mappings workflows and Shell Scripts to extract validate transform data according to the business rules Involved in writing the PLSQL Packages Stored Procedures Functions to accomplish the business rules and tuning the SQL queries using EXPLAIN Plan in Toad Designed and developed the sessions for the relevant mappings or Informatica jobs and organized as sequential concurrent Scheduled the main workflows as per the business rules using the Informatica scheduler using UNIX shell scriptinging for some of the existing data jobs Used Informatica to extract and transform the data from existing new and modified sources and finally loaded into the Staging area Data Mart Target databases and Data warehouse depending upon the requirements Informatica will be used for job scheduling and sessionjob level monitoring and Notification Created Unix script to automate the process Used Informatica debugger for Unit Testing the mappings Performed Unit Systems and Regression testing of the mappings Involved in writing the test cases and also assisted the users in performing UAT Environment Informatica Power Center 6 UNIX shell scripting Oracle 8i SQL PLSQL Toad Windows NT Software Engineer Microline Infosystems IN August 2005 to October 2006 The Objective of this Program is to create various data marts like the Individual Sales Mart which caters to specific requirements for the policyholders and the agents This system helps to analyze and grow their business The source data which includes Types of Policies Information about the policy holder Policy covered item details Premium payment details Involved in all phases of SDLC from requirement design development testing training and rollout to the field user and support for production environment Worked with Informatica Power Mart client tools like Source Analyzer Warehouse Designer and Mapping Designer Developed ETL mappings in Informatica Power Center Designer using various transformations like Source Qualifier Normalizer Expression Connected and Unconnected Lookup Update Strategy Sequence Generator etc Implemented Slowly Changing Dimensions using Power Center to insertupdate the dimensions Implemented delta loading for data loading from source to target Created Mapplet and used them in different Mappings for maintaining the standards Developed the Test Scripts and performed the Unit Tests on the ETL mappings Developed and scheduled Workflows using workflow designer in Workflow manager Involved in analyzing source systems and designing the processes for Extracting Transforming and Loading the data to Data marts Scheduled sessions for pulling the data from transactional databases in order to maintain the Daily and weekly based loads Created UNIX script for scheduling the informatica workflows Environment Informatica Power Center 6 UNIX shell scripting Oracle 8i SQL PLSQL Education Bachelors Degree in Information Technology in Information Technology JNTU 2004 Skills Db2 Etl Informatica Teradata Ms access",
    "unique_id": "4044b9c7-30e7-4b22-b5ad-558e4f748b98"
}