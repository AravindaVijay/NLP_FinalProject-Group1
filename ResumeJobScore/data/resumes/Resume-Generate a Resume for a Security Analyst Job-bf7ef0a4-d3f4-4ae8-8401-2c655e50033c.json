{
    "clean_data": "Senior Data Scientist Senior Data Scientist Senior Data Scientist Wood Dale IL Work Experience Senior Data Scientist TCS Schaumburg IL May 2017 to July 2019 Analyze clean and interpret structured and unstructured data using Python prepare data visualization build machine learning models Designed and built complex statistical models to predict scientific outcomes using R analyzed and interpreted large datasets with thousands of features Develops and deploys custom tailored recommendation software using multiple filtering and machine learning techniques to identify opportunity Provides business case and ROI recommendations Used Spark API over Hortonworks Hadoop YARN to perform analytics on data in Hive Performed Big Data Analytics using Hadoop Ecosystem and Spark Ecosystem Involved in start to end process of Hadoop cluster setup which includes Configuring and Monitoring the Hadoop Cluster Involved in processing large volumes of data in Hadoop infrastructure Responsible for Installation and configuration of Hive Pig HBase and Sqoop on the Hadoop Cluster Configured various property files like Coresitexml Hdfssitexml Mapredsitexml based upon the job requirement Involved in loading data from UNIX file system to HDFS Involved in data management using SQL database Implemented Hadoop stack and different big data analytic tools migration from different databases to Hadoop Monitored multiple Hadoop clusters environments Monitored workload job performance and capacity planning Recommending hardware configuration for Hadoop cluster Installing Upgrading and Managing Hadoop Cluster on Hortonworks distribution Data Scientist State Farm Bloomington IL February 2016 to May 2017 Collaborate with business partners to understand their requirements and design solutions that are aligned with business objectives and in compliance with the organizations architectural standards Conduct proof of concepts on new technologies and work closely with senior architects to develop recommendations that align with State Farms IT strategy Perform extensive research and maintain current understanding of how technology can enhance and offer a range of solutions for business partners Performed Big Data Analytics using Hadoop Ecosystem and Spark Ecosystem Wrote Hive UDFs to query data and create dash boards Used JAVA to write MapReduce jobs to detect sensitive information in the test environment Used Sqoop to import and export data into Hadoop cluster fromto RDBMS which includes MySQL and Oracle databases Improved Data Scanning processing and created an automated system for handling large volume data scans Helped building an automated tool for the Detective Controls Team in the test environment Wrote a program in Spark to minimize false positives that eventually saved significant amount of man hours and money in detecting sensitive information Developed an application to automate the checkout process for enterprise claims system that resulted in cost avoidance of 50K per year to the team Migrated legacy application code that was written in Python Senior Software Developer Digital Staffing Chicago IL February 2015 to November 2015 Created user information solutions by developing implementing and maintaining Javabased components and interfaces Defined site objectives by analyzing user requirements envisioning system features and functionality Set expectations and features priorities throughout the development lifecycle determining design methodologies and tool sets Completed programming using languages and software products Designed and conducted tests to ensure smooth workflow Saved the company 500K by writing inhouse web reports used by 400 Hospitals including Mayo Clinic and Northwestern Hospital Designed REST Web Services using Java Developed the software application to download data from CRM systems and integrate into existing portals Completed business gathering design development and coding of the application Managed the full SDLC project lifecycle for the Agiloft CRM data API Implemented the persistence layer using HibernateORM worked on Spring Web Flow on Spring MVC for building flows in the web application Helped in a new centralized resource portal for documentation including business gathering and Java coded business rules Assisted with changing servers and helped to create the new Tomcat 7 server Configured and tested the server for speed performance and settings Mentored Juniorlevel Developers assisting them with troubleshooting and understanding companydepartmental standards Deployed applications into a custom environment for testing before placing into production Performed UAT QA stress tests and unit tests to ensure each application was working well Utilized Source Control SVN daily to track all codes used throughout organizational history Tracked projects and identified issues using Jira Created an XML file with government specifications converted hospital data files into XML files and uploaded onto the government website CMSgov Senior Python Software Engineer Data Scientist Acerugs Inc Bensenville IL January 2009 to February 2015 Provided high quality solutions to address business needs within diverse technology environments Served as the Senior Python Software Engineer on an eCommerce website to lead endtoend development testing and integration Developed enhancements to Python for functionality and operation Developed enhancements in Python to improve functionality and operation including a web shopping cart Streamlined the Intranet Inventory Control System and consistently worked on enhancements to the system to meet business requirements Automated the Intranet Inventory Control System to be utilized solely online Significantly reduced employee time requirement by streamlining intranet inventory system improved customer service delivery by allowing sales associates to interact more frequently with customers Designed and developed innovative features for locationbased inventory system to improve efficiency of order processing and reduce operational costs Created a wholesale portal with easy checkout enhanced features targeting wholesale needs and improving user experience Using R Python for the applications thru the algorithms of Natural Language Processing NLP Machine Learning and Deep Learning for the big dataset Created dashboards and reports using Tableau Build a Recommender System Worked on Azure Machine Learning Studio Education Master of Computer Science in Data Science in Computer Science University of Illinois Urbana Champaign Champaign IL Bachelor of Science in Computer Science in Computer Science Northeastern Illinois University Chicago IL Skills Cassandra Impala Mapreduce Hbase Kafka",
    "entities": [
        "Mayo Clinic",
        "Mentored Juniorlevel Developers",
        "Hadoop infrastructure Responsible for Installation",
        "Assisted",
        "API Implemented",
        "Performed Big Data Analytics",
        "the Detective Controls Team",
        "Sqoop",
        "Hortonworks Hadoop",
        "UNIX",
        "Created",
        "Agiloft",
        "Tomcat 7",
        "the Intranet Inventory Control System",
        "Hive Performed Big Data Analytics",
        "Tableau Build",
        "Deep Learning",
        "HibernateORM",
        "SVN",
        "Hive Pig HBase",
        "Hadoop Monitored multiple Hadoop",
        "Natural Language Processing NLP Machine Learning",
        "Completed",
        "Automated the Intranet Inventory Control System",
        "Northwestern Hospital Designed",
        "SQL",
        "Data Scientist",
        "Hadoop",
        "HDFS Involved",
        "XML",
        "MapReduce",
        "the Hadoop Cluster Configured",
        "Coresitexml Hdfssitexml Mapredsitexml",
        "Data Scientist State Farm",
        "Implemented Hadoop",
        "Python Software Engineer Data",
        "Schaumburg",
        "Spark"
    ],
    "experience": "Experience Senior Data Scientist TCS Schaumburg IL May 2017 to July 2019 Analyze clean and interpret structured and unstructured data using Python prepare data visualization build machine learning models Designed and built complex statistical models to predict scientific outcomes using R analyzed and interpreted large datasets with thousands of features Develops and deploys custom tailored recommendation software using multiple filtering and machine learning techniques to identify opportunity Provides business case and ROI recommendations Used Spark API over Hortonworks Hadoop YARN to perform analytics on data in Hive Performed Big Data Analytics using Hadoop Ecosystem and Spark Ecosystem Involved in start to end process of Hadoop cluster setup which includes Configuring and Monitoring the Hadoop Cluster Involved in processing large volumes of data in Hadoop infrastructure Responsible for Installation and configuration of Hive Pig HBase and Sqoop on the Hadoop Cluster Configured various property files like Coresitexml Hdfssitexml Mapredsitexml based upon the job requirement Involved in loading data from UNIX file system to HDFS Involved in data management using SQL database Implemented Hadoop stack and different big data analytic tools migration from different databases to Hadoop Monitored multiple Hadoop clusters environments Monitored workload job performance and capacity planning Recommending hardware configuration for Hadoop cluster Installing Upgrading and Managing Hadoop Cluster on Hortonworks distribution Data Scientist State Farm Bloomington IL February 2016 to May 2017 Collaborate with business partners to understand their requirements and design solutions that are aligned with business objectives and in compliance with the organizations architectural standards Conduct proof of concepts on new technologies and work closely with senior architects to develop recommendations that align with State Farms IT strategy Perform extensive research and maintain current understanding of how technology can enhance and offer a range of solutions for business partners Performed Big Data Analytics using Hadoop Ecosystem and Spark Ecosystem Wrote Hive UDFs to query data and create dash boards Used JAVA to write MapReduce jobs to detect sensitive information in the test environment Used Sqoop to import and export data into Hadoop cluster fromto RDBMS which includes MySQL and Oracle databases Improved Data Scanning processing and created an automated system for handling large volume data scans Helped building an automated tool for the Detective Controls Team in the test environment Wrote a program in Spark to minimize false positives that eventually saved significant amount of man hours and money in detecting sensitive information Developed an application to automate the checkout process for enterprise claims system that resulted in cost avoidance of 50 K per year to the team Migrated legacy application code that was written in Python Senior Software Developer Digital Staffing Chicago IL February 2015 to November 2015 Created user information solutions by developing implementing and maintaining Javabased components and interfaces Defined site objectives by analyzing user requirements envisioning system features and functionality Set expectations and features priorities throughout the development lifecycle determining design methodologies and tool sets Completed programming using languages and software products Designed and conducted tests to ensure smooth workflow Saved the company 500 K by writing inhouse web reports used by 400 Hospitals including Mayo Clinic and Northwestern Hospital Designed REST Web Services using Java Developed the software application to download data from CRM systems and integrate into existing portals Completed business gathering design development and coding of the application Managed the full SDLC project lifecycle for the Agiloft CRM data API Implemented the persistence layer using HibernateORM worked on Spring Web Flow on Spring MVC for building flows in the web application Helped in a new centralized resource portal for documentation including business gathering and Java coded business rules Assisted with changing servers and helped to create the new Tomcat 7 server Configured and tested the server for speed performance and settings Mentored Juniorlevel Developers assisting them with troubleshooting and understanding companydepartmental standards Deployed applications into a custom environment for testing before placing into production Performed UAT QA stress tests and unit tests to ensure each application was working well Utilized Source Control SVN daily to track all codes used throughout organizational history Tracked projects and identified issues using Jira Created an XML file with government specifications converted hospital data files into XML files and uploaded onto the government website CMSgov Senior Python Software Engineer Data Scientist Acerugs Inc Bensenville IL January 2009 to February 2015 Provided high quality solutions to address business needs within diverse technology environments Served as the Senior Python Software Engineer on an eCommerce website to lead endtoend development testing and integration Developed enhancements to Python for functionality and operation Developed enhancements in Python to improve functionality and operation including a web shopping cart Streamlined the Intranet Inventory Control System and consistently worked on enhancements to the system to meet business requirements Automated the Intranet Inventory Control System to be utilized solely online Significantly reduced employee time requirement by streamlining intranet inventory system improved customer service delivery by allowing sales associates to interact more frequently with customers Designed and developed innovative features for locationbased inventory system to improve efficiency of order processing and reduce operational costs Created a wholesale portal with easy checkout enhanced features targeting wholesale needs and improving user experience Using R Python for the applications thru the algorithms of Natural Language Processing NLP Machine Learning and Deep Learning for the big dataset Created dashboards and reports using Tableau Build a Recommender System Worked on Azure Machine Learning Studio Education Master of Computer Science in Data Science in Computer Science University of Illinois Urbana Champaign Champaign IL Bachelor of Science in Computer Science in Computer Science Northeastern Illinois University Chicago IL Skills Cassandra Impala Mapreduce Hbase Kafka",
    "extracted_keywords": [
        "Senior",
        "Data",
        "Scientist",
        "Senior",
        "Data",
        "Scientist",
        "Senior",
        "Data",
        "Scientist",
        "Wood",
        "Dale",
        "IL",
        "Work",
        "Experience",
        "Senior",
        "Data",
        "Scientist",
        "TCS",
        "Schaumburg",
        "IL",
        "May",
        "July",
        "Analyze",
        "data",
        "Python",
        "data",
        "visualization",
        "machine",
        "learning",
        "models",
        "models",
        "outcomes",
        "R",
        "datasets",
        "thousands",
        "features",
        "Develops",
        "custom",
        "recommendation",
        "software",
        "filtering",
        "machine",
        "techniques",
        "opportunity",
        "business",
        "case",
        "recommendations",
        "Spark",
        "API",
        "Hortonworks",
        "Hadoop",
        "YARN",
        "analytics",
        "data",
        "Hive",
        "Performed",
        "Big",
        "Data",
        "Analytics",
        "Hadoop",
        "Ecosystem",
        "Spark",
        "Ecosystem",
        "start",
        "end",
        "process",
        "Hadoop",
        "cluster",
        "setup",
        "Configuring",
        "Hadoop",
        "Cluster",
        "volumes",
        "data",
        "Hadoop",
        "infrastructure",
        "Installation",
        "configuration",
        "Hive",
        "Pig",
        "HBase",
        "Sqoop",
        "Hadoop",
        "Cluster",
        "property",
        "files",
        "Coresitexml",
        "Hdfssitexml",
        "Mapredsitexml",
        "job",
        "requirement",
        "loading",
        "data",
        "UNIX",
        "file",
        "system",
        "HDFS",
        "data",
        "management",
        "SQL",
        "database",
        "Hadoop",
        "stack",
        "data",
        "tools",
        "migration",
        "databases",
        "Hadoop",
        "Monitored",
        "Hadoop",
        "clusters",
        "workload",
        "job",
        "performance",
        "capacity",
        "hardware",
        "configuration",
        "Hadoop",
        "cluster",
        "Installing",
        "Upgrading",
        "Managing",
        "Hadoop",
        "Cluster",
        "Hortonworks",
        "distribution",
        "Data",
        "Scientist",
        "State",
        "Farm",
        "Bloomington",
        "IL",
        "February",
        "May",
        "business",
        "partners",
        "requirements",
        "design",
        "solutions",
        "business",
        "objectives",
        "compliance",
        "organizations",
        "standards",
        "Conduct",
        "proof",
        "concepts",
        "technologies",
        "work",
        "architects",
        "recommendations",
        "State",
        "Farms",
        "IT",
        "strategy",
        "research",
        "understanding",
        "technology",
        "range",
        "solutions",
        "business",
        "partners",
        "Performed",
        "Big",
        "Data",
        "Analytics",
        "Hadoop",
        "Ecosystem",
        "Spark",
        "Ecosystem",
        "Wrote",
        "Hive",
        "UDFs",
        "data",
        "dash",
        "boards",
        "MapReduce",
        "jobs",
        "information",
        "test",
        "environment",
        "Sqoop",
        "export",
        "data",
        "Hadoop",
        "cluster",
        "fromto",
        "RDBMS",
        "MySQL",
        "Oracle",
        "Data",
        "Scanning",
        "processing",
        "system",
        "volume",
        "data",
        "scans",
        "tool",
        "Detective",
        "Controls",
        "Team",
        "test",
        "environment",
        "program",
        "Spark",
        "positives",
        "amount",
        "man",
        "hours",
        "money",
        "information",
        "application",
        "checkout",
        "process",
        "enterprise",
        "claims",
        "system",
        "cost",
        "avoidance",
        "K",
        "year",
        "team",
        "legacy",
        "application",
        "code",
        "Python",
        "Senior",
        "Software",
        "Developer",
        "Digital",
        "Staffing",
        "Chicago",
        "IL",
        "February",
        "November",
        "user",
        "information",
        "solutions",
        "components",
        "interfaces",
        "site",
        "objectives",
        "user",
        "requirements",
        "system",
        "features",
        "Set",
        "expectations",
        "priorities",
        "development",
        "lifecycle",
        "design",
        "methodologies",
        "tool",
        "programming",
        "languages",
        "software",
        "products",
        "tests",
        "workflow",
        "company",
        "K",
        "inhouse",
        "web",
        "reports",
        "Hospitals",
        "Mayo",
        "Clinic",
        "Northwestern",
        "Hospital",
        "REST",
        "Web",
        "Services",
        "Java",
        "Developed",
        "software",
        "application",
        "data",
        "CRM",
        "systems",
        "portals",
        "business",
        "gathering",
        "design",
        "development",
        "coding",
        "application",
        "SDLC",
        "project",
        "lifecycle",
        "Agiloft",
        "CRM",
        "data",
        "API",
        "persistence",
        "layer",
        "HibernateORM",
        "Spring",
        "Web",
        "Flow",
        "Spring",
        "MVC",
        "flows",
        "web",
        "application",
        "resource",
        "portal",
        "documentation",
        "business",
        "gathering",
        "Java",
        "business",
        "rules",
        "servers",
        "Tomcat",
        "server",
        "server",
        "speed",
        "performance",
        "settings",
        "Mentored",
        "Juniorlevel",
        "Developers",
        "troubleshooting",
        "standards",
        "applications",
        "custom",
        "environment",
        "production",
        "UAT",
        "QA",
        "stress",
        "tests",
        "unit",
        "tests",
        "application",
        "Source",
        "Control",
        "SVN",
        "codes",
        "history",
        "projects",
        "issues",
        "Jira",
        "XML",
        "file",
        "government",
        "specifications",
        "hospital",
        "data",
        "files",
        "XML",
        "files",
        "government",
        "website",
        "CMSgov",
        "Senior",
        "Python",
        "Software",
        "Engineer",
        "Data",
        "Scientist",
        "Acerugs",
        "Inc",
        "Bensenville",
        "IL",
        "January",
        "February",
        "quality",
        "solutions",
        "business",
        "needs",
        "technology",
        "environments",
        "Senior",
        "Python",
        "Software",
        "Engineer",
        "eCommerce",
        "website",
        "development",
        "testing",
        "integration",
        "enhancements",
        "Python",
        "functionality",
        "operation",
        "enhancements",
        "Python",
        "functionality",
        "operation",
        "web",
        "shopping",
        "cart",
        "Intranet",
        "Inventory",
        "Control",
        "System",
        "enhancements",
        "system",
        "business",
        "requirements",
        "Intranet",
        "Inventory",
        "Control",
        "System",
        "employee",
        "time",
        "requirement",
        "intranet",
        "inventory",
        "system",
        "customer",
        "service",
        "delivery",
        "sales",
        "associates",
        "customers",
        "features",
        "inventory",
        "system",
        "efficiency",
        "order",
        "processing",
        "costs",
        "portal",
        "checkout",
        "features",
        "needs",
        "user",
        "experience",
        "R",
        "Python",
        "applications",
        "algorithms",
        "Natural",
        "Language",
        "Processing",
        "NLP",
        "Machine",
        "Learning",
        "Deep",
        "Learning",
        "dataset",
        "Created",
        "dashboards",
        "reports",
        "Tableau",
        "Build",
        "Recommender",
        "System",
        "Azure",
        "Machine",
        "Learning",
        "Studio",
        "Education",
        "Master",
        "Computer",
        "Science",
        "Data",
        "Science",
        "Computer",
        "Science",
        "University",
        "Illinois",
        "Urbana",
        "Champaign",
        "Champaign",
        "IL",
        "Bachelor",
        "Science",
        "Computer",
        "Science",
        "Computer",
        "Science",
        "Northeastern",
        "Illinois",
        "University",
        "Chicago",
        "IL",
        "Skills",
        "Cassandra",
        "Impala",
        "Mapreduce",
        "Hbase",
        "Kafka"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T21:36:16.637815",
    "resume_data": "Senior Data Scientist Senior Data Scientist Senior Data Scientist Wood Dale IL Work Experience Senior Data Scientist TCS Schaumburg IL May 2017 to July 2019 Analyze clean and interpret structured and unstructured data using Python prepare data visualization build machine learning models Designed and built complex statistical models to predict scientific outcomes using R analyzed and interpreted large datasets with thousands of features Develops and deploys custom tailored recommendation software using multiple filtering and machine learning techniques to identify opportunity Provides business case and ROI recommendations Used Spark API over Hortonworks Hadoop YARN to perform analytics on data in Hive Performed Big Data Analytics using Hadoop Ecosystem and Spark Ecosystem Involved in start to end process of Hadoop cluster setup which includes Configuring and Monitoring the Hadoop Cluster Involved in processing large volumes of data in Hadoop infrastructure Responsible for Installation and configuration of Hive Pig HBase and Sqoop on the Hadoop Cluster Configured various property files like Coresitexml Hdfssitexml Mapredsitexml based upon the job requirement Involved in loading data from UNIX file system to HDFS Involved in data management using SQL database Implemented Hadoop stack and different big data analytic tools migration from different databases to Hadoop Monitored multiple Hadoop clusters environments Monitored workload job performance and capacity planning Recommending hardware configuration for Hadoop cluster Installing Upgrading and Managing Hadoop Cluster on Hortonworks distribution Data Scientist State Farm Bloomington IL February 2016 to May 2017 Collaborate with business partners to understand their requirements and design solutions that are aligned with business objectives and in compliance with the organizations architectural standards Conduct proof of concepts on new technologies and work closely with senior architects to develop recommendations that align with State Farms IT strategy Perform extensive research and maintain current understanding of how technology can enhance and offer a range of solutions for business partners Performed Big Data Analytics using Hadoop Ecosystem and Spark Ecosystem Wrote Hive UDFs to query data and create dash boards Used JAVA to write MapReduce jobs to detect sensitive information in the test environment Used Sqoop to import and export data into Hadoop cluster fromto RDBMS which includes MySQL and Oracle databases Improved Data Scanning processing and created an automated system for handling large volume data scans Helped building an automated tool for the Detective Controls Team in the test environment Wrote a program in Spark to minimize false positives that eventually saved significant amount of man hours and money in detecting sensitive information Developed an application to automate the checkout process for enterprise claims system that resulted in cost avoidance of 50K per year to the team Migrated legacy application code that was written in Python Senior Software Developer Digital Staffing Chicago IL February 2015 to November 2015 Created user information solutions by developing implementing and maintaining Javabased components and interfaces Defined site objectives by analyzing user requirements envisioning system features and functionality Set expectations and features priorities throughout the development lifecycle determining design methodologies and tool sets Completed programming using languages and software products Designed and conducted tests to ensure smooth workflow Saved the company 500K by writing inhouse web reports used by 400 Hospitals including Mayo Clinic and Northwestern Hospital Designed REST Web Services using Java Developed the software application to download data from CRM systems and integrate into existing portals Completed business gathering design development and coding of the application Managed the full SDLC project lifecycle for the Agiloft CRM data API Implemented the persistence layer using HibernateORM worked on Spring Web Flow on Spring MVC for building flows in the web application Helped in a new centralized resource portal for documentation including business gathering and Java coded business rules Assisted with changing servers and helped to create the new Tomcat 7 server Configured and tested the server for speed performance and settings Mentored Juniorlevel Developers assisting them with troubleshooting and understanding companydepartmental standards Deployed applications into a custom environment for testing before placing into production Performed UAT QA stress tests and unit tests to ensure each application was working well Utilized Source Control SVN daily to track all codes used throughout organizational history Tracked projects and identified issues using Jira Created an XML file with government specifications converted hospital data files into XML files and uploaded onto the government website CMSgov Senior Python Software Engineer Data Scientist Acerugs Inc Bensenville IL January 2009 to February 2015 Provided high quality solutions to address business needs within diverse technology environments Served as the Senior Python Software Engineer on an eCommerce website to lead endtoend development testing and integration Developed enhancements to Python for functionality and operation Developed enhancements in Python to improve functionality and operation including a web shopping cart Streamlined the Intranet Inventory Control System and consistently worked on enhancements to the system to meet business requirements Automated the Intranet Inventory Control System to be utilized solely online Significantly reduced employee time requirement by streamlining intranet inventory system improved customer service delivery by allowing sales associates to interact more frequently with customers Designed and developed innovative features for locationbased inventory system to improve efficiency of order processing and reduce operational costs Created a wholesale portal with easy checkout enhanced features targeting wholesale needs and improving user experience Using R Python for the applications thru the algorithms of Natural Language Processing NLP Machine Learning and Deep Learning for the big dataset Created dashboards and reports using Tableau Build a Recommender System Worked on Azure Machine Learning Studio Education Master of Computer Science in Data Science in Computer Science University of Illinois Urbana Champaign Champaign IL Bachelor of Science in Computer Science in Computer Science Northeastern Illinois University Chicago IL Skills Cassandra Impala Mapreduce Hbase Kafka",
    "unique_id": "bf7ef0a4-d3f4-4ae8-8401-2c655e50033c"
}