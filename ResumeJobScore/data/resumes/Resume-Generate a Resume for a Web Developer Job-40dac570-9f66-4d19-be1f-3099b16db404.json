{
    "clean_data": "DATA SCIENTIST DATA SCIENTIST DATA SCIENTIST CERNER Kansas City KS Around 7 years of experience in IT field with 3 years as Data Scientist with strong technical and business experience and communication skills to drive highimpact business outcomes through datadriven innovations and decisions Expertise in Statistical analysis Predictive modeling Text mining Supervised learning Unsupervised Learning and Reinforcement learning Expert in developing NLP models for Topic extraction Sentiment Analysis Strong mathematical background in Linear algebra Probability Statistics Differentiation and Integration Having good experience in Amazon Web Services AWS Expertise in transforming business requirements into analytical models designing algorithms building models developing data mining and reporting solutions that scale across a massive volume of Structured and unstructured data Proficient in Data Mining Methods Factor Analysis ANOVA Hypothetical testing normal distribution and other advanced Statistical modeling both Linear and nonlinear LOGISTIC REGRESSION LINEAR REGRESSION NAVE BAYES DECISION TREES RANDOM FOREST NEURAL NETWORKS SVM CLUSTERING KNN Experience with Deep learning techniques such as Convolutional Neural Networks Recurrent Neural Networks by using Keras TensorFlow and OpenCV Worked on several python packages like NumPy Pandas Scikit Learn Matplotlib Beautiful Soup Pickle SciPy Python PyTables etc Proficient in implementing Dimensionality Reduction Techniques like Principal Component Analysis tStochastics Neighborhood Embedding tSNE and Linear Discriminant Analysis LDA Experience in implementing data analysis with various analytic tools such as Anaconda 40 Jupyter Notebook 4X RStudio RShiney Expertise in all aspects of Software Development Lifecycle SDLC from requirement analysis Design Development Coding Testing Implementation and Maintenance Hands on advanced SQL experience summarizing transforming segmenting joining datasets Experience in visualization tools like Tableau 9X 10X for creating dashboards Experience in using GIT Version Control System Authorized to work in the US for any employer Work Experience DATA SCIENTIST CERNER Kansas City MO January 2018 to Present RESPONSIBILITIES Participated in all phases of Machine Learning and Data Mining data collection data cleaning developing models validation visualization Used Pandas NumPy seaborn scipy matplotlib scikitlearn nltk in python for developing various machine learning algorithms Implemented Bagging and Boosting to enhance the model performance Leveraged disparate data sources that provide deep customer insight including online transactional data web data payment orders history and marketing campaigns exposure data Implemented the endtoend platform for performing user behavior analytics using unsupervised machine learning Implemented Classification using supervised algorithms like Logistic Regression Decision trees KNN Naive Bayes Data transformation from various resources data organization features extraction from raw and stored Designed and implemented system architecture for AmazonEC2 based cloud hosted solution for the client Identified outliers and inconsistencies in data by conducting exploratory data analysis EDA using python NumPy and Seaborn to see the insights of data and validate each feature Prepare scripts to ensure proper data access manipulation and reporting functions with R programming Involved in converting HIVESQL queries into Spark transformations using Spark RDDs and Python Developed Adhoc Queries for moving data from HDFS to Hive and analyzing the data using HIVE QL Validated models using crossvalidation and loss function to measure model performance Created Confusion Matrix and ROC Expert in performing Text Mining and Text classification in NLP by using TfidfVectorizer Developed NLP models for Topic Extraction Sentiment Analysis Addressed overfitting by implementing of the algorithm regularization methods like L2 and L1 Performed price sensitivity and variation analysis across different marketing channels and conducted exploratory data analysis on variables such as lifetime value and profit score Built data pipelines implemented code modularization involving package creation and codeveloped REST APIs using Flask for production deployment Performed data discovery and build a stream that automatically retrieves data from multitude of sources SQL databases external data such as social network data user reviews to generate KPIs using Tableau ENVIRONMENT Anaconda Azure Python R Studio R Shiny Jupyter Notebook VS code SpyderAWS Oracle SSMS Unix Tableau HDFS SPARK IMPALA HIVE Hue DATA SCIENTISTDATA ANALYTICS SPECALIST EQUIFAX ST LOUIS January 2016 to December 2017 RESPONSIBILITIES Analyzed the data using various machine learning algorithms whether to extendnot credit limit to an existing applicant and to approvenot new credit line to a new applicant will likely result in profit or loss based on various circumstances like credit history utilization rate income age location hard enquiries number of deliquesces Extracted terabytes of structured and unstructured data by using SQL queries and performed data mining tasks including handling missing data data wrangling feature scaling outlier analysis in python by importing pandas Conducted data investigation discovery mapping tools to scan every single data record Worked on predictive and whatif analysis using Python from HDFS and successfully loaded files to HDFS from Teradata and loaded from HDFS to HIVE Performed data analysis data validation data cleansing and data verification to identify data mismatch using Relational Data modeling 3NF and Dimensional Data Modeling Performed exploratory data analysis on all the features to understand feature importance and analyzed the behavior of features by using different statistical approaches Studied the feature distribution with the help of Probability Density Function Cumulative Distribution Function Percentiles Quantiles to draw some insights Developed automated model training testing deployment via machine learning continuous delivery pipelines Built decision tree model from the set of training data using the information entropy and the attribute with the highest normalized information gain is chosen to make the decision of credit approval Created S3 buckets and managing policies for S3 buckets and Utilized S3 bucket and Glacier for Archival storage and backup on AWS Experienced in designing and deploying AWS Solutions using EC2 S3 EBS an Elastic Load Balancer ELB and auto scaling groups Able to create scripts for system administration and AWS using languages such as BASH and Python Used ML algorithms logistic regression support vector machine k nearest neighbors Nave Bayes bagging boosting ensemble learning to analyze the data based on the features selected for datadriven decisions Performed text analysis on the reviews of the products using NLP techniques like Bag of Words Term FrequencyInverse Document Frequency Word2vec Average Word2vec with help of NLTK Beautiful soup libraries Used machine learning algorithms to forecast the companys shortterm and longterm growth in terms of revenue number of customers various costs stock changes etcetera Used Classified instances Relative Operating Characteristic curve ROC and Confusion Matrix to find the accuracy of the models built Acquired knowledge on designing iterating and finetuning neural network models architecture for runtime efficiency to achieve optimal performance Visualized results in python using Matplotlib Seaborn libraries of Scikitlearn and used Tableau to create the interactive dashboards to present results for team members management and clients ENVIRONMENT Anaconda Python R Studio Jupyter Notebook VS Code Spyder PyCharm SSMS Unix Tableau Jira HDFS SPARK IMPALA HIVE Hue PYTHON DEVELOPER MAVIN SOLUTION Hyderabad Telangana July 2012 to August 2015 INDIA RESPONSIBILITIES Involved in the design and development of different webbased applications based on clients requirements Designed use case diagrams class diagrams sequence diagrams and state diagrams Learned new technical skills as required for the system like Django Flask Frameworks and ModelViewController MVC design pattern Developed applications using Flask Python frameworks Designed email marketing campaigns and created responsive web forms that saved data into a database using Python Django Framework Developed Python scripts to read from Excel files generate XML configuration files and for generating IP access frequency lists in different data logs Deployed web applications to Google App Engine Learnt to deploy projects using Jenkins Utilized Pandas Python library for analyzing data and data structures Managed large datasets using Pandas data frames and SQLite Performed frontend development for web initiatives to ensure usability using HTML and CSS and enhanced quality feel and usability of consumerfacing website Tested all completed work to ensure proper and error free functionality Collaborated with a team of instructors and programmers to develop the curriculum and guidelines for workshops to teach the logic of programming Created and ran custom SQL queries stored procedures and created an application to store client phone calls and emails that were routed to various developers Performed data profiling and analysis applied various data cleansing rules designed data standards architecture and designed the relational models Maintained metadata data definitions of table structures and version controlling for the data model Environment Python Django Flask SQLite SSMS Google App Engine Jenkins Pandas HTML CSS PYTHON DEVELOPER SUTHERLAND Hyderabad Telangana May 2011 to June 2012 INDIA RESPONSIBILITIES Actively involved in interacting with front end users project lead and business analyst to gather user requirements and online system specifications Followed Agile Methodologies to manage full lifecycle development of the project Designed and developed communication between client and server using Secured Web services Written backend programming in Python and used the Django Framework to develop the application Participated in entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Implemented user interface guidelines and standards throughout the development and maintenance of the website using the HTML5 CSS3 JavaScript Developed views and templates with Python and Djangos view controller and templating language to create a userfriendly website interface Developed RESTful services using Django Developed and tested many features for dashboard using Python CSS JavaScript Used JavaScript and XML to update a portion of a webpage Successfully migrated the Django database from SQLite3 to PostgreSQL with complete data integrity Worked on Jenkins continuous integration tool for deployment of project Created custom TSQL procedures to read data from flat files to dump to SQL Server database using SQL Server import and export data wizard Developed user defined functions based on the requirements and used various builtin functions Handled errors using Exception handling try catch extensively for the ease of debugging and displaying the error messages in the application Developed batch scripts for scheduling data migration scripts Created clustered nonclustered indexes and indexed views to optimize the queries performance Coordinated with onsite folks and mentored the offshore team Worked PLSQL in Oracle database for writing queries functions stored procedures and triggers ENVIRONMENT Python Django JavaScript HTML CSS XML MYSQL TSQL SSMS MS Excel MSword TSQL Windows Server TOOLS TECHNOLOGIES Languages Packages Python SQL TensorFlow PySpark Numpy Pandas Keras NLTK Caffe Languages Packages Python SQL Numpy Pandas ScikitLearn Matplotlib TensorFlow Keras NLTK Tableau MySQL Databases Hadoop Ecosystem SQL Server HDFS Map Reduce HIVE IMPALA Spark PySpark and Kafka Mathematical Matrix operations Differentiation Integration Probability Statistics Linear Algebra Geometry Machine Learning Algorithms Logistic Regression Linear Regression K Means Clustering Algorithm Decision Trees Support Vector Machines Nave Bayes Hierarchical Clustering Deep Learning Techniques Artificial Neural Networks Convolutional Neural Networks Multilayer Perceptrons Recurrent Neural Networks LSTM Back Propagation Chain rule Choosing Activation Functions Drop Out Optimization algorithms User Interfaces HTML CSS Java Script XML Version control Tools Git Tools Spyder Jupyter Notebook VS Code R Studio SQL Server Oracle Anconda R Shiney Tableau Plotly Operating Systems Windows Linux Methodologies Agile Scrum Education Masters Skills Linux Business Intelligence SQL Statistical analysis NLP AWS Python HIVESQL",
    "entities": [
        "NLTK",
        "Data Mining Methods Factor Analysis",
        "HDFS",
        "Multilayer Perceptrons Recurrent Neural Networks",
        "Software Development Lifecycle SDLC",
        "KNN Naive Bayes Data",
        "DATA SCIENTIST DATA SCIENTIST DATA SCIENTIST CERNER",
        "Probability Density Function Cumulative Distribution Function Percentiles Quantiles",
        "IP",
        "EQUIFAX",
        "Utilized S3",
        "Design Development and Deployment Testing and Implementation",
        "Spark PySpark",
        "XML",
        "GIT Version Control System Authorized",
        "Maintained",
        "Kansas City",
        "Glacier for Archival",
        "Principal Component Analysis",
        "Created S3",
        "Created custom TSQL",
        "Python",
        "SQL Server",
        "Bag of Words Term FrequencyInverse Document",
        "Developed",
        "Implemented Classification",
        "TfidfVectorizer Developed",
        "Secured Web services Written",
        "Amazon Web Services AWS Expertise",
        "Text Mining",
        "HIVE QL Validated",
        "Exception",
        "Data Mining",
        "Python Django Framework Developed Python",
        "User Interfaces HTML CSS Java Script XML Version",
        "Linear Discriminant Analysis LDA Experience",
        "Data Scientist",
        "Flask",
        "Collaborated",
        "Built",
        "Flask Python",
        "ROC",
        "Design Development Coding Testing Implementation and Maintenance Hands",
        "MVC",
        "SQLite Performed",
        "Spark",
        "Linear",
        "US",
        "HIVE",
        "Leveraged",
        "Google App Engine Learnt",
        "Created",
        "AWS",
        "Oracle",
        "EDA",
        "ELB",
        "ENVIRONMENT Anaconda Python",
        "HTML",
        "Tableau ENVIRONMENT Anaconda Azure",
        "Dimensional Data Modeling Performed",
        "SQL",
        "NLP",
        "Confusion Matrix",
        "Anaconda",
        "HIVESQL",
        "Relational Data",
        "Pandas",
        "Created Confusion Matrix",
        "Python Developed Adhoc Queries",
        "Performed",
        "Unsupervised Learning",
        "Djangos",
        "OpenCV Worked",
        "Convolutional Neural Networks Recurrent Neural Networks",
        "Dimensionality Reduction Techniques",
        "Logistic Regression Decision",
        "NLP AWS Python HIVESQL",
        "ML",
        "Environment Python Django Flask",
        "CSS",
        "Topic Extraction Sentiment Analysis",
        "REST",
        "Structured",
        "AWS Experienced",
        "AWS Solutions",
        "Tableau",
        "Machine Learning",
        "BASH",
        "Work Experience DATA SCIENTIST CERNER",
        "Teradata"
    ],
    "experience": "Experience with Deep learning techniques such as Convolutional Neural Networks Recurrent Neural Networks by using Keras TensorFlow and OpenCV Worked on several python packages like NumPy Pandas Scikit Learn Matplotlib Beautiful Soup Pickle SciPy Python PyTables etc Proficient in implementing Dimensionality Reduction Techniques like Principal Component Analysis tStochastics Neighborhood Embedding tSNE and Linear Discriminant Analysis LDA Experience in implementing data analysis with various analytic tools such as Anaconda 40 Jupyter Notebook 4X RStudio RShiney Expertise in all aspects of Software Development Lifecycle SDLC from requirement analysis Design Development Coding Testing Implementation and Maintenance Hands on advanced SQL experience summarizing transforming segmenting joining datasets Experience in visualization tools like Tableau 9X 10X for creating dashboards Experience in using GIT Version Control System Authorized to work in the US for any employer Work Experience DATA SCIENTIST CERNER Kansas City MO January 2018 to Present RESPONSIBILITIES Participated in all phases of Machine Learning and Data Mining data collection data cleaning developing models validation visualization Used Pandas NumPy seaborn scipy matplotlib scikitlearn nltk in python for developing various machine learning algorithms Implemented Bagging and Boosting to enhance the model performance Leveraged disparate data sources that provide deep customer insight including online transactional data web data payment orders history and marketing campaigns exposure data Implemented the endtoend platform for performing user behavior analytics using unsupervised machine learning Implemented Classification using supervised algorithms like Logistic Regression Decision trees KNN Naive Bayes Data transformation from various resources data organization features extraction from raw and stored Designed and implemented system architecture for AmazonEC2 based cloud hosted solution for the client Identified outliers and inconsistencies in data by conducting exploratory data analysis EDA using python NumPy and Seaborn to see the insights of data and validate each feature Prepare scripts to ensure proper data access manipulation and reporting functions with R programming Involved in converting HIVESQL queries into Spark transformations using Spark RDDs and Python Developed Adhoc Queries for moving data from HDFS to Hive and analyzing the data using HIVE QL Validated models using crossvalidation and loss function to measure model performance Created Confusion Matrix and ROC Expert in performing Text Mining and Text classification in NLP by using TfidfVectorizer Developed NLP models for Topic Extraction Sentiment Analysis Addressed overfitting by implementing of the algorithm regularization methods like L2 and L1 Performed price sensitivity and variation analysis across different marketing channels and conducted exploratory data analysis on variables such as lifetime value and profit score Built data pipelines implemented code modularization involving package creation and codeveloped REST APIs using Flask for production deployment Performed data discovery and build a stream that automatically retrieves data from multitude of sources SQL databases external data such as social network data user reviews to generate KPIs using Tableau ENVIRONMENT Anaconda Azure Python R Studio R Shiny Jupyter Notebook VS code SpyderAWS Oracle SSMS Unix Tableau HDFS SPARK IMPALA HIVE Hue DATA SCIENTISTDATA ANALYTICS SPECALIST EQUIFAX ST LOUIS January 2016 to December 2017 RESPONSIBILITIES Analyzed the data using various machine learning algorithms whether to extendnot credit limit to an existing applicant and to approvenot new credit line to a new applicant will likely result in profit or loss based on various circumstances like credit history utilization rate income age location hard enquiries number of deliquesces Extracted terabytes of structured and unstructured data by using SQL queries and performed data mining tasks including handling missing data data wrangling feature scaling outlier analysis in python by importing pandas Conducted data investigation discovery mapping tools to scan every single data record Worked on predictive and whatif analysis using Python from HDFS and successfully loaded files to HDFS from Teradata and loaded from HDFS to HIVE Performed data analysis data validation data cleansing and data verification to identify data mismatch using Relational Data modeling 3NF and Dimensional Data Modeling Performed exploratory data analysis on all the features to understand feature importance and analyzed the behavior of features by using different statistical approaches Studied the feature distribution with the help of Probability Density Function Cumulative Distribution Function Percentiles Quantiles to draw some insights Developed automated model training testing deployment via machine learning continuous delivery pipelines Built decision tree model from the set of training data using the information entropy and the attribute with the highest normalized information gain is chosen to make the decision of credit approval Created S3 buckets and managing policies for S3 buckets and Utilized S3 bucket and Glacier for Archival storage and backup on AWS Experienced in designing and deploying AWS Solutions using EC2 S3 EBS an Elastic Load Balancer ELB and auto scaling groups Able to create scripts for system administration and AWS using languages such as BASH and Python Used ML algorithms logistic regression support vector machine k nearest neighbors Nave Bayes bagging boosting ensemble learning to analyze the data based on the features selected for datadriven decisions Performed text analysis on the reviews of the products using NLP techniques like Bag of Words Term FrequencyInverse Document Frequency Word2vec Average Word2vec with help of NLTK Beautiful soup libraries Used machine learning algorithms to forecast the companys shortterm and longterm growth in terms of revenue number of customers various costs stock changes etcetera Used Classified instances Relative Operating Characteristic curve ROC and Confusion Matrix to find the accuracy of the models built Acquired knowledge on designing iterating and finetuning neural network models architecture for runtime efficiency to achieve optimal performance Visualized results in python using Matplotlib Seaborn libraries of Scikitlearn and used Tableau to create the interactive dashboards to present results for team members management and clients ENVIRONMENT Anaconda Python R Studio Jupyter Notebook VS Code Spyder PyCharm SSMS Unix Tableau Jira HDFS SPARK IMPALA HIVE Hue PYTHON DEVELOPER MAVIN SOLUTION Hyderabad Telangana July 2012 to August 2015 INDIA RESPONSIBILITIES Involved in the design and development of different webbased applications based on clients requirements Designed use case diagrams class diagrams sequence diagrams and state diagrams Learned new technical skills as required for the system like Django Flask Frameworks and ModelViewController MVC design pattern Developed applications using Flask Python frameworks Designed email marketing campaigns and created responsive web forms that saved data into a database using Python Django Framework Developed Python scripts to read from Excel files generate XML configuration files and for generating IP access frequency lists in different data logs Deployed web applications to Google App Engine Learnt to deploy projects using Jenkins Utilized Pandas Python library for analyzing data and data structures Managed large datasets using Pandas data frames and SQLite Performed frontend development for web initiatives to ensure usability using HTML and CSS and enhanced quality feel and usability of consumerfacing website Tested all completed work to ensure proper and error free functionality Collaborated with a team of instructors and programmers to develop the curriculum and guidelines for workshops to teach the logic of programming Created and ran custom SQL queries stored procedures and created an application to store client phone calls and emails that were routed to various developers Performed data profiling and analysis applied various data cleansing rules designed data standards architecture and designed the relational models Maintained metadata data definitions of table structures and version controlling for the data model Environment Python Django Flask SQLite SSMS Google App Engine Jenkins Pandas HTML CSS PYTHON DEVELOPER SUTHERLAND Hyderabad Telangana May 2011 to June 2012 INDIA RESPONSIBILITIES Actively involved in interacting with front end users project lead and business analyst to gather user requirements and online system specifications Followed Agile Methodologies to manage full lifecycle development of the project Designed and developed communication between client and server using Secured Web services Written backend programming in Python and used the Django Framework to develop the application Participated in entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Implemented user interface guidelines and standards throughout the development and maintenance of the website using the HTML5 CSS3 JavaScript Developed views and templates with Python and Djangos view controller and templating language to create a userfriendly website interface Developed RESTful services using Django Developed and tested many features for dashboard using Python CSS JavaScript Used JavaScript and XML to update a portion of a webpage Successfully migrated the Django database from SQLite3 to PostgreSQL with complete data integrity Worked on Jenkins continuous integration tool for deployment of project Created custom TSQL procedures to read data from flat files to dump to SQL Server database using SQL Server import and export data wizard Developed user defined functions based on the requirements and used various builtin functions Handled errors using Exception handling try catch extensively for the ease of debugging and displaying the error messages in the application Developed batch scripts for scheduling data migration scripts Created clustered nonclustered indexes and indexed views to optimize the queries performance Coordinated with onsite folks and mentored the offshore team Worked PLSQL in Oracle database for writing queries functions stored procedures and triggers ENVIRONMENT Python Django JavaScript HTML CSS XML MYSQL TSQL SSMS MS Excel MSword TSQL Windows Server TOOLS TECHNOLOGIES Languages Packages Python SQL TensorFlow PySpark Numpy Pandas Keras NLTK Caffe Languages Packages Python SQL Numpy Pandas ScikitLearn Matplotlib TensorFlow Keras NLTK Tableau MySQL Databases Hadoop Ecosystem SQL Server HDFS Map Reduce HIVE IMPALA Spark PySpark and Kafka Mathematical Matrix operations Differentiation Integration Probability Statistics Linear Algebra Geometry Machine Learning Algorithms Logistic Regression Linear Regression K Means Clustering Algorithm Decision Trees Support Vector Machines Nave Bayes Hierarchical Clustering Deep Learning Techniques Artificial Neural Networks Convolutional Neural Networks Multilayer Perceptrons Recurrent Neural Networks LSTM Back Propagation Chain rule Choosing Activation Functions Drop Out Optimization algorithms User Interfaces HTML CSS Java Script XML Version control Tools Git Tools Spyder Jupyter Notebook VS Code R Studio SQL Server Oracle Anconda R Shiney Tableau Plotly Operating Systems Windows Linux Methodologies Agile Scrum Education Masters Skills Linux Business Intelligence SQL Statistical analysis NLP AWS Python HIVESQL",
    "extracted_keywords": [
        "DATA",
        "SCIENTIST",
        "DATA",
        "SCIENTIST",
        "DATA",
        "SCIENTIST",
        "CERNER",
        "Kansas",
        "City",
        "KS",
        "years",
        "experience",
        "IT",
        "field",
        "years",
        "Data",
        "Scientist",
        "business",
        "experience",
        "communication",
        "skills",
        "highimpact",
        "business",
        "outcomes",
        "innovations",
        "decisions",
        "Expertise",
        "analysis",
        "modeling",
        "Text",
        "mining",
        "Unsupervised",
        "Learning",
        "Reinforcement",
        "Expert",
        "NLP",
        "models",
        "extraction",
        "Sentiment",
        "Analysis",
        "background",
        "Linear",
        "Probability",
        "Statistics",
        "Differentiation",
        "Integration",
        "experience",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "Expertise",
        "business",
        "requirements",
        "models",
        "algorithms",
        "building",
        "models",
        "data",
        "mining",
        "reporting",
        "solutions",
        "volume",
        "data",
        "Proficient",
        "Data",
        "Mining",
        "Methods",
        "Factor",
        "Analysis",
        "ANOVA",
        "Hypothetical",
        "distribution",
        "modeling",
        "Linear",
        "LOGISTIC",
        "REGRESSION",
        "LINEAR",
        "NAVE",
        "BAYES",
        "DECISION",
        "TREES",
        "RANDOM",
        "FOREST",
        "NEURAL",
        "NETWORKS",
        "SVM",
        "KNN",
        "Experience",
        "Deep",
        "techniques",
        "Convolutional",
        "Neural",
        "Networks",
        "Recurrent",
        "Neural",
        "Networks",
        "Keras",
        "TensorFlow",
        "OpenCV",
        "Worked",
        "python",
        "packages",
        "NumPy",
        "Pandas",
        "Scikit",
        "Learn",
        "Matplotlib",
        "Beautiful",
        "Soup",
        "Pickle",
        "SciPy",
        "Python",
        "PyTables",
        "Proficient",
        "Dimensionality",
        "Reduction",
        "Techniques",
        "Principal",
        "Component",
        "Analysis",
        "tStochastics",
        "Neighborhood",
        "tSNE",
        "Linear",
        "Discriminant",
        "Analysis",
        "LDA",
        "Experience",
        "data",
        "analysis",
        "tools",
        "Anaconda",
        "Jupyter",
        "Notebook",
        "4X",
        "RStudio",
        "RShiney",
        "Expertise",
        "aspects",
        "Software",
        "Development",
        "Lifecycle",
        "SDLC",
        "requirement",
        "analysis",
        "Design",
        "Development",
        "Coding",
        "Testing",
        "Implementation",
        "Maintenance",
        "Hands",
        "SQL",
        "experience",
        "datasets",
        "Experience",
        "visualization",
        "tools",
        "Tableau",
        "9X",
        "dashboards",
        "Experience",
        "GIT",
        "Version",
        "Control",
        "System",
        "Authorized",
        "US",
        "employer",
        "Work",
        "Experience",
        "DATA",
        "SCIENTIST",
        "CERNER",
        "Kansas",
        "City",
        "MO",
        "January",
        "RESPONSIBILITIES",
        "phases",
        "Machine",
        "Learning",
        "Data",
        "Mining",
        "data",
        "collection",
        "data",
        "models",
        "validation",
        "visualization",
        "Pandas",
        "NumPy",
        "matplotlib",
        "nltk",
        "python",
        "machine",
        "learning",
        "algorithms",
        "Bagging",
        "model",
        "performance",
        "Leveraged",
        "data",
        "sources",
        "customer",
        "insight",
        "data",
        "web",
        "data",
        "payment",
        "orders",
        "history",
        "marketing",
        "campaigns",
        "exposure",
        "data",
        "endtoend",
        "platform",
        "user",
        "behavior",
        "analytics",
        "machine",
        "Classification",
        "algorithms",
        "Logistic",
        "Regression",
        "Decision",
        "KNN",
        "Naive",
        "Bayes",
        "Data",
        "transformation",
        "resources",
        "data",
        "organization",
        "extraction",
        "system",
        "architecture",
        "AmazonEC2",
        "cloud",
        "solution",
        "client",
        "outliers",
        "inconsistencies",
        "data",
        "data",
        "analysis",
        "EDA",
        "NumPy",
        "Seaborn",
        "insights",
        "data",
        "feature",
        "scripts",
        "data",
        "access",
        "manipulation",
        "reporting",
        "functions",
        "R",
        "programming",
        "HIVESQL",
        "queries",
        "Spark",
        "transformations",
        "Spark",
        "RDDs",
        "Python",
        "Developed",
        "Adhoc",
        "Queries",
        "data",
        "HDFS",
        "Hive",
        "data",
        "HIVE",
        "QL",
        "models",
        "crossvalidation",
        "loss",
        "function",
        "model",
        "performance",
        "Created",
        "Confusion",
        "Matrix",
        "ROC",
        "Expert",
        "Text",
        "Mining",
        "Text",
        "classification",
        "NLP",
        "TfidfVectorizer",
        "Developed",
        "NLP",
        "models",
        "Topic",
        "Extraction",
        "Sentiment",
        "Analysis",
        "algorithm",
        "regularization",
        "methods",
        "L2",
        "L1",
        "Performed",
        "price",
        "sensitivity",
        "variation",
        "analysis",
        "marketing",
        "channels",
        "data",
        "analysis",
        "variables",
        "lifetime",
        "value",
        "profit",
        "score",
        "data",
        "pipelines",
        "code",
        "modularization",
        "package",
        "creation",
        "REST",
        "APIs",
        "Flask",
        "production",
        "deployment",
        "Performed",
        "data",
        "discovery",
        "stream",
        "data",
        "multitude",
        "sources",
        "SQL",
        "data",
        "network",
        "data",
        "user",
        "reviews",
        "KPIs",
        "Tableau",
        "ENVIRONMENT",
        "Anaconda",
        "Azure",
        "Python",
        "R",
        "Studio",
        "R",
        "Shiny",
        "Jupyter",
        "Notebook",
        "VS",
        "code",
        "Oracle",
        "SSMS",
        "Unix",
        "Tableau",
        "HDFS",
        "SPARK",
        "IMPALA",
        "HIVE",
        "Hue",
        "DATA",
        "SCIENTISTDATA",
        "ANALYTICS",
        "SPECALIST",
        "EQUIFAX",
        "ST",
        "LOUIS",
        "January",
        "December",
        "RESPONSIBILITIES",
        "data",
        "machine",
        "learning",
        "credit",
        "limit",
        "applicant",
        "credit",
        "line",
        "applicant",
        "profit",
        "loss",
        "circumstances",
        "credit",
        "history",
        "utilization",
        "rate",
        "income",
        "age",
        "location",
        "enquiries",
        "number",
        "deliquesces",
        "terabytes",
        "data",
        "SQL",
        "queries",
        "data",
        "mining",
        "tasks",
        "data",
        "data",
        "feature",
        "analysis",
        "python",
        "pandas",
        "data",
        "investigation",
        "discovery",
        "mapping",
        "tools",
        "data",
        "record",
        "analysis",
        "Python",
        "HDFS",
        "files",
        "HDFS",
        "Teradata",
        "HDFS",
        "HIVE",
        "Performed",
        "data",
        "analysis",
        "data",
        "validation",
        "data",
        "cleansing",
        "data",
        "verification",
        "data",
        "mismatch",
        "Relational",
        "Data",
        "modeling",
        "Dimensional",
        "Data",
        "data",
        "analysis",
        "features",
        "feature",
        "importance",
        "behavior",
        "features",
        "approaches",
        "feature",
        "distribution",
        "help",
        "Probability",
        "Density",
        "Function",
        "Cumulative",
        "Distribution",
        "Function",
        "Percentiles",
        "Quantiles",
        "insights",
        "model",
        "training",
        "testing",
        "deployment",
        "machine",
        "delivery",
        "pipelines",
        "decision",
        "tree",
        "model",
        "set",
        "training",
        "data",
        "information",
        "entropy",
        "attribute",
        "information",
        "gain",
        "decision",
        "credit",
        "approval",
        "S3",
        "buckets",
        "policies",
        "S3",
        "buckets",
        "S3",
        "bucket",
        "Glacier",
        "Archival",
        "storage",
        "backup",
        "AWS",
        "AWS",
        "Solutions",
        "EC2",
        "S3",
        "EBS",
        "Elastic",
        "Load",
        "Balancer",
        "ELB",
        "auto",
        "scaling",
        "groups",
        "scripts",
        "system",
        "administration",
        "AWS",
        "languages",
        "BASH",
        "Python",
        "ML",
        "regression",
        "support",
        "vector",
        "machine",
        "k",
        "neighbors",
        "Nave",
        "Bayes",
        "learning",
        "data",
        "features",
        "decisions",
        "text",
        "analysis",
        "reviews",
        "products",
        "NLP",
        "techniques",
        "Bag",
        "Words",
        "Term",
        "FrequencyInverse",
        "Document",
        "Frequency",
        "Word2vec",
        "Average",
        "Word2vec",
        "help",
        "NLTK",
        "Beautiful",
        "soup",
        "machine",
        "learning",
        "algorithms",
        "companys",
        "growth",
        "terms",
        "revenue",
        "number",
        "customers",
        "costs",
        "stock",
        "changes",
        "etcetera",
        "instances",
        "Relative",
        "Characteristic",
        "curve",
        "ROC",
        "Confusion",
        "Matrix",
        "accuracy",
        "models",
        "knowledge",
        "iterating",
        "network",
        "models",
        "architecture",
        "runtime",
        "efficiency",
        "performance",
        "results",
        "python",
        "Matplotlib",
        "Seaborn",
        "libraries",
        "Scikitlearn",
        "Tableau",
        "dashboards",
        "results",
        "team",
        "members",
        "management",
        "clients",
        "Anaconda",
        "Python",
        "R",
        "Studio",
        "Jupyter",
        "Notebook",
        "VS",
        "Code",
        "Spyder",
        "PyCharm",
        "Unix",
        "Tableau",
        "Jira",
        "HDFS",
        "SPARK",
        "IMPALA",
        "HIVE",
        "Hue",
        "PYTHON",
        "DEVELOPER",
        "SOLUTION",
        "Hyderabad",
        "Telangana",
        "July",
        "August",
        "INDIA",
        "RESPONSIBILITIES",
        "design",
        "development",
        "applications",
        "clients",
        "requirements",
        "use",
        "case",
        "diagrams",
        "class",
        "diagrams",
        "sequence",
        "diagrams",
        "state",
        "diagrams",
        "skills",
        "system",
        "Django",
        "Flask",
        "Frameworks",
        "ModelViewController",
        "MVC",
        "design",
        "pattern",
        "applications",
        "Flask",
        "Python",
        "frameworks",
        "email",
        "marketing",
        "campaigns",
        "web",
        "forms",
        "data",
        "database",
        "Python",
        "Django",
        "Framework",
        "Python",
        "scripts",
        "Excel",
        "files",
        "XML",
        "configuration",
        "files",
        "IP",
        "access",
        "frequency",
        "lists",
        "data",
        "logs",
        "Deployed",
        "web",
        "applications",
        "Google",
        "App",
        "Engine",
        "Learnt",
        "projects",
        "Jenkins",
        "Pandas",
        "Python",
        "library",
        "data",
        "data",
        "structures",
        "datasets",
        "Pandas",
        "data",
        "frames",
        "SQLite",
        "Performed",
        "frontend",
        "development",
        "web",
        "initiatives",
        "usability",
        "HTML",
        "CSS",
        "quality",
        "feel",
        "usability",
        "website",
        "work",
        "error",
        "functionality",
        "team",
        "instructors",
        "programmers",
        "curriculum",
        "guidelines",
        "workshops",
        "logic",
        "programming",
        "custom",
        "SQL",
        "procedures",
        "application",
        "client",
        "phone",
        "calls",
        "emails",
        "developers",
        "data",
        "profiling",
        "analysis",
        "data",
        "cleansing",
        "rules",
        "data",
        "standards",
        "architecture",
        "models",
        "metadata",
        "data",
        "definitions",
        "table",
        "structures",
        "version",
        "data",
        "model",
        "Environment",
        "Python",
        "Django",
        "Flask",
        "SQLite",
        "Google",
        "App",
        "Engine",
        "Jenkins",
        "Pandas",
        "HTML",
        "CSS",
        "PYTHON",
        "DEVELOPER",
        "SUTHERLAND",
        "Hyderabad",
        "Telangana",
        "May",
        "June",
        "INDIA",
        "RESPONSIBILITIES",
        "end",
        "users",
        "project",
        "lead",
        "business",
        "analyst",
        "user",
        "requirements",
        "system",
        "specifications",
        "Agile",
        "Methodologies",
        "lifecycle",
        "development",
        "project",
        "communication",
        "client",
        "server",
        "Secured",
        "Web",
        "services",
        "programming",
        "Python",
        "Django",
        "Framework",
        "application",
        "lifecycle",
        "projects",
        "Design",
        "Development",
        "Deployment",
        "Testing",
        "Implementation",
        "user",
        "interface",
        "guidelines",
        "standards",
        "development",
        "maintenance",
        "website",
        "HTML5",
        "CSS3",
        "JavaScript",
        "views",
        "templates",
        "Python",
        "Djangos",
        "controller",
        "templating",
        "language",
        "website",
        "interface",
        "services",
        "Django",
        "Developed",
        "features",
        "dashboard",
        "Python",
        "CSS",
        "JavaScript",
        "JavaScript",
        "XML",
        "portion",
        "webpage",
        "Django",
        "database",
        "SQLite3",
        "PostgreSQL",
        "data",
        "integrity",
        "Jenkins",
        "integration",
        "tool",
        "deployment",
        "project",
        "custom",
        "TSQL",
        "procedures",
        "data",
        "files",
        "SQL",
        "Server",
        "database",
        "SQL",
        "Server",
        "import",
        "export",
        "data",
        "user",
        "functions",
        "requirements",
        "builtin",
        "functions",
        "errors",
        "Exception",
        "handling",
        "try",
        "ease",
        "error",
        "messages",
        "application",
        "batch",
        "scripts",
        "scheduling",
        "data",
        "migration",
        "scripts",
        "indexes",
        "views",
        "queries",
        "performance",
        "folks",
        "team",
        "Oracle",
        "database",
        "queries",
        "functions",
        "procedures",
        "triggers",
        "Python",
        "Django",
        "JavaScript",
        "HTML",
        "CSS",
        "XML",
        "MYSQL",
        "TSQL",
        "SSMS",
        "MS",
        "Excel",
        "MSword",
        "TSQL",
        "Windows",
        "Server",
        "TOOLS",
        "TECHNOLOGIES",
        "Languages",
        "Packages",
        "Python",
        "SQL",
        "TensorFlow",
        "PySpark",
        "Numpy",
        "Pandas",
        "Keras",
        "NLTK",
        "Caffe",
        "Languages",
        "Packages",
        "Python",
        "SQL",
        "Numpy",
        "Pandas",
        "ScikitLearn",
        "Matplotlib",
        "TensorFlow",
        "Keras",
        "NLTK",
        "Tableau",
        "MySQL",
        "Databases",
        "Hadoop",
        "Ecosystem",
        "SQL",
        "Server",
        "HDFS",
        "Map",
        "HIVE",
        "IMPALA",
        "Spark",
        "PySpark",
        "Kafka",
        "Mathematical",
        "Matrix",
        "operations",
        "Differentiation",
        "Integration",
        "Probability",
        "Statistics",
        "Linear",
        "Algebra",
        "Geometry",
        "Machine",
        "Learning",
        "Algorithms",
        "Logistic",
        "Regression",
        "Linear",
        "Regression",
        "K",
        "Clustering",
        "Algorithm",
        "Decision",
        "Trees",
        "Support",
        "Vector",
        "Machines",
        "Nave",
        "Bayes",
        "Hierarchical",
        "Clustering",
        "Deep",
        "Learning",
        "Techniques",
        "Artificial",
        "Neural",
        "Networks",
        "Convolutional",
        "Neural",
        "Networks",
        "Multilayer",
        "Perceptrons",
        "Recurrent",
        "Neural",
        "Networks",
        "LSTM",
        "Back",
        "Propagation",
        "Chain",
        "rule",
        "Activation",
        "Functions",
        "Drop",
        "Out",
        "Optimization",
        "User",
        "Interfaces",
        "HTML",
        "CSS",
        "Java",
        "Script",
        "XML",
        "Version",
        "control",
        "Tools",
        "Git",
        "Tools",
        "Spyder",
        "Jupyter",
        "Notebook",
        "VS",
        "Code",
        "R",
        "Studio",
        "SQL",
        "Server",
        "Oracle",
        "Anconda",
        "R",
        "Shiney",
        "Tableau",
        "Operating",
        "Systems",
        "Windows",
        "Linux",
        "Methodologies",
        "Agile",
        "Scrum",
        "Education",
        "Masters",
        "Skills",
        "Linux",
        "Business",
        "Intelligence",
        "SQL",
        "analysis",
        "NLP",
        "Python",
        "HIVESQL"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T23:13:16.051123",
    "resume_data": "DATA SCIENTIST DATA SCIENTIST DATA SCIENTIST CERNER Kansas City KS Around 7 years of experience in IT field with 3 years as Data Scientist with strong technical and business experience and communication skills to drive highimpact business outcomes through datadriven innovations and decisions Expertise in Statistical analysis Predictive modeling Text mining Supervised learning Unsupervised Learning and Reinforcement learning Expert in developing NLP models for Topic extraction Sentiment Analysis Strong mathematical background in Linear algebra Probability Statistics Differentiation and Integration Having good experience in Amazon Web Services AWS Expertise in transforming business requirements into analytical models designing algorithms building models developing data mining and reporting solutions that scale across a massive volume of Structured and unstructured data Proficient in Data Mining Methods Factor Analysis ANOVA Hypothetical testing normal distribution and other advanced Statistical modeling both Linear and nonlinear LOGISTIC REGRESSION LINEAR REGRESSION NAVE BAYES DECISION TREES RANDOM FOREST NEURAL NETWORKS SVM CLUSTERING KNN Experience with Deep learning techniques such as Convolutional Neural Networks Recurrent Neural Networks by using Keras TensorFlow and OpenCV Worked on several python packages like NumPy Pandas Scikit Learn Matplotlib Beautiful Soup Pickle SciPy Python PyTables etc Proficient in implementing Dimensionality Reduction Techniques like Principal Component Analysis tStochastics Neighborhood Embedding tSNE and Linear Discriminant Analysis LDA Experience in implementing data analysis with various analytic tools such as Anaconda 40 Jupyter Notebook 4X RStudio RShiney Expertise in all aspects of Software Development Lifecycle SDLC from requirement analysis Design Development Coding Testing Implementation and Maintenance Hands on advanced SQL experience summarizing transforming segmenting joining datasets Experience in visualization tools like Tableau 9X 10X for creating dashboards Experience in using GIT Version Control System Authorized to work in the US for any employer Work Experience DATA SCIENTIST CERNER Kansas City MO January 2018 to Present RESPONSIBILITIES Participated in all phases of Machine Learning and Data Mining data collection data cleaning developing models validation visualization Used Pandas NumPy seaborn scipy matplotlib scikitlearn nltk in python for developing various machine learning algorithms Implemented Bagging and Boosting to enhance the model performance Leveraged disparate data sources that provide deep customer insight including online transactional data web data payment orders history and marketing campaigns exposure data Implemented the endtoend platform for performing user behavior analytics using unsupervised machine learning Implemented Classification using supervised algorithms like Logistic Regression Decision trees KNN Naive Bayes Data transformation from various resources data organization features extraction from raw and stored Designed and implemented system architecture for AmazonEC2 based cloud hosted solution for the client Identified outliers and inconsistencies in data by conducting exploratory data analysis EDA using python NumPy and Seaborn to see the insights of data and validate each feature Prepare scripts to ensure proper data access manipulation and reporting functions with R programming Involved in converting HIVESQL queries into Spark transformations using Spark RDDs and Python Developed Adhoc Queries for moving data from HDFS to Hive and analyzing the data using HIVE QL Validated models using crossvalidation and loss function to measure model performance Created Confusion Matrix and ROC Expert in performing Text Mining and Text classification in NLP by using TfidfVectorizer Developed NLP models for Topic Extraction Sentiment Analysis Addressed overfitting by implementing of the algorithm regularization methods like L2 and L1 Performed price sensitivity and variation analysis across different marketing channels and conducted exploratory data analysis on variables such as lifetime value and profit score Built data pipelines implemented code modularization involving package creation and codeveloped REST APIs using Flask for production deployment Performed data discovery and build a stream that automatically retrieves data from multitude of sources SQL databases external data such as social network data user reviews to generate KPIs using Tableau ENVIRONMENT Anaconda Azure Python R Studio R Shiny Jupyter Notebook VS code SpyderAWS Oracle SSMS Unix Tableau HDFS SPARK IMPALA HIVE Hue DATA SCIENTISTDATA ANALYTICS SPECALIST EQUIFAX ST LOUIS January 2016 to December 2017 RESPONSIBILITIES Analyzed the data using various machine learning algorithms whether to extendnot credit limit to an existing applicant and to approvenot new credit line to a new applicant will likely result in profit or loss based on various circumstances like credit history utilization rate income age location hard enquiries number of deliquesces Extracted terabytes of structured and unstructured data by using SQL queries and performed data mining tasks including handling missing data data wrangling feature scaling outlier analysis in python by importing pandas Conducted data investigation discovery mapping tools to scan every single data record Worked on predictive and whatif analysis using Python from HDFS and successfully loaded files to HDFS from Teradata and loaded from HDFS to HIVE Performed data analysis data validation data cleansing and data verification to identify data mismatch using Relational Data modeling 3NF and Dimensional Data Modeling Performed exploratory data analysis on all the features to understand feature importance and analyzed the behavior of features by using different statistical approaches Studied the feature distribution with the help of Probability Density Function Cumulative Distribution Function Percentiles Quantiles to draw some insights Developed automated model training testing deployment via machine learning continuous delivery pipelines Built decision tree model from the set of training data using the information entropy and the attribute with the highest normalized information gain is chosen to make the decision of credit approval Created S3 buckets and managing policies for S3 buckets and Utilized S3 bucket and Glacier for Archival storage and backup on AWS Experienced in designing and deploying AWS Solutions using EC2 S3 EBS an Elastic Load Balancer ELB and auto scaling groups Able to create scripts for system administration and AWS using languages such as BASH and Python Used ML algorithms logistic regression support vector machine k nearest neighbors Nave Bayes bagging boosting ensemble learning to analyze the data based on the features selected for datadriven decisions Performed text analysis on the reviews of the products using NLP techniques like Bag of Words Term FrequencyInverse Document Frequency Word2vec Average Word2vec with help of NLTK Beautiful soup libraries Used machine learning algorithms to forecast the companys shortterm and longterm growth in terms of revenue number of customers various costs stock changes etcetera Used Classified instances Relative Operating Characteristic curve ROC and Confusion Matrix to find the accuracy of the models built Acquired knowledge on designing iterating and finetuning neural network models architecture for runtime efficiency to achieve optimal performance Visualized results in python using Matplotlib Seaborn libraries of Scikitlearn and used Tableau to create the interactive dashboards to present results for team members management and clients ENVIRONMENT Anaconda Python R Studio Jupyter Notebook VS Code Spyder PyCharm SSMS Unix Tableau Jira HDFS SPARK IMPALA HIVE Hue PYTHON DEVELOPER MAVIN SOLUTION Hyderabad Telangana July 2012 to August 2015 INDIA RESPONSIBILITIES Involved in the design and development of different webbased applications based on clients requirements Designed use case diagrams class diagrams sequence diagrams and state diagrams Learned new technical skills as required for the system like Django Flask Frameworks and ModelViewController MVC design pattern Developed applications using Flask Python frameworks Designed email marketing campaigns and created responsive web forms that saved data into a database using Python Django Framework Developed Python scripts to read from Excel files generate XML configuration files and for generating IP access frequency lists in different data logs Deployed web applications to Google App Engine Learnt to deploy projects using Jenkins Utilized Pandas Python library for analyzing data and data structures Managed large datasets using Pandas data frames and SQLite Performed frontend development for web initiatives to ensure usability using HTML and CSS and enhanced quality feel and usability of consumerfacing website Tested all completed work to ensure proper and error free functionality Collaborated with a team of instructors and programmers to develop the curriculum and guidelines for workshops to teach the logic of programming Created and ran custom SQL queries stored procedures and created an application to store client phone calls and emails that were routed to various developers Performed data profiling and analysis applied various data cleansing rules designed data standards architecture and designed the relational models Maintained metadata data definitions of table structures and version controlling for the data model Environment Python Django Flask SQLite SSMS Google App Engine Jenkins Pandas HTML CSS PYTHON DEVELOPER SUTHERLAND Hyderabad Telangana May 2011 to June 2012 INDIA RESPONSIBILITIES Actively involved in interacting with front end users project lead and business analyst to gather user requirements and online system specifications Followed Agile Methodologies to manage full lifecycle development of the project Designed and developed communication between client and server using Secured Web services Written backend programming in Python and used the Django Framework to develop the application Participated in entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Implemented user interface guidelines and standards throughout the development and maintenance of the website using the HTML5 CSS3 JavaScript Developed views and templates with Python and Djangos view controller and templating language to create a userfriendly website interface Developed RESTful services using Django Developed and tested many features for dashboard using Python CSS JavaScript Used JavaScript and XML to update a portion of a webpage Successfully migrated the Django database from SQLite3 to PostgreSQL with complete data integrity Worked on Jenkins continuous integration tool for deployment of project Created custom TSQL procedures to read data from flat files to dump to SQL Server database using SQL Server import and export data wizard Developed user defined functions based on the requirements and used various builtin functions Handled errors using Exception handling try catch extensively for the ease of debugging and displaying the error messages in the application Developed batch scripts for scheduling data migration scripts Created clustered nonclustered indexes and indexed views to optimize the queries performance Coordinated with onsite folks and mentored the offshore team Worked PLSQL in Oracle database for writing queries functions stored procedures and triggers ENVIRONMENT Python Django JavaScript HTML CSS XML MYSQL TSQL SSMS MS Excel MSword TSQL Windows Server TOOLS TECHNOLOGIES Languages Packages Python SQL TensorFlow PySpark Numpy Pandas Keras NLTK Caffe Languages Packages Python SQL Numpy Pandas ScikitLearn Matplotlib TensorFlow Keras NLTK Tableau MySQL Databases Hadoop Ecosystem SQL Server HDFS Map Reduce HIVE IMPALA Spark PySpark and Kafka Mathematical Matrix operations Differentiation Integration Probability Statistics Linear Algebra Geometry Machine Learning Algorithms Logistic Regression Linear Regression K Means Clustering Algorithm Decision Trees Support Vector Machines Nave Bayes Hierarchical Clustering Deep Learning Techniques Artificial Neural Networks Convolutional Neural Networks Multilayer Perceptrons Recurrent Neural Networks LSTM Back Propagation Chain rule Choosing Activation Functions Drop Out Optimization algorithms User Interfaces HTML CSS Java Script XML Version control Tools Git Tools Spyder Jupyter Notebook VS Code R Studio SQL Server Oracle Anconda R Shiney Tableau Plotly Operating Systems Windows Linux Methodologies Agile Scrum Education Masters Skills Linux Business Intelligence SQL Statistical analysis NLP AWS Python HIVESQL",
    "unique_id": "40dac570-9f66-4d19-be1f-3099b16db404"
}