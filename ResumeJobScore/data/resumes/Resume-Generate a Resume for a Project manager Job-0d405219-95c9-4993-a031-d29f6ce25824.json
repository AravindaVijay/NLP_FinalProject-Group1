{
    "clean_data": "Senior Python Developer Senior span lPythonspan span lDeveloperspan Senior Python Developer Redwood City CA Over 7 years of experience in developing webbased applications software development and design using Python 3327 Django 1918 XML CSS HTML DHTML JavaScript JQuery Angular Js 3 years of QA experience working in environment with different types of Software Development Life Cycle and Software Testing Methodology Good experience in Shell Scriptings Server Unix and Linux Open stock and Expertise python scripting with focus on Devops tools CICD and AWS Cloud Architecture Experienced in writing SQL Queries Stored procedures functions packages tables views triggers Knowledge of the Software Development Life Cycle SDLC Agile and Waterfall Methodologies and Familiar with concepts and devices such routers switches and TCPIP protocols and OSI layer Worked on AJAX framework to transform Datasets and Data tables into HTTPserializable JSON strings Experienced in developing service oriented architecture SOA and web Services using SOAP JAXWS WSDL and UDDI Built the web application by using Python Django AWS J2EE PostgreSQL MySQL Oracle 10g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins Well versed with design and development of presentation layer for web applications using technologies like HTML CSS and JavaScript Bootstrap Expertise in writing cloud computing applications using ruby Had knowledge on continuous integration and deployment using Jenkins Docker Experience working with network protocols SNMP NetConf Experience in developing applications using amazon web services like EC2 Cloud Search Elastic Load balancer ELB S3 Cloud Front Used R Language among statisticians and data miners for developing statistical software and data analysis Expertise in operating Symantec Altiris Remote Agent to remotely fix problems Excellent understanding and knowledge of Hadoop Distributed file system data modelling architecture and design principles and Developed Python Mapper and Reducer scripts and implemented them using Hadoop streaming Experienced in developing Web Services with Python programming language and Good working experience in processing large datasets with Spark using Scala and Pyspark Good working experience in processing large datasets with Spark using Scala and Pyspark and Familiar with JSON based REST Web services Experienced in understanding Service Virtualization needs Requirements creating VSIs using WSDL WADL Recording Request Response pairs Expertise in creating Restful API in NodeJS and communicate with Clojure server via protocol and use Backbone to generate template Built the web application by using Python Django AWS J2EE PostgreSQL MySQL Oracle 10g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins Strong handson on AWS cloud services like EC2 S3 RDS ELB and EBS for installing configuring Experienced in understanding Service Virtualization needs Requirements creating VSIs using Authorized to work in the US for any employer Work Experience Senior Python Developer Phillips 66 Houston Houston TX March 2017 to Present Over 7 years of experience as a WebApplication Developer and coding with analytical Programming using Python Django Java Involved in software development in Python libraries used Beautiful Soup NumPy SciPy matplotlib Pandas data frame network urllib2 MySQL  for database connectivity and IDEs sublime text Spyder PyCharm Good knowledge of web services with protocols SOAP REST and knowledge of server Apache Tomcat WebLogic Hands on experience in SVN Git JIRA and Bugzilla worked in SQL databases MS SQL Apache Cassandra Oracle and MongoDB Used AWS lambda to run code virtually Developed API for using AWS Lambda to manage the servers and run the code in AWS SQL and PLSQL programming developing complex code units database triggers and using the latest features to optimize performance Bulk Binds Materialized views Inline views Global Temporary Tables Good experience in Shell Scripting Server Unix and Linux Open stock and Expertise python scripting with focus on DevOps tools CICD and AWS Cloud Architecture Working with containerbased deployments using Docker working with Docker images Docker Hub and Docker registries and Kubernetes Modifying data usingSASBASESAS MACROS Open Source templatebased Qt reporting solution Big data processing using Spark AWS and Redshift Extracting data from the database usingSASAccessSASSQL procedures and createSASdata sets Writing SQL Queries Stored procedures functions packages tables views triggers Knowledge of the Software Development Life Cycle SDLC Agile and Waterfall Methodologies and Familiar with concepts and devices such routers switches and TCPIP protocols and OSI layer Worked on AJAX framework to transform Datasets and Data tables into HTTPserializable JSON strings Used Groovy and Grails withspring Java J2EE for user interface Built the web application by using Python Django AWS J2EE PostgreSQL MySQL Oracle 10g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins Extensive working experience in free marker Struts frameworkSpringframework and OR Mapping Hibernate framework Used differentPySparkAPIs to perform necessary transformations and actions on the data which gets from Kafka in real time Experience in usingobjectrelationalmapperORM library to automate the transfer of data stored inrelationaldatabases tables into objects Performed various Parsing techniques usingPySparkAPIS to cleanse the data from Kafka Had knowledge on continuous integration and deployment using Jenkins Docker Implemented Restful web service to interact withRedisCache framework Worked on developing Restful endpoints to cache application specific data in inmemory data clusters likeREDISand exposed them with Restful endpoints Experience in developing applications using amazon web services like EC2 Cloud Search Elastic Load balancer ELB S3 CloudFront Used SQL Alchemy asObjectRelationalMapperORM for writing ORM queries Worked with Spring Batch Used Spring ORM module to integrate withHibernate Developed custom consumers and producers for ApacheKafkain Go Golang for cars monitoring system Designed the realtime analytics and ingestion platform using Storm andKafka Wrote Storm topology to accept the events fromKafkaproducer and emit into Cassandra DB Manage the configurations of multiple servers usingAnsible Implemented realtime log analytics pipeline using Confluent Kafka storm elastic search Logstash Kibana and Greenplum Worked withKibanalog monitoring system and fixed a critical issue easily by capturing the context Maintaining the Elasticsearch cluster and Logstash nodes to process around 5TB of Data Daily from various sources like Kafka kubernetes etc Design build and manage the ELK Elasticsearch Logstash graphite Kibana cluster for centralized logging and search functionalities for the App Golang Infrastructure Teams and Engineering Productivity utilizing Kubernetes Docker influx  Ansible Spinnaker Deployed mircoservices2 including provisioning AWS environments usingAnsiblePlaybooks Provisioned load balancer autoscaling group and launch configuration for microservice usingAnsible UsedAnsibleplaybooks to setup Continuous Delivery pipeline This primarily consists of a Jenkins and Sonar server the infrastructure to run these packages and various supporting software components such as Maven etc Experience in writing playbooks forAnsibleand deploying applications usingAnsible Automated various infrastructure activities like Continuous Deployment Application Server setup Stack Monitoring usingAnsibleplaybooks and has integratedAnsiblewith Run deck and Jenkins Provisioned and patched servers regularly usingAnsible Created realtime dashboard for Executives utilizing Logstash graphite Elastic Search Kibana Redis ImplementedAnsibleto manage all existing servers and automate the buildconfiguration of new servers Developed anAnsiblerole for Zabbixagent which will be integrated into the to the CICD pipeline UsedAnsibleto document all infrastructures into version control UsedAnsibleto document application dependencies into version control Responsible for on boarding Application teams to build and deploy their code using GitHub Jenkins Nexus andAnsible Written transformations and actions on data frames usedSparkSQL on data frames to access hive tables intosparkfor faster processing of data Involved in converting HiveSQL queries intoSparktransformations usingSparkRDDs Python and Scala Used Hive to do transformations joins filter and some preaggregations after storing the data to HDFS UsedSparkStreaming APIs to perform necessary transformations and actions on the fly for building the common learner data model which gets the data from Kafka in near real time and Persists into Cassandra AutomatedRabbitMQcluster installations and configuration using PythonBash Excellent understanding and knowledge of Hadoop Distributed file system data modelling architecture and design principles and Developed Python Mapper and Reducer scripts and implemented them using Hadoop streaming Experienced in developing Web Services with Python programming language and Good working experience in processing large datasets with Spark using Scala and Spark Good working experience in processing large datasets with Spark using Scala and Spark and Familiar with JSON based REST Web services Experienced in understanding Service Virtualization needs Requirements creating VSIs using WSDL WADL Recording Request Response pairs Expertise in creating Restful API in NodeJS and communicate with Clojure server via protocol and use Backbone to generate template UsedKubernetesto deploy scale load balance scale and manage Docker containers with multiple name spaced versions Different grid operations using panda flask andSQL Alchemycombination Involved in multitiered J2EE design utilizing MVC architecture Spring StrutsHibernateand EJB deployed on WebSphere Application Server connecting to an Oracle database Developed and configured the Java beans using Struts MVC andHibernate Use AWS cloud management console spinnaker to work with AWS Wrote python scripts using boto3 library to manage ec2 instances and CloudFormation stack Developed CICD system with Jenkins on GooglesKubernetescontainer environment utilizingKubernetesand Docker for the runtime environment for the CICD system to build and test and deploy Strong handson on AWS cloud services like EC2 S3 RDS ELB and EBS for installing configuring Analyzed queries and database behavior usingPerconatools DB Tuna Developed backup and recovery engine for VM backuprecovery using VMware vSphere APIs Golang programming language andRabbitMQMessage bus communication interface Monitoring Cassandra cluster for resource utilization Managing Cassandra clusters using Datastax OpsCenter Knowledge of Cassandra systems backup and recovery Knowledge of Cassandra security Knowledge of Cassandra maintenance and tuning both database and server Created Terraform modules for two tier Architecture which includes AWS resources VPC Subnets Security groups Ec2 Load Balancers Auto scaling group CloudWatch Alarms ECS clusters S3 buckets for logs Built Jenkins jobs to create AWS infrastructure from GitHub repos containing Terraform code to deploy different Applications infrastructure for Dev QA and Preprod based on the requirement from different teams Built servers in AWS importing Volumes launching EC2 creating Security groups Auto scaling Load balancers ELBs and Installed required packages on servers Crypto Blockchain Bitcoin Monaro Bitcoin Cash Ecommerce platform built utilizing Python with Flask backend and JinjaJavaScript frontend Currently building RESTful service API to allow users to see Blockchain transactions orders and info Deployed on AWS and with services EC2 S3 CloudFront Configured AWS CLI and performed necessary actions on the AWS services using shell scripting Created Modules utilizing Requests JSON to interact RPC Wallet servers and Blockchain Created scripts that monitored a device using Prometheus andGrafanavia ODL sash GRPC NC Client and model driven telemetry and checked for memory leaks and health of the router Senior Python developer Kroger Ohio November 2015 to February 2017 Extensively used Python Django Framework for developing backend applications Strong Expertise in working with serverside technologies including databases Restful API and MVC design patterns Actively involved in Initial software development life cycle SDLC of requirement gathering and in suggesting system configuration specifications during client interaction Was leading an effort to build a real time click stream analytics platform for processing the beacons from web and mobile devices using Spark Kafka elastic and building dashboard using Kibana and Grafana Experience in the Hadoop ecosystem components like HDFSSparkwith Scala and python Zookeeper Yarn MapReduce Pig Sqoop HBase Hive Flume Cassandra MongoDB Oozie Kafka Flume and TEZ Hands on experience in developingSPARKapplications usingSparkAPIs likeSparkcoreSpark StreamingSparkMLlib andSparkSQL and worked with different file formats such as Text Sequence files Avro ORC JSON and Parquette UsedobjectrelationalmapperORM to automate the transfer of data stored inrelationaldatabases tables into objects Experience in using Design Patterns such as MVC Singleton and frameworks such as DJANGO Ability in handling Django ORM ObjectRelationalMapper and SQL Alchemy Implementing customer data collection withPySparkHadoop analytics Managed and reviewed Hadoop log file and also worked in analyzing SQL scripts and designed the solution for the process usingPySpark Develop customSAScode for performance monitoring reports Import excel files intoSASfor data manipulation and extraction DevelopedSAScode for data analysis and report generation using Macro Processing Proc Report to generate Excel spreadsheets Pysparkwe implemented Caching Accumulators and UDFs We have implementedpysparkfor Transformation and Actions in Spark Hands on experience withSparkCoreSparkSQL and Data FramesData SetsRDD API Changed mapreduce jobs and Hive scripts withSparkDataFrame transformation and action Excellent knowledge onSparkArchitecture and Hadoop Architecture and its ecosystems such as HDFS Job Tracker Task Tracker Name Node Data Node and Map Reduce programming paradigm Develop python code to automate the ingestion of common formats such as JSON CSV by using Logstash from elastic search toKibanadashboard to be viewed by clients Responsible for designing and deploying new ELK clusters Elasticsearch Logstash Graphite Kibana beats Kafka zookeeper etc Experience on Key AWS services EC2 S3 DynamoDB NoSQL and Lambda Responsible for the Automation of the deployment of the Conductor application on AWS lambda using highend AWS architectural components Developed AWS lambda scripts to build on demand EC2 instance formation AutomatedRabbitMQcluster installations and configuration using PythonBash Fixed issues related to OpenStack components such as Nova Glance Neutron Keystone MySQLPerconaDB RabbitMQ Cech Repose HAP Roxy and Horizon Experienced in developing API services PythonTornado while leveraging AMQP andRabbitMQfor distributed architectures Designed and developed web crawler in python using Scrappy framework and usingRabbitMQas a messaging server between the micro services Experience  check logs and other timestamped data sets stored in Elastic Search Written and Maintained Automated Salt scripts for Elasticsearch Logstash Kibana and Beats Worked on several python packages like NumPy Beautiful SoupSQL Alchemy Py Tables etc Developed full stack Python web framework with an emphasis on simplicity flexibility and extensibility It is built atop excellent components and reinvents zero wheels WSGI routing templating forms data plugins config  Alchemy Storm CouchDB OpenID App Engine jQuery etc Enabled continuous delivery via Gitlab Spinnaker Docker Jenkins Terraform and AWS Designed and developed load tests using Scala Gatling Migrated 10 TB of data from Oracle to Cassandra datacenter 12 nodes that have 4TB drives each using Stable Loader Worked on performance tuning of cluster using Cassandra Configuration file and JVM Parameters Configured internode communication between Cassandra nodes and client using SSL encryption Evaluated benchmarked and tuned data model by running endurance tests using JMeter Cassandra Stress Tool and OpsCenter Analysis of logs data and filter required columns by Logstash configuration and send it to Elasticsearch Validated BI Support events transformed and batched events which are sent to HNM andKafkaby triggering these events usingKafka Mesos Used micro service architecture with Spring Bootbased services interacting of REST andKafka DevelopedKafkaproducer and consumers HBase clients Spark shark Streams and Hadoop MapReduce jobs along with components on HDFS Hive Creating restful web services for Catalog and Pricing with Django MVT Jersey MySQL and MongoDB Worked with JSON based REST Web services and Amazon Web Services AWS Use AWS cloud management console spinnaker to work with AWS Wrote python scripts using boto3 library to manage ec2 instances and CloudFormation stack Created realtime dashboard for Executives utilizing Logstash graphite Elastic Search Kibana Redis Experience in configuring and working with Flume andKafkato load the data from multiple web sources directly into HDFS Used Redis cache for storing commonly used info and propagate the changes usingRabbitMQ Worked on Angular JS framework to develop interactive websites based on client needs Used Cassandra for database andRedisfor cache for storing and fetching the data UsedRedisCache for high performance which creates space for new data by removing old data Developed Ruby on Rails web applications using MongoDB and background processes using Risqu andRedis Utilized Python in the handling of all hits on DjangoRedis and other application Successfully migrated the websites main database from MySQL to PostgreSQL Helped the big data analytics team with implementation of python scripts for Sqoop spark and Hadoop batch data streaming Developed frontends using HTML5 CSS3 JavaScript and jQuery Designed and created the database tables and wrote SQL queries to access PostgreSQL Used Kubernetes to deploy scale load balance and worked on Docker Engine Docker HUB Docker Images Docker Compose for handling images for installations and domain configurations Implemented in Jenkins for Continuous Integration and for automating all builds and deployments and Build Jenkins jobs to createAWSinfrastructure from GitHub repos containing terraform code and Installed and Administered Jenkins CI for Maven Builds Developed Python based API RESTful Web Service to track the events and perform analysis using Flask Ingested large CSV XML JSON data from computers around the world utilizing Python with pandas csv xml and NumPy Formatted the raw data and built dynamic statistic pages for engineers Migrated data from a mongo  and python2 environment to an Elasticsearch python 3 workflow Developed Micro services for the HP team using Spring Boot and Java 8 IntegratedHibernateORM with SpringHibernateframework to facilitate DML and DQL queries and represent objectdatabase mapping Kubernetesis being used to orchestrate the deployment scaling and management of Docker Containers Used Jenkins pipelines to drive all micro services builds out to the Docker registry and then deployed toKubernetes Created Pods and managed usingKubernetes Managed local deployments inKubernetes creating local cluster and deploying application containers Wrote AJAX calls to populate tables tab menu and other components with JSON data in AngularJS Extensively used HTML5 AngularJS JSON AJAX and DOM scripting for form validations Worked on the MySQL migration project to make the system completely independent of the database being used UsedSpringto implement this Involved in multitiered J2EE design utilizing MVC architectureSpring Struts Hibernate and EJB deployed on WebSphere Application Server connecting to an Oracle database Implemented a continuous Delivery Pipeline with Jenkins and GitHub to build a newDocker container automatically UsedDockerto implement a highlevel API to provide lightweight containers that run processes isolation and worked on creation of customizedDockercontainer images tagged and pushed the images to theDockerrepository Participated in development of a well responsive single page application using AngularJS framework Java Script and jQuery in conjunction with HTML5 CSS3 standards with frontend UI team Extensively used HTML5 AngularJS JSON AJAX and DOM scripting for form validations Automated various infrastructure activities like Continuous Deployment Application Server setup Stack monitoring using Ansible playbooks and has Integrated Ansible with Run deck and Jenkins Wrote Ansible Playbooks with Python SSH as the Wrapper to Manage Configurations of AWS nodes and Tested Playbooks on AWS instances using Python Run Ansible Scripts to Provide Dev Servers Experience in using GIT Repository Managers for Maven builds Used Celery as task queue andRabbitMQ Redis as messaging broker to execute asynchronous tasks Python Developer UPS Atlanta GA August 2013 to October 2015 Developed Wrapper in Python for instantiating multithreaded application and Deploy and monitor scalable infrastructure on Amazon web services AWS Used Test driven approachTDD for developing services required for the application Managed datasets using Panda data frames and MySQL queries MYSQL database queries from python using PythonMySQL connector and MySQL  package to retrieve Datacenter migration to Amazon Web Services AWS infrastructure and provided initial support to Applications and Database teams Familiarity and experience with some ORM ObjectRelationalMapper libraries Developed requirements and enterprise architecture for EIA metadata Eguide and EBI underSASVB Developed and implemented Legacy system programs by using COBOL DB2 CICS JCL JAVA and VSAM ResponsibleSASreports analysis usingSASmacros in UNIX operating system Worked on Big Data infrastructure for batch processing and realtime processing using ApacheSpark Built scalable distributed Hadoop cluster running Hortonworks Data Platform Responsible for design and development ofSparkSQL Scripts based on Functional Specifications Worked on the largescale Hadoop YARN cluster for distributed data processing and analysis usingSpark Hive Develop python code to automate the ingestion of common formats such as JSON CSV by using Logstash from elastic search toKibanadashboard to be viewed by clients Responsible for designing and deploying new ELK clusters Elasticsearch Logstash Graphite Kibana beats Kafka zookeeper etc Parsed the unstructured data into semistructured format by writing complex algorithms inpyspark Extensive working experience in free marker Struts framework Spring framework and OR Mapping Hibernateframework Designed and codedHibernate struts for mapping configurations and HQL for enhancement and new module development of Transport Optimization Planning and Scheduling Web app AutomatedRabbitMQcluster installations and configuration using PythonBash Managed developed and designed a dashboard control panel for customers and Administrators using Django Oracle DB PostgreSQL and VMWare API calls Developed micro services usingspringboot exposed as REST API and integrated with AngularJS based web applications Integrated AD with Cassandra Authorization Designed Automated the process of installation and configuration of secure DataStax Enterprise Cassandra cluster using puppet Monitored the cluster with Zabbix Configured internode communication between Cassandra nodes and client using SSL encryption Developed shell scripts along with setting up of CRON jobs for monitoring and automated data backup on Cassandra cluster Created data frames schema from raw data stored at Amazon S3 lambda usingPySpark Created azure templates to automate server creation and DSE deployments Installed and configured Cassandra cluster and CQL on the cluster Experience in upgrading the existing Cassandra cluster to latest releases Implemented application level persistence using Hibernate andspring Configured Struts Hibernate framework withSpringMVC Docker container deploying micro services and scaling the deployment usingKubernetes Developed Chat Ops interfaces with slack andKuberneteson GKE Experience with Streaming platforms like ApacheKafka Used ApacheKafkaMessage Queues for reliable and asynchronous exchange of important information between multiple business applications Extensively used python modules such as requests urllib2 for web crawling Working on Spinnaker platform for MultiCloud Continuous Delivery Bake Test DeployContainer Pipelines using Packer Terraform Kubernetes AWS GCP SetupDockeron Linux and configured Jenkins to run underDockerhost Wrote and executed various MYSQL database queries from python using PythonMySQL connector and MySQL  package Managed local deployments inKubernetes creating local cluster and deploying application containers Experienced in developing API services PythonTornado while leveraging AMQP andRabbitMQfor distributed architectures Added support for Amazon AWS S3 and RDS to host staticmedia files and the database into Amazon Cloud Designed and managed API system deployment using fast http server and Amazon AWS architecture Design and implementation of CICD pipelines using Jenkins and automated CICD pipelines by invoking Ansible playbooks Automated the Oracle 12c installation using ansible scripts Automated email notification using celery andRabbitMQfor status of jobs and pending task list manager to users and admin Profound knowledge and experience on underlying mechanism of docker containers and automated the docker containers using Ansible Expertise in Implementing a Production ready Highly Available Fault Tolerant Kubernetes infrastructure Working on Scheduling deploying and managing container replicas on a node cluster using Kubernetes Setting up the CICD pipeline using GitHub Jenkins Maven Chef Terraform and AWS DevOps experience with GitHub Maven Nagios Docker Jenkins Puppet Chef Ansible Virtualized the servers using the Docker for the test environments and devenvironments needs and configuration automation using Docker Containers Integrated Kafka with Spark streaming for high speed data processing Built Web pages that are more userinteractive using Jasmine Karma HTML CSS LESS RESTFUL API Services JavaScript Bootstrap GIT and JSON Used Celery as task queue andRabbitMQ Redis as messaging broker to execute asynchronous tasks Built Web pages that are more userinteractive using Jasmine Karma HTML CSS LESS RESTFUL A Having good experience in Struts Spring IOC Spring MVC Spring Data Spring Boot Spring Security and other spring frameworks implementation and integration Followed Agile SCRUM methodology and used Test Driven Development TDD and Used BDD pattern for code quality and good readability standards Worked on Redux making to do list reduces reducers functions and implementing store method PI Services JavaScript Bootstrap GIT and JSON Implemented application level persistence usingHibernateand spring Configured StrutsHibernateframework with Spring MVC Written the Grok pattern in Logstash Configured Logstash input filter output plugins database log file sources and elastic search as output Python developer Aetna Hartford CT August 2011 to July 2013 Designed Installed and Implemented Ansible configuration management system Used Ansible to manage Web applications Environments configuration Files Users Mount points and Packages Involved in database Administration activities like taking backup checking log messages looking for database optimization Executed asynchronous tasks with help of Celery and RabbitMQ Developed Kafka consumers to consume data from Kafka topics Responsible for Configuring Kafka Consumer and Producer metrics to visualize the Kafka System performance and monitoring Experience with Kibana to check logs and other timestamped data sets stored in Elastic Search Written and Maintained Automated Salt scripts for Elasticsearch Logstash Kibana and Beats Used Amazon Web Services AWS for improved efficiency of storage and fast access Vast experience with Core Java and J2EE using most of the advanced features of Java including JDBC Spring Struts EJB Servlets Hibernate Added support for Amazon AWS S3 and RDS to host staticmedia files and the database into Amazon Cloud Developed Merge jobs in Python to extract and load data into MySQL database and used Test driven approach for developing applications Cloud platform engineering Kubernetes Spinnaker Docker Terraform Consul drone Jenkins Chef Kitchen Scheduled deployed and managed container replicas onto a node cluster using Kubernetes Developed views and templates with Python and Django view controller and templating language to create a userfriendly interface using MVC architecture Worked on resulting reports of the application and Tableau reports and involved in modifying data using SASBASE SAS MACROS Extracting data from the database using SASAccess SAS SQL procedures and create SAS data sets Involved in installing software using pip command for python libraries like Beautiful Soup NumPy SciPy pythontwitter RabbitMQ Celery matplotlib Pandas dataframe and used the PEP8 coding convention Migration of API code written for Sybase to Oracle and was involved in Overlook the migration activity of PLSQL programs Managed local deployments in Kubernetes creating local cluster and deploying application containers Build backend application with Python Django Worked on Dockers RabbitMQ Celery and Jenkins Experienced in implementing Model View Control MVC architecture using serverside applications like Django and Flask for developing web applications Involved in the migration of the data contained in the earlier ASPL Database from Sybase to Oracle Expertise in working with serverside technologies including Databases Restful API and MVC design patterns Wrote and executed various MySQL database queries from PythonMySQL connector and MySQL db package Used the Python modules NumPy matplotlib etc for generating complex graphical data creation of histograms etc Involved in migrating the Libraries written using Sybase APIs to Oracle OCCI API Automate Build and Release tasks using ANT Shell and Perl for efficiency and repeatability Communication with team members for both Ansible Core and Ansible Tower teams to clarify requirements and overcome obstacles Automated various service and application deployments with ANSIBLE on CentOS and RHEL in AWS Wrote ANSIBLE Playbooks with Python SSH as the Wrapper to Manage Configurations of AWS Nodes and Test Playbooks on AWS instances using Python Run Ansible Scripts to provision Dev servers Used Python Libraries Pandas and NumPy SQL and Tableau to procure clean and aggregate data from Relational database to generate status reports and dashboards Education Bachelors Skills DJANGO 5 years PYTHON 7 years jQuery 5 years AJAX 5 years Flask 5 years Restful 5 years AWS 5 years rabbitMQ 3 years Ajax 4 years Agile 4 years azure 3 years Additional Information SKILLS Python 3327 Django 1413 Flask Java C Shell Script SQL JavaJ2EE AJAX JavaScript HTML DHTML XHTML XML React JSON Jquery Angularjs",
    "entities": [
        "Spring Bootbased",
        "Continuous Deployment Application Server",
        "Functional Specifications Worked",
        "Python Developer UPS Atlanta",
        "AJAX",
        "ApacheKafka Used ApacheKafkaMessage Queues",
        "Amazon AWS architecture",
        "Spark AWS",
        "GitHub Maven Nagios",
        "Test Driven Development TDD",
        "ORM",
        "PythonBash",
        "Risqu andRedis Utilized Python",
        "Relational",
        "UNIX",
        "Libraries",
        "DataStax Enterprise Cassandra",
        "EIA",
        "Python Django AWS J2EE PostgreSQL",
        "ImplementedAnsibleto",
        "GooglesKubernetescontainer",
        "Design Patterns",
        "JSON",
        "Created Terraform",
        "OpenStack",
        "Cassandra DB Manage",
        "Amazon Web Services AWS",
        "Heroku",
        "Panda",
        "Release",
        "Model View Control MVC",
        "Hadoop",
        "Kubernetes Spinnaker Docker Terraform Consul",
        "DHTML",
        "CRON",
        "OpsCenter Analysis",
        "Amazon Web Services AWS Use AWS",
        "NodeJS",
        "DevOps",
        "ANT Shell",
        "HBase",
        "Automated",
        "SASAccess SAS SQL",
        "Cassandra Configuration",
        "Devops",
        "HNM",
        "TX",
        "Amazon",
        "Amazon S3",
        "Software Development Life Cycle and Software Testing Methodology Good",
        "VMware vSphere",
        "ELK",
        "Python",
        "Migration of API",
        "Amazon AWS S3",
        "Developed",
        "Developed micro services",
        "Redshift Extracting",
        "Node Data",
        "Conductor",
        "Spring MVC",
        "SpringHibernateframework",
        "Hadoop MapReduce",
        "Restful",
        "JSON Used Celery",
        "UsedAnsibleto",
        "UsedKubernetesto",
        "Spark Hands",
        "DQL",
        "forAnsibleand",
        "Monitored",
        "ANSIBLE",
        "SOA",
        "Cech Repose HAP Roxy",
        "API RESTful Web Service",
        "Installed and Administered Jenkins CI",
        "the Software Development Life Cycle",
        "Data Daily",
        "GitHub Jenkins Nexus andAnsible Written",
        "EJB Servlets Hibernate Added",
        "Flask",
        "AWS Wrote",
        "MVC Singleton",
        "Built",
        "Performed various Parsing",
        "Storm andKafka Wrote Storm",
        "VMWare API",
        "Kubernetes Modifying",
        "Docker",
        "ASPL Database",
        "DOM",
        "Oracle OCCI API Automate Build",
        "Maintaining the Elasticsearch",
        "RDS",
        "Celery",
        "Elasticsearch Validated",
        "SSL",
        "Kubernetesis",
        "PEP8",
        "CLI",
        "Transport Optimization Planning and Scheduling",
        "MVC",
        "Spark",
        "Redux",
        "jQuery Designed",
        "Developed Python Mapper",
        "Created Modules",
        "EJB",
        "DSE",
        "Bugzilla",
        "Datastax OpsCenter Knowledge of Cassandra systems backup",
        "HTML CSS",
        "WSGI",
        "API",
        "US",
        "Terraform",
        "Sqoop",
        "Sybase",
        "QA",
        "Writing SQL Queries Stored",
        "UsedDockerto",
        "Python Django Framework",
        "JMeter Cassandra Stress Tool",
        "the App Golang Infrastructure Teams",
        "Created",
        "Scala",
        "AWS",
        "Analyzed",
        "Hadoop Architecture",
        "Jenkins Provisioned",
        "Gitlab Spinnaker Docker Jenkins Terraform",
        "Implemented",
        "Developed Micro",
        "Aetna",
        "Pyspark",
        "Oracle Expertise",
        "ELB",
        "HDFS Job Tracker Task Tracker",
        "Maven Builds Developed Python",
        "SAS",
        "Macro Processing Proc Report",
        "AWS Cloud Architecture Experienced",
        "Shell Scripting Server Unix",
        "Kubernetes Docker",
        "Elasticsearch",
        "SQL",
        "OSI",
        "Clojure",
        "PythonBash Fixed",
        "GitHub",
        "Django Oracle DB PostgreSQL",
        "DML",
        "lPythonspan",
        "newDocker",
        "PI Services",
        "Mesos Used micro service",
        "S3 CloudFront Configured AWS",
        "Kubernetes",
        "Administrators",
        "WebApplication Developer",
        "UsedSpringto",
        "JVM Parameters Configured",
        "SSH",
        "SQL Alchemy",
        "GIT Repository Managers",
        "Spring StrutsHibernateand EJB",
        "UsedAnsibleplaybooks",
        "Profound",
        "CICD",
        "Packer Terraform Kubernetes AWS GCP",
        "Golang",
        "Pandas",
        "Developed AWS",
        "Python Django Worked on Dockers RabbitMQ",
        "Maven",
        "Zabbix Configured",
        "Kubernetes Developed",
        "Logstash",
        "UI",
        "Nova",
        "CQL",
        "BDD",
        "Spark shark Streams",
        "Kroger",
        "Kafka System",
        "GRPC NC Client",
        "CloudWatch Alarms ECS",
        "SQL Queries Stored",
        "RPC Wallet",
        "Expertise",
        "Transformation and Actions",
        "jQuery",
        "GitHub Jenkins Maven Chef Terraform",
        "REST",
        "Data",
        "Communication",
        "NetConf",
        "Developed Ruby on Rails",
        "NoSQL",
        "Tableau",
        "Application",
        "Shell Scriptings Server Unix",
        "EBS",
        "WebSphere Application Server",
        "Horizon Experienced",
        "Grafana Experience",
        "PythonTornado",
        "Overlook",
        "Lambda Responsible",
        "CloudFormation",
        "Ohio"
    ],
    "experience": "Experience working with network protocols SNMP NetConf Experience in developing applications using amazon web services like EC2 Cloud Search Elastic Load balancer ELB S3 Cloud Front Used R Language among statisticians and data miners for developing statistical software and data analysis Expertise in operating Symantec Altiris Remote Agent to remotely fix problems Excellent understanding and knowledge of Hadoop Distributed file system data modelling architecture and design principles and Developed Python Mapper and Reducer scripts and implemented them using Hadoop streaming Experienced in developing Web Services with Python programming language and Good working experience in processing large datasets with Spark using Scala and Pyspark Good working experience in processing large datasets with Spark using Scala and Pyspark and Familiar with JSON based REST Web services Experienced in understanding Service Virtualization needs Requirements creating VSIs using WSDL WADL Recording Request Response pairs Expertise in creating Restful API in NodeJS and communicate with Clojure server via protocol and use Backbone to generate template Built the web application by using Python Django AWS J2EE PostgreSQL MySQL Oracle 10 g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins Strong handson on AWS cloud services like EC2 S3 RDS ELB and EBS for installing configuring Experienced in understanding Service Virtualization needs Requirements creating VSIs using Authorized to work in the US for any employer Work Experience Senior Python Developer Phillips 66 Houston Houston TX March 2017 to Present Over 7 years of experience as a WebApplication Developer and coding with analytical Programming using Python Django Java Involved in software development in Python libraries used Beautiful Soup NumPy SciPy matplotlib Pandas data frame network urllib2 MySQL   for database connectivity and IDEs sublime text Spyder PyCharm Good knowledge of web services with protocols SOAP REST and knowledge of server Apache Tomcat WebLogic Hands on experience in SVN Git JIRA and Bugzilla worked in SQL databases MS SQL Apache Cassandra Oracle and MongoDB Used AWS lambda to run code virtually Developed API for using AWS Lambda to manage the servers and run the code in AWS SQL and PLSQL programming developing complex code units database triggers and using the latest features to optimize performance Bulk Binds Materialized views Inline views Global Temporary Tables Good experience in Shell Scripting Server Unix and Linux Open stock and Expertise python scripting with focus on DevOps tools CICD and AWS Cloud Architecture Working with containerbased deployments using Docker working with Docker images Docker Hub and Docker registries and Kubernetes Modifying data usingSASBASESAS MACROS Open Source templatebased Qt reporting solution Big data processing using Spark AWS and Redshift Extracting data from the database usingSASAccessSASSQL procedures and createSASdata sets Writing SQL Queries Stored procedures functions packages tables views triggers Knowledge of the Software Development Life Cycle SDLC Agile and Waterfall Methodologies and Familiar with concepts and devices such routers switches and TCPIP protocols and OSI layer Worked on AJAX framework to transform Datasets and Data tables into HTTPserializable JSON strings Used Groovy and Grails withspring Java J2EE for user interface Built the web application by using Python Django AWS J2EE PostgreSQL MySQL Oracle 10 g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins Extensive working experience in free marker Struts frameworkSpringframework and OR Mapping Hibernate framework Used differentPySparkAPIs to perform necessary transformations and actions on the data which gets from Kafka in real time Experience in usingobjectrelationalmapperORM library to automate the transfer of data stored inrelationaldatabases tables into objects Performed various Parsing techniques usingPySparkAPIS to cleanse the data from Kafka Had knowledge on continuous integration and deployment using Jenkins Docker Implemented Restful web service to interact withRedisCache framework Worked on developing Restful endpoints to cache application specific data in inmemory data clusters likeREDISand exposed them with Restful endpoints Experience in developing applications using amazon web services like EC2 Cloud Search Elastic Load balancer ELB S3 CloudFront Used SQL Alchemy asObjectRelationalMapperORM for writing ORM queries Worked with Spring Batch Used Spring ORM module to integrate withHibernate Developed custom consumers and producers for ApacheKafkain Go Golang for cars monitoring system Designed the realtime analytics and ingestion platform using Storm andKafka Wrote Storm topology to accept the events fromKafkaproducer and emit into Cassandra DB Manage the configurations of multiple servers usingAnsible Implemented realtime log analytics pipeline using Confluent Kafka storm elastic search Logstash Kibana and Greenplum Worked withKibanalog monitoring system and fixed a critical issue easily by capturing the context Maintaining the Elasticsearch cluster and Logstash nodes to process around 5 TB of Data Daily from various sources like Kafka kubernetes etc Design build and manage the ELK Elasticsearch Logstash graphite Kibana cluster for centralized logging and search functionalities for the App Golang Infrastructure Teams and Engineering Productivity utilizing Kubernetes Docker influx   Ansible Spinnaker Deployed mircoservices2 including provisioning AWS environments usingAnsiblePlaybooks Provisioned load balancer autoscaling group and launch configuration for microservice usingAnsible UsedAnsibleplaybooks to setup Continuous Delivery pipeline This primarily consists of a Jenkins and Sonar server the infrastructure to run these packages and various supporting software components such as Maven etc Experience in writing playbooks forAnsibleand deploying applications usingAnsible Automated various infrastructure activities like Continuous Deployment Application Server setup Stack Monitoring usingAnsibleplaybooks and has integratedAnsiblewith Run deck and Jenkins Provisioned and patched servers regularly usingAnsible Created realtime dashboard for Executives utilizing Logstash graphite Elastic Search Kibana Redis ImplementedAnsibleto manage all existing servers and automate the buildconfiguration of new servers Developed anAnsiblerole for Zabbixagent which will be integrated into the to the CICD pipeline UsedAnsibleto document all infrastructures into version control UsedAnsibleto document application dependencies into version control Responsible for on boarding Application teams to build and deploy their code using GitHub Jenkins Nexus andAnsible Written transformations and actions on data frames usedSparkSQL on data frames to access hive tables intosparkfor faster processing of data Involved in converting HiveSQL queries intoSparktransformations usingSparkRDDs Python and Scala Used Hive to do transformations joins filter and some preaggregations after storing the data to HDFS UsedSparkStreaming APIs to perform necessary transformations and actions on the fly for building the common learner data model which gets the data from Kafka in near real time and Persists into Cassandra AutomatedRabbitMQcluster installations and configuration using PythonBash Excellent understanding and knowledge of Hadoop Distributed file system data modelling architecture and design principles and Developed Python Mapper and Reducer scripts and implemented them using Hadoop streaming Experienced in developing Web Services with Python programming language and Good working experience in processing large datasets with Spark using Scala and Spark Good working experience in processing large datasets with Spark using Scala and Spark and Familiar with JSON based REST Web services Experienced in understanding Service Virtualization needs Requirements creating VSIs using WSDL WADL Recording Request Response pairs Expertise in creating Restful API in NodeJS and communicate with Clojure server via protocol and use Backbone to generate template UsedKubernetesto deploy scale load balance scale and manage Docker containers with multiple name spaced versions Different grid operations using panda flask andSQL Alchemycombination Involved in multitiered J2EE design utilizing MVC architecture Spring StrutsHibernateand EJB deployed on WebSphere Application Server connecting to an Oracle database Developed and configured the Java beans using Struts MVC andHibernate Use AWS cloud management console spinnaker to work with AWS Wrote python scripts using boto3 library to manage ec2 instances and CloudFormation stack Developed CICD system with Jenkins on GooglesKubernetescontainer environment utilizingKubernetesand Docker for the runtime environment for the CICD system to build and test and deploy Strong handson on AWS cloud services like EC2 S3 RDS ELB and EBS for installing configuring Analyzed queries and database behavior usingPerconatools DB Tuna Developed backup and recovery engine for VM backuprecovery using VMware vSphere APIs Golang programming language andRabbitMQMessage bus communication interface Monitoring Cassandra cluster for resource utilization Managing Cassandra clusters using Datastax OpsCenter Knowledge of Cassandra systems backup and recovery Knowledge of Cassandra security Knowledge of Cassandra maintenance and tuning both database and server Created Terraform modules for two tier Architecture which includes AWS resources VPC Subnets Security groups Ec2 Load Balancers Auto scaling group CloudWatch Alarms ECS clusters S3 buckets for logs Built Jenkins jobs to create AWS infrastructure from GitHub repos containing Terraform code to deploy different Applications infrastructure for Dev QA and Preprod based on the requirement from different teams Built servers in AWS importing Volumes launching EC2 creating Security groups Auto scaling Load balancers ELBs and Installed required packages on servers Crypto Blockchain Bitcoin Monaro Bitcoin Cash Ecommerce platform built utilizing Python with Flask backend and JinjaJavaScript frontend Currently building RESTful service API to allow users to see Blockchain transactions orders and info Deployed on AWS and with services EC2 S3 CloudFront Configured AWS CLI and performed necessary actions on the AWS services using shell scripting Created Modules utilizing Requests JSON to interact RPC Wallet servers and Blockchain Created scripts that monitored a device using Prometheus andGrafanavia ODL sash GRPC NC Client and model driven telemetry and checked for memory leaks and health of the router Senior Python developer Kroger Ohio November 2015 to February 2017 Extensively used Python Django Framework for developing backend applications Strong Expertise in working with serverside technologies including databases Restful API and MVC design patterns Actively involved in Initial software development life cycle SDLC of requirement gathering and in suggesting system configuration specifications during client interaction Was leading an effort to build a real time click stream analytics platform for processing the beacons from web and mobile devices using Spark Kafka elastic and building dashboard using Kibana and Grafana Experience in the Hadoop ecosystem components like HDFSSparkwith Scala and python Zookeeper Yarn MapReduce Pig Sqoop HBase Hive Flume Cassandra MongoDB Oozie Kafka Flume and TEZ Hands on experience in developingSPARKapplications usingSparkAPIs likeSparkcoreSpark StreamingSparkMLlib andSparkSQL and worked with different file formats such as Text Sequence files Avro ORC JSON and Parquette UsedobjectrelationalmapperORM to automate the transfer of data stored inrelationaldatabases tables into objects Experience in using Design Patterns such as MVC Singleton and frameworks such as DJANGO Ability in handling Django ORM ObjectRelationalMapper and SQL Alchemy Implementing customer data collection withPySparkHadoop analytics Managed and reviewed Hadoop log file and also worked in analyzing SQL scripts and designed the solution for the process usingPySpark Develop customSAScode for performance monitoring reports Import excel files intoSASfor data manipulation and extraction DevelopedSAScode for data analysis and report generation using Macro Processing Proc Report to generate Excel spreadsheets Pysparkwe implemented Caching Accumulators and UDFs We have implementedpysparkfor Transformation and Actions in Spark Hands on experience withSparkCoreSparkSQL and Data FramesData SetsRDD API Changed mapreduce jobs and Hive scripts withSparkDataFrame transformation and action Excellent knowledge onSparkArchitecture and Hadoop Architecture and its ecosystems such as HDFS Job Tracker Task Tracker Name Node Data Node and Map Reduce programming paradigm Develop python code to automate the ingestion of common formats such as JSON CSV by using Logstash from elastic search toKibanadashboard to be viewed by clients Responsible for designing and deploying new ELK clusters Elasticsearch Logstash Graphite Kibana beats Kafka zookeeper etc Experience on Key AWS services EC2 S3 DynamoDB NoSQL and Lambda Responsible for the Automation of the deployment of the Conductor application on AWS lambda using highend AWS architectural components Developed AWS lambda scripts to build on demand EC2 instance formation AutomatedRabbitMQcluster installations and configuration using PythonBash Fixed issues related to OpenStack components such as Nova Glance Neutron Keystone MySQLPerconaDB RabbitMQ Cech Repose HAP Roxy and Horizon Experienced in developing API services PythonTornado while leveraging AMQP andRabbitMQfor distributed architectures Designed and developed web crawler in python using Scrappy framework and usingRabbitMQas a messaging server between the micro services Experience   check logs and other timestamped data sets stored in Elastic Search Written and Maintained Automated Salt scripts for Elasticsearch Logstash Kibana and Beats Worked on several python packages like NumPy Beautiful SoupSQL Alchemy Py Tables etc Developed full stack Python web framework with an emphasis on simplicity flexibility and extensibility It is built atop excellent components and reinvents zero wheels WSGI routing templating forms data plugins config   Alchemy Storm CouchDB OpenID App Engine jQuery etc Enabled continuous delivery via Gitlab Spinnaker Docker Jenkins Terraform and AWS Designed and developed load tests using Scala Gatling Migrated 10 TB of data from Oracle to Cassandra datacenter 12 nodes that have 4 TB drives each using Stable Loader Worked on performance tuning of cluster using Cassandra Configuration file and JVM Parameters Configured internode communication between Cassandra nodes and client using SSL encryption Evaluated benchmarked and tuned data model by running endurance tests using JMeter Cassandra Stress Tool and OpsCenter Analysis of logs data and filter required columns by Logstash configuration and send it to Elasticsearch Validated BI Support events transformed and batched events which are sent to HNM andKafkaby triggering these events usingKafka Mesos Used micro service architecture with Spring Bootbased services interacting of REST andKafka DevelopedKafkaproducer and consumers HBase clients Spark shark Streams and Hadoop MapReduce jobs along with components on HDFS Hive Creating restful web services for Catalog and Pricing with Django MVT Jersey MySQL and MongoDB Worked with JSON based REST Web services and Amazon Web Services AWS Use AWS cloud management console spinnaker to work with AWS Wrote python scripts using boto3 library to manage ec2 instances and CloudFormation stack Created realtime dashboard for Executives utilizing Logstash graphite Elastic Search Kibana Redis Experience in configuring and working with Flume andKafkato load the data from multiple web sources directly into HDFS Used Redis cache for storing commonly used info and propagate the changes usingRabbitMQ Worked on Angular JS framework to develop interactive websites based on client needs Used Cassandra for database andRedisfor cache for storing and fetching the data UsedRedisCache for high performance which creates space for new data by removing old data Developed Ruby on Rails web applications using MongoDB and background processes using Risqu andRedis Utilized Python in the handling of all hits on DjangoRedis and other application Successfully migrated the websites main database from MySQL to PostgreSQL Helped the big data analytics team with implementation of python scripts for Sqoop spark and Hadoop batch data streaming Developed frontends using HTML5 CSS3 JavaScript and jQuery Designed and created the database tables and wrote SQL queries to access PostgreSQL Used Kubernetes to deploy scale load balance and worked on Docker Engine Docker HUB Docker Images Docker Compose for handling images for installations and domain configurations Implemented in Jenkins for Continuous Integration and for automating all builds and deployments and Build Jenkins jobs to createAWSinfrastructure from GitHub repos containing terraform code and Installed and Administered Jenkins CI for Maven Builds Developed Python based API RESTful Web Service to track the events and perform analysis using Flask Ingested large CSV XML JSON data from computers around the world utilizing Python with pandas csv xml and NumPy Formatted the raw data and built dynamic statistic pages for engineers Migrated data from a mongo   and python2 environment to an Elasticsearch python 3 workflow Developed Micro services for the HP team using Spring Boot and Java 8 IntegratedHibernateORM with SpringHibernateframework to facilitate DML and DQL queries and represent objectdatabase mapping Kubernetesis being used to orchestrate the deployment scaling and management of Docker Containers Used Jenkins pipelines to drive all micro services builds out to the Docker registry and then deployed toKubernetes Created Pods and managed usingKubernetes Managed local deployments inKubernetes creating local cluster and deploying application containers Wrote AJAX calls to populate tables tab menu and other components with JSON data in AngularJS Extensively used HTML5 AngularJS JSON AJAX and DOM scripting for form validations Worked on the MySQL migration project to make the system completely independent of the database being used UsedSpringto implement this Involved in multitiered J2EE design utilizing MVC architectureSpring Struts Hibernate and EJB deployed on WebSphere Application Server connecting to an Oracle database Implemented a continuous Delivery Pipeline with Jenkins and GitHub to build a newDocker container automatically UsedDockerto implement a highlevel API to provide lightweight containers that run processes isolation and worked on creation of customizedDockercontainer images tagged and pushed the images to theDockerrepository Participated in development of a well responsive single page application using AngularJS framework Java Script and jQuery in conjunction with HTML5 CSS3 standards with frontend UI team Extensively used HTML5 AngularJS JSON AJAX and DOM scripting for form validations Automated various infrastructure activities like Continuous Deployment Application Server setup Stack monitoring using Ansible playbooks and has Integrated Ansible with Run deck and Jenkins Wrote Ansible Playbooks with Python SSH as the Wrapper to Manage Configurations of AWS nodes and Tested Playbooks on AWS instances using Python Run Ansible Scripts to Provide Dev Servers Experience in using GIT Repository Managers for Maven builds Used Celery as task queue andRabbitMQ Redis as messaging broker to execute asynchronous tasks Python Developer UPS Atlanta GA August 2013 to October 2015 Developed Wrapper in Python for instantiating multithreaded application and Deploy and monitor scalable infrastructure on Amazon web services AWS Used Test driven approachTDD for developing services required for the application Managed datasets using Panda data frames and MySQL queries MYSQL database queries from python using PythonMySQL connector and MySQL   package to retrieve Datacenter migration to Amazon Web Services AWS infrastructure and provided initial support to Applications and Database teams Familiarity and experience with some ORM ObjectRelationalMapper libraries Developed requirements and enterprise architecture for EIA metadata Eguide and EBI underSASVB Developed and implemented Legacy system programs by using COBOL DB2 CICS JCL JAVA and VSAM ResponsibleSASreports analysis usingSASmacros in UNIX operating system Worked on Big Data infrastructure for batch processing and realtime processing using ApacheSpark Built scalable distributed Hadoop cluster running Hortonworks Data Platform Responsible for design and development ofSparkSQL Scripts based on Functional Specifications Worked on the largescale Hadoop YARN cluster for distributed data processing and analysis usingSpark Hive Develop python code to automate the ingestion of common formats such as JSON CSV by using Logstash from elastic search toKibanadashboard to be viewed by clients Responsible for designing and deploying new ELK clusters Elasticsearch Logstash Graphite Kibana beats Kafka zookeeper etc Parsed the unstructured data into semistructured format by writing complex algorithms inpyspark Extensive working experience in free marker Struts framework Spring framework and OR Mapping Hibernateframework Designed and codedHibernate struts for mapping configurations and HQL for enhancement and new module development of Transport Optimization Planning and Scheduling Web app AutomatedRabbitMQcluster installations and configuration using PythonBash Managed developed and designed a dashboard control panel for customers and Administrators using Django Oracle DB PostgreSQL and VMWare API calls Developed micro services usingspringboot exposed as REST API and integrated with AngularJS based web applications Integrated AD with Cassandra Authorization Designed Automated the process of installation and configuration of secure DataStax Enterprise Cassandra cluster using puppet Monitored the cluster with Zabbix Configured internode communication between Cassandra nodes and client using SSL encryption Developed shell scripts along with setting up of CRON jobs for monitoring and automated data backup on Cassandra cluster Created data frames schema from raw data stored at Amazon S3 lambda usingPySpark Created azure templates to automate server creation and DSE deployments Installed and configured Cassandra cluster and CQL on the cluster Experience in upgrading the existing Cassandra cluster to latest releases Implemented application level persistence using Hibernate andspring Configured Struts Hibernate framework withSpringMVC Docker container deploying micro services and scaling the deployment usingKubernetes Developed Chat Ops interfaces with slack andKuberneteson GKE Experience with Streaming platforms like ApacheKafka Used ApacheKafkaMessage Queues for reliable and asynchronous exchange of important information between multiple business applications Extensively used python modules such as requests urllib2 for web crawling Working on Spinnaker platform for MultiCloud Continuous Delivery Bake Test DeployContainer Pipelines using Packer Terraform Kubernetes AWS GCP SetupDockeron Linux and configured Jenkins to run underDockerhost Wrote and executed various MYSQL database queries from python using PythonMySQL connector and MySQL   package Managed local deployments inKubernetes creating local cluster and deploying application containers Experienced in developing API services PythonTornado while leveraging AMQP andRabbitMQfor distributed architectures Added support for Amazon AWS S3 and RDS to host staticmedia files and the database into Amazon Cloud Designed and managed API system deployment using fast http server and Amazon AWS architecture Design and implementation of CICD pipelines using Jenkins and automated CICD pipelines by invoking Ansible playbooks Automated the Oracle 12c installation using ansible scripts Automated email notification using celery andRabbitMQfor status of jobs and pending task list manager to users and admin Profound knowledge and experience on underlying mechanism of docker containers and automated the docker containers using Ansible Expertise in Implementing a Production ready Highly Available Fault Tolerant Kubernetes infrastructure Working on Scheduling deploying and managing container replicas on a node cluster using Kubernetes Setting up the CICD pipeline using GitHub Jenkins Maven Chef Terraform and AWS DevOps experience with GitHub Maven Nagios Docker Jenkins Puppet Chef Ansible Virtualized the servers using the Docker for the test environments and devenvironments needs and configuration automation using Docker Containers Integrated Kafka with Spark streaming for high speed data processing Built Web pages that are more userinteractive using Jasmine Karma HTML CSS LESS RESTFUL API Services JavaScript Bootstrap GIT and JSON Used Celery as task queue andRabbitMQ Redis as messaging broker to execute asynchronous tasks Built Web pages that are more userinteractive using Jasmine Karma HTML CSS LESS RESTFUL A Having good experience in Struts Spring IOC Spring MVC Spring Data Spring Boot Spring Security and other spring frameworks implementation and integration Followed Agile SCRUM methodology and used Test Driven Development TDD and Used BDD pattern for code quality and good readability standards Worked on Redux making to do list reduces reducers functions and implementing store method PI Services JavaScript Bootstrap GIT and JSON Implemented application level persistence usingHibernateand spring Configured StrutsHibernateframework with Spring MVC Written the Grok pattern in Logstash Configured Logstash input filter output plugins database log file sources and elastic search as output Python developer Aetna Hartford CT August 2011 to July 2013 Designed Installed and Implemented Ansible configuration management system Used Ansible to manage Web applications Environments configuration Files Users Mount points and Packages Involved in database Administration activities like taking backup checking log messages looking for database optimization Executed asynchronous tasks with help of Celery and RabbitMQ Developed Kafka consumers to consume data from Kafka topics Responsible for Configuring Kafka Consumer and Producer metrics to visualize the Kafka System performance and monitoring Experience with Kibana to check logs and other timestamped data sets stored in Elastic Search Written and Maintained Automated Salt scripts for Elasticsearch Logstash Kibana and Beats Used Amazon Web Services AWS for improved efficiency of storage and fast access Vast experience with Core Java and J2EE using most of the advanced features of Java including JDBC Spring Struts EJB Servlets Hibernate Added support for Amazon AWS S3 and RDS to host staticmedia files and the database into Amazon Cloud Developed Merge jobs in Python to extract and load data into MySQL database and used Test driven approach for developing applications Cloud platform engineering Kubernetes Spinnaker Docker Terraform Consul drone Jenkins Chef Kitchen Scheduled deployed and managed container replicas onto a node cluster using Kubernetes Developed views and templates with Python and Django view controller and templating language to create a userfriendly interface using MVC architecture Worked on resulting reports of the application and Tableau reports and involved in modifying data using SASBASE SAS MACROS Extracting data from the database using SASAccess SAS SQL procedures and create SAS data sets Involved in installing software using pip command for python libraries like Beautiful Soup NumPy SciPy pythontwitter RabbitMQ Celery matplotlib Pandas dataframe and used the PEP8 coding convention Migration of API code written for Sybase to Oracle and was involved in Overlook the migration activity of PLSQL programs Managed local deployments in Kubernetes creating local cluster and deploying application containers Build backend application with Python Django Worked on Dockers RabbitMQ Celery and Jenkins Experienced in implementing Model View Control MVC architecture using serverside applications like Django and Flask for developing web applications Involved in the migration of the data contained in the earlier ASPL Database from Sybase to Oracle Expertise in working with serverside technologies including Databases Restful API and MVC design patterns Wrote and executed various MySQL database queries from PythonMySQL connector and MySQL db package Used the Python modules NumPy matplotlib etc for generating complex graphical data creation of histograms etc Involved in migrating the Libraries written using Sybase APIs to Oracle OCCI API Automate Build and Release tasks using ANT Shell and Perl for efficiency and repeatability Communication with team members for both Ansible Core and Ansible Tower teams to clarify requirements and overcome obstacles Automated various service and application deployments with ANSIBLE on CentOS and RHEL in AWS Wrote ANSIBLE Playbooks with Python SSH as the Wrapper to Manage Configurations of AWS Nodes and Test Playbooks on AWS instances using Python Run Ansible Scripts to provision Dev servers Used Python Libraries Pandas and NumPy SQL and Tableau to procure clean and aggregate data from Relational database to generate status reports and dashboards Education Bachelors Skills DJANGO 5 years PYTHON 7 years jQuery 5 years AJAX 5 years Flask 5 years Restful 5 years AWS 5 years rabbitMQ 3 years Ajax 4 years Agile 4 years azure 3 years Additional Information SKILLS Python 3327 Django 1413 Flask Java C Shell Script SQL JavaJ2EE AJAX JavaScript HTML DHTML XHTML XML React JSON Jquery Angularjs",
    "extracted_keywords": [
        "Python",
        "Developer",
        "Senior",
        "span",
        "lPythonspan",
        "span",
        "lDeveloperspan",
        "Senior",
        "Python",
        "Developer",
        "Redwood",
        "City",
        "CA",
        "years",
        "experience",
        "applications",
        "software",
        "development",
        "design",
        "Python",
        "Django",
        "XML",
        "CSS",
        "HTML",
        "DHTML",
        "JavaScript",
        "JQuery",
        "Angular",
        "Js",
        "years",
        "QA",
        "experience",
        "environment",
        "types",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "Software",
        "Testing",
        "Methodology",
        "Good",
        "experience",
        "Shell",
        "Scriptings",
        "Server",
        "Unix",
        "Linux",
        "Open",
        "stock",
        "Expertise",
        "python",
        "focus",
        "Devops",
        "tools",
        "CICD",
        "AWS",
        "Cloud",
        "Architecture",
        "SQL",
        "Queries",
        "procedures",
        "functions",
        "packages",
        "tables",
        "views",
        "Knowledge",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "SDLC",
        "Agile",
        "Waterfall",
        "Methodologies",
        "Familiar",
        "concepts",
        "devices",
        "routers",
        "switches",
        "protocols",
        "OSI",
        "layer",
        "AJAX",
        "framework",
        "Datasets",
        "Data",
        "tables",
        "JSON",
        "strings",
        "service",
        "architecture",
        "SOA",
        "web",
        "Services",
        "SOAP",
        "JAXWS",
        "WSDL",
        "UDDI",
        "web",
        "application",
        "Python",
        "Django",
        "J2EE",
        "PostgreSQL",
        "MySQL",
        "Oracle",
        "g",
        "MongoDB",
        "Knowledgeable",
        "deployment",
        "Heroku",
        "Jenkins",
        "design",
        "development",
        "presentation",
        "layer",
        "web",
        "applications",
        "technologies",
        "HTML",
        "CSS",
        "JavaScript",
        "Bootstrap",
        "Expertise",
        "cloud",
        "computing",
        "applications",
        "ruby",
        "knowledge",
        "integration",
        "deployment",
        "Jenkins",
        "Docker",
        "Experience",
        "network",
        "protocols",
        "SNMP",
        "NetConf",
        "Experience",
        "applications",
        "amazon",
        "web",
        "services",
        "EC2",
        "Cloud",
        "Search",
        "Elastic",
        "Load",
        "balancer",
        "ELB",
        "S3",
        "Cloud",
        "Front",
        "R",
        "Language",
        "statisticians",
        "data",
        "miners",
        "software",
        "data",
        "analysis",
        "Expertise",
        "Altiris",
        "Remote",
        "Agent",
        "problems",
        "understanding",
        "knowledge",
        "Hadoop",
        "file",
        "system",
        "data",
        "modelling",
        "architecture",
        "design",
        "principles",
        "Developed",
        "Python",
        "Mapper",
        "Reducer",
        "scripts",
        "Hadoop",
        "streaming",
        "Web",
        "Services",
        "Python",
        "programming",
        "language",
        "working",
        "experience",
        "datasets",
        "Spark",
        "Scala",
        "Pyspark",
        "Good",
        "working",
        "experience",
        "datasets",
        "Spark",
        "Scala",
        "Pyspark",
        "Familiar",
        "JSON",
        "REST",
        "Web",
        "services",
        "Service",
        "Virtualization",
        "Requirements",
        "VSIs",
        "WSDL",
        "WADL",
        "Recording",
        "Request",
        "Response",
        "Expertise",
        "API",
        "NodeJS",
        "Clojure",
        "server",
        "protocol",
        "Backbone",
        "template",
        "web",
        "application",
        "Python",
        "Django",
        "J2EE",
        "PostgreSQL",
        "MySQL",
        "Oracle",
        "g",
        "MongoDB",
        "Knowledgeable",
        "deployment",
        "Heroku",
        "Jenkins",
        "Strong",
        "handson",
        "AWS",
        "cloud",
        "services",
        "EC2",
        "S3",
        "RDS",
        "ELB",
        "EBS",
        "Service",
        "Virtualization",
        "Requirements",
        "VSIs",
        "Authorized",
        "US",
        "employer",
        "Work",
        "Experience",
        "Senior",
        "Python",
        "Developer",
        "Phillips",
        "Houston",
        "Houston",
        "TX",
        "March",
        "Present",
        "years",
        "experience",
        "WebApplication",
        "Developer",
        "Programming",
        "Python",
        "Django",
        "Java",
        "software",
        "development",
        "Python",
        "libraries",
        "Beautiful",
        "Soup",
        "NumPy",
        "SciPy",
        "matplotlib",
        "Pandas",
        "data",
        "frame",
        "network",
        "urllib2",
        "MySQL",
        "database",
        "connectivity",
        "IDEs",
        "text",
        "Spyder",
        "PyCharm",
        "knowledge",
        "web",
        "services",
        "protocols",
        "SOAP",
        "REST",
        "knowledge",
        "server",
        "Apache",
        "Tomcat",
        "WebLogic",
        "Hands",
        "experience",
        "SVN",
        "Git",
        "JIRA",
        "Bugzilla",
        "SQL",
        "MS",
        "SQL",
        "Apache",
        "Cassandra",
        "Oracle",
        "AWS",
        "lambda",
        "code",
        "API",
        "AWS",
        "Lambda",
        "servers",
        "code",
        "AWS",
        "SQL",
        "PLSQL",
        "programming",
        "code",
        "units",
        "database",
        "triggers",
        "features",
        "performance",
        "Bulk",
        "Binds",
        "views",
        "Inline",
        "Global",
        "Temporary",
        "Tables",
        "experience",
        "Shell",
        "Scripting",
        "Server",
        "Unix",
        "Linux",
        "Open",
        "stock",
        "Expertise",
        "python",
        "focus",
        "DevOps",
        "tools",
        "CICD",
        "AWS",
        "Cloud",
        "Architecture",
        "Working",
        "deployments",
        "Docker",
        "Docker",
        "Docker",
        "Hub",
        "Docker",
        "registries",
        "Kubernetes",
        "Modifying",
        "data",
        "usingSASBASESAS",
        "MACROS",
        "Open",
        "Source",
        "Qt",
        "reporting",
        "solution",
        "data",
        "processing",
        "Spark",
        "AWS",
        "Redshift",
        "data",
        "database",
        "usingSASAccessSASSQL",
        "procedures",
        "createSASdata",
        "sets",
        "SQL",
        "Queries",
        "procedures",
        "functions",
        "packages",
        "tables",
        "views",
        "Knowledge",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "SDLC",
        "Agile",
        "Waterfall",
        "Methodologies",
        "Familiar",
        "concepts",
        "devices",
        "routers",
        "switches",
        "protocols",
        "OSI",
        "layer",
        "AJAX",
        "framework",
        "Datasets",
        "Data",
        "tables",
        "JSON",
        "strings",
        "Groovy",
        "Grails",
        "Java",
        "J2EE",
        "user",
        "interface",
        "web",
        "application",
        "Python",
        "Django",
        "J2EE",
        "PostgreSQL",
        "MySQL",
        "Oracle",
        "g",
        "MongoDB",
        "Knowledgeable",
        "deployment",
        "Heroku",
        "Jenkins",
        "working",
        "experience",
        "marker",
        "Struts",
        "frameworkSpringframework",
        "Mapping",
        "Hibernate",
        "framework",
        "differentPySparkAPIs",
        "transformations",
        "actions",
        "data",
        "Kafka",
        "time",
        "Experience",
        "library",
        "transfer",
        "data",
        "inrelationaldatabases",
        "tables",
        "objects",
        "techniques",
        "data",
        "Kafka",
        "knowledge",
        "integration",
        "deployment",
        "Jenkins",
        "Docker",
        "Restful",
        "web",
        "service",
        "withRedisCache",
        "framework",
        "endpoints",
        "cache",
        "application",
        "data",
        "data",
        "clusters",
        "likeREDISand",
        "endpoints",
        "Experience",
        "applications",
        "amazon",
        "web",
        "services",
        "EC2",
        "Cloud",
        "Search",
        "Elastic",
        "Load",
        "balancer",
        "ELB",
        "S3",
        "CloudFront",
        "SQL",
        "Alchemy",
        "asObjectRelationalMapperORM",
        "ORM",
        "queries",
        "Spring",
        "Batch",
        "Spring",
        "ORM",
        "module",
        "withHibernate",
        "custom",
        "consumers",
        "producers",
        "ApacheKafkain",
        "Go",
        "Golang",
        "cars",
        "monitoring",
        "system",
        "analytics",
        "ingestion",
        "platform",
        "Storm",
        "Wrote",
        "Storm",
        "topology",
        "events",
        "Cassandra",
        "DB",
        "Manage",
        "configurations",
        "servers",
        "log",
        "analytics",
        "pipeline",
        "Confluent",
        "Kafka",
        "storm",
        "search",
        "Logstash",
        "Kibana",
        "Greenplum",
        "Worked",
        "withKibanalog",
        "monitoring",
        "system",
        "issue",
        "context",
        "Elasticsearch",
        "cluster",
        "Logstash",
        "nodes",
        "TB",
        "Data",
        "Daily",
        "sources",
        "Kafka",
        "Design",
        "build",
        "ELK",
        "Elasticsearch",
        "Logstash",
        "graphite",
        "Kibana",
        "cluster",
        "logging",
        "search",
        "functionalities",
        "App",
        "Golang",
        "Infrastructure",
        "Teams",
        "Engineering",
        "Productivity",
        "Kubernetes",
        "Docker",
        "Ansible",
        "Spinnaker",
        "Deployed",
        "mircoservices2",
        "AWS",
        "usingAnsiblePlaybooks",
        "load",
        "balancer",
        "group",
        "configuration",
        "microservice",
        "UsedAnsibleplaybooks",
        "Continuous",
        "Delivery",
        "pipeline",
        "Jenkins",
        "Sonar",
        "server",
        "infrastructure",
        "packages",
        "software",
        "components",
        "Maven",
        "Experience",
        "playbooks",
        "forAnsibleand",
        "deploying",
        "applications",
        "infrastructure",
        "activities",
        "Continuous",
        "Deployment",
        "Application",
        "Server",
        "setup",
        "Stack",
        "Monitoring",
        "usingAnsibleplaybooks",
        "Run",
        "deck",
        "Jenkins",
        "Provisioned",
        "servers",
        "realtime",
        "dashboard",
        "Executives",
        "graphite",
        "Elastic",
        "Search",
        "Kibana",
        "Redis",
        "ImplementedAnsibleto",
        "servers",
        "buildconfiguration",
        "servers",
        "anAnsiblerole",
        "Zabbixagent",
        "CICD",
        "pipeline",
        "UsedAnsibleto",
        "document",
        "infrastructures",
        "version",
        "control",
        "UsedAnsibleto",
        "document",
        "application",
        "dependencies",
        "version",
        "control",
        "boarding",
        "Application",
        "teams",
        "code",
        "GitHub",
        "Jenkins",
        "Nexus",
        "andAnsible",
        "transformations",
        "actions",
        "data",
        "frames",
        "usedSparkSQL",
        "data",
        "frames",
        "tables",
        "processing",
        "data",
        "HiveSQL",
        "queries",
        "usingSparkRDDs",
        "Python",
        "Scala",
        "Hive",
        "transformations",
        "filter",
        "preaggregations",
        "data",
        "HDFS",
        "APIs",
        "transformations",
        "actions",
        "fly",
        "learner",
        "data",
        "model",
        "data",
        "Kafka",
        "time",
        "Persists",
        "Cassandra",
        "AutomatedRabbitMQcluster",
        "installations",
        "configuration",
        "PythonBash",
        "Excellent",
        "understanding",
        "knowledge",
        "Hadoop",
        "file",
        "system",
        "data",
        "modelling",
        "architecture",
        "design",
        "principles",
        "Developed",
        "Python",
        "Mapper",
        "Reducer",
        "scripts",
        "Hadoop",
        "streaming",
        "Web",
        "Services",
        "Python",
        "programming",
        "language",
        "working",
        "experience",
        "datasets",
        "Spark",
        "Scala",
        "Spark",
        "Good",
        "working",
        "experience",
        "datasets",
        "Spark",
        "Scala",
        "Spark",
        "Familiar",
        "JSON",
        "REST",
        "Web",
        "services",
        "Service",
        "Virtualization",
        "Requirements",
        "VSIs",
        "WSDL",
        "WADL",
        "Recording",
        "Request",
        "Response",
        "Expertise",
        "API",
        "NodeJS",
        "Clojure",
        "server",
        "protocol",
        "Backbone",
        "template",
        "UsedKubernetesto",
        "scale",
        "load",
        "balance",
        "scale",
        "Docker",
        "containers",
        "name",
        "versions",
        "grid",
        "operations",
        "panda",
        "flask",
        "andSQL",
        "Alchemycombination",
        "J2EE",
        "design",
        "MVC",
        "architecture",
        "Spring",
        "StrutsHibernateand",
        "EJB",
        "WebSphere",
        "Application",
        "Server",
        "Oracle",
        "database",
        "Java",
        "beans",
        "Struts",
        "MVC",
        "andHibernate",
        "Use",
        "AWS",
        "cloud",
        "management",
        "console",
        "spinnaker",
        "AWS",
        "python",
        "scripts",
        "library",
        "ec2",
        "instances",
        "CloudFormation",
        "CICD",
        "system",
        "Jenkins",
        "GooglesKubernetescontainer",
        "environment",
        "Docker",
        "runtime",
        "environment",
        "CICD",
        "system",
        "handson",
        "AWS",
        "cloud",
        "services",
        "EC2",
        "S3",
        "RDS",
        "ELB",
        "EBS",
        "queries",
        "database",
        "behavior",
        "DB",
        "Tuna",
        "backup",
        "recovery",
        "engine",
        "VM",
        "backuprecovery",
        "VMware",
        "vSphere",
        "APIs",
        "Golang",
        "programming",
        "language",
        "andRabbitMQMessage",
        "bus",
        "communication",
        "interface",
        "Monitoring",
        "Cassandra",
        "cluster",
        "resource",
        "utilization",
        "Cassandra",
        "clusters",
        "Datastax",
        "OpsCenter",
        "Knowledge",
        "Cassandra",
        "systems",
        "backup",
        "recovery",
        "Knowledge",
        "Cassandra",
        "security",
        "Knowledge",
        "Cassandra",
        "maintenance",
        "database",
        "server",
        "Created",
        "Terraform",
        "modules",
        "tier",
        "Architecture",
        "AWS",
        "resources",
        "VPC",
        "Subnets",
        "Security",
        "groups",
        "Load",
        "Balancers",
        "Auto",
        "scaling",
        "group",
        "CloudWatch",
        "Alarms",
        "ECS",
        "S3",
        "buckets",
        "logs",
        "Jenkins",
        "jobs",
        "AWS",
        "infrastructure",
        "GitHub",
        "repos",
        "Terraform",
        "code",
        "Applications",
        "infrastructure",
        "Dev",
        "QA",
        "Preprod",
        "requirement",
        "teams",
        "servers",
        "AWS",
        "Volumes",
        "EC2",
        "Security",
        "groups",
        "Auto",
        "Load",
        "balancers",
        "ELBs",
        "Installed",
        "packages",
        "servers",
        "Crypto",
        "Blockchain",
        "Bitcoin",
        "Monaro",
        "Bitcoin",
        "Cash",
        "Ecommerce",
        "platform",
        "Python",
        "Flask",
        "backend",
        "JinjaJavaScript",
        "service",
        "API",
        "users",
        "Blockchain",
        "transactions",
        "orders",
        "info",
        "AWS",
        "services",
        "EC2",
        "S3",
        "CloudFront",
        "Configured",
        "AWS",
        "CLI",
        "actions",
        "AWS",
        "services",
        "shell",
        "scripting",
        "Created",
        "Modules",
        "Requests",
        "JSON",
        "RPC",
        "Wallet",
        "servers",
        "Blockchain",
        "scripts",
        "device",
        "Prometheus",
        "andGrafanavia",
        "ODL",
        "sash",
        "GRPC",
        "NC",
        "Client",
        "model",
        "telemetry",
        "memory",
        "leaks",
        "health",
        "router",
        "Senior",
        "Python",
        "developer",
        "Kroger",
        "Ohio",
        "November",
        "February",
        "Python",
        "Django",
        "Framework",
        "applications",
        "Strong",
        "Expertise",
        "serverside",
        "technologies",
        "API",
        "MVC",
        "design",
        "patterns",
        "software",
        "development",
        "life",
        "cycle",
        "SDLC",
        "requirement",
        "gathering",
        "system",
        "configuration",
        "specifications",
        "client",
        "interaction",
        "effort",
        "time",
        "stream",
        "analytics",
        "platform",
        "beacons",
        "web",
        "devices",
        "Spark",
        "Kafka",
        "dashboard",
        "Kibana",
        "Grafana",
        "Experience",
        "Hadoop",
        "ecosystem",
        "components",
        "HDFSSparkwith",
        "Scala",
        "python",
        "Zookeeper",
        "Yarn",
        "MapReduce",
        "Pig",
        "Sqoop",
        "HBase",
        "Hive",
        "Flume",
        "Cassandra",
        "MongoDB",
        "Oozie",
        "Kafka",
        "Flume",
        "TEZ",
        "Hands",
        "experience",
        "developingSPARKapplications",
        "likeSparkcoreSpark",
        "StreamingSparkMLlib",
        "andSparkSQL",
        "file",
        "formats",
        "Text",
        "Sequence",
        "Avro",
        "ORC",
        "JSON",
        "Parquette",
        "UsedobjectrelationalmapperORM",
        "transfer",
        "data",
        "inrelationaldatabases",
        "tables",
        "objects",
        "Experience",
        "Design",
        "Patterns",
        "MVC",
        "Singleton",
        "frameworks",
        "DJANGO",
        "Ability",
        "Django",
        "ORM",
        "ObjectRelationalMapper",
        "SQL",
        "Alchemy",
        "customer",
        "data",
        "collection",
        "withPySparkHadoop",
        "analytics",
        "Hadoop",
        "log",
        "file",
        "SQL",
        "scripts",
        "solution",
        "process",
        "usingPySpark",
        "Develop",
        "customSAScode",
        "performance",
        "monitoring",
        "Import",
        "files",
        "data",
        "manipulation",
        "extraction",
        "data",
        "analysis",
        "report",
        "generation",
        "Macro",
        "Processing",
        "Proc",
        "Report",
        "Excel",
        "spreadsheets",
        "Pysparkwe",
        "Caching",
        "Accumulators",
        "UDFs",
        "implementedpysparkfor",
        "Transformation",
        "Actions",
        "Spark",
        "Hands",
        "experience",
        "withSparkCoreSparkSQL",
        "Data",
        "FramesData",
        "API",
        "mapreduce",
        "jobs",
        "Hive",
        "scripts",
        "withSparkDataFrame",
        "transformation",
        "action",
        "Excellent",
        "knowledge",
        "onSparkArchitecture",
        "Hadoop",
        "Architecture",
        "ecosystems",
        "HDFS",
        "Job",
        "Tracker",
        "Task",
        "Tracker",
        "Name",
        "Node",
        "Data",
        "Node",
        "Map",
        "Reduce",
        "programming",
        "paradigm",
        "Develop",
        "python",
        "code",
        "ingestion",
        "formats",
        "JSON",
        "CSV",
        "Logstash",
        "search",
        "toKibanadashboard",
        "clients",
        "ELK",
        "clusters",
        "Elasticsearch",
        "Logstash",
        "Graphite",
        "Kibana",
        "Kafka",
        "zookeeper",
        "Experience",
        "Key",
        "AWS",
        "EC2",
        "S3",
        "DynamoDB",
        "NoSQL",
        "Lambda",
        "Responsible",
        "Automation",
        "deployment",
        "Conductor",
        "application",
        "AWS",
        "lambda",
        "highend",
        "AWS",
        "components",
        "AWS",
        "lambda",
        "scripts",
        "demand",
        "EC2",
        "instance",
        "formation",
        "AutomatedRabbitMQcluster",
        "installations",
        "configuration",
        "PythonBash",
        "issues",
        "OpenStack",
        "components",
        "Nova",
        "Glance",
        "Neutron",
        "Keystone",
        "Cech",
        "Repose",
        "HAP",
        "Roxy",
        "Horizon",
        "API",
        "services",
        "PythonTornado",
        "AMQP",
        "architectures",
        "web",
        "crawler",
        "python",
        "framework",
        "usingRabbitMQas",
        "server",
        "micro",
        "services",
        "Experience",
        "check",
        "logs",
        "data",
        "sets",
        "Elastic",
        "Search",
        "Written",
        "Salt",
        "scripts",
        "Elasticsearch",
        "Logstash",
        "Kibana",
        "Beats",
        "python",
        "packages",
        "NumPy",
        "SoupSQL",
        "Alchemy",
        "Py",
        "Tables",
        "stack",
        "Python",
        "web",
        "framework",
        "emphasis",
        "simplicity",
        "flexibility",
        "extensibility",
        "components",
        "reinvents",
        "wheels",
        "WSGI",
        "templating",
        "forms",
        "data",
        "Alchemy",
        "Storm",
        "CouchDB",
        "OpenID",
        "App",
        "Engine",
        "jQuery",
        "delivery",
        "Gitlab",
        "Spinnaker",
        "Docker",
        "Jenkins",
        "Terraform",
        "AWS",
        "load",
        "tests",
        "Scala",
        "Gatling",
        "TB",
        "data",
        "Oracle",
        "Cassandra",
        "datacenter",
        "nodes",
        "TB",
        "drives",
        "Stable",
        "Loader",
        "performance",
        "tuning",
        "cluster",
        "Cassandra",
        "Configuration",
        "file",
        "JVM",
        "Parameters",
        "communication",
        "Cassandra",
        "nodes",
        "client",
        "SSL",
        "encryption",
        "data",
        "model",
        "endurance",
        "tests",
        "JMeter",
        "Cassandra",
        "Stress",
        "Tool",
        "OpsCenter",
        "Analysis",
        "logs",
        "data",
        "filter",
        "columns",
        "Logstash",
        "configuration",
        "Elasticsearch",
        "Validated",
        "BI",
        "Support",
        "events",
        "events",
        "HNM",
        "andKafkaby",
        "events",
        "Mesos",
        "Used",
        "micro",
        "service",
        "architecture",
        "Spring",
        "Bootbased",
        "services",
        "REST",
        "andKafka",
        "DevelopedKafkaproducer",
        "consumers",
        "HBase",
        "Spark",
        "shark",
        "Streams",
        "Hadoop",
        "MapReduce",
        "jobs",
        "components",
        "HDFS",
        "Hive",
        "Creating",
        "web",
        "services",
        "Catalog",
        "Pricing",
        "Django",
        "MVT",
        "Jersey",
        "MySQL",
        "MongoDB",
        "JSON",
        "REST",
        "Web",
        "services",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "AWS",
        "cloud",
        "management",
        "console",
        "spinnaker",
        "AWS",
        "python",
        "scripts",
        "library",
        "ec2",
        "instances",
        "CloudFormation",
        "stack",
        "dashboard",
        "Executives",
        "graphite",
        "Elastic",
        "Search",
        "Kibana",
        "Redis",
        "Experience",
        "configuring",
        "Flume",
        "andKafkato",
        "data",
        "web",
        "sources",
        "HDFS",
        "Redis",
        "cache",
        "info",
        "changes",
        "usingRabbitMQ",
        "JS",
        "framework",
        "websites",
        "client",
        "Cassandra",
        "database",
        "cache",
        "data",
        "UsedRedisCache",
        "performance",
        "space",
        "data",
        "data",
        "Developed",
        "Ruby",
        "Rails",
        "web",
        "applications",
        "MongoDB",
        "background",
        "processes",
        "Risqu",
        "andRedis",
        "Python",
        "handling",
        "hits",
        "DjangoRedis",
        "application",
        "websites",
        "database",
        "MySQL",
        "PostgreSQL",
        "data",
        "analytics",
        "team",
        "implementation",
        "scripts",
        "Sqoop",
        "spark",
        "Hadoop",
        "batch",
        "data",
        "frontends",
        "HTML5",
        "CSS3",
        "JavaScript",
        "jQuery",
        "database",
        "tables",
        "SQL",
        "access",
        "PostgreSQL",
        "Kubernetes",
        "scale",
        "load",
        "balance",
        "Docker",
        "Engine",
        "Docker",
        "HUB",
        "Docker",
        "Images",
        "Docker",
        "Compose",
        "images",
        "installations",
        "domain",
        "configurations",
        "Jenkins",
        "Continuous",
        "Integration",
        "builds",
        "deployments",
        "Build",
        "Jenkins",
        "jobs",
        "GitHub",
        "repos",
        "terraform",
        "code",
        "Installed",
        "Administered",
        "Jenkins",
        "CI",
        "Maven",
        "Builds",
        "Developed",
        "Python",
        "API",
        "RESTful",
        "Web",
        "Service",
        "events",
        "analysis",
        "Flask",
        "CSV",
        "XML",
        "JSON",
        "data",
        "computers",
        "world",
        "Python",
        "pandas",
        "csv",
        "xml",
        "NumPy",
        "data",
        "pages",
        "engineers",
        "data",
        "mongo",
        "python2",
        "environment",
        "Elasticsearch",
        "python",
        "workflow",
        "Developed",
        "Micro",
        "services",
        "HP",
        "team",
        "Spring",
        "Boot",
        "Java",
        "SpringHibernateframework",
        "DML",
        "DQL",
        "queries",
        "objectdatabase",
        "mapping",
        "Kubernetesis",
        "deployment",
        "scaling",
        "management",
        "Docker",
        "Containers",
        "Jenkins",
        "pipelines",
        "micro",
        "services",
        "Docker",
        "registry",
        "toKubernetes",
        "Pods",
        "usingKubernetes",
        "deployments",
        "cluster",
        "application",
        "containers",
        "Wrote",
        "AJAX",
        "tables",
        "tab",
        "menu",
        "components",
        "data",
        "AngularJS",
        "HTML5",
        "AngularJS",
        "JSON",
        "AJAX",
        "DOM",
        "scripting",
        "form",
        "validations",
        "MySQL",
        "migration",
        "project",
        "system",
        "database",
        "UsedSpringto",
        "J2EE",
        "design",
        "MVC",
        "Struts",
        "Hibernate",
        "EJB",
        "WebSphere",
        "Application",
        "Server",
        "Oracle",
        "database",
        "Delivery",
        "Pipeline",
        "Jenkins",
        "GitHub",
        "newDocker",
        "container",
        "UsedDockerto",
        "highlevel",
        "API",
        "containers",
        "isolation",
        "creation",
        "customizedDockercontainer",
        "images",
        "images",
        "theDockerrepository",
        "Participated",
        "development",
        "page",
        "application",
        "framework",
        "Java",
        "Script",
        "jQuery",
        "conjunction",
        "HTML5",
        "CSS3",
        "standards",
        "frontend",
        "UI",
        "team",
        "HTML5",
        "AngularJS",
        "JSON",
        "AJAX",
        "DOM",
        "scripting",
        "form",
        "infrastructure",
        "activities",
        "Continuous",
        "Deployment",
        "Application",
        "Server",
        "setup",
        "Stack",
        "monitoring",
        "playbooks",
        "Integrated",
        "Ansible",
        "Run",
        "deck",
        "Jenkins",
        "Wrote",
        "Ansible",
        "Playbooks",
        "Python",
        "SSH",
        "Wrapper",
        "Manage",
        "Configurations",
        "AWS",
        "nodes",
        "Playbooks",
        "AWS",
        "instances",
        "Python",
        "Run",
        "Ansible",
        "Scripts",
        "Dev",
        "Servers",
        "Experience",
        "GIT",
        "Repository",
        "Managers",
        "Maven",
        "Celery",
        "task",
        "queue",
        "andRabbitMQ",
        "Redis",
        "broker",
        "tasks",
        "Python",
        "Developer",
        "UPS",
        "Atlanta",
        "GA",
        "August",
        "October",
        "Developed",
        "Wrapper",
        "Python",
        "application",
        "infrastructure",
        "Amazon",
        "web",
        "services",
        "AWS",
        "Test",
        "approachTDD",
        "services",
        "application",
        "datasets",
        "Panda",
        "data",
        "frames",
        "MySQL",
        "MYSQL",
        "database",
        "python",
        "PythonMySQL",
        "connector",
        "MySQL",
        "package",
        "Datacenter",
        "migration",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "infrastructure",
        "support",
        "Applications",
        "Database",
        "teams",
        "Familiarity",
        "experience",
        "ORM",
        "ObjectRelationalMapper",
        "requirements",
        "enterprise",
        "architecture",
        "EIA",
        "metadata",
        "Eguide",
        "EBI",
        "underSASVB",
        "Developed",
        "Legacy",
        "system",
        "programs",
        "COBOL",
        "DB2",
        "CICS",
        "JCL",
        "ResponsibleSASreports",
        "analysis",
        "usingSASmacros",
        "UNIX",
        "operating",
        "system",
        "Big",
        "Data",
        "infrastructure",
        "batch",
        "processing",
        "processing",
        "ApacheSpark",
        "Hadoop",
        "cluster",
        "Hortonworks",
        "Data",
        "Platform",
        "Responsible",
        "design",
        "development",
        "Scripts",
        "Functional",
        "Specifications",
        "largescale",
        "Hadoop",
        "YARN",
        "cluster",
        "data",
        "processing",
        "analysis",
        "Hive",
        "Develop",
        "python",
        "code",
        "ingestion",
        "formats",
        "JSON",
        "CSV",
        "Logstash",
        "search",
        "toKibanadashboard",
        "clients",
        "ELK",
        "clusters",
        "Elasticsearch",
        "Logstash",
        "Graphite",
        "Kibana",
        "Kafka",
        "zookeeper",
        "data",
        "format",
        "algorithms",
        "working",
        "experience",
        "marker",
        "Struts",
        "framework",
        "Spring",
        "framework",
        "Mapping",
        "Hibernateframework",
        "struts",
        "mapping",
        "configurations",
        "HQL",
        "enhancement",
        "module",
        "development",
        "Transport",
        "Optimization",
        "Planning",
        "Scheduling",
        "Web",
        "app",
        "AutomatedRabbitMQcluster",
        "installations",
        "configuration",
        "PythonBash",
        "Managed",
        "dashboard",
        "control",
        "panel",
        "customers",
        "Administrators",
        "Django",
        "Oracle",
        "DB",
        "PostgreSQL",
        "VMWare",
        "API",
        "Developed",
        "micro",
        "services",
        "usingspringboot",
        "REST",
        "API",
        "AngularJS",
        "web",
        "applications",
        "AD",
        "Cassandra",
        "Authorization",
        "process",
        "installation",
        "configuration",
        "DataStax",
        "Enterprise",
        "Cassandra",
        "cluster",
        "puppet",
        "cluster",
        "Zabbix",
        "Configured",
        "communication",
        "Cassandra",
        "nodes",
        "client",
        "SSL",
        "encryption",
        "shell",
        "scripts",
        "CRON",
        "jobs",
        "monitoring",
        "data",
        "backup",
        "Cassandra",
        "cluster",
        "Created",
        "data",
        "schema",
        "data",
        "Amazon",
        "S3",
        "lambda",
        "azure",
        "templates",
        "server",
        "creation",
        "DSE",
        "deployments",
        "Cassandra",
        "cluster",
        "CQL",
        "cluster",
        "Experience",
        "Cassandra",
        "cluster",
        "releases",
        "application",
        "level",
        "persistence",
        "Hibernate",
        "Configured",
        "Struts",
        "Hibernate",
        "framework",
        "withSpringMVC",
        "Docker",
        "container",
        "deploying",
        "micro",
        "services",
        "deployment",
        "usingKubernetes",
        "Chat",
        "Ops",
        "interfaces",
        "slack",
        "andKuberneteson",
        "GKE",
        "Experience",
        "Streaming",
        "platforms",
        "ApacheKafka",
        "ApacheKafkaMessage",
        "Queues",
        "exchange",
        "information",
        "business",
        "applications",
        "modules",
        "requests",
        "urllib2",
        "web",
        "Working",
        "Spinnaker",
        "platform",
        "MultiCloud",
        "Continuous",
        "Delivery",
        "Bake",
        "Test",
        "DeployContainer",
        "Pipelines",
        "Packer",
        "Terraform",
        "Kubernetes",
        "AWS",
        "GCP",
        "SetupDockeron",
        "Linux",
        "Jenkins",
        "Wrote",
        "MYSQL",
        "database",
        "python",
        "PythonMySQL",
        "connector",
        "MySQL",
        "package",
        "Managed",
        "deployments",
        "cluster",
        "application",
        "containers",
        "API",
        "services",
        "PythonTornado",
        "AMQP",
        "architectures",
        "support",
        "Amazon",
        "AWS",
        "S3",
        "RDS",
        "files",
        "database",
        "Amazon",
        "Cloud",
        "API",
        "system",
        "deployment",
        "http",
        "server",
        "Amazon",
        "AWS",
        "Design",
        "implementation",
        "CICD",
        "pipelines",
        "Jenkins",
        "CICD",
        "pipelines",
        "playbooks",
        "Oracle",
        "12c",
        "installation",
        "scripts",
        "email",
        "notification",
        "celery",
        "status",
        "jobs",
        "task",
        "list",
        "manager",
        "users",
        "admin",
        "Profound",
        "knowledge",
        "experience",
        "mechanism",
        "docker",
        "containers",
        "docker",
        "containers",
        "Ansible",
        "Expertise",
        "Production",
        "Fault",
        "Tolerant",
        "Kubernetes",
        "infrastructure",
        "Working",
        "Scheduling",
        "deploying",
        "container",
        "replicas",
        "cluster",
        "Kubernetes",
        "CICD",
        "pipeline",
        "GitHub",
        "Jenkins",
        "Maven",
        "Chef",
        "Terraform",
        "DevOps",
        "experience",
        "GitHub",
        "Maven",
        "Nagios",
        "Docker",
        "Jenkins",
        "Puppet",
        "Chef",
        "Ansible",
        "servers",
        "Docker",
        "test",
        "environments",
        "devenvironments",
        "needs",
        "configuration",
        "automation",
        "Docker",
        "Containers",
        "Integrated",
        "Kafka",
        "Spark",
        "streaming",
        "speed",
        "data",
        "Web",
        "pages",
        "Jasmine",
        "Karma",
        "HTML",
        "CSS",
        "RESTFUL",
        "API",
        "Services",
        "JavaScript",
        "Bootstrap",
        "GIT",
        "JSON",
        "Celery",
        "task",
        "queue",
        "andRabbitMQ",
        "Redis",
        "broker",
        "tasks",
        "Web",
        "pages",
        "Jasmine",
        "Karma",
        "HTML",
        "CSS",
        "RESTFUL",
        "A",
        "experience",
        "Struts",
        "Spring",
        "IOC",
        "Spring",
        "MVC",
        "Spring",
        "Data",
        "Spring",
        "Boot",
        "Spring",
        "Security",
        "spring",
        "frameworks",
        "implementation",
        "integration",
        "Agile",
        "SCRUM",
        "methodology",
        "Test",
        "Driven",
        "Development",
        "TDD",
        "BDD",
        "pattern",
        "code",
        "quality",
        "readability",
        "standards",
        "Redux",
        "list",
        "reducers",
        "functions",
        "store",
        "method",
        "PI",
        "Services",
        "JavaScript",
        "Bootstrap",
        "GIT",
        "application",
        "level",
        "persistence",
        "usingHibernateand",
        "spring",
        "Configured",
        "StrutsHibernateframework",
        "Spring",
        "MVC",
        "Written",
        "Grok",
        "pattern",
        "Logstash",
        "Configured",
        "Logstash",
        "input",
        "filter",
        "output",
        "plugins",
        "database",
        "log",
        "file",
        "sources",
        "search",
        "output",
        "Python",
        "developer",
        "Aetna",
        "Hartford",
        "CT",
        "August",
        "July",
        "Installed",
        "configuration",
        "management",
        "system",
        "Ansible",
        "Web",
        "applications",
        "Environments",
        "configuration",
        "Files",
        "Users",
        "Mount",
        "points",
        "Packages",
        "database",
        "Administration",
        "activities",
        "backup",
        "log",
        "messages",
        "database",
        "optimization",
        "tasks",
        "help",
        "Celery",
        "Developed",
        "Kafka",
        "consumers",
        "data",
        "Kafka",
        "topics",
        "Configuring",
        "Kafka",
        "Consumer",
        "Producer",
        "metrics",
        "Kafka",
        "System",
        "performance",
        "Experience",
        "Kibana",
        "logs",
        "data",
        "sets",
        "Elastic",
        "Search",
        "Written",
        "Salt",
        "scripts",
        "Elasticsearch",
        "Logstash",
        "Kibana",
        "Beats",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "efficiency",
        "storage",
        "access",
        "experience",
        "Core",
        "Java",
        "J2EE",
        "features",
        "Java",
        "JDBC",
        "Spring",
        "Struts",
        "EJB",
        "Servlets",
        "Hibernate",
        "support",
        "Amazon",
        "AWS",
        "S3",
        "RDS",
        "files",
        "database",
        "Amazon",
        "Cloud",
        "Merge",
        "jobs",
        "Python",
        "data",
        "MySQL",
        "database",
        "Test",
        "approach",
        "applications",
        "Cloud",
        "platform",
        "engineering",
        "Kubernetes",
        "Spinnaker",
        "Docker",
        "Terraform",
        "Consul",
        "drone",
        "Jenkins",
        "Chef",
        "Kitchen",
        "container",
        "replicas",
        "cluster",
        "Kubernetes",
        "views",
        "templates",
        "Python",
        "Django",
        "controller",
        "templating",
        "language",
        "interface",
        "MVC",
        "architecture",
        "reports",
        "application",
        "Tableau",
        "data",
        "SASBASE",
        "SAS",
        "MACROS",
        "data",
        "database",
        "SASAccess",
        "SAS",
        "SQL",
        "procedures",
        "SAS",
        "data",
        "sets",
        "software",
        "pip",
        "command",
        "python",
        "libraries",
        "Beautiful",
        "Soup",
        "NumPy",
        "SciPy",
        "pythontwitter",
        "Celery",
        "matplotlib",
        "Pandas",
        "dataframe",
        "PEP8",
        "convention",
        "Migration",
        "API",
        "code",
        "Sybase",
        "Oracle",
        "Overlook",
        "migration",
        "activity",
        "PLSQL",
        "programs",
        "deployments",
        "Kubernetes",
        "cluster",
        "application",
        "containers",
        "application",
        "Python",
        "Django",
        "Dockers",
        "RabbitMQ",
        "Celery",
        "Jenkins",
        "Model",
        "View",
        "Control",
        "MVC",
        "architecture",
        "serverside",
        "applications",
        "Django",
        "Flask",
        "web",
        "applications",
        "migration",
        "data",
        "ASPL",
        "Database",
        "Sybase",
        "Oracle",
        "Expertise",
        "serverside",
        "technologies",
        "Databases",
        "API",
        "MVC",
        "design",
        "patterns",
        "Wrote",
        "MySQL",
        "database",
        "connector",
        "MySQL",
        "package",
        "Python",
        "modules",
        "NumPy",
        "matplotlib",
        "data",
        "creation",
        "histograms",
        "Libraries",
        "Sybase",
        "APIs",
        "Oracle",
        "API",
        "Automate",
        "Build",
        "Release",
        "tasks",
        "ANT",
        "Shell",
        "Perl",
        "efficiency",
        "repeatability",
        "Communication",
        "team",
        "members",
        "Ansible",
        "Core",
        "Ansible",
        "Tower",
        "teams",
        "requirements",
        "obstacles",
        "service",
        "application",
        "deployments",
        "ANSIBLE",
        "CentOS",
        "RHEL",
        "AWS",
        "Wrote",
        "ANSIBLE",
        "Playbooks",
        "Python",
        "SSH",
        "Wrapper",
        "Manage",
        "Configurations",
        "AWS",
        "Nodes",
        "Test",
        "Playbooks",
        "AWS",
        "instances",
        "Python",
        "Run",
        "Ansible",
        "Scripts",
        "provision",
        "Dev",
        "servers",
        "Python",
        "Pandas",
        "NumPy",
        "SQL",
        "Tableau",
        "data",
        "database",
        "status",
        "reports",
        "dashboards",
        "Education",
        "Bachelors",
        "Skills",
        "DJANGO",
        "years",
        "PYTHON",
        "years",
        "jQuery",
        "years",
        "AJAX",
        "years",
        "Flask",
        "years",
        "years",
        "AWS",
        "years",
        "years",
        "years",
        "years",
        "years",
        "Information",
        "SKILLS",
        "Python",
        "Django",
        "Flask",
        "Java",
        "C",
        "Shell",
        "Script",
        "SQL",
        "JavaJ2EE",
        "AJAX",
        "JavaScript",
        "HTML",
        "DHTML",
        "XHTML",
        "XML",
        "JSON",
        "Jquery",
        "Angularjs"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:43:15.292855",
    "resume_data": "Senior Python Developer Senior span lPythonspan span lDeveloperspan Senior Python Developer Redwood City CA Over 7 years of experience in developing webbased applications software development and design using Python 3327 Django 1918 XML CSS HTML DHTML JavaScript JQuery Angular Js 3 years of QA experience working in environment with different types of Software Development Life Cycle and Software Testing Methodology Good experience in Shell Scriptings Server Unix and Linux Open stock and Expertise python scripting with focus on Devops tools CICD and AWS Cloud Architecture Experienced in writing SQL Queries Stored procedures functions packages tables views triggers Knowledge of the Software Development Life Cycle SDLC Agile and Waterfall Methodologies and Familiar with concepts and devices such routers switches and TCPIP protocols and OSI layer Worked on AJAX framework to transform Datasets and Data tables into HTTPserializable JSON strings Experienced in developing service oriented architecture SOA and web Services using SOAP JAXWS WSDL and UDDI Built the web application by using Python Django AWS J2EE PostgreSQL MySQL Oracle 10g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins Well versed with design and development of presentation layer for web applications using technologies like HTML CSS and JavaScript Bootstrap Expertise in writing cloud computing applications using ruby Had knowledge on continuous integration and deployment using Jenkins Docker Experience working with network protocols SNMP NetConf Experience in developing applications using amazon web services like EC2 Cloud Search Elastic Load balancer ELB S3 Cloud Front Used R Language among statisticians and data miners for developing statistical software and data analysis Expertise in operating Symantec Altiris Remote Agent to remotely fix problems Excellent understanding and knowledge of Hadoop Distributed file system data modelling architecture and design principles and Developed Python Mapper and Reducer scripts and implemented them using Hadoop streaming Experienced in developing Web Services with Python programming language and Good working experience in processing large datasets with Spark using Scala and Pyspark Good working experience in processing large datasets with Spark using Scala and Pyspark and Familiar with JSON based REST Web services Experienced in understanding Service Virtualization needs Requirements creating VSIs using WSDL WADL Recording Request Response pairs Expertise in creating Restful API in NodeJS and communicate with Clojure server via protocol and use Backbone to generate template Built the web application by using Python Django AWS J2EE PostgreSQL MySQL Oracle 10g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins Strong handson on AWS cloud services like EC2 S3 RDS ELB and EBS for installing configuring Experienced in understanding Service Virtualization needs Requirements creating VSIs using Authorized to work in the US for any employer Work Experience Senior Python Developer Phillips 66 Houston Houston TX March 2017 to Present Over 7 years of experience as a WebApplication Developer and coding with analytical Programming using Python Django Java Involved in software development in Python libraries used Beautiful Soup NumPy SciPy matplotlib Pandas data frame network urllib2 MySQL dB for database connectivity and IDEs sublime text Spyder PyCharm Good knowledge of web services with protocols SOAP REST and knowledge of server Apache Tomcat WebLogic Hands on experience in SVN Git JIRA and Bugzilla worked in SQL databases MS SQL Apache Cassandra Oracle and MongoDB Used AWS lambda to run code virtually Developed API for using AWS Lambda to manage the servers and run the code in AWS SQL and PLSQL programming developing complex code units database triggers and using the latest features to optimize performance Bulk Binds Materialized views Inline views Global Temporary Tables Good experience in Shell Scripting Server Unix and Linux Open stock and Expertise python scripting with focus on DevOps tools CICD and AWS Cloud Architecture Working with containerbased deployments using Docker working with Docker images Docker Hub and Docker registries and Kubernetes Modifying data usingSASBASESAS MACROS Open Source templatebased Qt reporting solution Big data processing using Spark AWS and Redshift Extracting data from the database usingSASAccessSASSQL procedures and createSASdata sets Writing SQL Queries Stored procedures functions packages tables views triggers Knowledge of the Software Development Life Cycle SDLC Agile and Waterfall Methodologies and Familiar with concepts and devices such routers switches and TCPIP protocols and OSI layer Worked on AJAX framework to transform Datasets and Data tables into HTTPserializable JSON strings Used Groovy and Grails withspring Java J2EE for user interface Built the web application by using Python Django AWS J2EE PostgreSQL MySQL Oracle 10g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins Extensive working experience in free marker Struts frameworkSpringframework and OR Mapping Hibernate framework Used differentPySparkAPIs to perform necessary transformations and actions on the data which gets from Kafka in real time Experience in usingobjectrelationalmapperORM library to automate the transfer of data stored inrelationaldatabases tables into objects Performed various Parsing techniques usingPySparkAPIS to cleanse the data from Kafka Had knowledge on continuous integration and deployment using Jenkins Docker Implemented Restful web service to interact withRedisCache framework Worked on developing Restful endpoints to cache application specific data in inmemory data clusters likeREDISand exposed them with Restful endpoints Experience in developing applications using amazon web services like EC2 Cloud Search Elastic Load balancer ELB S3 CloudFront Used SQL Alchemy asObjectRelationalMapperORM for writing ORM queries Worked with Spring Batch Used Spring ORM module to integrate withHibernate Developed custom consumers and producers for ApacheKafkain Go Golang for cars monitoring system Designed the realtime analytics and ingestion platform using Storm andKafka Wrote Storm topology to accept the events fromKafkaproducer and emit into Cassandra DB Manage the configurations of multiple servers usingAnsible Implemented realtime log analytics pipeline using Confluent Kafka storm elastic search Logstash Kibana and Greenplum Worked withKibanalog monitoring system and fixed a critical issue easily by capturing the context Maintaining the Elasticsearch cluster and Logstash nodes to process around 5TB of Data Daily from various sources like Kafka kubernetes etc Design build and manage the ELK Elasticsearch Logstash graphite Kibana cluster for centralized logging and search functionalities for the App Golang Infrastructure Teams and Engineering Productivity utilizing Kubernetes Docker influx dB Ansible Spinnaker Deployed mircoservices2 including provisioning AWS environments usingAnsiblePlaybooks Provisioned load balancer autoscaling group and launch configuration for microservice usingAnsible UsedAnsibleplaybooks to setup Continuous Delivery pipeline This primarily consists of a Jenkins and Sonar server the infrastructure to run these packages and various supporting software components such as Maven etc Experience in writing playbooks forAnsibleand deploying applications usingAnsible Automated various infrastructure activities like Continuous Deployment Application Server setup Stack Monitoring usingAnsibleplaybooks and has integratedAnsiblewith Run deck and Jenkins Provisioned and patched servers regularly usingAnsible Created realtime dashboard for Executives utilizing Logstash graphite Elastic Search Kibana Redis ImplementedAnsibleto manage all existing servers and automate the buildconfiguration of new servers Developed anAnsiblerole for Zabbixagent which will be integrated into the to the CICD pipeline UsedAnsibleto document all infrastructures into version control UsedAnsibleto document application dependencies into version control Responsible for on boarding Application teams to build and deploy their code using GitHub Jenkins Nexus andAnsible Written transformations and actions on data frames usedSparkSQL on data frames to access hive tables intosparkfor faster processing of data Involved in converting HiveSQL queries intoSparktransformations usingSparkRDDs Python and Scala Used Hive to do transformations joins filter and some preaggregations after storing the data to HDFS UsedSparkStreaming APIs to perform necessary transformations and actions on the fly for building the common learner data model which gets the data from Kafka in near real time and Persists into Cassandra AutomatedRabbitMQcluster installations and configuration using PythonBash Excellent understanding and knowledge of Hadoop Distributed file system data modelling architecture and design principles and Developed Python Mapper and Reducer scripts and implemented them using Hadoop streaming Experienced in developing Web Services with Python programming language and Good working experience in processing large datasets with Spark using Scala and Spark Good working experience in processing large datasets with Spark using Scala and Spark and Familiar with JSON based REST Web services Experienced in understanding Service Virtualization needs Requirements creating VSIs using WSDL WADL Recording Request Response pairs Expertise in creating Restful API in NodeJS and communicate with Clojure server via protocol and use Backbone to generate template UsedKubernetesto deploy scale load balance scale and manage Docker containers with multiple name spaced versions Different grid operations using panda flask andSQL Alchemycombination Involved in multitiered J2EE design utilizing MVC architecture Spring StrutsHibernateand EJB deployed on WebSphere Application Server connecting to an Oracle database Developed and configured the Java beans using Struts MVC andHibernate Use AWS cloud management console spinnaker to work with AWS Wrote python scripts using boto3 library to manage ec2 instances and CloudFormation stack Developed CICD system with Jenkins on GooglesKubernetescontainer environment utilizingKubernetesand Docker for the runtime environment for the CICD system to build and test and deploy Strong handson on AWS cloud services like EC2 S3 RDS ELB and EBS for installing configuring Analyzed queries and database behavior usingPerconatools DB Tuna Developed backup and recovery engine for VM backuprecovery using VMware vSphere APIs Golang programming language andRabbitMQMessage bus communication interface Monitoring Cassandra cluster for resource utilization Managing Cassandra clusters using Datastax OpsCenter Knowledge of Cassandra systems backup and recovery Knowledge of Cassandra security Knowledge of Cassandra maintenance and tuning both database and server Created Terraform modules for two tier Architecture which includes AWS resources VPC Subnets Security groups Ec2 Load Balancers Auto scaling group CloudWatch Alarms ECS clusters S3 buckets for logs Built Jenkins jobs to create AWS infrastructure from GitHub repos containing Terraform code to deploy different Applications infrastructure for Dev QA and Preprod based on the requirement from different teams Built servers in AWS importing Volumes launching EC2 creating Security groups Auto scaling Load balancers ELBs and Installed required packages on servers Crypto Blockchain Bitcoin Monaro Bitcoin Cash Ecommerce platform built utilizing Python with Flask backend and JinjaJavaScript frontend Currently building RESTful service API to allow users to see Blockchain transactions orders and info Deployed on AWS and with services EC2 S3 CloudFront Configured AWS CLI and performed necessary actions on the AWS services using shell scripting Created Modules utilizing Requests JSON to interact RPC Wallet servers and Blockchain Created scripts that monitored a device using Prometheus andGrafanavia ODL sash GRPC NC Client and model driven telemetry and checked for memory leaks and health of the router Senior Python developer Kroger Ohio November 2015 to February 2017 Extensively used Python Django Framework for developing backend applications Strong Expertise in working with serverside technologies including databases Restful API and MVC design patterns Actively involved in Initial software development life cycle SDLC of requirement gathering and in suggesting system configuration specifications during client interaction Was leading an effort to build a real time click stream analytics platform for processing the beacons from web and mobile devices using Spark Kafka elastic and building dashboard using Kibana and Grafana Experience in the Hadoop ecosystem components like HDFSSparkwith Scala and python Zookeeper Yarn MapReduce Pig Sqoop HBase Hive Flume Cassandra MongoDB Oozie Kafka Flume and TEZ Hands on experience in developingSPARKapplications usingSparkAPIs likeSparkcoreSpark StreamingSparkMLlib andSparkSQL and worked with different file formats such as Text Sequence files Avro ORC JSON and Parquette UsedobjectrelationalmapperORM to automate the transfer of data stored inrelationaldatabases tables into objects Experience in using Design Patterns such as MVC Singleton and frameworks such as DJANGO Ability in handling Django ORM ObjectRelationalMapper and SQL Alchemy Implementing customer data collection withPySparkHadoop analytics Managed and reviewed Hadoop log file and also worked in analyzing SQL scripts and designed the solution for the process usingPySpark Develop customSAScode for performance monitoring reports Import excel files intoSASfor data manipulation and extraction DevelopedSAScode for data analysis and report generation using Macro Processing Proc Report to generate Excel spreadsheets Pysparkwe implemented Caching Accumulators and UDFs We have implementedpysparkfor Transformation and Actions in Spark Hands on experience withSparkCoreSparkSQL and Data FramesData SetsRDD API Changed mapreduce jobs and Hive scripts withSparkDataFrame transformation and action Excellent knowledge onSparkArchitecture and Hadoop Architecture and its ecosystems such as HDFS Job Tracker Task Tracker Name Node Data Node and Map Reduce programming paradigm Develop python code to automate the ingestion of common formats such as JSON CSV by using Logstash from elastic search toKibanadashboard to be viewed by clients Responsible for designing and deploying new ELK clusters Elasticsearch Logstash Graphite Kibana beats Kafka zookeeper etc Experience on Key AWS services EC2 S3 DynamoDB NoSQL and Lambda Responsible for the Automation of the deployment of the Conductor application on AWS lambda using highend AWS architectural components Developed AWS lambda scripts to build on demand EC2 instance formation AutomatedRabbitMQcluster installations and configuration using PythonBash Fixed issues related to OpenStack components such as Nova Glance Neutron Keystone MySQLPerconaDB RabbitMQ Cech Repose HAP Roxy and Horizon Experienced in developing API services PythonTornado while leveraging AMQP andRabbitMQfor distributed architectures Designed and developed web crawler in python using Scrappy framework and usingRabbitMQas a messaging server between the micro services Experience withKibanato check logs and other timestamped data sets stored in Elastic Search Written and Maintained Automated Salt scripts for Elasticsearch Logstash Kibana and Beats Worked on several python packages like NumPy Beautiful SoupSQL Alchemy Py Tables etc Developed full stack Python web framework with an emphasis on simplicity flexibility and extensibility It is built atop excellent components and reinvents zero wheels WSGI routing templating forms data plugins config eventsSQL Alchemy Storm CouchDB OpenID App Engine jQuery etc Enabled continuous delivery via Gitlab Spinnaker Docker Jenkins Terraform and AWS Designed and developed load tests using Scala Gatling Migrated 10 TB of data from Oracle to Cassandra datacenter 12 nodes that have 4TB drives each using Stable Loader Worked on performance tuning of cluster using Cassandra Configuration file and JVM Parameters Configured internode communication between Cassandra nodes and client using SSL encryption Evaluated benchmarked and tuned data model by running endurance tests using JMeter Cassandra Stress Tool and OpsCenter Analysis of logs data and filter required columns by Logstash configuration and send it to Elasticsearch Validated BI Support events transformed and batched events which are sent to HNM andKafkaby triggering these events usingKafka Mesos Used micro service architecture with Spring Bootbased services interacting of REST andKafka DevelopedKafkaproducer and consumers HBase clients Spark shark Streams and Hadoop MapReduce jobs along with components on HDFS Hive Creating restful web services for Catalog and Pricing with Django MVT Jersey MySQL and MongoDB Worked with JSON based REST Web services and Amazon Web Services AWS Use AWS cloud management console spinnaker to work with AWS Wrote python scripts using boto3 library to manage ec2 instances and CloudFormation stack Created realtime dashboard for Executives utilizing Logstash graphite Elastic Search Kibana Redis Experience in configuring and working with Flume andKafkato load the data from multiple web sources directly into HDFS Used Redis cache for storing commonly used info and propagate the changes usingRabbitMQ Worked on Angular JS framework to develop interactive websites based on client needs Used Cassandra for database andRedisfor cache for storing and fetching the data UsedRedisCache for high performance which creates space for new data by removing old data Developed Ruby on Rails web applications using MongoDB and background processes using Risqu andRedis Utilized Python in the handling of all hits on DjangoRedis and other application Successfully migrated the websites main database from MySQL to PostgreSQL Helped the big data analytics team with implementation of python scripts for Sqoop spark and Hadoop batch data streaming Developed frontends using HTML5 CSS3 JavaScript and jQuery Designed and created the database tables and wrote SQL queries to access PostgreSQL Used Kubernetes to deploy scale load balance and worked on Docker Engine Docker HUB Docker Images Docker Compose for handling images for installations and domain configurations Implemented in Jenkins for Continuous Integration and for automating all builds and deployments and Build Jenkins jobs to createAWSinfrastructure from GitHub repos containing terraform code and Installed and Administered Jenkins CI for Maven Builds Developed Python based API RESTful Web Service to track the events and perform analysis using Flask Ingested large CSV XML JSON data from computers around the world utilizing Python with pandas csv xml and NumPy Formatted the raw data and built dynamic statistic pages for engineers Migrated data from a mongo dB and python2 environment to an Elasticsearch python 3 workflow Developed Micro services for the HP team using Spring Boot and Java 8 IntegratedHibernateORM with SpringHibernateframework to facilitate DML and DQL queries and represent objectdatabase mapping Kubernetesis being used to orchestrate the deployment scaling and management of Docker Containers Used Jenkins pipelines to drive all micro services builds out to the Docker registry and then deployed toKubernetes Created Pods and managed usingKubernetes Managed local deployments inKubernetes creating local cluster and deploying application containers Wrote AJAX calls to populate tables tab menu and other components with JSON data in AngularJS Extensively used HTML5 AngularJS JSON AJAX and DOM scripting for form validations Worked on the MySQL migration project to make the system completely independent of the database being used UsedSpringto implement this Involved in multitiered J2EE design utilizing MVC architectureSpring Struts Hibernate and EJB deployed on WebSphere Application Server connecting to an Oracle database Implemented a continuous Delivery Pipeline with Jenkins and GitHub to build a newDocker container automatically UsedDockerto implement a highlevel API to provide lightweight containers that run processes isolation and worked on creation of customizedDockercontainer images tagged and pushed the images to theDockerrepository Participated in development of a well responsive single page application using AngularJS framework Java Script and jQuery in conjunction with HTML5 CSS3 standards with frontend UI team Extensively used HTML5 AngularJS JSON AJAX and DOM scripting for form validations Automated various infrastructure activities like Continuous Deployment Application Server setup Stack monitoring using Ansible playbooks and has Integrated Ansible with Run deck and Jenkins Wrote Ansible Playbooks with Python SSH as the Wrapper to Manage Configurations of AWS nodes and Tested Playbooks on AWS instances using Python Run Ansible Scripts to Provide Dev Servers Experience in using GIT Repository Managers for Maven builds Used Celery as task queue andRabbitMQ Redis as messaging broker to execute asynchronous tasks Python Developer UPS Atlanta GA August 2013 to October 2015 Developed Wrapper in Python for instantiating multithreaded application and Deploy and monitor scalable infrastructure on Amazon web services AWS Used Test driven approachTDD for developing services required for the application Managed datasets using Panda data frames and MySQL queries MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve Datacenter migration to Amazon Web Services AWS infrastructure and provided initial support to Applications and Database teams Familiarity and experience with some ORM ObjectRelationalMapper libraries Developed requirements and enterprise architecture for EIA metadata Eguide and EBI underSASVB Developed and implemented Legacy system programs by using COBOL DB2 CICS JCL JAVA and VSAM ResponsibleSASreports analysis usingSASmacros in UNIX operating system Worked on Big Data infrastructure for batch processing and realtime processing using ApacheSpark Built scalable distributed Hadoop cluster running Hortonworks Data Platform Responsible for design and development ofSparkSQL Scripts based on Functional Specifications Worked on the largescale Hadoop YARN cluster for distributed data processing and analysis usingSpark Hive Develop python code to automate the ingestion of common formats such as JSON CSV by using Logstash from elastic search toKibanadashboard to be viewed by clients Responsible for designing and deploying new ELK clusters Elasticsearch Logstash Graphite Kibana beats Kafka zookeeper etc Parsed the unstructured data into semistructured format by writing complex algorithms inpyspark Extensive working experience in free marker Struts framework Spring framework and OR Mapping Hibernateframework Designed and codedHibernate struts for mapping configurations and HQL for enhancement and new module development of Transport Optimization Planning and Scheduling Web app AutomatedRabbitMQcluster installations and configuration using PythonBash Managed developed and designed a dashboard control panel for customers and Administrators using Django Oracle DB PostgreSQL and VMWare API calls Developed micro services usingspringboot exposed as REST API and integrated with AngularJS based web applications Integrated AD with Cassandra Authorization Designed Automated the process of installation and configuration of secure DataStax Enterprise Cassandra cluster using puppet Monitored the cluster with Zabbix Configured internode communication between Cassandra nodes and client using SSL encryption Developed shell scripts along with setting up of CRON jobs for monitoring and automated data backup on Cassandra cluster Created data frames schema from raw data stored at Amazon S3 lambda usingPySpark Created azure templates to automate server creation and DSE deployments Installed and configured Cassandra cluster and CQL on the cluster Experience in upgrading the existing Cassandra cluster to latest releases Implemented application level persistence using Hibernate andspring Configured Struts Hibernate framework withSpringMVC Docker container deploying micro services and scaling the deployment usingKubernetes Developed Chat Ops interfaces with slack andKuberneteson GKE Experience with Streaming platforms like ApacheKafka Used ApacheKafkaMessage Queues for reliable and asynchronous exchange of important information between multiple business applications Extensively used python modules such as requests urllib2 for web crawling Working on Spinnaker platform for MultiCloud Continuous Delivery Bake Test DeployContainer Pipelines using Packer Terraform Kubernetes AWS GCP SetupDockeron Linux and configured Jenkins to run underDockerhost Wrote and executed various MYSQL database queries from python using PythonMySQL connector and MySQL dB package Managed local deployments inKubernetes creating local cluster and deploying application containers Experienced in developing API services PythonTornado while leveraging AMQP andRabbitMQfor distributed architectures Added support for Amazon AWS S3 and RDS to host staticmedia files and the database into Amazon Cloud Designed and managed API system deployment using fast http server and Amazon AWS architecture Design and implementation of CICD pipelines using Jenkins and automated CICD pipelines by invoking Ansible playbooks Automated the Oracle 12c installation using ansible scripts Automated email notification using celery andRabbitMQfor status of jobs and pending task list manager to users and admin Profound knowledge and experience on underlying mechanism of docker containers and automated the docker containers using Ansible Expertise in Implementing a Production ready Highly Available Fault Tolerant Kubernetes infrastructure Working on Scheduling deploying and managing container replicas on a node cluster using Kubernetes Setting up the CICD pipeline using GitHub Jenkins Maven Chef Terraform and AWS DevOps experience with GitHub Maven Nagios Docker Jenkins Puppet Chef Ansible Virtualized the servers using the Docker for the test environments and devenvironments needs and configuration automation using Docker Containers Integrated Kafka with Spark streaming for high speed data processing Built Web pages that are more userinteractive using Jasmine Karma HTML CSS LESS RESTFUL API Services JavaScript Bootstrap GIT and JSON Used Celery as task queue andRabbitMQ Redis as messaging broker to execute asynchronous tasks Built Web pages that are more userinteractive using Jasmine Karma HTML CSS LESS RESTFUL A Having good experience in Struts Spring IOC Spring MVC Spring Data Spring Boot Spring Security and other spring frameworks implementation and integration Followed Agile SCRUM methodology and used Test Driven Development TDD and Used BDD pattern for code quality and good readability standards Worked on Redux making to do list reduces reducers functions and implementing store method PI Services JavaScript Bootstrap GIT and JSON Implemented application level persistence usingHibernateand spring Configured StrutsHibernateframework with Spring MVC Written the Grok pattern in Logstash Configured Logstash input filter output plugins database log file sources and elastic search as output Python developer Aetna Hartford CT August 2011 to July 2013 Designed Installed and Implemented Ansible configuration management system Used Ansible to manage Web applications Environments configuration Files Users Mount points and Packages Involved in database Administration activities like taking backup checking log messages looking for database optimization Executed asynchronous tasks with help of Celery and RabbitMQ Developed Kafka consumers to consume data from Kafka topics Responsible for Configuring Kafka Consumer and Producer metrics to visualize the Kafka System performance and monitoring Experience with Kibana to check logs and other timestamped data sets stored in Elastic Search Written and Maintained Automated Salt scripts for Elasticsearch Logstash Kibana and Beats Used Amazon Web Services AWS for improved efficiency of storage and fast access Vast experience with Core Java and J2EE using most of the advanced features of Java including JDBC Spring Struts EJB Servlets Hibernate Added support for Amazon AWS S3 and RDS to host staticmedia files and the database into Amazon Cloud Developed Merge jobs in Python to extract and load data into MySQL database and used Test driven approach for developing applications Cloud platform engineering Kubernetes Spinnaker Docker Terraform Consul drone Jenkins Chef Kitchen Scheduled deployed and managed container replicas onto a node cluster using Kubernetes Developed views and templates with Python and Django view controller and templating language to create a userfriendly interface using MVC architecture Worked on resulting reports of the application and Tableau reports and involved in modifying data using SASBASE SAS MACROS Extracting data from the database using SASAccess SAS SQL procedures and create SAS data sets Involved in installing software using pip command for python libraries like Beautiful Soup NumPy SciPy pythontwitter RabbitMQ Celery matplotlib Pandas dataframe and used the PEP8 coding convention Migration of API code written for Sybase to Oracle and was involved in Overlook the migration activity of PLSQL programs Managed local deployments in Kubernetes creating local cluster and deploying application containers Build backend application with Python Django Worked on Dockers RabbitMQ Celery and Jenkins Experienced in implementing Model View Control MVC architecture using serverside applications like Django and Flask for developing web applications Involved in the migration of the data contained in the earlier ASPL Database from Sybase to Oracle Expertise in working with serverside technologies including Databases Restful API and MVC design patterns Wrote and executed various MySQL database queries from PythonMySQL connector and MySQL db package Used the Python modules NumPy matplotlib etc for generating complex graphical data creation of histograms etc Involved in migrating the Libraries written using Sybase APIs to Oracle OCCI API Automate Build and Release tasks using ANT Shell and Perl for efficiency and repeatability Communication with team members for both Ansible Core and Ansible Tower teams to clarify requirements and overcome obstacles Automated various service and application deployments with ANSIBLE on CentOS and RHEL in AWS Wrote ANSIBLE Playbooks with Python SSH as the Wrapper to Manage Configurations of AWS Nodes and Test Playbooks on AWS instances using Python Run Ansible Scripts to provision Dev servers Used Python Libraries Pandas and NumPy SQL and Tableau to procure clean and aggregate data from Relational database to generate status reports and dashboards Education Bachelors Skills DJANGO 5 years PYTHON 7 years jQuery 5 years AJAX 5 years Flask 5 years Restful 5 years AWS 5 years rabbitMQ 3 years Ajax 4 years Agile 4 years azure 3 years Additional Information SKILLS Python 3327 Django 1413 Flask Java C Shell Script SQL JavaJ2EE AJAX JavaScript HTML DHTML XHTML XML React JSON Jquery Angularjs",
    "unique_id": "0d405219-95c9-4993-a031-d29f6ce25824"
}