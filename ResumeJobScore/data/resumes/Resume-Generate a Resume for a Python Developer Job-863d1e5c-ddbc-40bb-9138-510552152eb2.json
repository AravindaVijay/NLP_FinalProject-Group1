{
    "clean_data": "Sr Python Developer Sr span lPythonspan span lDeveloperspan Sr Python Developer Enphase Energy 7 Years of experience in Analysis Design Development and Implementation of various standalone clientserver enterprise applications Experience with full software development lifecycle architecting scalable platforms objects oriented programming database design and agile methodologies Extensive experience with Django a highlevel Python Web Framework Experience in Object Oriented Programming OOP concepts using Python Core Java Extensive experience in designing and developing webbased applications using Python Django HTML CSS JavaScript JQuery XML and JSON Experience in implementing RESTful Web Services with server side technologies using restful API and MVC design patterns with Django REST framework and Django framework Good experience in handling errorsexceptions and debugging the issues in large scale applications Hands on experience working in WAMP Windows Apache MySQL and Python and LAMP Linux Apache MySQL and Python Architecture Experienced in caching large scale applications using Memcache Redis Expertise in working with different databases like MySQL PostgreSQL Oracle and very good knowledge in NoSQL databases MongoDB Redis Proficient in developing complex SQL queries Stored Procedures Functions along with performing DDL and DML operations on the database Excellent working knowledge in UNIX and Linux shell environment using command line utilities Expertise in Production support and Knowledge of deployment using Jenkins and Ansible Experience working in both Waterfall and Agile software methodologies Familiarity with development best practices such as code reviews Unit Testing System Integration Testing and User Acceptance Testing UAT Hands on experience in working with various Version Control Systems mostly GIT subversion SVN CVS and Mercurial Involved in all the phases of Software Development Life Cycle SDLC using Project Management tools JIRA and Redmine Expert level user of several project management tools including JIRA Trello Well versed with Agile and Test Driven Development methodologies Followed the best practices of Python such as PEP8 Performed code reviews and implemented best Python Programming Practices Experience in writing test scripts test cases test specifications and test coverage Posses good interpersonal skills ability to work in SelfManaged and Team Player Willing to take initiative and able to learn quickly and apply new tools and technologies in the projects Work Experience Sr Python Developer Enphase Energy Petaluma CA April 2016 to Present Enphase Energy brings a systembased hightech approach to solar energy leveraging expertise in semiconductor integration power electronics and networking technologies to continually advance the performance intelligence and reliability of solar energy systems Responsibilities Understanding the project documentation analyzing and converting into technical requirements Requirement analysis and Estimation of project timelines Participating in Sprint Planning and Releases Performed efficient delivery of code based on principles of Test Driven development TDD and continuous integration to keep in line with Agile Software Methodology principles and SCRUM process Implemented Utility Services for collecting and visualizing the Energy data Used Pandas Library for statistical analysis Designed the functionality to read the data from DynamoDB and clean the data and arrange the data into timeframes using Pandas Used Numpy along with Pandas for computing min max and mean power voltages Implemented REST API calls to access the production data Implementing lambda functions to perform tasks when subscribed rules matched Creating s3 buckets and adding permissions to store and access the data files from external scripts Added support to sync all staticmedia files to AWS S3 bucket from Django Developed custom modules to parsing XML and JSON Files using lxml simplejson and load the data into database Designed the entire web application using Python Django MySQL MongoDB and Some Amazon Web Services like S3 RDS and DynamoDB Utilized JIRA for bug reports update reports and monitoring team work progress Integrated Confluence pages into JIRA tool for maintaining the Project planning Project documentation and meeting notes Used JIRA tool for creating and estimating stories building a sprint backlogs reporting on team progress Used Jenkins to automate the Deployment process and run Unit Test cases Environment Python 35 Linux Eclipse Vim Django 19  Html CSS JavaScript JQuery Bootstrap Django REST Framework Agile Scrum Framework JIRA Jenkins Amazon Web Services Git MongoDB MySQL Pandas Sr Python Developer Johnson Johnson New Jersey November 2015 to March 2016 This project involves for collecting information about HIVAids related articles blogs and forums from different websites like hivforums aidmap cdcgov etc and stored the into JSON formatted file Client will apply some analytics and show case into their analytics web application Responsibilities Gathering requirements specifications and analyzing the requirements Created entire framework using Python Scrapy MySQL and Linux Implemented and customized Web Scraping Framework using Pythons Scrapy Framework Utilized python libraries Requests urllib urlparse MySQLdb xlrd xlwt JSON Selenium Facebook and Twitter Developed spiders for collecting the metadata from specified website Created databases and tables using MySQL wrote several queries to extractstore data Implemented functionality to get the timeline information Specified Doctors from Facebook and Twitter websites using their Python APIs Developed some spiders using python selenium library to collect the metadata Developed functionality to verify the data quality and applying some sanity checks on top of the collected data Developed independent scripts to read the data from MySQL and generating Excel formatted using Xlrd Xlwt and CSV python libraries Followed PEP8 Coding Standards for maintaining the quality code Used JIRA tool for creating and estimating stories building a sprint backlog reporting on team progress Utilized JIRA tool for bug tracking Environment Python 27 Ubuntu Vim Scrapy Requests Urllib MySQL Shell Scripting Json CSV Xlrd Xlwt Selenium APIsFacebook Twitter JIRA Scrum Framework Agile Python Developer Cisco System Bangalore Karnataka May 2015 to October 2015 This project involves to take a collection of scripts which collectively take an IOS formatted configuration file from user Convert CLI commands contained within the input file over to their equivalents appropriate for an IOSXR system and present the converted results to the user in an interactive manner that allows the user to analyze the efficiency of the conversion Responsibilities Analyzed the requirements specifications and in NCE interaction during requirements specifications Developed views and templates with Python and Django view controllers and template language to create a user friendly interface Used Django configuration to manage URLs and application parameters Created entire application using python Django MySQL and Windows Developed presentation layer using HTML CSS JavaScript and JQuery Used JQuery libraries for all client side JavaScript manipulations and validations Utilized Python libraries Gzip Selenium Unittest SQLAlchemy and Json Implemented SQLAlchemy which is a python library for complete access over SQL Implemented functionality to validate the selected or uploaded input file extension must be zip Developed backend functionality to unzip the uploaded input file and read the input files one by one Utilized existing scripts to Parse input lines into scopes BGP Interface accesslist routemap and instantiate a corresponding object class Implemented new feature to download the output into outputzip file Created database using MySQL wrote several queries to extractstore data Used Selenium Library to automate the testing process with multiple browsers Deployed the application into Apache using Mercurial Version Control System Responsible for debugging and troubleshooting the web application Followed PEP8 Coding Standards for maintaining the quality code Environments Python 27 Komodo Edit Windows 7 Django Pyramid Gzip Html Css Javascript Jquery Selenium Mercurial MySQL SQLAlchemy unittest Django ORM Lead Python Developer Rovi Corp Bangalore Karnataka May 2014 to April 2015 This project involves for collecting all Movies and Tvshows Availability information and Metadata from different branded network websites like Amazon CBS Hulu Netflix ABC NBC etc and push into MySQL database Client will consume these information and apply some Merge algorithms to showcase in the client interface Responsibilities Responsible for gathering requirements specifications and in client interaction during requirements Involved in system analysis design development testing and deployment process Participated in the complete SDLC process Implemented and customized Web Scraping Framework using Pythons Scrapy Framework Created database using MySQL wrote several queries to extractstore data Developed functionality to create new table schemas automatically when they are not exists Designed the framework to store and get the scraping urls from corresponding url queue table Written pipelines functionality to store the scraped items into files in json format Implemented functionality to validate the scraped items if any item is not valid it will drop Automatically Developed functionality to send alert emails when something went wrong in the framework Implemented functionality to validate the scraped items if any item is not valid it will drop automatically Written scripts to read the data from files and populated into MySQL tables Written shell scripts to move files from one location to another location and removing empty data files Developed new system called Dead System to check specific asset health status in source site if it is not existing we will remove from our DB Developed new REST API using Django REST API Framework to display the records available in the database Followed PEP8 Coding Standards for maintaining the quality code and code standards Used tools like Pyflakes Pylint and Pychecker for checking the code quality and finding bugs in code level very oftenly Environment Python 27 Vim Ubuntu Scrapy Requests Urllib MySQL Shell Scripting Json CVS Django REST Framework Django ORM pip pychecker pylint Lead Python Developer Rovi Corp Bangalore Karnataka September 2013 to April 2014 Objective of this project is to group all friends of user in different social networking sites like Facebook Twitter and Google etc into one platform For this needs to get permission from the auth server and the user User can grant and revoke access at any time and for any network site Responsibilities Implemented Login through various social networking sites Facebook Twitter Netflix and Google Fetching the user profile info shares posts likes friends and followers using APIs of the social network sites Implemented algorithms to get wiki merges for respective postlikeshares Used Selenium Library to write fully functioning test automation process that allowed the simulation of submitting different we request from multiple browser to web application Environment Python 27 Vim Django Django ORM Oauth2 Requests Urllib ApisFacebook Twitter Netflix Selenium CVS pip Lead Python Developer Headrun Technologies Bangalore Karnataka February 2013 to August 2013 It is a social media analytics organization Buzzinga listens into all mainstream social media sources such as Twitter Facebook public Google YouTube Instagram and Flickr and also maintains a massive listening index of millions of News Blogs and Forum sources enabling listening on a near realtime level Responsibilities Implemented backend functionality to add modify and delete the tacking keywords Supported to track keywords asynchronously using tornado Gathering tremendous amounts of data from the Internet for given keywords Built Pipelines to store the data in Redis Server Applying sentiment and Klout scores to enrich the data Written functionality to store enriched data into Elasticsearch Implemented automate scripts to backup the old records using mongodb export command and transfer these backup files into backup machine using ftplib Maintaining multiple copies of data in different database servers using MongoDB Replication concept Environment Python 27 Vim Django Django ORM Scrapy Requests Urllib ApisFacebook Twitter Klout MongoDB Redis ElasticSearch Tornado ftplib Github pip Lead Python Developer Veveo Inc Bangalore Karnataka February 2012 to January 2013 Project is aimed to monitor the quality of voice search product developed by my client For this developed a Django tool that displays the passfail count of test cases Responsibilities Lead developer on a small team that oversees all levels of support includes maintenance improvements and new development Daily tasks include frontend development and backend development Implemented stats table which displays the passfail statues of the test cases Implemented feature to download the test cases report in JsonExcel format Responsible for deploying the source code to production after adding any new feature into this and checking performance Environment Python 27 Vim Django Django ORM MySQL Requests Urllib lxml Html Css JavaScript Jquery CVS pip Python Developer Veveo Inc Bangalore Karnataka August 2011 to January 2012 This project which is responsible to track persons current travels and orders Our aim is to extract content of air travel confirmation emails and order confirmation emails Responsibilities Emails formats are vary from agency to agency for travel mails or for product order mails First we have to check how many different pattern emails are available and maintain a config file that have the email format and a template filename which parse this type of email content Written scripts to save emails content as HTML files for ease while parsing data Written scripts to identify the email format and select template file name from config file and run the template file and write parsed email content into data files Implemented a loader functionality which loads parsed data files into MySQL tables Email parsing templates code is developed by crawling team Written an automated script that will check and inform through mail whether there is any new format email appears or not If yes inform the crawling team and once the code developed add new email format details in config file so that new email formats also get parsed Based on the city names between which cities the person is traveling get the latlong details using internal tools Environment Python 27 Vim BeautifulSoup Requests MySQL CVS Redmine Python Developer Veveo Inc Bangalore Karnataka August 2010 to July 2011 This project which is responsible to track persons current travels and orders Our aim is to extract content of air travel confirmation emails and order confirmation emails Responsibilities This Project involves crawling metadata from different websites like sports related media sites tvshowsmovies sites and other social networking sites through scripts and storing the data into MySQL database Responsibilities Finding the websites related to media Analyze the website to reach the client requirement Writing code templates and implementing them with different methods to get the metadata Developer Pumping records into database and verifying the records in database Scheduling the Script to run regularly Environment Python 27 Urllib lxml Requests MySQL Vim CVS pip Education Masters in Computer Applications Bharathidasan University Tiruchchirappalli Tamil Nadu Additional Information TECHNICAL PROFICIENCIES Programming Languages Python 2x 3x Java Shell Scripting Python Frameworks Django Django REST Framework Flask Pyramid Scrapy Tornado Python Libraries Pandas Numpy Unittest JSON CSV XML XLS Selenium  Database Systems MySQL Sqlite3 Django ORM SQLAlchemy Oracle NoSQL Database Systems MongoDB Redis Web Development Languages HTML CSS JavaScript JQuery JSON NodeJS Operating Systems Linux Ubuntu CentOS Windows 7 10 XP Development Methodologies Agile Methodology Scrum Framework OOP MVC Architecture Deployment Tools Jenkins Ansible Version Control Git SVN CVS Mercurial Development Tools IDEs Eclipse NetBeans ViVim Sublime Text Komodo Edit PyCharm IDLE Tracking Tools JIRA Redmine Trello Confluence Amazon Web ServicesAWS EC2 S3 EBS Lambda DynamoDB Redshift SNS",
    "entities": [
        "Html CSS",
        "the Project planning Project",
        "Karnataka",
        "UNIX",
        "Agile Software Methodology",
        "Dead System",
        "Present Enphase Energy",
        "JsonExcel",
        "LAMP Linux",
        "Mercurial Involved",
        "Google",
        "Participating in Sprint Planning",
        "XML",
        "Software Development Life Cycle SDLC",
        "Redis Server Applying",
        "Python Developer Rovi Corp",
        "Amazon",
        "Built Pipelines",
        "Test Driven",
        "AWS S3",
        "Utilized",
        "New Jersey",
        "Waterfall",
        "Client",
        "DDL",
        "CBS",
        "Python Developer Veveo Inc",
        "Work Experience Sr Python Developer Enphase Energy",
        "SelfManaged",
        "Agile and Test Driven Development methodologies Followed",
        "Google Fetching",
        "Redis ElasticSearch Tornado",
        "Unit Test cases Environment Python",
        "MySQL PostgreSQL Oracle",
        "SQL Implemented",
        "MVC",
        "Responsibilities Understanding",
        "Posses",
        "GIT",
        "Python Web Framework",
        "DB Developed",
        "WAMP Windows Apache MySQL and Python",
        "Estimation",
        "SVN CVS Mercurial Development Tools",
        "CSV",
        "API",
        "HTML CSS JavaScript",
        "Created",
        "Automatically Developed",
        "Project Management",
        "Redis Proficient",
        "Pychecker",
        "Apache",
        "Used Selenium Library",
        "Pandas Used Numpy",
        "Python Programming Practices",
        "Responsibilities Responsible",
        "Followed PEP8 Coding Standards",
        "SQL",
        "DML",
        "lPythonspan",
        "SVN CVS",
        "Pylint",
        "Utilized Python",
        "Pandas",
        "Implemented Utility Services",
        "Unit Testing System Integration Testing",
        "Web Scraping Framework",
        "Stored Procedures Functions",
        "Elasticsearch Implemented",
        "Mercurial Version Control System Responsible",
        "JavaScript",
        "Responsibilities Analyzed",
        "Responsibilities Emails",
        "Version Control Systems",
        "Parse",
        "Responsibilities This Project",
        "Developer Pumping",
        "BGP Interface",
        "Analysis Design Development and Implementation",
        "Energy",
        "info",
        "NoSQL Database Systems",
        "NetBeans",
        "TDD",
        "NoSQL"
    ],
    "experience": "Experience with full software development lifecycle architecting scalable platforms objects oriented programming database design and agile methodologies Extensive experience with Django a highlevel Python Web Framework Experience in Object Oriented Programming OOP concepts using Python Core Java Extensive experience in designing and developing webbased applications using Python Django HTML CSS JavaScript JQuery XML and JSON Experience in implementing RESTful Web Services with server side technologies using restful API and MVC design patterns with Django REST framework and Django framework Good experience in handling errorsexceptions and debugging the issues in large scale applications Hands on experience working in WAMP Windows Apache MySQL and Python and LAMP Linux Apache MySQL and Python Architecture Experienced in caching large scale applications using Memcache Redis Expertise in working with different databases like MySQL PostgreSQL Oracle and very good knowledge in NoSQL databases MongoDB Redis Proficient in developing complex SQL queries Stored Procedures Functions along with performing DDL and DML operations on the database Excellent working knowledge in UNIX and Linux shell environment using command line utilities Expertise in Production support and Knowledge of deployment using Jenkins and Ansible Experience working in both Waterfall and Agile software methodologies Familiarity with development best practices such as code reviews Unit Testing System Integration Testing and User Acceptance Testing UAT Hands on experience in working with various Version Control Systems mostly GIT subversion SVN CVS and Mercurial Involved in all the phases of Software Development Life Cycle SDLC using Project Management tools JIRA and Redmine Expert level user of several project management tools including JIRA Trello Well versed with Agile and Test Driven Development methodologies Followed the best practices of Python such as PEP8 Performed code reviews and implemented best Python Programming Practices Experience in writing test scripts test cases test specifications and test coverage Posses good interpersonal skills ability to work in SelfManaged and Team Player Willing to take initiative and able to learn quickly and apply new tools and technologies in the projects Work Experience Sr Python Developer Enphase Energy Petaluma CA April 2016 to Present Enphase Energy brings a systembased hightech approach to solar energy leveraging expertise in semiconductor integration power electronics and networking technologies to continually advance the performance intelligence and reliability of solar energy systems Responsibilities Understanding the project documentation analyzing and converting into technical requirements Requirement analysis and Estimation of project timelines Participating in Sprint Planning and Releases Performed efficient delivery of code based on principles of Test Driven development TDD and continuous integration to keep in line with Agile Software Methodology principles and SCRUM process Implemented Utility Services for collecting and visualizing the Energy data Used Pandas Library for statistical analysis Designed the functionality to read the data from DynamoDB and clean the data and arrange the data into timeframes using Pandas Used Numpy along with Pandas for computing min max and mean power voltages Implemented REST API calls to access the production data Implementing lambda functions to perform tasks when subscribed rules matched Creating s3 buckets and adding permissions to store and access the data files from external scripts Added support to sync all staticmedia files to AWS S3 bucket from Django Developed custom modules to parsing XML and JSON Files using lxml simplejson and load the data into database Designed the entire web application using Python Django MySQL MongoDB and Some Amazon Web Services like S3 RDS and DynamoDB Utilized JIRA for bug reports update reports and monitoring team work progress Integrated Confluence pages into JIRA tool for maintaining the Project planning Project documentation and meeting notes Used JIRA tool for creating and estimating stories building a sprint backlogs reporting on team progress Used Jenkins to automate the Deployment process and run Unit Test cases Environment Python 35 Linux Eclipse Vim Django 19   Html CSS JavaScript JQuery Bootstrap Django REST Framework Agile Scrum Framework JIRA Jenkins Amazon Web Services Git MongoDB MySQL Pandas Sr Python Developer Johnson Johnson New Jersey November 2015 to March 2016 This project involves for collecting information about HIVAids related articles blogs and forums from different websites like hivforums aidmap cdcgov etc and stored the into JSON formatted file Client will apply some analytics and show case into their analytics web application Responsibilities Gathering requirements specifications and analyzing the requirements Created entire framework using Python Scrapy MySQL and Linux Implemented and customized Web Scraping Framework using Pythons Scrapy Framework Utilized python libraries Requests urllib urlparse MySQLdb xlrd xlwt JSON Selenium Facebook and Twitter Developed spiders for collecting the metadata from specified website Created databases and tables using MySQL wrote several queries to extractstore data Implemented functionality to get the timeline information Specified Doctors from Facebook and Twitter websites using their Python APIs Developed some spiders using python selenium library to collect the metadata Developed functionality to verify the data quality and applying some sanity checks on top of the collected data Developed independent scripts to read the data from MySQL and generating Excel formatted using Xlrd Xlwt and CSV python libraries Followed PEP8 Coding Standards for maintaining the quality code Used JIRA tool for creating and estimating stories building a sprint backlog reporting on team progress Utilized JIRA tool for bug tracking Environment Python 27 Ubuntu Vim Scrapy Requests Urllib MySQL Shell Scripting Json CSV Xlrd Xlwt Selenium APIsFacebook Twitter JIRA Scrum Framework Agile Python Developer Cisco System Bangalore Karnataka May 2015 to October 2015 This project involves to take a collection of scripts which collectively take an IOS formatted configuration file from user Convert CLI commands contained within the input file over to their equivalents appropriate for an IOSXR system and present the converted results to the user in an interactive manner that allows the user to analyze the efficiency of the conversion Responsibilities Analyzed the requirements specifications and in NCE interaction during requirements specifications Developed views and templates with Python and Django view controllers and template language to create a user friendly interface Used Django configuration to manage URLs and application parameters Created entire application using python Django MySQL and Windows Developed presentation layer using HTML CSS JavaScript and JQuery Used JQuery libraries for all client side JavaScript manipulations and validations Utilized Python libraries Gzip Selenium Unittest SQLAlchemy and Json Implemented SQLAlchemy which is a python library for complete access over SQL Implemented functionality to validate the selected or uploaded input file extension must be zip Developed backend functionality to unzip the uploaded input file and read the input files one by one Utilized existing scripts to Parse input lines into scopes BGP Interface accesslist routemap and instantiate a corresponding object class Implemented new feature to download the output into outputzip file Created database using MySQL wrote several queries to extractstore data Used Selenium Library to automate the testing process with multiple browsers Deployed the application into Apache using Mercurial Version Control System Responsible for debugging and troubleshooting the web application Followed PEP8 Coding Standards for maintaining the quality code Environments Python 27 Komodo Edit Windows 7 Django Pyramid Gzip Html Css Javascript Jquery Selenium Mercurial MySQL SQLAlchemy unittest Django ORM Lead Python Developer Rovi Corp Bangalore Karnataka May 2014 to April 2015 This project involves for collecting all Movies and Tvshows Availability information and Metadata from different branded network websites like Amazon CBS Hulu Netflix ABC NBC etc and push into MySQL database Client will consume these information and apply some Merge algorithms to showcase in the client interface Responsibilities Responsible for gathering requirements specifications and in client interaction during requirements Involved in system analysis design development testing and deployment process Participated in the complete SDLC process Implemented and customized Web Scraping Framework using Pythons Scrapy Framework Created database using MySQL wrote several queries to extractstore data Developed functionality to create new table schemas automatically when they are not exists Designed the framework to store and get the scraping urls from corresponding url queue table Written pipelines functionality to store the scraped items into files in json format Implemented functionality to validate the scraped items if any item is not valid it will drop Automatically Developed functionality to send alert emails when something went wrong in the framework Implemented functionality to validate the scraped items if any item is not valid it will drop automatically Written scripts to read the data from files and populated into MySQL tables Written shell scripts to move files from one location to another location and removing empty data files Developed new system called Dead System to check specific asset health status in source site if it is not existing we will remove from our DB Developed new REST API using Django REST API Framework to display the records available in the database Followed PEP8 Coding Standards for maintaining the quality code and code standards Used tools like Pyflakes Pylint and Pychecker for checking the code quality and finding bugs in code level very oftenly Environment Python 27 Vim Ubuntu Scrapy Requests Urllib MySQL Shell Scripting Json CVS Django REST Framework Django ORM pip pychecker pylint Lead Python Developer Rovi Corp Bangalore Karnataka September 2013 to April 2014 Objective of this project is to group all friends of user in different social networking sites like Facebook Twitter and Google etc into one platform For this needs to get permission from the auth server and the user User can grant and revoke access at any time and for any network site Responsibilities Implemented Login through various social networking sites Facebook Twitter Netflix and Google Fetching the user profile info shares posts likes friends and followers using APIs of the social network sites Implemented algorithms to get wiki merges for respective postlikeshares Used Selenium Library to write fully functioning test automation process that allowed the simulation of submitting different we request from multiple browser to web application Environment Python 27 Vim Django Django ORM Oauth2 Requests Urllib ApisFacebook Twitter Netflix Selenium CVS pip Lead Python Developer Headrun Technologies Bangalore Karnataka February 2013 to August 2013 It is a social media analytics organization Buzzinga listens into all mainstream social media sources such as Twitter Facebook public Google YouTube Instagram and Flickr and also maintains a massive listening index of millions of News Blogs and Forum sources enabling listening on a near realtime level Responsibilities Implemented backend functionality to add modify and delete the tacking keywords Supported to track keywords asynchronously using tornado Gathering tremendous amounts of data from the Internet for given keywords Built Pipelines to store the data in Redis Server Applying sentiment and Klout scores to enrich the data Written functionality to store enriched data into Elasticsearch Implemented automate scripts to backup the old records using mongodb export command and transfer these backup files into backup machine using ftplib Maintaining multiple copies of data in different database servers using MongoDB Replication concept Environment Python 27 Vim Django Django ORM Scrapy Requests Urllib ApisFacebook Twitter Klout MongoDB Redis ElasticSearch Tornado ftplib Github pip Lead Python Developer Veveo Inc Bangalore Karnataka February 2012 to January 2013 Project is aimed to monitor the quality of voice search product developed by my client For this developed a Django tool that displays the passfail count of test cases Responsibilities Lead developer on a small team that oversees all levels of support includes maintenance improvements and new development Daily tasks include frontend development and backend development Implemented stats table which displays the passfail statues of the test cases Implemented feature to download the test cases report in JsonExcel format Responsible for deploying the source code to production after adding any new feature into this and checking performance Environment Python 27 Vim Django Django ORM MySQL Requests Urllib lxml Html Css JavaScript Jquery CVS pip Python Developer Veveo Inc Bangalore Karnataka August 2011 to January 2012 This project which is responsible to track persons current travels and orders Our aim is to extract content of air travel confirmation emails and order confirmation emails Responsibilities Emails formats are vary from agency to agency for travel mails or for product order mails First we have to check how many different pattern emails are available and maintain a config file that have the email format and a template filename which parse this type of email content Written scripts to save emails content as HTML files for ease while parsing data Written scripts to identify the email format and select template file name from config file and run the template file and write parsed email content into data files Implemented a loader functionality which loads parsed data files into MySQL tables Email parsing templates code is developed by crawling team Written an automated script that will check and inform through mail whether there is any new format email appears or not If yes inform the crawling team and once the code developed add new email format details in config file so that new email formats also get parsed Based on the city names between which cities the person is traveling get the latlong details using internal tools Environment Python 27 Vim BeautifulSoup Requests MySQL CVS Redmine Python Developer Veveo Inc Bangalore Karnataka August 2010 to July 2011 This project which is responsible to track persons current travels and orders Our aim is to extract content of air travel confirmation emails and order confirmation emails Responsibilities This Project involves crawling metadata from different websites like sports related media sites tvshowsmovies sites and other social networking sites through scripts and storing the data into MySQL database Responsibilities Finding the websites related to media Analyze the website to reach the client requirement Writing code templates and implementing them with different methods to get the metadata Developer Pumping records into database and verifying the records in database Scheduling the Script to run regularly Environment Python 27 Urllib lxml Requests MySQL Vim CVS pip Education Masters in Computer Applications Bharathidasan University Tiruchchirappalli Tamil Nadu Additional Information TECHNICAL PROFICIENCIES Programming Languages Python 2x 3x Java Shell Scripting Python Frameworks Django Django REST Framework Flask Pyramid Scrapy Tornado Python Libraries Pandas Numpy Unittest JSON CSV XML XLS Selenium   Database Systems MySQL Sqlite3 Django ORM SQLAlchemy Oracle NoSQL Database Systems MongoDB Redis Web Development Languages HTML CSS JavaScript JQuery JSON NodeJS Operating Systems Linux Ubuntu CentOS Windows 7 10 XP Development Methodologies Agile Methodology Scrum Framework OOP MVC Architecture Deployment Tools Jenkins Ansible Version Control Git SVN CVS Mercurial Development Tools IDEs Eclipse NetBeans ViVim Sublime Text Komodo Edit PyCharm IDLE Tracking Tools JIRA Redmine Trello Confluence Amazon Web ServicesAWS EC2 S3 EBS Lambda DynamoDB Redshift SNS",
    "extracted_keywords": [
        "Sr",
        "Python",
        "Developer",
        "Sr",
        "lPythonspan",
        "span",
        "lDeveloperspan",
        "Sr",
        "Python",
        "Developer",
        "Enphase",
        "Energy",
        "Years",
        "experience",
        "Analysis",
        "Design",
        "Development",
        "Implementation",
        "enterprise",
        "applications",
        "Experience",
        "software",
        "development",
        "lifecycle",
        "platforms",
        "programming",
        "database",
        "design",
        "methodologies",
        "experience",
        "Django",
        "highlevel",
        "Python",
        "Web",
        "Framework",
        "Experience",
        "Object",
        "Programming",
        "OOP",
        "concepts",
        "Python",
        "Core",
        "Java",
        "experience",
        "applications",
        "Python",
        "Django",
        "HTML",
        "CSS",
        "JavaScript",
        "JQuery",
        "XML",
        "JSON",
        "Experience",
        "Web",
        "Services",
        "server",
        "side",
        "technologies",
        "API",
        "MVC",
        "design",
        "patterns",
        "Django",
        "REST",
        "framework",
        "Django",
        "experience",
        "errorsexceptions",
        "issues",
        "scale",
        "applications",
        "Hands",
        "experience",
        "WAMP",
        "Windows",
        "Apache",
        "MySQL",
        "Python",
        "LAMP",
        "Linux",
        "Apache",
        "MySQL",
        "Python",
        "Architecture",
        "scale",
        "applications",
        "Memcache",
        "Redis",
        "Expertise",
        "databases",
        "MySQL",
        "PostgreSQL",
        "Oracle",
        "knowledge",
        "NoSQL",
        "Redis",
        "Proficient",
        "SQL",
        "Stored",
        "Procedures",
        "Functions",
        "DDL",
        "DML",
        "operations",
        "database",
        "Excellent",
        "knowledge",
        "UNIX",
        "Linux",
        "shell",
        "environment",
        "command",
        "line",
        "utilities",
        "Expertise",
        "Production",
        "support",
        "Knowledge",
        "deployment",
        "Jenkins",
        "Ansible",
        "Experience",
        "Waterfall",
        "software",
        "Familiarity",
        "development",
        "practices",
        "code",
        "reviews",
        "Unit",
        "Testing",
        "System",
        "Integration",
        "Testing",
        "User",
        "Acceptance",
        "Testing",
        "UAT",
        "Hands",
        "experience",
        "Version",
        "Control",
        "Systems",
        "GIT",
        "subversion",
        "SVN",
        "CVS",
        "Mercurial",
        "phases",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "SDLC",
        "Project",
        "Management",
        "tools",
        "JIRA",
        "Redmine",
        "Expert",
        "level",
        "user",
        "project",
        "management",
        "tools",
        "JIRA",
        "Trello",
        "Agile",
        "Test",
        "Driven",
        "Development",
        "methodologies",
        "practices",
        "Python",
        "PEP8",
        "Performed",
        "code",
        "reviews",
        "Python",
        "Programming",
        "Practices",
        "Experience",
        "test",
        "scripts",
        "test",
        "cases",
        "specifications",
        "test",
        "coverage",
        "Posses",
        "skills",
        "ability",
        "SelfManaged",
        "Team",
        "Player",
        "Willing",
        "initiative",
        "tools",
        "technologies",
        "projects",
        "Work",
        "Experience",
        "Sr",
        "Python",
        "Developer",
        "Enphase",
        "Energy",
        "Petaluma",
        "CA",
        "April",
        "Present",
        "Enphase",
        "Energy",
        "hightech",
        "approach",
        "energy",
        "expertise",
        "semiconductor",
        "integration",
        "power",
        "electronics",
        "networking",
        "technologies",
        "performance",
        "intelligence",
        "reliability",
        "energy",
        "systems",
        "Responsibilities",
        "project",
        "documentation",
        "requirements",
        "Requirement",
        "analysis",
        "Estimation",
        "project",
        "timelines",
        "Sprint",
        "Planning",
        "Releases",
        "delivery",
        "code",
        "principles",
        "Test",
        "development",
        "TDD",
        "integration",
        "line",
        "Agile",
        "Software",
        "Methodology",
        "principles",
        "SCRUM",
        "process",
        "Utility",
        "Services",
        "Energy",
        "data",
        "Pandas",
        "Library",
        "analysis",
        "functionality",
        "data",
        "DynamoDB",
        "data",
        "data",
        "timeframes",
        "Pandas",
        "Numpy",
        "Pandas",
        "min",
        "max",
        "power",
        "voltages",
        "REST",
        "API",
        "production",
        "data",
        "lambda",
        "functions",
        "tasks",
        "rules",
        "Creating",
        "s3",
        "buckets",
        "permissions",
        "data",
        "files",
        "scripts",
        "support",
        "files",
        "AWS",
        "S3",
        "bucket",
        "Django",
        "custom",
        "modules",
        "XML",
        "JSON",
        "Files",
        "lxml",
        "simplejson",
        "data",
        "database",
        "web",
        "application",
        "Python",
        "Django",
        "MySQL",
        "Amazon",
        "Web",
        "Services",
        "S3",
        "RDS",
        "DynamoDB",
        "JIRA",
        "bug",
        "reports",
        "reports",
        "team",
        "work",
        "Integrated",
        "Confluence",
        "pages",
        "JIRA",
        "tool",
        "Project",
        "planning",
        "Project",
        "documentation",
        "meeting",
        "JIRA",
        "tool",
        "stories",
        "sprint",
        "backlogs",
        "team",
        "progress",
        "Jenkins",
        "Deployment",
        "process",
        "Unit",
        "Test",
        "cases",
        "Environment",
        "Python",
        "Linux",
        "Eclipse",
        "Vim",
        "Django",
        "Html",
        "CSS",
        "JavaScript",
        "JQuery",
        "Bootstrap",
        "Django",
        "Framework",
        "Agile",
        "Scrum",
        "Framework",
        "JIRA",
        "Jenkins",
        "Amazon",
        "Web",
        "Services",
        "Git",
        "MongoDB",
        "MySQL",
        "Pandas",
        "Sr",
        "Python",
        "Developer",
        "Johnson",
        "Johnson",
        "New",
        "Jersey",
        "November",
        "March",
        "project",
        "information",
        "articles",
        "blogs",
        "forums",
        "websites",
        "hivforums",
        "cdcgov",
        "file",
        "Client",
        "analytics",
        "case",
        "analytics",
        "web",
        "application",
        "Responsibilities",
        "Gathering",
        "requirements",
        "specifications",
        "requirements",
        "framework",
        "Python",
        "Scrapy",
        "MySQL",
        "Linux",
        "Web",
        "Framework",
        "Pythons",
        "Scrapy",
        "Framework",
        "python",
        "Requests",
        "xlwt",
        "JSON",
        "Selenium",
        "Facebook",
        "Twitter",
        "Developed",
        "spiders",
        "metadata",
        "website",
        "databases",
        "tables",
        "MySQL",
        "queries",
        "data",
        "functionality",
        "timeline",
        "information",
        "Doctors",
        "Facebook",
        "Twitter",
        "websites",
        "Python",
        "APIs",
        "spiders",
        "python",
        "selenium",
        "library",
        "metadata",
        "functionality",
        "data",
        "quality",
        "sanity",
        "checks",
        "top",
        "data",
        "scripts",
        "data",
        "MySQL",
        "Excel",
        "Xlrd",
        "Xlwt",
        "CSV",
        "python",
        "libraries",
        "PEP8",
        "Coding",
        "Standards",
        "quality",
        "code",
        "JIRA",
        "tool",
        "stories",
        "sprint",
        "backlog",
        "team",
        "JIRA",
        "tool",
        "bug",
        "Environment",
        "Python",
        "Ubuntu",
        "Vim",
        "Scrapy",
        "Requests",
        "Urllib",
        "MySQL",
        "Shell",
        "Scripting",
        "Json",
        "CSV",
        "Xlrd",
        "Xlwt",
        "Selenium",
        "Twitter",
        "JIRA",
        "Scrum",
        "Framework",
        "Agile",
        "Python",
        "Developer",
        "Cisco",
        "System",
        "Bangalore",
        "Karnataka",
        "May",
        "October",
        "project",
        "collection",
        "scripts",
        "configuration",
        "file",
        "user",
        "Convert",
        "CLI",
        "commands",
        "input",
        "file",
        "equivalents",
        "IOSXR",
        "system",
        "results",
        "user",
        "manner",
        "user",
        "efficiency",
        "conversion",
        "Responsibilities",
        "requirements",
        "specifications",
        "NCE",
        "interaction",
        "requirements",
        "specifications",
        "views",
        "templates",
        "Python",
        "Django",
        "controllers",
        "template",
        "language",
        "user",
        "interface",
        "Django",
        "configuration",
        "URLs",
        "application",
        "parameters",
        "application",
        "python",
        "Django",
        "MySQL",
        "Windows",
        "presentation",
        "layer",
        "HTML",
        "CSS",
        "JavaScript",
        "JQuery",
        "JQuery",
        "libraries",
        "client",
        "side",
        "JavaScript",
        "manipulations",
        "validations",
        "Python",
        "Gzip",
        "Selenium",
        "Unittest",
        "SQLAlchemy",
        "Json",
        "Implemented",
        "SQLAlchemy",
        "library",
        "access",
        "SQL",
        "functionality",
        "input",
        "file",
        "extension",
        "zip",
        "functionality",
        "input",
        "file",
        "input",
        "files",
        "scripts",
        "input",
        "lines",
        "scopes",
        "BGP",
        "Interface",
        "accesslist",
        "routemap",
        "object",
        "class",
        "feature",
        "output",
        "file",
        "database",
        "MySQL",
        "queries",
        "data",
        "Selenium",
        "Library",
        "testing",
        "process",
        "browsers",
        "application",
        "Apache",
        "Mercurial",
        "Version",
        "Control",
        "System",
        "Responsible",
        "web",
        "application",
        "PEP8",
        "Coding",
        "Standards",
        "quality",
        "code",
        "Python",
        "Komodo",
        "Edit",
        "Windows",
        "Django",
        "Pyramid",
        "Gzip",
        "Html",
        "Css",
        "Javascript",
        "Jquery",
        "Selenium",
        "Mercurial",
        "MySQL",
        "SQLAlchemy",
        "Django",
        "ORM",
        "Lead",
        "Python",
        "Developer",
        "Rovi",
        "Corp",
        "Bangalore",
        "Karnataka",
        "May",
        "April",
        "project",
        "Movies",
        "Availability",
        "information",
        "Metadata",
        "network",
        "websites",
        "Amazon",
        "CBS",
        "Hulu",
        "Netflix",
        "ABC",
        "NBC",
        "MySQL",
        "database",
        "Client",
        "information",
        "Merge",
        "algorithms",
        "client",
        "interface",
        "Responsibilities",
        "requirements",
        "specifications",
        "client",
        "interaction",
        "requirements",
        "system",
        "analysis",
        "design",
        "development",
        "testing",
        "deployment",
        "process",
        "SDLC",
        "process",
        "Web",
        "Framework",
        "Pythons",
        "Scrapy",
        "Framework",
        "database",
        "MySQL",
        "queries",
        "data",
        "functionality",
        "table",
        "schemas",
        "framework",
        "urls",
        "url",
        "queue",
        "table",
        "pipelines",
        "items",
        "files",
        "json",
        "format",
        "functionality",
        "items",
        "item",
        "functionality",
        "emails",
        "framework",
        "functionality",
        "items",
        "item",
        "scripts",
        "data",
        "files",
        "MySQL",
        "tables",
        "Written",
        "shell",
        "scripts",
        "files",
        "location",
        "location",
        "data",
        "files",
        "system",
        "Dead",
        "System",
        "asset",
        "health",
        "status",
        "source",
        "site",
        "DB",
        "REST",
        "API",
        "Django",
        "REST",
        "API",
        "Framework",
        "records",
        "database",
        "PEP8",
        "Coding",
        "Standards",
        "quality",
        "code",
        "code",
        "standards",
        "tools",
        "Pyflakes",
        "Pylint",
        "Pychecker",
        "code",
        "quality",
        "bugs",
        "code",
        "level",
        "Environment",
        "Python",
        "Vim",
        "Ubuntu",
        "Scrapy",
        "Requests",
        "Urllib",
        "MySQL",
        "Shell",
        "Scripting",
        "Json",
        "CVS",
        "Django",
        "REST",
        "Framework",
        "Django",
        "ORM",
        "pychecker",
        "pylint",
        "Lead",
        "Python",
        "Developer",
        "Rovi",
        "Corp",
        "Bangalore",
        "Karnataka",
        "September",
        "April",
        "Objective",
        "project",
        "friends",
        "user",
        "networking",
        "sites",
        "Facebook",
        "Twitter",
        "Google",
        "platform",
        "needs",
        "permission",
        "auth",
        "server",
        "user",
        "User",
        "access",
        "time",
        "network",
        "site",
        "Responsibilities",
        "Login",
        "networking",
        "sites",
        "Facebook",
        "Twitter",
        "Netflix",
        "Google",
        "user",
        "profile",
        "info",
        "shares",
        "posts",
        "friends",
        "followers",
        "APIs",
        "network",
        "sites",
        "algorithms",
        "merges",
        "postlikeshares",
        "Selenium",
        "Library",
        "test",
        "automation",
        "process",
        "simulation",
        "browser",
        "web",
        "application",
        "Environment",
        "Python",
        "Vim",
        "Django",
        "Django",
        "ORM",
        "Oauth2",
        "Requests",
        "Urllib",
        "ApisFacebook",
        "Twitter",
        "Netflix",
        "Selenium",
        "CVS",
        "pip",
        "Lead",
        "Python",
        "Developer",
        "Headrun",
        "Technologies",
        "Bangalore",
        "Karnataka",
        "February",
        "August",
        "media",
        "analytics",
        "organization",
        "Buzzinga",
        "media",
        "sources",
        "Twitter",
        "Facebook",
        "Google",
        "YouTube",
        "Instagram",
        "Flickr",
        "listening",
        "index",
        "millions",
        "News",
        "Blogs",
        "Forum",
        "sources",
        "level",
        "Responsibilities",
        "functionality",
        "keywords",
        "keywords",
        "tornado",
        "amounts",
        "data",
        "Internet",
        "keywords",
        "Pipelines",
        "data",
        "Redis",
        "Server",
        "sentiment",
        "Klout",
        "data",
        "functionality",
        "data",
        "Elasticsearch",
        "automate",
        "scripts",
        "records",
        "mongodb",
        "export",
        "command",
        "files",
        "machine",
        "ftplib",
        "copies",
        "data",
        "database",
        "servers",
        "MongoDB",
        "Replication",
        "concept",
        "Environment",
        "Python",
        "Vim",
        "Django",
        "Django",
        "ORM",
        "Scrapy",
        "Requests",
        "Urllib",
        "ApisFacebook",
        "Twitter",
        "Klout",
        "MongoDB",
        "Redis",
        "ElasticSearch",
        "Tornado",
        "ftplib",
        "Github",
        "pip",
        "Lead",
        "Python",
        "Developer",
        "Veveo",
        "Inc",
        "Bangalore",
        "Karnataka",
        "February",
        "January",
        "Project",
        "quality",
        "voice",
        "search",
        "product",
        "client",
        "Django",
        "tool",
        "passfail",
        "count",
        "test",
        "cases",
        "Responsibilities",
        "developer",
        "team",
        "levels",
        "support",
        "maintenance",
        "improvements",
        "development",
        "Daily",
        "tasks",
        "frontend",
        "development",
        "development",
        "stats",
        "table",
        "passfail",
        "statues",
        "test",
        "cases",
        "feature",
        "test",
        "cases",
        "JsonExcel",
        "format",
        "source",
        "code",
        "production",
        "feature",
        "performance",
        "Environment",
        "Python",
        "Vim",
        "Django",
        "Django",
        "ORM",
        "MySQL",
        "lxml",
        "Html",
        "Css",
        "JavaScript",
        "Jquery",
        "CVS",
        "Python",
        "Developer",
        "Veveo",
        "Inc",
        "Bangalore",
        "Karnataka",
        "August",
        "January",
        "project",
        "persons",
        "travels",
        "orders",
        "aim",
        "content",
        "air",
        "travel",
        "confirmation",
        "emails",
        "order",
        "confirmation",
        "emails",
        "Responsibilities",
        "Emails",
        "formats",
        "agency",
        "agency",
        "travel",
        "mails",
        "product",
        "order",
        "pattern",
        "emails",
        "config",
        "file",
        "email",
        "format",
        "template",
        "filename",
        "type",
        "email",
        "content",
        "scripts",
        "emails",
        "content",
        "HTML",
        "ease",
        "data",
        "scripts",
        "email",
        "format",
        "template",
        "file",
        "name",
        "config",
        "file",
        "template",
        "file",
        "email",
        "content",
        "data",
        "files",
        "loader",
        "functionality",
        "data",
        "files",
        "MySQL",
        "tables",
        "Email",
        "templates",
        "code",
        "team",
        "script",
        "mail",
        "format",
        "email",
        "team",
        "code",
        "email",
        "format",
        "details",
        "config",
        "file",
        "email",
        "formats",
        "city",
        "names",
        "person",
        "details",
        "tools",
        "Environment",
        "Python",
        "Vim",
        "BeautifulSoup",
        "Requests",
        "MySQL",
        "CVS",
        "Redmine",
        "Python",
        "Developer",
        "Veveo",
        "Inc",
        "Bangalore",
        "Karnataka",
        "August",
        "July",
        "project",
        "persons",
        "travels",
        "orders",
        "aim",
        "content",
        "air",
        "travel",
        "confirmation",
        "emails",
        "order",
        "confirmation",
        "emails",
        "Project",
        "metadata",
        "websites",
        "sports",
        "media",
        "sites",
        "tvshowsmovies",
        "sites",
        "networking",
        "sites",
        "scripts",
        "data",
        "MySQL",
        "database",
        "Responsibilities",
        "websites",
        "media",
        "Analyze",
        "website",
        "client",
        "requirement",
        "code",
        "templates",
        "methods",
        "metadata",
        "Developer",
        "records",
        "database",
        "records",
        "database",
        "Script",
        "Environment",
        "Python",
        "lxml",
        "MySQL",
        "Vim",
        "CVS",
        "Education",
        "Masters",
        "Computer",
        "Applications",
        "Bharathidasan",
        "University",
        "Tiruchchirappalli",
        "Tamil",
        "Nadu",
        "Additional",
        "Information",
        "TECHNICAL",
        "PROFICIENCIES",
        "Programming",
        "Languages",
        "Python",
        "Java",
        "Shell",
        "Scripting",
        "Python",
        "Frameworks",
        "Django",
        "Django",
        "REST",
        "Framework",
        "Flask",
        "Pyramid",
        "Scrapy",
        "Tornado",
        "Python",
        "Pandas",
        "Numpy",
        "Unittest",
        "CSV",
        "XML",
        "XLS",
        "Selenium",
        "Database",
        "Systems",
        "MySQL",
        "Django",
        "ORM",
        "SQLAlchemy",
        "Oracle",
        "NoSQL",
        "Database",
        "Systems",
        "MongoDB",
        "Redis",
        "Web",
        "Development",
        "Languages",
        "HTML",
        "CSS",
        "JavaScript",
        "JQuery",
        "JSON",
        "NodeJS",
        "Operating",
        "Systems",
        "Linux",
        "Ubuntu",
        "CentOS",
        "Windows",
        "XP",
        "Development",
        "Methodologies",
        "Agile",
        "Methodology",
        "Scrum",
        "Framework",
        "OOP",
        "MVC",
        "Architecture",
        "Deployment",
        "Tools",
        "Jenkins",
        "Ansible",
        "Version",
        "Control",
        "Git",
        "SVN",
        "CVS",
        "Mercurial",
        "Development",
        "Tools",
        "IDEs",
        "Eclipse",
        "NetBeans",
        "ViVim",
        "Sublime",
        "Text",
        "Komodo",
        "Edit",
        "PyCharm",
        "IDLE",
        "Tracking",
        "Tools",
        "JIRA",
        "Redmine",
        "Trello",
        "Confluence",
        "Amazon",
        "Web",
        "ServicesAWS",
        "EC2",
        "S3",
        "EBS",
        "Lambda",
        "DynamoDB",
        "Redshift",
        "SNS"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T21:20:39.162144",
    "resume_data": "Sr Python Developer Sr span lPythonspan span lDeveloperspan Sr Python Developer Enphase Energy 7 Years of experience in Analysis Design Development and Implementation of various standalone clientserver enterprise applications Experience with full software development lifecycle architecting scalable platforms objects oriented programming database design and agile methodologies Extensive experience with Django a highlevel Python Web Framework Experience in Object Oriented Programming OOP concepts using Python Core Java Extensive experience in designing and developing webbased applications using Python Django HTML CSS JavaScript JQuery XML and JSON Experience in implementing RESTful Web Services with server side technologies using restful API and MVC design patterns with Django REST framework and Django framework Good experience in handling errorsexceptions and debugging the issues in large scale applications Hands on experience working in WAMP Windows Apache MySQL and Python and LAMP Linux Apache MySQL and Python Architecture Experienced in caching large scale applications using Memcache Redis Expertise in working with different databases like MySQL PostgreSQL Oracle and very good knowledge in NoSQL databases MongoDB Redis Proficient in developing complex SQL queries Stored Procedures Functions along with performing DDL and DML operations on the database Excellent working knowledge in UNIX and Linux shell environment using command line utilities Expertise in Production support and Knowledge of deployment using Jenkins and Ansible Experience working in both Waterfall and Agile software methodologies Familiarity with development best practices such as code reviews Unit Testing System Integration Testing and User Acceptance Testing UAT Hands on experience in working with various Version Control Systems mostly GIT subversion SVN CVS and Mercurial Involved in all the phases of Software Development Life Cycle SDLC using Project Management tools JIRA and Redmine Expert level user of several project management tools including JIRA Trello Well versed with Agile and Test Driven Development methodologies Followed the best practices of Python such as PEP8 Performed code reviews and implemented best Python Programming Practices Experience in writing test scripts test cases test specifications and test coverage Posses good interpersonal skills ability to work in SelfManaged and Team Player Willing to take initiative and able to learn quickly and apply new tools and technologies in the projects Work Experience Sr Python Developer Enphase Energy Petaluma CA April 2016 to Present Enphase Energy brings a systembased hightech approach to solar energy leveraging expertise in semiconductor integration power electronics and networking technologies to continually advance the performance intelligence and reliability of solar energy systems Responsibilities Understanding the project documentation analyzing and converting into technical requirements Requirement analysis and Estimation of project timelines Participating in Sprint Planning and Releases Performed efficient delivery of code based on principles of Test Driven development TDD and continuous integration to keep in line with Agile Software Methodology principles and SCRUM process Implemented Utility Services for collecting and visualizing the Energy data Used Pandas Library for statistical analysis Designed the functionality to read the data from DynamoDB and clean the data and arrange the data into timeframes using Pandas Used Numpy along with Pandas for computing min max and mean power voltages Implemented REST API calls to access the production data Implementing lambda functions to perform tasks when subscribed rules matched Creating s3 buckets and adding permissions to store and access the data files from external scripts Added support to sync all staticmedia files to AWS S3 bucket from Django Developed custom modules to parsing XML and JSON Files using lxml simplejson and load the data into database Designed the entire web application using Python Django MySQL MongoDB and Some Amazon Web Services like S3 RDS and DynamoDB Utilized JIRA for bug reports update reports and monitoring team work progress Integrated Confluence pages into JIRA tool for maintaining the Project planning Project documentation and meeting notes Used JIRA tool for creating and estimating stories building a sprint backlogs reporting on team progress Used Jenkins to automate the Deployment process and run Unit Test cases Environment Python 35 Linux Eclipse Vim Django 19 Boto3 Html CSS JavaScript JQuery Bootstrap Django REST Framework Agile Scrum Framework JIRA Jenkins Amazon Web Services Git MongoDB MySQL Pandas Sr Python Developer Johnson Johnson New Jersey November 2015 to March 2016 This project involves for collecting information about HIVAids related articles blogs and forums from different websites like hivforums aidmap cdcgov etc and stored the into JSON formatted file Client will apply some analytics and show case into their analytics web application Responsibilities Gathering requirements specifications and analyzing the requirements Created entire framework using Python Scrapy MySQL and Linux Implemented and customized Web Scraping Framework using Pythons Scrapy Framework Utilized python libraries Requests urllib urlparse MySQLdb xlrd xlwt JSON Selenium Facebook and Twitter Developed spiders for collecting the metadata from specified website Created databases and tables using MySQL wrote several queries to extractstore data Implemented functionality to get the timeline information Specified Doctors from Facebook and Twitter websites using their Python APIs Developed some spiders using python selenium library to collect the metadata Developed functionality to verify the data quality and applying some sanity checks on top of the collected data Developed independent scripts to read the data from MySQL and generating Excel formatted using Xlrd Xlwt and CSV python libraries Followed PEP8 Coding Standards for maintaining the quality code Used JIRA tool for creating and estimating stories building a sprint backlog reporting on team progress Utilized JIRA tool for bug tracking Environment Python 27 Ubuntu Vim Scrapy Requests Urllib MySQL Shell Scripting Json CSV Xlrd Xlwt Selenium APIsFacebook Twitter JIRA Scrum Framework Agile Python Developer Cisco System Bangalore Karnataka May 2015 to October 2015 This project involves to take a collection of scripts which collectively take an IOS formatted configuration file from user Convert CLI commands contained within the input file over to their equivalents appropriate for an IOSXR system and present the converted results to the user in an interactive manner that allows the user to analyze the efficiency of the conversion Responsibilities Analyzed the requirements specifications and in NCE interaction during requirements specifications Developed views and templates with Python and Django view controllers and template language to create a user friendly interface Used Django configuration to manage URLs and application parameters Created entire application using python Django MySQL and Windows Developed presentation layer using HTML CSS JavaScript and JQuery Used JQuery libraries for all client side JavaScript manipulations and validations Utilized Python libraries Gzip Selenium Unittest SQLAlchemy and Json Implemented SQLAlchemy which is a python library for complete access over SQL Implemented functionality to validate the selected or uploaded input file extension must be zip Developed backend functionality to unzip the uploaded input file and read the input files one by one Utilized existing scripts to Parse input lines into scopes BGP Interface accesslist routemap and instantiate a corresponding object class Implemented new feature to download the output into outputzip file Created database using MySQL wrote several queries to extractstore data Used Selenium Library to automate the testing process with multiple browsers Deployed the application into Apache using Mercurial Version Control System Responsible for debugging and troubleshooting the web application Followed PEP8 Coding Standards for maintaining the quality code Environments Python 27 Komodo Edit Windows 7 Django Pyramid Gzip Html Css Javascript Jquery Selenium Mercurial MySQL SQLAlchemy unittest Django ORM Lead Python Developer Rovi Corp Bangalore Karnataka May 2014 to April 2015 This project involves for collecting all Movies and Tvshows Availability information and Metadata from different branded network websites like Amazon CBS Hulu Netflix ABC NBC etc and push into MySQL database Client will consume these information and apply some Merge algorithms to showcase in the client interface Responsibilities Responsible for gathering requirements specifications and in client interaction during requirements Involved in system analysis design development testing and deployment process Participated in the complete SDLC process Implemented and customized Web Scraping Framework using Pythons Scrapy Framework Created database using MySQL wrote several queries to extractstore data Developed functionality to create new table schemas automatically when they are not exists Designed the framework to store and get the scraping urls from corresponding url queue table Written pipelines functionality to store the scraped items into files in json format Implemented functionality to validate the scraped items if any item is not valid it will drop Automatically Developed functionality to send alert emails when something went wrong in the framework Implemented functionality to validate the scraped items if any item is not valid it will drop automatically Written scripts to read the data from files and populated into MySQL tables Written shell scripts to move files from one location to another location and removing empty data files Developed new system called Dead System to check specific asset health status in source site if it is not existing we will remove from our DB Developed new REST API using Django REST API Framework to display the records available in the database Followed PEP8 Coding Standards for maintaining the quality code and code standards Used tools like Pyflakes Pylint and Pychecker for checking the code quality and finding bugs in code level very oftenly Environment Python 27 Vim Ubuntu Scrapy Requests Urllib MySQL Shell Scripting Json CVS Django REST Framework Django ORM pip pychecker pylint Lead Python Developer Rovi Corp Bangalore Karnataka September 2013 to April 2014 Objective of this project is to group all friends of user in different social networking sites like Facebook Twitter and Google etc into one platform For this needs to get permission from the auth server and the user User can grant and revoke access at any time and for any network site Responsibilities Implemented Login through various social networking sites Facebook Twitter Netflix and Google Fetching the user profile info shares posts likes friends and followers using APIs of the social network sites Implemented algorithms to get wiki merges for respective postlikeshares Used Selenium Library to write fully functioning test automation process that allowed the simulation of submitting different we request from multiple browser to web application Environment Python 27 Vim Django Django ORM Oauth2 Requests Urllib ApisFacebook Twitter Netflix Selenium CVS pip Lead Python Developer Headrun Technologies Bangalore Karnataka February 2013 to August 2013 It is a social media analytics organization Buzzinga listens into all mainstream social media sources such as Twitter Facebook public Google YouTube Instagram and Flickr and also maintains a massive listening index of millions of News Blogs and Forum sources enabling listening on a near realtime level Responsibilities Implemented backend functionality to add modify and delete the tacking keywords Supported to track keywords asynchronously using tornado Gathering tremendous amounts of data from the Internet for given keywords Built Pipelines to store the data in Redis Server Applying sentiment and Klout scores to enrich the data Written functionality to store enriched data into Elasticsearch Implemented automate scripts to backup the old records using mongodb export command and transfer these backup files into backup machine using ftplib Maintaining multiple copies of data in different database servers using MongoDB Replication concept Environment Python 27 Vim Django Django ORM Scrapy Requests Urllib ApisFacebook Twitter Klout MongoDB Redis ElasticSearch Tornado ftplib Github pip Lead Python Developer Veveo Inc Bangalore Karnataka February 2012 to January 2013 Project is aimed to monitor the quality of voice search product developed by my client For this developed a Django tool that displays the passfail count of test cases Responsibilities Lead developer on a small team that oversees all levels of support includes maintenance improvements and new development Daily tasks include frontend development and backend development Implemented stats table which displays the passfail statues of the test cases Implemented feature to download the test cases report in JsonExcel format Responsible for deploying the source code to production after adding any new feature into this and checking performance Environment Python 27 Vim Django Django ORM MySQL Requests Urllib lxml Html Css JavaScript Jquery CVS pip Python Developer Veveo Inc Bangalore Karnataka August 2011 to January 2012 This project which is responsible to track persons current travels and orders Our aim is to extract content of air travel confirmation emails and order confirmation emails Responsibilities Emails formats are vary from agency to agency for travel mails or for product order mails First we have to check how many different pattern emails are available and maintain a config file that have the email format and a template filename which parse this type of email content Written scripts to save emails content as HTML files for ease while parsing data Written scripts to identify the email format and select template file name from config file and run the template file and write parsed email content into data files Implemented a loader functionality which loads parsed data files into MySQL tables Email parsing templates code is developed by crawling team Written an automated script that will check and inform through mail whether there is any new format email appears or not If yes inform the crawling team and once the code developed add new email format details in config file so that new email formats also get parsed Based on the city names between which cities the person is traveling get the latlong details using internal tools Environment Python 27 Vim BeautifulSoup Requests MySQL CVS Redmine Python Developer Veveo Inc Bangalore Karnataka August 2010 to July 2011 This project which is responsible to track persons current travels and orders Our aim is to extract content of air travel confirmation emails and order confirmation emails Responsibilities This Project involves crawling metadata from different websites like sports related media sites tvshowsmovies sites and other social networking sites through scripts and storing the data into MySQL database Responsibilities Finding the websites related to media Analyze the website to reach the client requirement Writing code templates and implementing them with different methods to get the metadata Developer Pumping records into database and verifying the records in database Scheduling the Script to run regularly Environment Python 27 Urllib lxml Requests MySQL Vim CVS pip Education Masters in Computer Applications Bharathidasan University Tiruchchirappalli Tamil Nadu Additional Information TECHNICAL PROFICIENCIES Programming Languages Python 2x 3x Java Shell Scripting Python Frameworks Django Django REST Framework Flask Pyramid Scrapy Tornado Python Libraries Pandas Numpy Unittest JSON CSV XML XLS Selenium Boto3 Database Systems MySQL Sqlite3 Django ORM SQLAlchemy Oracle NoSQL Database Systems MongoDB Redis Web Development Languages HTML CSS JavaScript JQuery JSON NodeJS Operating Systems Linux Ubuntu CentOS Windows 7 10 XP Development Methodologies Agile Methodology Scrum Framework OOP MVC Architecture Deployment Tools Jenkins Ansible Version Control Git SVN CVS Mercurial Development Tools IDEs Eclipse NetBeans ViVim Sublime Text Komodo Edit PyCharm IDLE Tracking Tools JIRA Redmine Trello Confluence Amazon Web ServicesAWS EC2 S3 EBS Lambda DynamoDB Redshift SNS",
    "unique_id": "863d1e5c-ddbc-40bb-9138-510552152eb2"
}