{
    "clean_data": "Data Analyst Data Analyst Data Analyst Genworth Richmond VA An analytical and detailoriented Data science professional with proven records of success in the collection and manipulation of large datasets Over 5 year of experience in data manipulation wrangling model building and visualizing data Designed data collection systems and strategies that optimize statistical efficiency and data quality Ability to perform Data preparation and exploration to build the appropriate machine learning model Proficient in Statistical Modeling and Machine Learning techniques in Forecasting Predictive Analytics Segmentation methodologies Regression based models Hypothesis testing Factor analysis PCA Ensembles Expertise in Machine Learning models like Linear Logistics Decision Trees Random Forest SVM KNearest Neighbors clustering Kmeans Hierarchical Bayesian Implement and practice Machine learning techniques on structured and unstructured data with equal proficiency Experience with Data Analytics Data Reporting Adhoc Reporting Graphs Scales Pivot Tables and OLAP reporting Used Tableau to refresh and make changes to the dashboards Engage with management to define the scope and drafting requirements Experience in writing complex queries subqueries and Triggers involving multiple tables using SQL for data integrity Work Experience Data Analyst Genworth Richmond VA January 2018 to Present Genworth Financial is an SP 400 insurance company The firm was founded as The Life Insurance Company of Virginia in 1871 At Genworth we focus on our strengths and leverage our experience to provide products services and resources that provide financial security to peoples lives families and their future Responsible of researching and developing the action plan required for the development of model Providing stakeholder end to end scenarios on the project life cycle Imported SAS data files in python to test the initial phase of the project Model data using MS Excel Access SQL andor other data ware house analytical tools Designed the visualization of the core competencies in the model parameter using ggplot2 seaborn matplotlib Understanding the CCAR and DFAST regulation of the company Maintained and updated database procedure manual Doing adhoc analysis and presented result in a clear manner Coordinate with different functional teams to implement model performance and data accuracy Used predictive modelling to increase and optimize customer experience revenue generation ad targeting and other business outcome Developed company AB testing framework and test model quality Mined and analyzed data from company databases to drive optimization and improvement of product development marketing techniques and business strategies Produced weekly and monthly dashboards and metric reports using Tableau Used APIs to develop custom dashboards to provide increased value and ROI back to our clients Conducted Google Analytics Tag Manager audits and publish results on regular basis track and manage all tag requests internal and external endtoend Develops key performance indicators KPIs to track progress makes recommendations to work toward established organizational goals monitors and facilitates deployment of reports to operations teams and partners Maintain item and customer master data in ERP system Built models using Statistical techniques like Bayesian HMM and Machine Learning classification models like XG Boost SVM and Random Forest Data Analyst Davelon Group Atlanta GA June 2017 to December 2017 The Davelon Group is a service group oriented primarily in supporting large organizations that have invested in Enterprise Wide Programs ERP Supply Chain Logistics and Business Intelligence It brings together a group of highly talented resources with proven track records in delivering value in DoD and large commercial initiatives Combine and clean raw data into usable data sets and interpret and analyze data using statistical techniques Coded existing model prototypes into Python Identified and developed additional model processes Designed data collection systems and strategies that optimize statistical efficiency and data quality Implemented ETL using SSIS to ensure right flow of data reverse engineered to understand business logic Performed data analysis using Python SQL for Data Preparation created visualizations in Tableau SSRS Wrote efficient modular and dependable code packages libraries and scripts Documented all work extensively and provide timely reporting to management on all projects and workflows Involved across the lifecycle of analysisrelated activities including implementing requirements collecting data developing analysis and monitoring performance and quality to identify improvements Operating on SQL queries for data conversion from multiple source systems to Common Data Model system Data Scientist Philips IN January 2015 to October 2016 Involved in the entire data science project life cycle including data extraction data cleansing transform and prepare the data ahead of analysis and data visualization phase Used R to manipulate data develop and validate quantitative models Cleansed the data by eliminating duplicate and inaccurate data in R and Python Tested the data and removed the outlier if any Machine learning algorithm such as linear regression logistic regression was built on correlated data sets and emphasized on advanced algorithms like neural networks SVM Contributed Technology Project management and Business management functions to push the business forward with innovative solutions Performed data acquisition and exploratory data analysis in R Visualized team metrics and communicated to the higher management using Power BI Develop testable hypotheses test and measure results Build update and maintain dashboards that report on key business metrics Query and analyzed large sets of data from multiple sources and system tools Process ad hoc analysis requests and make recommendations to stakeholders Experience in descriptive statistics and hypothesis testing using Chisquare Ttest Pearson correlation and Analysis of variance ANOVA Analyzed Relational Nonrelational data using MySQL and HBase Involved in addressing a wide range of challenging problems using techniques from applied statistics machine learning and data mining field Finetuned models to obtain more recall than accuracy Tradeoff between False Positives and False Negatives Evaluated models using Recall Precision Cross Validation and ROC Zscore standardization Laplace estimator and other techniques was applied on the model for performance improvement Preparing the Final Documents with all the recommendations and ensure delivery to the Client before EOD Data was visualized using different visualization scatter plot box plots and histograms techniques from ggplot2 package in R Tried and implemented multiple models to evaluate predictions and performance Associate Data Analyst Abhudhaya Multimedia IN January 2014 to December 2014 Conducted the initial data quality check to verify the correctness of the collected data Conducted naive outlier analysis to improve the classifier quality Tested different sampling techniques to account for the imbalanced training set Under sampling proved to be the most effective method to balance the two classes Develop reports to help business operators stay nimble and make strategy recommendations to inform acquisition marketing major product and operational decisions Worked closely with data engineers to build a data pipeline that prepares aggregated results for dashboards using SQL Explore our data through user segmentation cohort analysis funnels regression models etc to drive a better shared understanding of user behavior Created views and models using 3rd party tools Develop testable hypotheses test and measure results Develop Tableau workbooks from multiple data sources using Data Blending Data Analyst Aditya Birla group July 2012 to December 2013 Identified analyzed and interpreted trends or patterns in complex data sets using data to locate and define new machinelearning improvement opportunities Filtering and cleaning data by reviewing reports data files and performance indicators to expose and plan corrections to code or data problems in R Analyzed the data and provide the insights about the customers using Tableau Created and maintained studies dashboards and reports which provide new insights information and ideas that lead to datasupported product improvements and actionable insights for our customers Designed reports dashboards and visualizations of various datasets for various team functions Tracking EndtoEnd contact Workflow to ensure there is no issues in quality of data Analyzed Business Technical Requirements to create Detailed Source to Target Mapping Documents Performed Data Profiling Review Results with Business Users Technical Architects Data Governance Specialists to devise standardized Data Quality Rules Coordinated with Technical Architecture Data Architecture Development ETL Quality Assurance QA Teams for the successful timely delivery of the project Generated a Tableau dashboard visualizing the different Segment clusters Assisted in building a Business Analysis Process Model using Rational Rose and Visio Performed extensive Requirement analysis and designed Use Cases Activity Diagrams Sequence diagrams and OOD Database administrator Adecco India pvt ltd May 2008 to May 2010 Build database systems of high availability and quality depending on each end users specialized role Design and implement database in accordance to end users information needs and views Monitored database efficiency Sustaining the security and integrity of data Creating complex query definitions that allow data to be extracted Updated and amended existing databases Contributes to team effort by accomplishing related results as needed Maintains quality service by establishing and enforcing organization standards Identifies database requirements by interviewing customers analyzing department applications programming and operations evaluating existing systems and designing proposed systems Supported team which is working on developing queries and procedures for data extraction from the Postgres Database Communicate regularly with technical applications and operational staff to ensure database integrity and security Education Master of Science MS in Information Systems in Information Systems Pace University Seidenberg School of CSIS New York NY Postgraduation Diploma in Management and Research in Management and Research Pillai Institute of Management and Research Navi Mumbai Maharashtra Bachelor of Engineering in Electronics Instrumentation Shri Govindram Seksaria Institute of Engineering and Science Indore Madhya Pradesh Skills Database Mysql Sql Qlikview Tableau C Php Python Visio Sftp Eclipse Java Ftp Telnet Visualization Excel Microsoft office Windows 95 Documentation MS Office",
    "entities": [
        "ERP",
        "Laplace",
        "Conducted Google Analytics Tag",
        "Machine",
        "Tableau Created",
        "Kmeans Hierarchical Bayesian Implement",
        "Conducted",
        "Windows 95 Documentation MS Office",
        "Recall Precision Cross Validation",
        "Build",
        "Performed",
        "ROC Zscore",
        "SQL Explore",
        "Statistical",
        "Target Mapping Documents Performed Data Profiling Review Results",
        "Hypothesis",
        "Science MS in Information Systems",
        "MS Excel Access SQL",
        "Power BI Develop",
        "MySQL and HBase Involved",
        "Data Blending Data",
        "Forecasting Predictive Analytics Segmentation",
        "Coded",
        "Client",
        "Data Quality Rules Coordinated with Technical Architecture Data Architecture Development ETL",
        "Triggers",
        "Genworth",
        "Tradeoff",
        "Management and Research in Management and Research Pillai Institute of Management and Research Navi",
        "Monitored",
        "Microsoft",
        "The Life Insurance Company of Virginia",
        "Develop",
        "The Davelon Group",
        "SAS",
        "XG Boost SVM",
        "Random Forest Data Analyst Davelon Group",
        "EOD Data",
        "Contributes",
        "Present Genworth Financial",
        "SQL",
        "Analyzed Business Technical Requirements",
        "Chisquare Ttest Pearson",
        "Use Cases Activity Diagrams Sequence",
        "Developed company AB",
        "Built",
        "Linear Logistics Decision Trees Random Forest SVM KNearest Neighbors",
        "Relational Nonrelational",
        "Model",
        "Python SQL for Data Preparation",
        "Finetuned",
        "Tableau",
        "Filtering",
        "Maintained",
        "Machine Learning",
        "Business Users Technical Architects Data",
        "Supply Chain Logistics and Business Intelligence",
        "HMM",
        "Science Indore Madhya Pradesh",
        "SVM Contributed Technology Project",
        "OOD Database",
        "Workflow",
        "Information Systems Pace University Seidenberg School of CSIS New York NY",
        "Develop Tableau",
        "Associate Data",
        "DoD",
        "EndtoEnd",
        "Data Analytics Data Reporting Adhoc Reporting Graphs",
        "ANOVA Analyzed",
        "SSIS"
    ],
    "experience": "Experience with Data Analytics Data Reporting Adhoc Reporting Graphs Scales Pivot Tables and OLAP reporting Used Tableau to refresh and make changes to the dashboards Engage with management to define the scope and drafting requirements Experience in writing complex queries subqueries and Triggers involving multiple tables using SQL for data integrity Work Experience Data Analyst Genworth Richmond VA January 2018 to Present Genworth Financial is an SP 400 insurance company The firm was founded as The Life Insurance Company of Virginia in 1871 At Genworth we focus on our strengths and leverage our experience to provide products services and resources that provide financial security to peoples lives families and their future Responsible of researching and developing the action plan required for the development of model Providing stakeholder end to end scenarios on the project life cycle Imported SAS data files in python to test the initial phase of the project Model data using MS Excel Access SQL andor other data ware house analytical tools Designed the visualization of the core competencies in the model parameter using ggplot2 seaborn matplotlib Understanding the CCAR and DFAST regulation of the company Maintained and updated database procedure manual Doing adhoc analysis and presented result in a clear manner Coordinate with different functional teams to implement model performance and data accuracy Used predictive modelling to increase and optimize customer experience revenue generation ad targeting and other business outcome Developed company AB testing framework and test model quality Mined and analyzed data from company databases to drive optimization and improvement of product development marketing techniques and business strategies Produced weekly and monthly dashboards and metric reports using Tableau Used APIs to develop custom dashboards to provide increased value and ROI back to our clients Conducted Google Analytics Tag Manager audits and publish results on regular basis track and manage all tag requests internal and external endtoend Develops key performance indicators KPIs to track progress makes recommendations to work toward established organizational goals monitors and facilitates deployment of reports to operations teams and partners Maintain item and customer master data in ERP system Built models using Statistical techniques like Bayesian HMM and Machine Learning classification models like XG Boost SVM and Random Forest Data Analyst Davelon Group Atlanta GA June 2017 to December 2017 The Davelon Group is a service group oriented primarily in supporting large organizations that have invested in Enterprise Wide Programs ERP Supply Chain Logistics and Business Intelligence It brings together a group of highly talented resources with proven track records in delivering value in DoD and large commercial initiatives Combine and clean raw data into usable data sets and interpret and analyze data using statistical techniques Coded existing model prototypes into Python Identified and developed additional model processes Designed data collection systems and strategies that optimize statistical efficiency and data quality Implemented ETL using SSIS to ensure right flow of data reverse engineered to understand business logic Performed data analysis using Python SQL for Data Preparation created visualizations in Tableau SSRS Wrote efficient modular and dependable code packages libraries and scripts Documented all work extensively and provide timely reporting to management on all projects and workflows Involved across the lifecycle of analysisrelated activities including implementing requirements collecting data developing analysis and monitoring performance and quality to identify improvements Operating on SQL queries for data conversion from multiple source systems to Common Data Model system Data Scientist Philips IN January 2015 to October 2016 Involved in the entire data science project life cycle including data extraction data cleansing transform and prepare the data ahead of analysis and data visualization phase Used R to manipulate data develop and validate quantitative models Cleansed the data by eliminating duplicate and inaccurate data in R and Python Tested the data and removed the outlier if any Machine learning algorithm such as linear regression logistic regression was built on correlated data sets and emphasized on advanced algorithms like neural networks SVM Contributed Technology Project management and Business management functions to push the business forward with innovative solutions Performed data acquisition and exploratory data analysis in R Visualized team metrics and communicated to the higher management using Power BI Develop testable hypotheses test and measure results Build update and maintain dashboards that report on key business metrics Query and analyzed large sets of data from multiple sources and system tools Process ad hoc analysis requests and make recommendations to stakeholders Experience in descriptive statistics and hypothesis testing using Chisquare Ttest Pearson correlation and Analysis of variance ANOVA Analyzed Relational Nonrelational data using MySQL and HBase Involved in addressing a wide range of challenging problems using techniques from applied statistics machine learning and data mining field Finetuned models to obtain more recall than accuracy Tradeoff between False Positives and False Negatives Evaluated models using Recall Precision Cross Validation and ROC Zscore standardization Laplace estimator and other techniques was applied on the model for performance improvement Preparing the Final Documents with all the recommendations and ensure delivery to the Client before EOD Data was visualized using different visualization scatter plot box plots and histograms techniques from ggplot2 package in R Tried and implemented multiple models to evaluate predictions and performance Associate Data Analyst Abhudhaya Multimedia IN January 2014 to December 2014 Conducted the initial data quality check to verify the correctness of the collected data Conducted naive outlier analysis to improve the classifier quality Tested different sampling techniques to account for the imbalanced training set Under sampling proved to be the most effective method to balance the two classes Develop reports to help business operators stay nimble and make strategy recommendations to inform acquisition marketing major product and operational decisions Worked closely with data engineers to build a data pipeline that prepares aggregated results for dashboards using SQL Explore our data through user segmentation cohort analysis funnels regression models etc to drive a better shared understanding of user behavior Created views and models using 3rd party tools Develop testable hypotheses test and measure results Develop Tableau workbooks from multiple data sources using Data Blending Data Analyst Aditya Birla group July 2012 to December 2013 Identified analyzed and interpreted trends or patterns in complex data sets using data to locate and define new machinelearning improvement opportunities Filtering and cleaning data by reviewing reports data files and performance indicators to expose and plan corrections to code or data problems in R Analyzed the data and provide the insights about the customers using Tableau Created and maintained studies dashboards and reports which provide new insights information and ideas that lead to datasupported product improvements and actionable insights for our customers Designed reports dashboards and visualizations of various datasets for various team functions Tracking EndtoEnd contact Workflow to ensure there is no issues in quality of data Analyzed Business Technical Requirements to create Detailed Source to Target Mapping Documents Performed Data Profiling Review Results with Business Users Technical Architects Data Governance Specialists to devise standardized Data Quality Rules Coordinated with Technical Architecture Data Architecture Development ETL Quality Assurance QA Teams for the successful timely delivery of the project Generated a Tableau dashboard visualizing the different Segment clusters Assisted in building a Business Analysis Process Model using Rational Rose and Visio Performed extensive Requirement analysis and designed Use Cases Activity Diagrams Sequence diagrams and OOD Database administrator Adecco India pvt ltd May 2008 to May 2010 Build database systems of high availability and quality depending on each end users specialized role Design and implement database in accordance to end users information needs and views Monitored database efficiency Sustaining the security and integrity of data Creating complex query definitions that allow data to be extracted Updated and amended existing databases Contributes to team effort by accomplishing related results as needed Maintains quality service by establishing and enforcing organization standards Identifies database requirements by interviewing customers analyzing department applications programming and operations evaluating existing systems and designing proposed systems Supported team which is working on developing queries and procedures for data extraction from the Postgres Database Communicate regularly with technical applications and operational staff to ensure database integrity and security Education Master of Science MS in Information Systems in Information Systems Pace University Seidenberg School of CSIS New York NY Postgraduation Diploma in Management and Research in Management and Research Pillai Institute of Management and Research Navi Mumbai Maharashtra Bachelor of Engineering in Electronics Instrumentation Shri Govindram Seksaria Institute of Engineering and Science Indore Madhya Pradesh Skills Database Mysql Sql Qlikview Tableau C Php Python Visio Sftp Eclipse Java Ftp Telnet Visualization Excel Microsoft office Windows 95 Documentation MS Office",
    "extracted_keywords": [
        "Data",
        "Analyst",
        "Data",
        "Analyst",
        "Data",
        "Analyst",
        "Genworth",
        "Richmond",
        "VA",
        "Data",
        "science",
        "records",
        "success",
        "collection",
        "manipulation",
        "datasets",
        "year",
        "experience",
        "data",
        "manipulation",
        "model",
        "building",
        "data",
        "data",
        "collection",
        "systems",
        "strategies",
        "efficiency",
        "data",
        "quality",
        "Ability",
        "Data",
        "preparation",
        "exploration",
        "machine",
        "model",
        "Proficient",
        "Statistical",
        "Modeling",
        "Machine",
        "Learning",
        "techniques",
        "Forecasting",
        "Predictive",
        "Analytics",
        "Segmentation",
        "methodologies",
        "Regression",
        "models",
        "Hypothesis",
        "testing",
        "Factor",
        "analysis",
        "PCA",
        "Ensembles",
        "Expertise",
        "Machine",
        "Learning",
        "models",
        "Linear",
        "Logistics",
        "Decision",
        "Trees",
        "Random",
        "Forest",
        "SVM",
        "KNearest",
        "Neighbors",
        "Kmeans",
        "Hierarchical",
        "Bayesian",
        "Implement",
        "Machine",
        "techniques",
        "data",
        "proficiency",
        "Experience",
        "Data",
        "Analytics",
        "Data",
        "Adhoc",
        "Reporting",
        "Graphs",
        "Scales",
        "Pivot",
        "Tables",
        "OLAP",
        "Tableau",
        "changes",
        "dashboards",
        "Engage",
        "management",
        "scope",
        "drafting",
        "requirements",
        "Experience",
        "queries",
        "subqueries",
        "Triggers",
        "tables",
        "SQL",
        "data",
        "integrity",
        "Work",
        "Experience",
        "Data",
        "Analyst",
        "Genworth",
        "Richmond",
        "VA",
        "January",
        "Present",
        "Genworth",
        "Financial",
        "SP",
        "insurance",
        "company",
        "firm",
        "Life",
        "Insurance",
        "Company",
        "Virginia",
        "Genworth",
        "strengths",
        "experience",
        "products",
        "services",
        "resources",
        "security",
        "peoples",
        "families",
        "future",
        "action",
        "plan",
        "development",
        "model",
        "stakeholder",
        "scenarios",
        "project",
        "life",
        "cycle",
        "Imported",
        "SAS",
        "data",
        "files",
        "python",
        "phase",
        "project",
        "Model",
        "data",
        "MS",
        "Excel",
        "Access",
        "SQL",
        "andor",
        "data",
        "house",
        "tools",
        "visualization",
        "core",
        "competencies",
        "model",
        "parameter",
        "ggplot2",
        "matplotlib",
        "CCAR",
        "DFAST",
        "regulation",
        "company",
        "database",
        "procedure",
        "manual",
        "adhoc",
        "analysis",
        "result",
        "manner",
        "Coordinate",
        "teams",
        "model",
        "performance",
        "data",
        "accuracy",
        "modelling",
        "customer",
        "experience",
        "revenue",
        "generation",
        "ad",
        "targeting",
        "business",
        "outcome",
        "company",
        "AB",
        "testing",
        "framework",
        "test",
        "model",
        "quality",
        "Mined",
        "data",
        "company",
        "optimization",
        "improvement",
        "product",
        "development",
        "marketing",
        "techniques",
        "business",
        "strategies",
        "dashboards",
        "reports",
        "Tableau",
        "APIs",
        "custom",
        "dashboards",
        "value",
        "clients",
        "Google",
        "Analytics",
        "Tag",
        "Manager",
        "audits",
        "results",
        "basis",
        "track",
        "tag",
        "requests",
        "endtoend",
        "performance",
        "indicators",
        "KPIs",
        "progress",
        "recommendations",
        "goals",
        "monitors",
        "deployment",
        "reports",
        "operations",
        "teams",
        "partners",
        "item",
        "customer",
        "master",
        "data",
        "ERP",
        "system",
        "models",
        "techniques",
        "Bayesian",
        "HMM",
        "Machine",
        "Learning",
        "classification",
        "models",
        "XG",
        "Boost",
        "SVM",
        "Random",
        "Forest",
        "Data",
        "Analyst",
        "Davelon",
        "Group",
        "Atlanta",
        "GA",
        "June",
        "December",
        "Davelon",
        "Group",
        "service",
        "group",
        "organizations",
        "Enterprise",
        "Wide",
        "Programs",
        "ERP",
        "Supply",
        "Chain",
        "Logistics",
        "Business",
        "Intelligence",
        "group",
        "resources",
        "track",
        "records",
        "value",
        "DoD",
        "initiatives",
        "Combine",
        "data",
        "data",
        "sets",
        "data",
        "techniques",
        "model",
        "prototypes",
        "Python",
        "model",
        "data",
        "collection",
        "systems",
        "strategies",
        "efficiency",
        "data",
        "quality",
        "ETL",
        "SSIS",
        "flow",
        "data",
        "reverse",
        "business",
        "logic",
        "Performed",
        "data",
        "analysis",
        "Python",
        "SQL",
        "Data",
        "Preparation",
        "visualizations",
        "Tableau",
        "SSRS",
        "Wrote",
        "code",
        "packages",
        "libraries",
        "scripts",
        "work",
        "reporting",
        "management",
        "projects",
        "workflows",
        "lifecycle",
        "activities",
        "requirements",
        "data",
        "analysis",
        "performance",
        "quality",
        "improvements",
        "SQL",
        "queries",
        "data",
        "conversion",
        "source",
        "systems",
        "Common",
        "Data",
        "Model",
        "system",
        "Data",
        "Scientist",
        "Philips",
        "January",
        "October",
        "data",
        "science",
        "project",
        "life",
        "cycle",
        "data",
        "extraction",
        "data",
        "cleansing",
        "transform",
        "data",
        "analysis",
        "data",
        "visualization",
        "phase",
        "R",
        "data",
        "models",
        "data",
        "data",
        "R",
        "Python",
        "data",
        "outlier",
        "Machine",
        "algorithm",
        "linear",
        "regression",
        "regression",
        "data",
        "sets",
        "algorithms",
        "networks",
        "SVM",
        "Contributed",
        "Technology",
        "Project",
        "management",
        "Business",
        "management",
        "functions",
        "business",
        "solutions",
        "Performed",
        "data",
        "acquisition",
        "data",
        "analysis",
        "R",
        "team",
        "metrics",
        "management",
        "Power",
        "BI",
        "Develop",
        "hypotheses",
        "measure",
        "results",
        "Build",
        "update",
        "dashboards",
        "business",
        "metrics",
        "Query",
        "sets",
        "data",
        "sources",
        "system",
        "tools",
        "Process",
        "ad",
        "analysis",
        "requests",
        "recommendations",
        "stakeholders",
        "Experience",
        "statistics",
        "hypothesis",
        "testing",
        "Chisquare",
        "Ttest",
        "Pearson",
        "correlation",
        "Analysis",
        "variance",
        "ANOVA",
        "Analyzed",
        "Relational",
        "Nonrelational",
        "data",
        "MySQL",
        "HBase",
        "range",
        "problems",
        "techniques",
        "statistics",
        "machine",
        "learning",
        "data",
        "mining",
        "field",
        "models",
        "recall",
        "accuracy",
        "Tradeoff",
        "False",
        "Positives",
        "False",
        "Negatives",
        "models",
        "Recall",
        "Precision",
        "Cross",
        "Validation",
        "ROC",
        "Zscore",
        "standardization",
        "Laplace",
        "estimator",
        "techniques",
        "model",
        "performance",
        "improvement",
        "Final",
        "Documents",
        "recommendations",
        "delivery",
        "Client",
        "EOD",
        "Data",
        "visualization",
        "scatter",
        "plot",
        "box",
        "plots",
        "techniques",
        "package",
        "R",
        "models",
        "predictions",
        "performance",
        "Associate",
        "Data",
        "Analyst",
        "Abhudhaya",
        "Multimedia",
        "January",
        "December",
        "data",
        "quality",
        "check",
        "correctness",
        "data",
        "analysis",
        "quality",
        "sampling",
        "techniques",
        "training",
        "sampling",
        "method",
        "classes",
        "Develop",
        "reports",
        "business",
        "operators",
        "strategy",
        "recommendations",
        "acquisition",
        "marketing",
        "product",
        "decisions",
        "data",
        "engineers",
        "data",
        "pipeline",
        "results",
        "dashboards",
        "SQL",
        "Explore",
        "data",
        "user",
        "segmentation",
        "cohort",
        "analysis",
        "funnels",
        "regression",
        "models",
        "understanding",
        "user",
        "behavior",
        "views",
        "models",
        "party",
        "tools",
        "hypotheses",
        "measure",
        "results",
        "Develop",
        "Tableau",
        "data",
        "sources",
        "Data",
        "Blending",
        "Data",
        "Analyst",
        "Aditya",
        "Birla",
        "group",
        "July",
        "December",
        "trends",
        "patterns",
        "data",
        "sets",
        "data",
        "machinelearning",
        "improvement",
        "opportunities",
        "Filtering",
        "cleaning",
        "data",
        "reports",
        "data",
        "files",
        "performance",
        "indicators",
        "corrections",
        "code",
        "data",
        "problems",
        "R",
        "data",
        "insights",
        "customers",
        "Tableau",
        "Created",
        "studies",
        "dashboards",
        "reports",
        "insights",
        "information",
        "ideas",
        "product",
        "improvements",
        "insights",
        "customers",
        "reports",
        "dashboards",
        "visualizations",
        "datasets",
        "team",
        "functions",
        "EndtoEnd",
        "contact",
        "Workflow",
        "issues",
        "quality",
        "data",
        "Business",
        "Technical",
        "Requirements",
        "Detailed",
        "Source",
        "Target",
        "Mapping",
        "Documents",
        "Performed",
        "Data",
        "Profiling",
        "Review",
        "Results",
        "Business",
        "Users",
        "Technical",
        "Architects",
        "Data",
        "Governance",
        "Specialists",
        "Data",
        "Quality",
        "Rules",
        "Technical",
        "Architecture",
        "Data",
        "Architecture",
        "Development",
        "ETL",
        "Quality",
        "Assurance",
        "QA",
        "Teams",
        "delivery",
        "project",
        "Tableau",
        "dashboard",
        "Segment",
        "clusters",
        "Business",
        "Analysis",
        "Process",
        "Model",
        "Rational",
        "Rose",
        "Visio",
        "Requirement",
        "analysis",
        "Use",
        "Cases",
        "Activity",
        "Diagrams",
        "Sequence",
        "diagrams",
        "OOD",
        "Database",
        "administrator",
        "Adecco",
        "India",
        "pvt",
        "ltd",
        "May",
        "May",
        "Build",
        "database",
        "systems",
        "availability",
        "quality",
        "end",
        "users",
        "role",
        "Design",
        "database",
        "accordance",
        "users",
        "information",
        "database",
        "efficiency",
        "security",
        "integrity",
        "data",
        "query",
        "definitions",
        "data",
        "databases",
        "Contributes",
        "effort",
        "results",
        "Maintains",
        "quality",
        "service",
        "organization",
        "standards",
        "Identifies",
        "database",
        "requirements",
        "customers",
        "department",
        "applications",
        "programming",
        "operations",
        "systems",
        "systems",
        "team",
        "queries",
        "procedures",
        "data",
        "extraction",
        "Postgres",
        "Database",
        "Communicate",
        "applications",
        "staff",
        "database",
        "integrity",
        "security",
        "Education",
        "Master",
        "Science",
        "MS",
        "Information",
        "Systems",
        "Information",
        "Systems",
        "Pace",
        "University",
        "Seidenberg",
        "School",
        "CSIS",
        "New",
        "York",
        "NY",
        "Postgraduation",
        "Diploma",
        "Management",
        "Research",
        "Management",
        "Research",
        "Pillai",
        "Institute",
        "Management",
        "Research",
        "Navi",
        "Mumbai",
        "Maharashtra",
        "Bachelor",
        "Engineering",
        "Electronics",
        "Instrumentation",
        "Shri",
        "Govindram",
        "Seksaria",
        "Institute",
        "Engineering",
        "Science",
        "Indore",
        "Madhya",
        "Pradesh",
        "Skills",
        "Database",
        "Mysql",
        "Sql",
        "Qlikview",
        "Tableau",
        "C",
        "Php",
        "Python",
        "Visio",
        "Sftp",
        "Eclipse",
        "Java",
        "Ftp",
        "Telnet",
        "Visualization",
        "Excel",
        "Microsoft",
        "office",
        "Documentation",
        "MS",
        "Office"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T19:38:29.678031",
    "resume_data": "Data Analyst Data Analyst Data Analyst Genworth Richmond VA An analytical and detailoriented Data science professional with proven records of success in the collection and manipulation of large datasets Over 5 year of experience in data manipulation wrangling model building and visualizing data Designed data collection systems and strategies that optimize statistical efficiency and data quality Ability to perform Data preparation and exploration to build the appropriate machine learning model Proficient in Statistical Modeling and Machine Learning techniques in Forecasting Predictive Analytics Segmentation methodologies Regression based models Hypothesis testing Factor analysis PCA Ensembles Expertise in Machine Learning models like Linear Logistics Decision Trees Random Forest SVM KNearest Neighbors clustering Kmeans Hierarchical Bayesian Implement and practice Machine learning techniques on structured and unstructured data with equal proficiency Experience with Data Analytics Data Reporting Adhoc Reporting Graphs Scales Pivot Tables and OLAP reporting Used Tableau to refresh and make changes to the dashboards Engage with management to define the scope and drafting requirements Experience in writing complex queries subqueries and Triggers involving multiple tables using SQL for data integrity Work Experience Data Analyst Genworth Richmond VA January 2018 to Present Genworth Financial is an SP 400 insurance company The firm was founded as The Life Insurance Company of Virginia in 1871 At Genworth we focus on our strengths and leverage our experience to provide products services and resources that provide financial security to peoples lives families and their future Responsible of researching and developing the action plan required for the development of model Providing stakeholder end to end scenarios on the project life cycle Imported SAS data files in python to test the initial phase of the project Model data using MS Excel Access SQL andor other data ware house analytical tools Designed the visualization of the core competencies in the model parameter using ggplot2 seaborn matplotlib Understanding the CCAR and DFAST regulation of the company Maintained and updated database procedure manual Doing adhoc analysis and presented result in a clear manner Coordinate with different functional teams to implement model performance and data accuracy Used predictive modelling to increase and optimize customer experience revenue generation ad targeting and other business outcome Developed company AB testing framework and test model quality Mined and analyzed data from company databases to drive optimization and improvement of product development marketing techniques and business strategies Produced weekly and monthly dashboards and metric reports using Tableau Used APIs to develop custom dashboards to provide increased value and ROI back to our clients Conducted Google Analytics Tag Manager audits and publish results on regular basis track and manage all tag requests internal and external endtoend Develops key performance indicators KPIs to track progress makes recommendations to work toward established organizational goals monitors and facilitates deployment of reports to operations teams and partners Maintain item and customer master data in ERP system Built models using Statistical techniques like Bayesian HMM and Machine Learning classification models like XG Boost SVM and Random Forest Data Analyst Davelon Group Atlanta GA June 2017 to December 2017 The Davelon Group is a service group oriented primarily in supporting large organizations that have invested in Enterprise Wide Programs ERP Supply Chain Logistics and Business Intelligence It brings together a group of highly talented resources with proven track records in delivering value in DoD and large commercial initiatives Combine and clean raw data into usable data sets and interpret and analyze data using statistical techniques Coded existing model prototypes into Python Identified and developed additional model processes Designed data collection systems and strategies that optimize statistical efficiency and data quality Implemented ETL using SSIS to ensure right flow of data reverse engineered to understand business logic Performed data analysis using Python SQL for Data Preparation created visualizations in Tableau SSRS Wrote efficient modular and dependable code packages libraries and scripts Documented all work extensively and provide timely reporting to management on all projects and workflows Involved across the lifecycle of analysisrelated activities including implementing requirements collecting data developing analysis and monitoring performance and quality to identify improvements Operating on SQL queries for data conversion from multiple source systems to Common Data Model system Data Scientist Philips IN January 2015 to October 2016 Involved in the entire data science project life cycle including data extraction data cleansing transform and prepare the data ahead of analysis and data visualization phase Used R to manipulate data develop and validate quantitative models Cleansed the data by eliminating duplicate and inaccurate data in R and Python Tested the data and removed the outlier if any Machine learning algorithm such as linear regression logistic regression was built on correlated data sets and emphasized on advanced algorithms like neural networks SVM Contributed Technology Project management and Business management functions to push the business forward with innovative solutions Performed data acquisition and exploratory data analysis in R Visualized team metrics and communicated to the higher management using Power BI Develop testable hypotheses test and measure results Build update and maintain dashboards that report on key business metrics Query and analyzed large sets of data from multiple sources and system tools Process ad hoc analysis requests and make recommendations to stakeholders Experience in descriptive statistics and hypothesis testing using Chisquare Ttest Pearson correlation and Analysis of variance ANOVA Analyzed Relational Nonrelational data using MySQL and HBase Involved in addressing a wide range of challenging problems using techniques from applied statistics machine learning and data mining field Finetuned models to obtain more recall than accuracy Tradeoff between False Positives and False Negatives Evaluated models using Recall Precision Cross Validation and ROC Zscore standardization Laplace estimator and other techniques was applied on the model for performance improvement Preparing the Final Documents with all the recommendations and ensure delivery to the Client before EOD Data was visualized using different visualization scatter plot box plots and histograms techniques from ggplot2 package in R Tried and implemented multiple models to evaluate predictions and performance Associate Data Analyst Abhudhaya Multimedia IN January 2014 to December 2014 Conducted the initial data quality check to verify the correctness of the collected data Conducted naive outlier analysis to improve the classifier quality Tested different sampling techniques to account for the imbalanced training set Under sampling proved to be the most effective method to balance the two classes Develop reports to help business operators stay nimble and make strategy recommendations to inform acquisition marketing major product and operational decisions Worked closely with data engineers to build a data pipeline that prepares aggregated results for dashboards using SQL Explore our data through user segmentation cohort analysis funnels regression models etc to drive a better shared understanding of user behavior Created views and models using 3rd party tools Develop testable hypotheses test and measure results Develop Tableau workbooks from multiple data sources using Data Blending Data Analyst Aditya Birla group July 2012 to December 2013 Identified analyzed and interpreted trends or patterns in complex data sets using data to locate and define new machinelearning improvement opportunities Filtering and cleaning data by reviewing reports data files and performance indicators to expose and plan corrections to code or data problems in R Analyzed the data and provide the insights about the customers using Tableau Created and maintained studies dashboards and reports which provide new insights information and ideas that lead to datasupported product improvements and actionable insights for our customers Designed reports dashboards and visualizations of various datasets for various team functions Tracking EndtoEnd contact Workflow to ensure there is no issues in quality of data Analyzed Business Technical Requirements to create Detailed Source to Target Mapping Documents Performed Data Profiling Review Results with Business Users Technical Architects Data Governance Specialists to devise standardized Data Quality Rules Coordinated with Technical Architecture Data Architecture Development ETL Quality Assurance QA Teams for the successful timely delivery of the project Generated a Tableau dashboard visualizing the different Segment clusters Assisted in building a Business Analysis Process Model using Rational Rose and Visio Performed extensive Requirement analysis and designed Use Cases Activity Diagrams Sequence diagrams and OOD Database administrator Adecco India pvt ltd May 2008 to May 2010 Build database systems of high availability and quality depending on each end users specialized role Design and implement database in accordance to end users information needs and views Monitored database efficiency Sustaining the security and integrity of data Creating complex query definitions that allow data to be extracted Updated and amended existing databases Contributes to team effort by accomplishing related results as needed Maintains quality service by establishing and enforcing organization standards Identifies database requirements by interviewing customers analyzing department applications programming and operations evaluating existing systems and designing proposed systems Supported team which is working on developing queries and procedures for data extraction from the Postgres Database Communicate regularly with technical applications and operational staff to ensure database integrity and security Education Master of Science MS in Information Systems in Information Systems Pace University Seidenberg School of CSIS New York NY Postgraduation Diploma in Management and Research in Management and Research Pillai Institute of Management and Research Navi Mumbai Maharashtra Bachelor of Engineering in Electronics Instrumentation Shri Govindram Seksaria Institute of Engineering and Science Indore Madhya Pradesh Skills Database Mysql Sql Qlikview Tableau C Php Python Visio Sftp Eclipse Java Ftp Telnet Visualization Excel Microsoft office Windows 95 Documentation MS Office",
    "unique_id": "d11d39a0-49eb-449c-8250-107b74ec136e"
}