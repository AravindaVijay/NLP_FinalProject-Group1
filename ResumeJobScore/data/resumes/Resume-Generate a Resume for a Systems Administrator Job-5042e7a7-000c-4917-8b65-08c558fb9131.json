{
    "clean_data": "Sr Data Engineer Python programmer Sr Data Engineerspan lPythonspan programmer Sr Data Engineer Python programmer BlackRock Dublin CA Experienced IT professional who has management team building and endtoend solution skills with focus on leveraging information technology seeking a leadership position using Big Data and data science to maximize business values Developer Engineer Architect with over 8 years of development administration and programming experience with primary focus in Big Data and emphasis on Hadoop Advanced HadoopBigDataAnalytic Experience Looking for handson Functional Programming and OO Programming role Looking for handson Spark Kafka Scala Python and Pyspark programming role Big Data Specialties Spark RDD and Spark DF development Pyspark using Pycharm development Worked with Hadoop HBase Cascading Zookeeper Oozie Hive HiveQL MapR MogoDB Pentaho Pig Worked with AWS Cloud EC2 EMR RedShift S3 etc Supported Hadoop and Verita as administrator about 7 to 700 nodes Supported and administrated users accounts and security rules with BigData domain Worked with Application Servers Tomcat Oracle and MySQL Experienced with distributed systems large scale nonrelational data stores mapreduce systems data modeling database performance and multiterabyte data warehouses Experienced in a SaaS environment that has an agile development process Experienced in Java Python or other object oriented programming language Experienced in Mobile Linux Unix Android MAC platform Experienced with server management server operating systemsWindows Linux Unix and VMware Experienced in testing APIs Restful APIs Experienced with full SW Lifecycle and Agile practice Experienced with scripting language in Perl Python Ruby QTP for automated and performance tests Experienced with testing DNA sequence machines SW for regulatory approval Experienced testing networking and storage technologies protocols and hardware Experienced with web services and SOAP UI testing Experienced with Oracle TOAD and SQL Experienced in testing UI technologies such as HTML5 Experienced in Big Data Hadoop CassandraMemcachedNoSQLMapReduce Lead and coached about 2 to 20 engineers onshore offshore and nearshore Lead the hiring process Bigdata and analytics platform administrator Vertica Greenplum Hdoop HiveApache Drills Sqoop Kafka AKKA and Docker Experienced with Display Advertising Behavioral Ad Networks Recommended Engines Personalization Experienced with Data Analytics Data mining Predictive Modeling Work Experience Sr Data Engineer Python programmer BlackRock San Francisco CA 2018 to Present Handon Data Lake Implementation in Big data for huge data warehouses Building data process ETL transformation data ingestion and platforms Coding in Pyspark Python Pandas Kafka Java Scala and Spark SQL Coding SAP Sybase ASE SQL Coding Kafka and Spark streaming and massaging Converted existing spaghetti code to modular code Configured and set up designed performance enhancements scalable systems using with java services exposure Leading BigData data warehouse application design data quality implementation and testingdeployment strategy Leading in identification and troubleshooting processing issues impacting timely availability of data in the data warehouse or delivery of critical reporting within established SLAs Identified and recommended improvements in production application solutions or operational processes in support of data warehouse applications and business intelligence reporting ie data quality performance static and dynamic reports etc Researched managed and coordinated resolution of complex issues through root cause analysis as appropriate Built Spark Engine and BlackRock Sale Business Engine Researched and implemented Blackchin technology Built machine learning ETL pipeline Built deep learning model and data pipeline Utilized multiple large Hadoop HDP infrastructure Utilized Git Jira Prometheus Docker Kubernetes tools Sr Data ArchitectAWS Cloud Realtorcom Santa Clara CA 2016 to 2018 DB development and DB performance tuning Built Hadoop development eco platforms Built AirFlow workflows and testing scripts Docker Master and installdeployment Worked on DB persistence with Java Hibernate development in AWS Redshift performance tuning and testing Spark RDD and Airflow workflow designing and testing Report design using MicroStrategy Built lead recommender systems for realtorcom website Scala functional programming with Spark streaming Solr Programming Hortonworks Programming VM programming Docker programming Sr Big data Architect developer FRB San Francisco CA 2015 to 2015 Handon Spark RDD and Spark DF development Docker Master and installdeployment NoSQL database design and Spark SQL development UnixHadoop administrator and development Expertise with Splunk UIGUI development and operations roles Prepared arranged and tested Splunk search strings and operational strings Managed the Splunk licenses and restricted the daily indexing limit AWS EMR Redshift administratordevelopment Cloudera Administratordevelopment Cloudera Navigator Administratordevelopment Kerbero Administrator Zoomdata administrator Big data platform design and architecturedevelopment Hive and Hbase development Security office for big data POC Hadoop AWS Cloudera Streaming Kafka and big data tools Work with scripts for Oozie and Hue systems Cassandra MongoDB Hbase Hive development Cloudera Hue and Solr development Data governance policymanagement and big data security Big data security and Kerberos development Multitenant set up and development Sr DataBase Architect San Francisco CA 2015 to 2015 Converting large SAS SQL scripts to HiveQL for Data Science Converting Oracle scripts to HiveQL programming for Data Science Architecture NoSQL databases and coding the MapReduce functions for over 10 years data about emails campaigning results analytics Working with data science to prototype data model and programming the business logic with Hive Pig Building database application on Hive Pig Hbase MongoDB Canssdra Spark Solr and shark on a large hadoop nodes cluster in house Backend NoSQL database design development architecture and testing Data gaverment Backend Big DataHadoop Engineer SS Network Redwood City CA 2014 to 2014 Spark RDD and Spark SQLHive SQL NoSQL database modeling AWS cloud computing and architecture with Hadoop on Big Data Build cloud application on AWS S3 EMR Hive Pig Hbase MongoDB Canssdra Spark Backend NoSQL database design development architecture and testing BigData and BIBW Consultant Cisco San Jose CA 2014 to 2014 Created and maintained scripts and programs to Extract Transform and Load data Automated ETL and aggregation processes using BASHPHP andor other scripting languages Created logging and monitoring elements to all Data Warehouse and ETL processes to allow Operations team to monitor Responded to Data Warehouse and ETL process alerts with support from operations team Created maintained and automated processes to distribute data warehouse extracts to various users Expertise with Splunk UIGUI development and operations roles Continually monitored measure and improved all data warehouse and ETL processes for speed reliability and accuracy Performed analyses and executed improvements regarding overall data quality including making recommendations to the business regarding inputs Sourced andor created tools to deliver monitoring metrics and dashboard reports to allow the rest of the company to understand the quality and timeliness of data warehouse data Installed and integrated 3rdparty data maintenance tools such as address cleaning software etc Used new technologies to service data warehousing needs such as Hadoop column databases etc Cisco big data analytics platform development testing and deployment Worked on data integration application design development and testing Used Pentaho data integration tool to create data integration jobs Used MapR to run Hadoop YARN jobs Moved enterprise data from Oracle to Hive for big data platform Moved WebEx voice phone video and email enterprise data to Hive and build data mart Wrote use story task plan and testing cases Wrote scripts for automating testing Wrote design document for enterprise data on board Analyzed deployment log for errors Monitored big data staging environment Monitored hive staging environment BigData and BI consultant Cisco Milpitas CA 2013 to 2013 Hadoop MapR BWBI data warehouse project Big data move from Informatica and TD Loaded data from different source to new build Hadoop analyst platform Built Hadoop QA team Used Hadoop HiveSqoopbash to deployment the data load and query data Monitored QA environment for Hadoop problems Testing report form MapR report tool Provided ideasworking process to other team Review other reports and code to understand coding logic Managed a technical team or functioning as a team lead Worked with Hadoop stack eg MapReduce Sqoop Pig Hive Hbase Flume relatedcomplementary open source software platforms and languages eg Java Linux Apache Perl PythonPHP Chef Worked with ETL ExtractTransformLoad tools eg Informatica Talend Pentaho Worked with BI tools and reporting software eg Microstrategy Cognos OBIEE Pentaho Worked with analytical tools languages or libraries eg SAS SPSS R Mahout Supported business development activities to shape and communicate proposed solutions to client executives Implemented of ETL applications Implemented of reporting applications Applicationimplementation of custom analytics support Administrated of relational databases Data migration from existing data stores Infrastructure and storage design Developed capacity plans for new and existing systems BigData and BI consultant Santa Clara CA 2013 to 2013 Spark RDD development and NoSQL database modeling DesignArchitecture Big Data Hadoop Testing Frameworks Building Hadoop cluster in Cloud and local Worked with AWS cloud environment EMR Redshift S3 Worked with Scala Java Python Kafka AKKA SQL MongoDB JSON Avro Tableau Worked with Git SBT Ant Maven Ganglia Jenkins Docker Worked with Hadoop Hbase Zookeeper Oozie Scalding Spark Shark Tested automation and coded in Scala Worked with ETL and reporting tools OBIEE SAP etc Coded on Scala Kafka Streaming Spark and AWS services Coded on Pig Small workflow SQL and Hive Built Analytic Spark platform Built Ad revenue feed process Built Big Data Projects testing platform BigData and BI consultant San Jose CA 2006 to 2012 ATT SAP BWBIBigData development support Conducted detailed design applications developed on Hadoop platforms Feature testing Regression Testing Acceptance Testing and Sanity Testing Implemented Business analysis tools with HadoopMapReduce scripts from ETL data to data warehouse for BI and enterprise analysis platform Administrated Log analysis scripts for Business Analyst tool with HDFS Hadoop file system level Advised the Hadoop and analytical workloads IO optimizing solutions Running benchmarked HadoopHBase clusters Supported development of Hadoop and Vertica Analytics Platform activities Storage architectureQA Netapp Hadoop ecosystem administrator and support Tested NetApp Open Solution for HadoopNOSH settings Supported and scaled Hadoop systems Supported cluster failed over test and document the results with various configurations Administrated enterprisegrade storage arrays and eliminated Hadoop network bottlenecks Supported hotpluggable disk shelves added storage and administrated services Supported NFS and HDFS file systems Loaded networkfree hardware RAID Daytoday support Hadoop hardware and software issues Used automation scripts to run performance testing of the new storage OS design Big Data System Consultant Bank of America TCOE Concord MA 2006 to 2009 Supported about over 100 projects and many functional teams Supported analytic massive amounts of data and BI Communicated and tracked defects to closure Administrated with large data set testing with BigData NoSQL Hadoop and Oracle DB2 scripts Wrote reviewed and executed scripts and tracked defects Expertise with Splunk UIGUI development and operations roles Used scripts languages in Perl and Python for Automations testing and test data condition Used scripts languages for ETL load with BW Middleware Architect Kaiser Walnut Creek CA 2004 to 2006 Designed all middleware with 3000 interfaces for BigData IBM MQ design architecture support Designed QA environment and production support Designed Message broker and production support Education Bachelors in Information Systems in Information Systems University of San Francisco 2004",
    "entities": [
        "Infrastructure",
        "Informatica",
        "Mahout Supported",
        "BI Communicated",
        "multiterabyte",
        "java services",
        "Informatica Talend Pentaho Worked",
        "Android",
        "BI",
        "Built AirFlow",
        "Researched",
        "Built Big Data Projects",
        "Hadoop Hbase Zookeeper Oozie Scalding Spark Shark Tested",
        "Big Data Hadoop",
        "Information Systems",
        "BWBI",
        "Cloud",
        "BASHPHP",
        "Mobile",
        "Spark DF",
        "RDD",
        "Hadoop",
        "HTML5 Experienced",
        "Information Systems University of San Francisco",
        "Vertica Analytics Platform",
        "MAC",
        "Data Analytics Data",
        "Restful APIs Experienced",
        "Sr Data",
        "Hadoop Advanced HadoopBigDataAnalytic Experience Looking",
        "Coded on Pig Small",
        "BigData IBM MQ",
        "HDFS Hadoop",
        "Present Handon Data Lake Implementation",
        "Conducted",
        "Data Warehouse",
        "Business Analyst",
        "Kerberos",
        "Hive Built Analytic Spark",
        "Utilized",
        "San Francisco",
        "DesignArchitecture Big Data Hadoop Testing Frameworks Building Hadoop",
        "Netapp Hadoop",
        "BigData NoSQL Hadoop",
        "Monitored",
        "San Jose",
        "OO Programming",
        "Automated ETL",
        "Airflow",
        "Regression Testing Acceptance Testing and Sanity Testing Implemented Business",
        "Functional Programming",
        "AWS S3 EMR",
        "Leading BigData",
        "Sr Data Engineer Python",
        "VMware Experienced",
        "SQL Experienced",
        "Sr DataBase Architect",
        "BigData",
        "Spark",
        "Used Hadoop HiveSqoopbash",
        "Extract Transform",
        "TD Loaded",
        "Santa Clara",
        "QA",
        "BlackRock Sale Business Engine Researched",
        "Data Science Architecture",
        "Created",
        "AWS",
        "Oracle",
        "Coded",
        "Coding",
        "Pyspark",
        "HadoopHBase",
        "SAS",
        "SQL",
        "Spark RDD",
        "lPythonspan",
        "Pycharm",
        "Sr Big",
        "Report",
        "Sr Data Engineerspan",
        "Verita",
        "Big Data",
        "Hive",
        "Big Data Specialties Spark",
        "Solr Programming Hortonworks Programming VM programming",
        "Hive Pig Hbase",
        "MapR",
        "Developer Engineer Architect",
        "ETL",
        "Performed",
        "Spark SQL",
        "Cisco",
        "Built Hadoop",
        "UI",
        "POC Hadoop",
        "Oracle TOAD",
        "Bigdata",
        "Display Advertising Behavioral Ad Networks Recommended Engines Personalization Experienced",
        "SOAP UI",
        "AWS Redshift",
        "MapReduce Sqoop",
        "Oracle to Hive for big data",
        "Blackchin",
        "MapReduce",
        "NFS",
        "UnixHadoop",
        "NoSQL",
        "SW",
        "Operations"
    ],
    "experience": "Experience Looking for handson Functional Programming and OO Programming role Looking for handson Spark Kafka Scala Python and Pyspark programming role Big Data Specialties Spark RDD and Spark DF development Pyspark using Pycharm development Worked with Hadoop HBase Cascading Zookeeper Oozie Hive HiveQL MapR MogoDB Pentaho Pig Worked with AWS Cloud EC2 EMR RedShift S3 etc Supported Hadoop and Verita as administrator about 7 to 700 nodes Supported and administrated users accounts and security rules with BigData domain Worked with Application Servers Tomcat Oracle and MySQL Experienced with distributed systems large scale nonrelational data stores mapreduce systems data modeling database performance and multiterabyte data warehouses Experienced in a SaaS environment that has an agile development process Experienced in Java Python or other object oriented programming language Experienced in Mobile Linux Unix Android MAC platform Experienced with server management server operating systemsWindows Linux Unix and VMware Experienced in testing APIs Restful APIs Experienced with full SW Lifecycle and Agile practice Experienced with scripting language in Perl Python Ruby QTP for automated and performance tests Experienced with testing DNA sequence machines SW for regulatory approval Experienced testing networking and storage technologies protocols and hardware Experienced with web services and SOAP UI testing Experienced with Oracle TOAD and SQL Experienced in testing UI technologies such as HTML5 Experienced in Big Data Hadoop CassandraMemcachedNoSQLMapReduce Lead and coached about 2 to 20 engineers onshore offshore and nearshore Lead the hiring process Bigdata and analytics platform administrator Vertica Greenplum Hdoop HiveApache Drills Sqoop Kafka AKKA and Docker Experienced with Display Advertising Behavioral Ad Networks Recommended Engines Personalization Experienced with Data Analytics Data mining Predictive Modeling Work Experience Sr Data Engineer Python programmer BlackRock San Francisco CA 2018 to Present Handon Data Lake Implementation in Big data for huge data warehouses Building data process ETL transformation data ingestion and platforms Coding in Pyspark Python Pandas Kafka Java Scala and Spark SQL Coding SAP Sybase ASE SQL Coding Kafka and Spark streaming and massaging Converted existing spaghetti code to modular code Configured and set up designed performance enhancements scalable systems using with java services exposure Leading BigData data warehouse application design data quality implementation and testingdeployment strategy Leading in identification and troubleshooting processing issues impacting timely availability of data in the data warehouse or delivery of critical reporting within established SLAs Identified and recommended improvements in production application solutions or operational processes in support of data warehouse applications and business intelligence reporting ie data quality performance static and dynamic reports etc Researched managed and coordinated resolution of complex issues through root cause analysis as appropriate Built Spark Engine and BlackRock Sale Business Engine Researched and implemented Blackchin technology Built machine learning ETL pipeline Built deep learning model and data pipeline Utilized multiple large Hadoop HDP infrastructure Utilized Git Jira Prometheus Docker Kubernetes tools Sr Data ArchitectAWS Cloud Realtorcom Santa Clara CA 2016 to 2018 DB development and DB performance tuning Built Hadoop development eco platforms Built AirFlow workflows and testing scripts Docker Master and installdeployment Worked on DB persistence with Java Hibernate development in AWS Redshift performance tuning and testing Spark RDD and Airflow workflow designing and testing Report design using MicroStrategy Built lead recommender systems for realtorcom website Scala functional programming with Spark streaming Solr Programming Hortonworks Programming VM programming Docker programming Sr Big data Architect developer FRB San Francisco CA 2015 to 2015 Handon Spark RDD and Spark DF development Docker Master and installdeployment NoSQL database design and Spark SQL development UnixHadoop administrator and development Expertise with Splunk UIGUI development and operations roles Prepared arranged and tested Splunk search strings and operational strings Managed the Splunk licenses and restricted the daily indexing limit AWS EMR Redshift administratordevelopment Cloudera Administratordevelopment Cloudera Navigator Administratordevelopment Kerbero Administrator Zoomdata administrator Big data platform design and architecturedevelopment Hive and Hbase development Security office for big data POC Hadoop AWS Cloudera Streaming Kafka and big data tools Work with scripts for Oozie and Hue systems Cassandra MongoDB Hbase Hive development Cloudera Hue and Solr development Data governance policymanagement and big data security Big data security and Kerberos development Multitenant set up and development Sr DataBase Architect San Francisco CA 2015 to 2015 Converting large SAS SQL scripts to HiveQL for Data Science Converting Oracle scripts to HiveQL programming for Data Science Architecture NoSQL databases and coding the MapReduce functions for over 10 years data about emails campaigning results analytics Working with data science to prototype data model and programming the business logic with Hive Pig Building database application on Hive Pig Hbase MongoDB Canssdra Spark Solr and shark on a large hadoop nodes cluster in house Backend NoSQL database design development architecture and testing Data gaverment Backend Big DataHadoop Engineer SS Network Redwood City CA 2014 to 2014 Spark RDD and Spark SQLHive SQL NoSQL database modeling AWS cloud computing and architecture with Hadoop on Big Data Build cloud application on AWS S3 EMR Hive Pig Hbase MongoDB Canssdra Spark Backend NoSQL database design development architecture and testing BigData and BIBW Consultant Cisco San Jose CA 2014 to 2014 Created and maintained scripts and programs to Extract Transform and Load data Automated ETL and aggregation processes using BASHPHP andor other scripting languages Created logging and monitoring elements to all Data Warehouse and ETL processes to allow Operations team to monitor Responded to Data Warehouse and ETL process alerts with support from operations team Created maintained and automated processes to distribute data warehouse extracts to various users Expertise with Splunk UIGUI development and operations roles Continually monitored measure and improved all data warehouse and ETL processes for speed reliability and accuracy Performed analyses and executed improvements regarding overall data quality including making recommendations to the business regarding inputs Sourced andor created tools to deliver monitoring metrics and dashboard reports to allow the rest of the company to understand the quality and timeliness of data warehouse data Installed and integrated 3rdparty data maintenance tools such as address cleaning software etc Used new technologies to service data warehousing needs such as Hadoop column databases etc Cisco big data analytics platform development testing and deployment Worked on data integration application design development and testing Used Pentaho data integration tool to create data integration jobs Used MapR to run Hadoop YARN jobs Moved enterprise data from Oracle to Hive for big data platform Moved WebEx voice phone video and email enterprise data to Hive and build data mart Wrote use story task plan and testing cases Wrote scripts for automating testing Wrote design document for enterprise data on board Analyzed deployment log for errors Monitored big data staging environment Monitored hive staging environment BigData and BI consultant Cisco Milpitas CA 2013 to 2013 Hadoop MapR BWBI data warehouse project Big data move from Informatica and TD Loaded data from different source to new build Hadoop analyst platform Built Hadoop QA team Used Hadoop HiveSqoopbash to deployment the data load and query data Monitored QA environment for Hadoop problems Testing report form MapR report tool Provided ideasworking process to other team Review other reports and code to understand coding logic Managed a technical team or functioning as a team lead Worked with Hadoop stack eg MapReduce Sqoop Pig Hive Hbase Flume relatedcomplementary open source software platforms and languages eg Java Linux Apache Perl PythonPHP Chef Worked with ETL ExtractTransformLoad tools eg Informatica Talend Pentaho Worked with BI tools and reporting software eg Microstrategy Cognos OBIEE Pentaho Worked with analytical tools languages or libraries eg SAS SPSS R Mahout Supported business development activities to shape and communicate proposed solutions to client executives Implemented of ETL applications Implemented of reporting applications Applicationimplementation of custom analytics support Administrated of relational databases Data migration from existing data stores Infrastructure and storage design Developed capacity plans for new and existing systems BigData and BI consultant Santa Clara CA 2013 to 2013 Spark RDD development and NoSQL database modeling DesignArchitecture Big Data Hadoop Testing Frameworks Building Hadoop cluster in Cloud and local Worked with AWS cloud environment EMR Redshift S3 Worked with Scala Java Python Kafka AKKA SQL MongoDB JSON Avro Tableau Worked with Git SBT Ant Maven Ganglia Jenkins Docker Worked with Hadoop Hbase Zookeeper Oozie Scalding Spark Shark Tested automation and coded in Scala Worked with ETL and reporting tools OBIEE SAP etc Coded on Scala Kafka Streaming Spark and AWS services Coded on Pig Small workflow SQL and Hive Built Analytic Spark platform Built Ad revenue feed process Built Big Data Projects testing platform BigData and BI consultant San Jose CA 2006 to 2012 ATT SAP BWBIBigData development support Conducted detailed design applications developed on Hadoop platforms Feature testing Regression Testing Acceptance Testing and Sanity Testing Implemented Business analysis tools with HadoopMapReduce scripts from ETL data to data warehouse for BI and enterprise analysis platform Administrated Log analysis scripts for Business Analyst tool with HDFS Hadoop file system level Advised the Hadoop and analytical workloads IO optimizing solutions Running benchmarked HadoopHBase clusters Supported development of Hadoop and Vertica Analytics Platform activities Storage architectureQA Netapp Hadoop ecosystem administrator and support Tested NetApp Open Solution for HadoopNOSH settings Supported and scaled Hadoop systems Supported cluster failed over test and document the results with various configurations Administrated enterprisegrade storage arrays and eliminated Hadoop network bottlenecks Supported hotpluggable disk shelves added storage and administrated services Supported NFS and HDFS file systems Loaded networkfree hardware RAID Daytoday support Hadoop hardware and software issues Used automation scripts to run performance testing of the new storage OS design Big Data System Consultant Bank of America TCOE Concord MA 2006 to 2009 Supported about over 100 projects and many functional teams Supported analytic massive amounts of data and BI Communicated and tracked defects to closure Administrated with large data set testing with BigData NoSQL Hadoop and Oracle DB2 scripts Wrote reviewed and executed scripts and tracked defects Expertise with Splunk UIGUI development and operations roles Used scripts languages in Perl and Python for Automations testing and test data condition Used scripts languages for ETL load with BW Middleware Architect Kaiser Walnut Creek CA 2004 to 2006 Designed all middleware with 3000 interfaces for BigData IBM MQ design architecture support Designed QA environment and production support Designed Message broker and production support Education Bachelors in Information Systems in Information Systems University of San Francisco 2004",
    "extracted_keywords": [
        "Sr",
        "Data",
        "Engineer",
        "Python",
        "programmer",
        "Sr",
        "Data",
        "Engineerspan",
        "lPythonspan",
        "programmer",
        "Sr",
        "Data",
        "Engineer",
        "Python",
        "programmer",
        "BlackRock",
        "Dublin",
        "CA",
        "IT",
        "management",
        "team",
        "building",
        "solution",
        "skills",
        "focus",
        "information",
        "technology",
        "leadership",
        "position",
        "Big",
        "Data",
        "data",
        "science",
        "business",
        "values",
        "Developer",
        "Engineer",
        "Architect",
        "years",
        "development",
        "administration",
        "programming",
        "experience",
        "focus",
        "Big",
        "Data",
        "emphasis",
        "Hadoop",
        "Advanced",
        "Experience",
        "handson",
        "Functional",
        "Programming",
        "OO",
        "Programming",
        "role",
        "handson",
        "Spark",
        "Kafka",
        "Scala",
        "Python",
        "Pyspark",
        "programming",
        "role",
        "Big",
        "Data",
        "Specialties",
        "Spark",
        "RDD",
        "Spark",
        "DF",
        "development",
        "Pyspark",
        "Pycharm",
        "development",
        "Hadoop",
        "HBase",
        "Zookeeper",
        "Oozie",
        "Hive",
        "HiveQL",
        "MapR",
        "MogoDB",
        "Pentaho",
        "Pig",
        "AWS",
        "Cloud",
        "EC2",
        "EMR",
        "RedShift",
        "S3",
        "Supported",
        "Hadoop",
        "Verita",
        "administrator",
        "nodes",
        "users",
        "accounts",
        "security",
        "rules",
        "BigData",
        "domain",
        "Application",
        "Servers",
        "Tomcat",
        "Oracle",
        "MySQL",
        "systems",
        "scale",
        "data",
        "stores",
        "systems",
        "data",
        "modeling",
        "database",
        "performance",
        "multiterabyte",
        "data",
        "warehouses",
        "SaaS",
        "environment",
        "development",
        "process",
        "Java",
        "Python",
        "object",
        "programming",
        "language",
        "Mobile",
        "Linux",
        "Unix",
        "Android",
        "MAC",
        "platform",
        "server",
        "management",
        "server",
        "systemsWindows",
        "Linux",
        "Unix",
        "VMware",
        "APIs",
        "APIs",
        "SW",
        "Lifecycle",
        "practice",
        "language",
        "Perl",
        "Python",
        "Ruby",
        "QTP",
        "performance",
        "tests",
        "DNA",
        "sequence",
        "SW",
        "approval",
        "testing",
        "networking",
        "storage",
        "technologies",
        "protocols",
        "hardware",
        "web",
        "services",
        "SOAP",
        "UI",
        "testing",
        "Oracle",
        "TOAD",
        "SQL",
        "UI",
        "technologies",
        "HTML5",
        "Big",
        "Data",
        "Hadoop",
        "CassandraMemcachedNoSQLMapReduce",
        "Lead",
        "engineers",
        "nearshore",
        "Lead",
        "hiring",
        "process",
        "Bigdata",
        "analytics",
        "platform",
        "administrator",
        "Vertica",
        "Greenplum",
        "Hdoop",
        "HiveApache",
        "Drills",
        "Sqoop",
        "Kafka",
        "AKKA",
        "Docker",
        "Display",
        "Advertising",
        "Behavioral",
        "Ad",
        "Networks",
        "Recommended",
        "Engines",
        "Personalization",
        "Data",
        "Analytics",
        "Data",
        "mining",
        "Predictive",
        "Modeling",
        "Work",
        "Experience",
        "Sr",
        "Data",
        "Engineer",
        "Python",
        "programmer",
        "BlackRock",
        "San",
        "Francisco",
        "CA",
        "Present",
        "Handon",
        "Data",
        "Lake",
        "Implementation",
        "data",
        "data",
        "warehouses",
        "data",
        "process",
        "ETL",
        "transformation",
        "data",
        "ingestion",
        "platforms",
        "Pyspark",
        "Python",
        "Pandas",
        "Kafka",
        "Java",
        "Scala",
        "Spark",
        "SQL",
        "SAP",
        "Sybase",
        "ASE",
        "SQL",
        "Coding",
        "Kafka",
        "Spark",
        "streaming",
        "spaghetti",
        "code",
        "code",
        "Configured",
        "performance",
        "enhancements",
        "systems",
        "services",
        "exposure",
        "BigData",
        "data",
        "warehouse",
        "application",
        "design",
        "data",
        "quality",
        "implementation",
        "testingdeployment",
        "strategy",
        "identification",
        "troubleshooting",
        "processing",
        "issues",
        "availability",
        "data",
        "data",
        "warehouse",
        "delivery",
        "reporting",
        "SLAs",
        "improvements",
        "production",
        "application",
        "solutions",
        "processes",
        "support",
        "data",
        "warehouse",
        "applications",
        "business",
        "intelligence",
        "data",
        "quality",
        "performance",
        "reports",
        "resolution",
        "issues",
        "root",
        "analysis",
        "Built",
        "Spark",
        "Engine",
        "BlackRock",
        "Sale",
        "Business",
        "Engine",
        "Blackchin",
        "technology",
        "machine",
        "ETL",
        "pipeline",
        "learning",
        "model",
        "data",
        "pipeline",
        "Hadoop",
        "HDP",
        "infrastructure",
        "Git",
        "Jira",
        "Prometheus",
        "Docker",
        "Kubernetes",
        "Sr",
        "Data",
        "ArchitectAWS",
        "Cloud",
        "Realtorcom",
        "Santa",
        "Clara",
        "CA",
        "DB",
        "development",
        "DB",
        "performance",
        "Built",
        "Hadoop",
        "development",
        "eco",
        "platforms",
        "AirFlow",
        "workflows",
        "testing",
        "scripts",
        "Docker",
        "Master",
        "installdeployment",
        "Worked",
        "DB",
        "persistence",
        "Java",
        "Hibernate",
        "development",
        "AWS",
        "Redshift",
        "performance",
        "tuning",
        "Spark",
        "RDD",
        "Airflow",
        "workflow",
        "designing",
        "testing",
        "Report",
        "design",
        "MicroStrategy",
        "lead",
        "recommender",
        "systems",
        "realtorcom",
        "website",
        "Scala",
        "programming",
        "Spark",
        "Solr",
        "Programming",
        "Hortonworks",
        "Programming",
        "VM",
        "programming",
        "Docker",
        "programming",
        "Sr",
        "Big",
        "data",
        "Architect",
        "developer",
        "FRB",
        "San",
        "Francisco",
        "CA",
        "Handon",
        "Spark",
        "RDD",
        "Spark",
        "DF",
        "development",
        "Docker",
        "Master",
        "NoSQL",
        "database",
        "design",
        "Spark",
        "SQL",
        "development",
        "UnixHadoop",
        "administrator",
        "development",
        "Expertise",
        "Splunk",
        "UIGUI",
        "development",
        "operations",
        "roles",
        "Splunk",
        "search",
        "strings",
        "strings",
        "Splunk",
        "licenses",
        "indexing",
        "limit",
        "AWS",
        "EMR",
        "Redshift",
        "administratordevelopment",
        "Cloudera",
        "Administratordevelopment",
        "Cloudera",
        "Navigator",
        "Administratordevelopment",
        "Kerbero",
        "Administrator",
        "Zoomdata",
        "administrator",
        "data",
        "platform",
        "design",
        "architecturedevelopment",
        "Hive",
        "Hbase",
        "development",
        "Security",
        "office",
        "data",
        "POC",
        "Hadoop",
        "AWS",
        "Cloudera",
        "Streaming",
        "Kafka",
        "data",
        "tools",
        "scripts",
        "Oozie",
        "Hue",
        "systems",
        "Cassandra",
        "MongoDB",
        "Hbase",
        "Hive",
        "development",
        "Cloudera",
        "Hue",
        "Solr",
        "development",
        "Data",
        "governance",
        "data",
        "security",
        "data",
        "security",
        "Kerberos",
        "development",
        "Multitenant",
        "development",
        "Sr",
        "DataBase",
        "Architect",
        "San",
        "Francisco",
        "CA",
        "SAS",
        "SQL",
        "scripts",
        "HiveQL",
        "Data",
        "Science",
        "Converting",
        "Oracle",
        "scripts",
        "programming",
        "Data",
        "Science",
        "Architecture",
        "NoSQL",
        "MapReduce",
        "functions",
        "years",
        "data",
        "emails",
        "results",
        "analytics",
        "data",
        "science",
        "prototype",
        "data",
        "model",
        "business",
        "logic",
        "Hive",
        "Pig",
        "Building",
        "database",
        "application",
        "Hive",
        "Pig",
        "Hbase",
        "MongoDB",
        "Canssdra",
        "Spark",
        "Solr",
        "shark",
        "hadoop",
        "nodes",
        "cluster",
        "house",
        "Backend",
        "NoSQL",
        "database",
        "design",
        "development",
        "architecture",
        "testing",
        "Data",
        "gaverment",
        "Backend",
        "Big",
        "DataHadoop",
        "Engineer",
        "SS",
        "Network",
        "Redwood",
        "City",
        "CA",
        "Spark",
        "RDD",
        "Spark",
        "SQL",
        "NoSQL",
        "database",
        "AWS",
        "cloud",
        "computing",
        "architecture",
        "Hadoop",
        "Big",
        "Data",
        "Build",
        "cloud",
        "application",
        "AWS",
        "S3",
        "EMR",
        "Hive",
        "Pig",
        "Hbase",
        "MongoDB",
        "Canssdra",
        "Spark",
        "Backend",
        "NoSQL",
        "database",
        "design",
        "development",
        "architecture",
        "BigData",
        "BIBW",
        "Consultant",
        "Cisco",
        "San",
        "Jose",
        "CA",
        "scripts",
        "programs",
        "Transform",
        "Load",
        "data",
        "Automated",
        "ETL",
        "aggregation",
        "processes",
        "BASHPHP",
        "scripting",
        "languages",
        "elements",
        "Data",
        "Warehouse",
        "ETL",
        "processes",
        "Operations",
        "team",
        "Data",
        "Warehouse",
        "ETL",
        "process",
        "support",
        "operations",
        "team",
        "processes",
        "data",
        "warehouse",
        "users",
        "Expertise",
        "Splunk",
        "UIGUI",
        "development",
        "operations",
        "roles",
        "measure",
        "data",
        "warehouse",
        "ETL",
        "processes",
        "speed",
        "reliability",
        "accuracy",
        "Performed",
        "analyses",
        "improvements",
        "data",
        "quality",
        "recommendations",
        "business",
        "inputs",
        "tools",
        "metrics",
        "dashboard",
        "reports",
        "rest",
        "company",
        "quality",
        "timeliness",
        "data",
        "warehouse",
        "data",
        "data",
        "maintenance",
        "tools",
        "address",
        "cleaning",
        "software",
        "technologies",
        "service",
        "data",
        "warehousing",
        "needs",
        "Hadoop",
        "column",
        "Cisco",
        "data",
        "analytics",
        "platform",
        "development",
        "testing",
        "deployment",
        "data",
        "integration",
        "application",
        "design",
        "development",
        "testing",
        "Pentaho",
        "data",
        "integration",
        "tool",
        "data",
        "integration",
        "jobs",
        "MapR",
        "Hadoop",
        "YARN",
        "jobs",
        "enterprise",
        "data",
        "Oracle",
        "Hive",
        "data",
        "platform",
        "Moved",
        "WebEx",
        "voice",
        "phone",
        "video",
        "email",
        "enterprise",
        "data",
        "Hive",
        "data",
        "mart",
        "Wrote",
        "use",
        "story",
        "task",
        "plan",
        "testing",
        "cases",
        "scripts",
        "testing",
        "Wrote",
        "design",
        "document",
        "enterprise",
        "data",
        "board",
        "deployment",
        "log",
        "errors",
        "data",
        "staging",
        "environment",
        "Monitored",
        "hive",
        "staging",
        "environment",
        "BigData",
        "BI",
        "consultant",
        "Cisco",
        "Milpitas",
        "CA",
        "Hadoop",
        "MapR",
        "BWBI",
        "data",
        "warehouse",
        "project",
        "data",
        "Informatica",
        "TD",
        "Loaded",
        "data",
        "source",
        "build",
        "Hadoop",
        "analyst",
        "platform",
        "Built",
        "Hadoop",
        "QA",
        "team",
        "Hadoop",
        "HiveSqoopbash",
        "data",
        "load",
        "query",
        "data",
        "Monitored",
        "QA",
        "environment",
        "Hadoop",
        "problems",
        "Testing",
        "report",
        "form",
        "MapR",
        "report",
        "tool",
        "process",
        "team",
        "Review",
        "reports",
        "code",
        "logic",
        "team",
        "team",
        "lead",
        "Hadoop",
        "stack",
        "eg",
        "MapReduce",
        "Sqoop",
        "Pig",
        "Hive",
        "Hbase",
        "Flume",
        "source",
        "software",
        "platforms",
        "languages",
        "Java",
        "Linux",
        "Apache",
        "Perl",
        "PythonPHP",
        "Chef",
        "ETL",
        "tools",
        "eg",
        "Informatica",
        "Talend",
        "Pentaho",
        "BI",
        "tools",
        "software",
        "eg",
        "Microstrategy",
        "Cognos",
        "OBIEE",
        "Pentaho",
        "tools",
        "languages",
        "libraries",
        "eg",
        "SAS",
        "SPSS",
        "R",
        "Mahout",
        "business",
        "development",
        "activities",
        "solutions",
        "client",
        "executives",
        "ETL",
        "applications",
        "applications",
        "Applicationimplementation",
        "custom",
        "analytics",
        "support",
        "databases",
        "Data",
        "migration",
        "data",
        "stores",
        "Infrastructure",
        "storage",
        "design",
        "capacity",
        "plans",
        "systems",
        "BigData",
        "BI",
        "consultant",
        "Santa",
        "Clara",
        "CA",
        "Spark",
        "RDD",
        "development",
        "NoSQL",
        "database",
        "DesignArchitecture",
        "Big",
        "Data",
        "Hadoop",
        "Testing",
        "Frameworks",
        "Building",
        "Hadoop",
        "cluster",
        "Cloud",
        "Worked",
        "AWS",
        "cloud",
        "environment",
        "EMR",
        "Redshift",
        "S3",
        "Scala",
        "Java",
        "Python",
        "Kafka",
        "AKKA",
        "SQL",
        "MongoDB",
        "JSON",
        "Avro",
        "Tableau",
        "Git",
        "SBT",
        "Ant",
        "Maven",
        "Ganglia",
        "Jenkins",
        "Docker",
        "Hadoop",
        "Hbase",
        "Zookeeper",
        "Oozie",
        "Scalding",
        "Spark",
        "Shark",
        "automation",
        "Scala",
        "ETL",
        "reporting",
        "tools",
        "OBIEE",
        "SAP",
        "Scala",
        "Kafka",
        "Streaming",
        "Spark",
        "AWS",
        "services",
        "Pig",
        "Small",
        "workflow",
        "SQL",
        "Hive",
        "Built",
        "Analytic",
        "Spark",
        "platform",
        "Ad",
        "revenue",
        "feed",
        "process",
        "Big",
        "Data",
        "Projects",
        "platform",
        "BigData",
        "BI",
        "consultant",
        "San",
        "Jose",
        "CA",
        "ATT",
        "SAP",
        "BWBIBigData",
        "development",
        "support",
        "design",
        "applications",
        "Hadoop",
        "platforms",
        "Feature",
        "testing",
        "Regression",
        "Testing",
        "Acceptance",
        "Testing",
        "Sanity",
        "Testing",
        "Business",
        "analysis",
        "tools",
        "HadoopMapReduce",
        "scripts",
        "ETL",
        "data",
        "data",
        "warehouse",
        "BI",
        "enterprise",
        "analysis",
        "platform",
        "Administrated",
        "Log",
        "analysis",
        "scripts",
        "Business",
        "Analyst",
        "tool",
        "HDFS",
        "Hadoop",
        "file",
        "system",
        "level",
        "Hadoop",
        "workloads",
        "IO",
        "solutions",
        "HadoopHBase",
        "clusters",
        "development",
        "Hadoop",
        "Vertica",
        "Analytics",
        "Platform",
        "activities",
        "Storage",
        "architectureQA",
        "Netapp",
        "Hadoop",
        "ecosystem",
        "administrator",
        "NetApp",
        "Open",
        "Solution",
        "settings",
        "Hadoop",
        "systems",
        "cluster",
        "test",
        "results",
        "configurations",
        "enterprisegrade",
        "storage",
        "arrays",
        "Hadoop",
        "network",
        "bottlenecks",
        "disk",
        "shelves",
        "storage",
        "services",
        "NFS",
        "HDFS",
        "file",
        "systems",
        "networkfree",
        "hardware",
        "RAID",
        "Daytoday",
        "support",
        "Hadoop",
        "hardware",
        "software",
        "issues",
        "automation",
        "scripts",
        "performance",
        "testing",
        "storage",
        "OS",
        "design",
        "Big",
        "Data",
        "System",
        "Consultant",
        "Bank",
        "America",
        "TCOE",
        "Concord",
        "MA",
        "projects",
        "teams",
        "amounts",
        "data",
        "BI",
        "Communicated",
        "defects",
        "data",
        "testing",
        "BigData",
        "NoSQL",
        "Hadoop",
        "Oracle",
        "DB2",
        "scripts",
        "Wrote",
        "scripts",
        "defects",
        "Expertise",
        "Splunk",
        "UIGUI",
        "development",
        "operations",
        "roles",
        "scripts",
        "languages",
        "Perl",
        "Python",
        "Automations",
        "testing",
        "test",
        "data",
        "condition",
        "scripts",
        "languages",
        "ETL",
        "load",
        "BW",
        "Middleware",
        "Architect",
        "Kaiser",
        "Walnut",
        "Creek",
        "CA",
        "middleware",
        "interfaces",
        "BigData",
        "IBM",
        "MQ",
        "design",
        "architecture",
        "support",
        "QA",
        "environment",
        "production",
        "support",
        "Message",
        "broker",
        "production",
        "support",
        "Education",
        "Bachelors",
        "Information",
        "Systems",
        "Information",
        "Systems",
        "University",
        "San",
        "Francisco"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T22:47:46.203530",
    "resume_data": "Sr Data Engineer Python programmer Sr Data Engineerspan lPythonspan programmer Sr Data Engineer Python programmer BlackRock Dublin CA Experienced IT professional who has management team building and endtoend solution skills with focus on leveraging information technology seeking a leadership position using Big Data and data science to maximize business values Developer Engineer Architect with over 8 years of development administration and programming experience with primary focus in Big Data and emphasis on Hadoop Advanced HadoopBigDataAnalytic Experience Looking for handson Functional Programming and OO Programming role Looking for handson Spark Kafka Scala Python and Pyspark programming role Big Data Specialties Spark RDD and Spark DF development Pyspark using Pycharm development Worked with Hadoop HBase Cascading Zookeeper Oozie Hive HiveQL MapR MogoDB Pentaho Pig Worked with AWS Cloud EC2 EMR RedShift S3 etc Supported Hadoop and Verita as administrator about 7 to 700 nodes Supported and administrated users accounts and security rules with BigData domain Worked with Application Servers Tomcat Oracle and MySQL Experienced with distributed systems large scale nonrelational data stores mapreduce systems data modeling database performance and multiterabyte data warehouses Experienced in a SaaS environment that has an agile development process Experienced in Java Python or other object oriented programming language Experienced in Mobile Linux Unix Android MAC platform Experienced with server management server operating systemsWindows Linux Unix and VMware Experienced in testing APIs Restful APIs Experienced with full SW Lifecycle and Agile practice Experienced with scripting language in Perl Python Ruby QTP for automated and performance tests Experienced with testing DNA sequence machines SW for regulatory approval Experienced testing networking and storage technologies protocols and hardware Experienced with web services and SOAP UI testing Experienced with Oracle TOAD and SQL Experienced in testing UI technologies such as HTML5 Experienced in Big Data Hadoop CassandraMemcachedNoSQLMapReduce Lead and coached about 2 to 20 engineers onshore offshore and nearshore Lead the hiring process Bigdata and analytics platform administrator Vertica Greenplum Hdoop HiveApache Drills Sqoop Kafka AKKA and Docker Experienced with Display Advertising Behavioral Ad Networks Recommended Engines Personalization Experienced with Data Analytics Data mining Predictive Modeling Work Experience Sr Data Engineer Python programmer BlackRock San Francisco CA 2018 to Present Handon Data Lake Implementation in Big data for huge data warehouses Building data process ETL transformation data ingestion and platforms Coding in Pyspark Python Pandas Kafka Java Scala and Spark SQL Coding SAP Sybase ASE SQL Coding Kafka and Spark streaming and massaging Converted existing spaghetti code to modular code Configured and set up designed performance enhancements scalable systems using with java services exposure Leading BigData data warehouse application design data quality implementation and testingdeployment strategy Leading in identification and troubleshooting processing issues impacting timely availability of data in the data warehouse or delivery of critical reporting within established SLAs Identified and recommended improvements in production application solutions or operational processes in support of data warehouse applications and business intelligence reporting ie data quality performance static and dynamic reports etc Researched managed and coordinated resolution of complex issues through root cause analysis as appropriate Built Spark Engine and BlackRock Sale Business Engine Researched and implemented Blackchin technology Built machine learning ETL pipeline Built deep learning model and data pipeline Utilized multiple large Hadoop HDP infrastructure Utilized Git Jira Prometheus Docker Kubernetes tools Sr Data ArchitectAWS Cloud Realtorcom Santa Clara CA 2016 to 2018 DB development and DB performance tuning Built Hadoop development eco platforms Built AirFlow workflows and testing scripts Docker Master and installdeployment Worked on DB persistence with Java Hibernate development in AWS Redshift performance tuning and testing Spark RDD and Airflow workflow designing and testing Report design using MicroStrategy Built lead recommender systems for realtorcom website Scala functional programming with Spark streaming Solr Programming Hortonworks Programming VM programming Docker programming Sr Big data Architect developer FRB San Francisco CA 2015 to 2015 Handon Spark RDD and Spark DF development Docker Master and installdeployment NoSQL database design and Spark SQL development UnixHadoop administrator and development Expertise with Splunk UIGUI development and operations roles Prepared arranged and tested Splunk search strings and operational strings Managed the Splunk licenses and restricted the daily indexing limit AWS EMR Redshift administratordevelopment Cloudera Administratordevelopment Cloudera Navigator Administratordevelopment Kerbero Administrator Zoomdata administrator Big data platform design and architecturedevelopment Hive and Hbase development Security office for big data POC Hadoop AWS Cloudera Streaming Kafka and big data tools Work with scripts for Oozie and Hue systems Cassandra MongoDB Hbase Hive development Cloudera Hue and Solr development Data governance policymanagement and big data security Big data security and Kerberos development Multitenant set up and development Sr DataBase Architect San Francisco CA 2015 to 2015 Converting large SAS SQL scripts to HiveQL for Data Science Converting Oracle scripts to HiveQL programming for Data Science Architecture NoSQL databases and coding the MapReduce functions for over 10 years data about emails campaigning results analytics Working with data science to prototype data model and programming the business logic with Hive Pig Building database application on Hive Pig Hbase MongoDB Canssdra Spark Solr and shark on a large hadoop nodes cluster in house Backend NoSQL database design development architecture and testing Data gaverment Backend Big DataHadoop Engineer SS Network Redwood City CA 2014 to 2014 Spark RDD and Spark SQLHive SQL NoSQL database modeling AWS cloud computing and architecture with Hadoop on Big Data Build cloud application on AWS S3 EMR Hive Pig Hbase MongoDB Canssdra Spark Backend NoSQL database design development architecture and testing BigData and BIBW Consultant Cisco San Jose CA 2014 to 2014 Created and maintained scripts and programs to Extract Transform and Load data Automated ETL and aggregation processes using BASHPHP andor other scripting languages Created logging and monitoring elements to all Data Warehouse and ETL processes to allow Operations team to monitor Responded to Data Warehouse and ETL process alerts with support from operations team Created maintained and automated processes to distribute data warehouse extracts to various users Expertise with Splunk UIGUI development and operations roles Continually monitored measure and improved all data warehouse and ETL processes for speed reliability and accuracy Performed analyses and executed improvements regarding overall data quality including making recommendations to the business regarding inputs Sourced andor created tools to deliver monitoring metrics and dashboard reports to allow the rest of the company to understand the quality and timeliness of data warehouse data Installed and integrated 3rdparty data maintenance tools such as address cleaning software etc Used new technologies to service data warehousing needs such as Hadoop column databases etc Cisco big data analytics platform development testing and deployment Worked on data integration application design development and testing Used Pentaho data integration tool to create data integration jobs Used MapR to run Hadoop YARN jobs Moved enterprise data from Oracle to Hive for big data platform Moved WebEx voice phone video and email enterprise data to Hive and build data mart Wrote use story task plan and testing cases Wrote scripts for automating testing Wrote design document for enterprise data on board Analyzed deployment log for errors Monitored big data staging environment Monitored hive staging environment BigData and BI consultant Cisco Milpitas CA 2013 to 2013 Hadoop MapR BWBI data warehouse project Big data move from Informatica and TD Loaded data from different source to new build Hadoop analyst platform Built Hadoop QA team Used Hadoop HiveSqoopbash to deployment the data load and query data Monitored QA environment for Hadoop problems Testing report form MapR report tool Provided ideasworking process to other team Review other reports and code to understand coding logic Managed a technical team or functioning as a team lead Worked with Hadoop stack eg MapReduce Sqoop Pig Hive Hbase Flume relatedcomplementary open source software platforms and languages eg Java Linux Apache Perl PythonPHP Chef Worked with ETL ExtractTransformLoad tools eg Informatica Talend Pentaho Worked with BI tools and reporting software eg Microstrategy Cognos OBIEE Pentaho Worked with analytical tools languages or libraries eg SAS SPSS R Mahout Supported business development activities to shape and communicate proposed solutions to client executives Implemented of ETL applications Implemented of reporting applications Applicationimplementation of custom analytics support Administrated of relational databases Data migration from existing data stores Infrastructure and storage design Developed capacity plans for new and existing systems BigData and BI consultant Santa Clara CA 2013 to 2013 Spark RDD development and NoSQL database modeling DesignArchitecture Big Data Hadoop Testing Frameworks Building Hadoop cluster in Cloud and local Worked with AWS cloud environment EMR Redshift S3 Worked with Scala Java Python Kafka AKKA SQL MongoDB JSON Avro Tableau Worked with Git SBT Ant Maven Ganglia Jenkins Docker Worked with Hadoop Hbase Zookeeper Oozie Scalding Spark Shark Tested automation and coded in Scala Worked with ETL and reporting tools OBIEE SAP etc Coded on Scala Kafka Streaming Spark and AWS services Coded on Pig Small workflow SQL and Hive Built Analytic Spark platform Built Ad revenue feed process Built Big Data Projects testing platform BigData and BI consultant San Jose CA 2006 to 2012 ATT SAP BWBIBigData development support Conducted detailed design applications developed on Hadoop platforms Feature testing Regression Testing Acceptance Testing and Sanity Testing Implemented Business analysis tools with HadoopMapReduce scripts from ETL data to data warehouse for BI and enterprise analysis platform Administrated Log analysis scripts for Business Analyst tool with HDFS Hadoop file system level Advised the Hadoop and analytical workloads IO optimizing solutions Running benchmarked HadoopHBase clusters Supported development of Hadoop and Vertica Analytics Platform activities Storage architectureQA Netapp Hadoop ecosystem administrator and support Tested NetApp Open Solution for HadoopNOSH settings Supported and scaled Hadoop systems Supported cluster failed over test and document the results with various configurations Administrated enterprisegrade storage arrays and eliminated Hadoop network bottlenecks Supported hotpluggable disk shelves added storage and administrated services Supported NFS and HDFS file systems Loaded networkfree hardware RAID Daytoday support Hadoop hardware and software issues Used automation scripts to run performance testing of the new storage OS design Big Data System Consultant Bank of America TCOE Concord MA 2006 to 2009 Supported about over 100 projects and many functional teams Supported analytic massive amounts of data and BI Communicated and tracked defects to closure Administrated with large data set testing with BigData NoSQL Hadoop and Oracle DB2 scripts Wrote reviewed and executed scripts and tracked defects Expertise with Splunk UIGUI development and operations roles Used scripts languages in Perl and Python for Automations testing and test data condition Used scripts languages for ETL load with BW Middleware Architect Kaiser Walnut Creek CA 2004 to 2006 Designed all middleware with 3000 interfaces for BigData IBM MQ design architecture support Designed QA environment and production support Designed Message broker and production support Education Bachelors in Information Systems in Information Systems University of San Francisco 2004",
    "unique_id": "5042e7a7-000c-4917-8b65-08c558fb9131"
}