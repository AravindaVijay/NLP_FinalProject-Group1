{
    "clean_data": "Hadoop Spark Developer Hadoop Spark Developer Hadoop Developer Esvee Technologies Inc Chantilly VA Authorized to work in the US for any employer Work Experience Hadoop Spark Developer Esvee Technologies Inc Chantilly VA September 2015 to Present Description Worked with financial and production dataset Our main aim was to help finance department in finding any patterns in the stock datasets which get influence with many natural and political news We did collect realtime data from different sources using flume and then data was analyzed using Spark Scala Responsibilities Design efficient Spark code using Scala and Spark SQL which can be forward engineered by our code generation developers Did spark streaming and microbatch processing using Scala as a programming language Using Hive Script in Spark for data cleaning and transformation purpose Consult with and code developers on how to improve their algorithms for generating high performing Spark code Consult with product management on the features that are applicable and valuable for a product which designs and submits Spark applications Spark Streaming for Fast failure and straggler recovery Load balancing unification of streaming batch and interactive workloads and advanced analytics Used Apache Phoenix to get access to HBase database and process using SQL commands Created Hive customized UDF for cleaning the data and storing it in Hive warehouse from HBase Manage Hadoop operations with multinode HDFS cluster using Cloudera Manager Created Oozie for fetching out data on the periodic basis and in periodic timely fashion Installing and configuring Hadoop ecosystem like Pig Hive Handle importing of data from various data sources perform transformations using Hive Map Reduce load data into HDFS and extract the data from My SQL into HDFS using Sqoop Extensively used Pig for data cleansing Create partitioned tables in Hive Use Hive to analyze the partitioned and bucketed data and compute various metrics for reporting Install and configure Pig and also write Pig Latin scripts Environment Hadoop 121 MapReduce Sqoop 144 Hive 0100 Pig 0111 Hbase 09411 Scala Zookeeper 343 Mac EL Caption Database Administrator Indore Madhya Pradesh December 2014 to August 2015 Description Implemented an MYSQL database for a pathology lab client We made a central database which helps in linking data between testing department and finance We developed some stored procedures for generating reports on periodic basis Responsibilities Lead and participated in designing coding validating and implementing database developments in MySQL Backing up and recovering data from data warehouse Validating schema and create necessary data objects Writing stored procedures triggers with development team for application Manipulate clean data as per requirement of the application Educate coworker with the structure of the database and their standard practice Providing information on request basis by management for BI purpose Environment MySQL SQLWorkbench and OS windows XP Education Bachelor of Science in Bioinformatics in Bioinformatics Soft vision Institute of Biotechnology Indore Madhya Pradesh Skills Apache 2 years APACHE HADOOP HDFS 2 years APACHE HADOOP MAPREDUCE 2 years database 2 years SQL 2 years Additional Information Over 3 years of professional experience in IT industry with handson experience in Developing Implementing and maintenance of various applications using Java technologies Around 2 years of experience with Hadoop Ecosystem including MapReduce Spark HDFS SQOOP HIVE Avrotools Pig HBase and YARN Around 1 year of professional experience in Database Administration and Data Analysis Hands on experience with Amazon Web Services infrastructure EC2 RDS EMR etc Experience in using and implementing Machine Learning Algorithms Experience in using PLSQL to write Stored Procedures Functions and Triggers Experience in Collecting log data from various sources and integrating into HDFS using Flume and experience in developing custom UDFs for Pig and Hive Experience working with Oozie workflow engine to schedule timebased jobs to perform multiple actions Good understanding of Data analysis Data engineering and Data Science Ability to plan prioritize and work under pressure with an excellent analytical leadership and support skills Experience in working with agile methodologies and suggesting process improvements in agile Used JIRA for an issue and project tracking Loaded data from flat data files into SQL Server 2008 database tables using bulk insert and table exportimport loaded data from flat files and excel sheet into Oracle database using SQLLoader Provide Consulting to Customers in identifying Big Data use cases and guiding them to implementation RDBMS experience includes Oracle PostgreSQL MySQL and programming using PLSQL SQL Load and transform large sets of structured semi structured and unstructured data Technical Skills Data Analytics SAS 93 Tableau Apache Hadoop 263 Spark HDFS Hbase MapReduce R Sqoop Flume Avrotools Pig Hbase oozi LanguagesWeb Technologies Java C Pythonpackage TensorFlow Anaconda Numpy C Net HTML XML Java Script JSON JSP CUDA Scala R packages Bioconductor random forest kernlab nnet and carert Angular JS WebApplication Servers Apache Tomcat Oracle VM Database MySQL SQL server 2005 HIVE Impala GitHub code Management Developer tools Eclipse RStudio Operating System Linux Windows Mac",
    "entities": [
        "Created Hive",
        "SQL Server",
        "Create",
        "US",
        "Hadoop Spark Developer Hadoop Spark Developer Hadoop Developer Esvee Technologies Inc Chantilly VA Authorized",
        "Sqoop",
        "Writing",
        "MapReduce Spark",
        "Collecting",
        "Educate",
        "BI",
        "Work Experience Hadoop Spark Developer Esvee Technologies Inc Chantilly VA",
        "HDFS",
        "Impala GitHub code Management Developer",
        "Technical Skills Data Analytics SAS",
        "Oracle",
        "SQLLoader Provide Consulting to Customers",
        "Angular JS WebApplication Servers",
        "Data Analysis Hands",
        "Oracle PostgreSQL MySQL",
        "Hadoop Ecosystem",
        "MapReduce Sqoop",
        "Institute of Biotechnology Indore Madhya Pradesh",
        "Data Science Ability",
        "LanguagesWeb Technologies Java C Pythonpackage TensorFlow Anaconda Numpy C",
        "SQL",
        "Hadoop",
        "HBase Manage Hadoop",
        "UDF",
        "Amazon Web Services",
        "Tableau Apache Hadoop",
        "Database Administration",
        "Manipulate",
        "HBase",
        "Spark code Consult",
        "Big Data",
        "Hive",
        "Spark",
        "Data analysis Data",
        "Spark Scala Responsibilities Design"
    ],
    "experience": "Experience Hadoop Spark Developer Esvee Technologies Inc Chantilly VA September 2015 to Present Description Worked with financial and production dataset Our main aim was to help finance department in finding any patterns in the stock datasets which get influence with many natural and political news We did collect realtime data from different sources using flume and then data was analyzed using Spark Scala Responsibilities Design efficient Spark code using Scala and Spark SQL which can be forward engineered by our code generation developers Did spark streaming and microbatch processing using Scala as a programming language Using Hive Script in Spark for data cleaning and transformation purpose Consult with and code developers on how to improve their algorithms for generating high performing Spark code Consult with product management on the features that are applicable and valuable for a product which designs and submits Spark applications Spark Streaming for Fast failure and straggler recovery Load balancing unification of streaming batch and interactive workloads and advanced analytics Used Apache Phoenix to get access to HBase database and process using SQL commands Created Hive customized UDF for cleaning the data and storing it in Hive warehouse from HBase Manage Hadoop operations with multinode HDFS cluster using Cloudera Manager Created Oozie for fetching out data on the periodic basis and in periodic timely fashion Installing and configuring Hadoop ecosystem like Pig Hive Handle importing of data from various data sources perform transformations using Hive Map Reduce load data into HDFS and extract the data from My SQL into HDFS using Sqoop Extensively used Pig for data cleansing Create partitioned tables in Hive Use Hive to analyze the partitioned and bucketed data and compute various metrics for reporting Install and configure Pig and also write Pig Latin scripts Environment Hadoop 121 MapReduce Sqoop 144 Hive 0100 Pig 0111 Hbase 09411 Scala Zookeeper 343 Mac EL Caption Database Administrator Indore Madhya Pradesh December 2014 to August 2015 Description Implemented an MYSQL database for a pathology lab client We made a central database which helps in linking data between testing department and finance We developed some stored procedures for generating reports on periodic basis Responsibilities Lead and participated in designing coding validating and implementing database developments in MySQL Backing up and recovering data from data warehouse Validating schema and create necessary data objects Writing stored procedures triggers with development team for application Manipulate clean data as per requirement of the application Educate coworker with the structure of the database and their standard practice Providing information on request basis by management for BI purpose Environment MySQL SQLWorkbench and OS windows XP Education Bachelor of Science in Bioinformatics in Bioinformatics Soft vision Institute of Biotechnology Indore Madhya Pradesh Skills Apache 2 years APACHE HADOOP HDFS 2 years APACHE HADOOP MAPREDUCE 2 years database 2 years SQL 2 years Additional Information Over 3 years of professional experience in IT industry with handson experience in Developing Implementing and maintenance of various applications using Java technologies Around 2 years of experience with Hadoop Ecosystem including MapReduce Spark HDFS SQOOP HIVE Avrotools Pig HBase and YARN Around 1 year of professional experience in Database Administration and Data Analysis Hands on experience with Amazon Web Services infrastructure EC2 RDS EMR etc Experience in using and implementing Machine Learning Algorithms Experience in using PLSQL to write Stored Procedures Functions and Triggers Experience in Collecting log data from various sources and integrating into HDFS using Flume and experience in developing custom UDFs for Pig and Hive Experience working with Oozie workflow engine to schedule timebased jobs to perform multiple actions Good understanding of Data analysis Data engineering and Data Science Ability to plan prioritize and work under pressure with an excellent analytical leadership and support skills Experience in working with agile methodologies and suggesting process improvements in agile Used JIRA for an issue and project tracking Loaded data from flat data files into SQL Server 2008 database tables using bulk insert and table exportimport loaded data from flat files and excel sheet into Oracle database using SQLLoader Provide Consulting to Customers in identifying Big Data use cases and guiding them to implementation RDBMS experience includes Oracle PostgreSQL MySQL and programming using PLSQL SQL Load and transform large sets of structured semi structured and unstructured data Technical Skills Data Analytics SAS 93 Tableau Apache Hadoop 263 Spark HDFS Hbase MapReduce R Sqoop Flume Avrotools Pig Hbase oozi LanguagesWeb Technologies Java C Pythonpackage TensorFlow Anaconda Numpy C Net HTML XML Java Script JSON JSP CUDA Scala R packages Bioconductor random forest kernlab nnet and carert Angular JS WebApplication Servers Apache Tomcat Oracle VM Database MySQL SQL server 2005 HIVE Impala GitHub code Management Developer tools Eclipse RStudio Operating System Linux Windows Mac",
    "extracted_keywords": [
        "Hadoop",
        "Spark",
        "Developer",
        "Hadoop",
        "Spark",
        "Developer",
        "Hadoop",
        "Developer",
        "Esvee",
        "Technologies",
        "Inc",
        "Chantilly",
        "VA",
        "Authorized",
        "US",
        "employer",
        "Work",
        "Experience",
        "Hadoop",
        "Spark",
        "Developer",
        "Esvee",
        "Technologies",
        "Inc",
        "Chantilly",
        "VA",
        "September",
        "Present",
        "Description",
        "production",
        "aim",
        "department",
        "patterns",
        "stock",
        "datasets",
        "influence",
        "news",
        "data",
        "sources",
        "flume",
        "data",
        "Spark",
        "Scala",
        "Responsibilities",
        "Design",
        "Spark",
        "code",
        "Scala",
        "Spark",
        "SQL",
        "code",
        "generation",
        "developers",
        "streaming",
        "processing",
        "Scala",
        "programming",
        "language",
        "Hive",
        "Script",
        "Spark",
        "data",
        "cleaning",
        "transformation",
        "purpose",
        "Consult",
        "code",
        "developers",
        "algorithms",
        "Spark",
        "code",
        "Consult",
        "product",
        "management",
        "features",
        "product",
        "Spark",
        "applications",
        "Spark",
        "Streaming",
        "failure",
        "straggler",
        "recovery",
        "Load",
        "unification",
        "streaming",
        "batch",
        "workloads",
        "analytics",
        "Apache",
        "Phoenix",
        "access",
        "HBase",
        "database",
        "process",
        "SQL",
        "commands",
        "Hive",
        "UDF",
        "data",
        "Hive",
        "warehouse",
        "HBase",
        "Manage",
        "Hadoop",
        "operations",
        "multinode",
        "HDFS",
        "cluster",
        "Cloudera",
        "Manager",
        "Oozie",
        "data",
        "basis",
        "fashion",
        "Hadoop",
        "ecosystem",
        "Pig",
        "Hive",
        "Handle",
        "importing",
        "data",
        "data",
        "sources",
        "transformations",
        "Hive",
        "Map",
        "Reduce",
        "load",
        "data",
        "HDFS",
        "data",
        "SQL",
        "HDFS",
        "Sqoop",
        "Pig",
        "data",
        "cleansing",
        "tables",
        "Hive",
        "Use",
        "Hive",
        "data",
        "metrics",
        "Install",
        "configure",
        "Pig",
        "Pig",
        "Latin",
        "scripts",
        "Environment",
        "Hadoop",
        "MapReduce",
        "Sqoop",
        "Hive",
        "Pig",
        "Hbase",
        "Scala",
        "Zookeeper",
        "Mac",
        "EL",
        "Caption",
        "Database",
        "Administrator",
        "Indore",
        "Madhya",
        "Pradesh",
        "December",
        "August",
        "Description",
        "MYSQL",
        "database",
        "pathology",
        "lab",
        "client",
        "database",
        "data",
        "testing",
        "department",
        "finance",
        "procedures",
        "reports",
        "basis",
        "Responsibilities",
        "Lead",
        "database",
        "developments",
        "MySQL",
        "Backing",
        "data",
        "data",
        "warehouse",
        "schema",
        "data",
        "objects",
        "procedures",
        "triggers",
        "development",
        "team",
        "application",
        "Manipulate",
        "data",
        "requirement",
        "application",
        "Educate",
        "coworker",
        "structure",
        "database",
        "practice",
        "information",
        "request",
        "basis",
        "management",
        "BI",
        "purpose",
        "Environment",
        "MySQL",
        "SQLWorkbench",
        "OS",
        "windows",
        "XP",
        "Education",
        "Bachelor",
        "Science",
        "Bioinformatics",
        "Bioinformatics",
        "Soft",
        "vision",
        "Institute",
        "Biotechnology",
        "Indore",
        "Madhya",
        "Pradesh",
        "Skills",
        "Apache",
        "years",
        "APACHE",
        "HADOOP",
        "HDFS",
        "years",
        "APACHE",
        "HADOOP",
        "MAPREDUCE",
        "years",
        "database",
        "years",
        "SQL",
        "years",
        "Additional",
        "Information",
        "years",
        "experience",
        "IT",
        "industry",
        "handson",
        "experience",
        "Implementing",
        "maintenance",
        "applications",
        "Java",
        "technologies",
        "years",
        "experience",
        "Hadoop",
        "Ecosystem",
        "MapReduce",
        "Spark",
        "HDFS",
        "SQOOP",
        "HIVE",
        "Avrotools",
        "Pig",
        "HBase",
        "YARN",
        "year",
        "experience",
        "Database",
        "Administration",
        "Data",
        "Analysis",
        "Hands",
        "experience",
        "Amazon",
        "Web",
        "Services",
        "infrastructure",
        "EC2",
        "RDS",
        "EMR",
        "Experience",
        "Machine",
        "Learning",
        "Algorithms",
        "Experience",
        "PLSQL",
        "Stored",
        "Procedures",
        "Functions",
        "Triggers",
        "Experience",
        "data",
        "sources",
        "HDFS",
        "Flume",
        "experience",
        "custom",
        "UDFs",
        "Pig",
        "Hive",
        "Experience",
        "Oozie",
        "workflow",
        "engine",
        "jobs",
        "actions",
        "understanding",
        "Data",
        "analysis",
        "Data",
        "engineering",
        "Data",
        "Science",
        "Ability",
        "pressure",
        "leadership",
        "support",
        "skills",
        "Experience",
        "methodologies",
        "process",
        "improvements",
        "JIRA",
        "issue",
        "project",
        "Loaded",
        "data",
        "data",
        "files",
        "SQL",
        "Server",
        "database",
        "tables",
        "insert",
        "table",
        "exportimport",
        "data",
        "files",
        "sheet",
        "Oracle",
        "database",
        "SQLLoader",
        "Provide",
        "Consulting",
        "Customers",
        "Big",
        "Data",
        "cases",
        "RDBMS",
        "experience",
        "Oracle",
        "PostgreSQL",
        "MySQL",
        "programming",
        "PLSQL",
        "SQL",
        "Load",
        "sets",
        "data",
        "Technical",
        "Skills",
        "Data",
        "Analytics",
        "SAS",
        "Tableau",
        "Apache",
        "Hadoop",
        "Spark",
        "HDFS",
        "Hbase",
        "MapReduce",
        "R",
        "Sqoop",
        "Flume",
        "Avrotools",
        "Pig",
        "Hbase",
        "oozi",
        "LanguagesWeb",
        "Technologies",
        "Java",
        "C",
        "Pythonpackage",
        "TensorFlow",
        "Anaconda",
        "Numpy",
        "C",
        "Net",
        "HTML",
        "XML",
        "Java",
        "Script",
        "JSON",
        "JSP",
        "CUDA",
        "Scala",
        "R",
        "packages",
        "Bioconductor",
        "forest",
        "kernlab",
        "nnet",
        "Angular",
        "JS",
        "WebApplication",
        "Servers",
        "Apache",
        "Tomcat",
        "Oracle",
        "VM",
        "Database",
        "MySQL",
        "SQL",
        "server",
        "HIVE",
        "Impala",
        "GitHub",
        "code",
        "Management",
        "Developer",
        "Eclipse",
        "RStudio",
        "Operating",
        "System",
        "Linux",
        "Windows",
        "Mac"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:15:29.624010",
    "resume_data": "Hadoop Spark Developer Hadoop Spark Developer Hadoop Developer Esvee Technologies Inc Chantilly VA Authorized to work in the US for any employer Work Experience Hadoop Spark Developer Esvee Technologies Inc Chantilly VA September 2015 to Present Description Worked with financial and production dataset Our main aim was to help finance department in finding any patterns in the stock datasets which get influence with many natural and political news We did collect realtime data from different sources using flume and then data was analyzed using Spark Scala Responsibilities Design efficient Spark code using Scala and Spark SQL which can be forward engineered by our code generation developers Did spark streaming and microbatch processing using Scala as a programming language Using Hive Script in Spark for data cleaning and transformation purpose Consult with and code developers on how to improve their algorithms for generating high performing Spark code Consult with product management on the features that are applicable and valuable for a product which designs and submits Spark applications Spark Streaming for Fast failure and straggler recovery Load balancing unification of streaming batch and interactive workloads and advanced analytics Used Apache Phoenix to get access to HBase database and process using SQL commands Created Hive customized UDF for cleaning the data and storing it in Hive warehouse from HBase Manage Hadoop operations with multinode HDFS cluster using Cloudera Manager Created Oozie for fetching out data on the periodic basis and in periodic timely fashion Installing and configuring Hadoop ecosystem like Pig Hive Handle importing of data from various data sources perform transformations using Hive Map Reduce load data into HDFS and extract the data from My SQL into HDFS using Sqoop Extensively used Pig for data cleansing Create partitioned tables in Hive Use Hive to analyze the partitioned and bucketed data and compute various metrics for reporting Install and configure Pig and also write Pig Latin scripts Environment Hadoop 121 MapReduce Sqoop 144 Hive 0100 Pig 0111 Hbase 09411 Scala Zookeeper 343 Mac EL Caption Database Administrator Indore Madhya Pradesh December 2014 to August 2015 Description Implemented an MYSQL database for a pathology lab client We made a central database which helps in linking data between testing department and finance We developed some stored procedures for generating reports on periodic basis Responsibilities Lead and participated in designing coding validating and implementing database developments in MySQL Backing up and recovering data from data warehouse Validating schema and create necessary data objects Writing stored procedures triggers with development team for application Manipulate clean data as per requirement of the application Educate coworker with the structure of the database and their standard practice Providing information on request basis by management for BI purpose Environment MySQL SQLWorkbench and OS windows XP Education Bachelor of Science in Bioinformatics in Bioinformatics Soft vision Institute of Biotechnology Indore Madhya Pradesh Skills Apache 2 years APACHE HADOOP HDFS 2 years APACHE HADOOP MAPREDUCE 2 years database 2 years SQL 2 years Additional Information Over 3 years of professional experience in IT industry with handson experience in Developing Implementing and maintenance of various applications using Java technologies Around 2 years of experience with Hadoop Ecosystem including MapReduce Spark HDFS SQOOP HIVE Avrotools Pig HBase and YARN Around 1 year of professional experience in Database Administration and Data Analysis Hands on experience with Amazon Web Services infrastructure EC2 RDS EMR etc Experience in using and implementing Machine Learning Algorithms Experience in using PLSQL to write Stored Procedures Functions and Triggers Experience in Collecting log data from various sources and integrating into HDFS using Flume and experience in developing custom UDFs for Pig and Hive Experience working with Oozie workflow engine to schedule timebased jobs to perform multiple actions Good understanding of Data analysis Data engineering and Data Science Ability to plan prioritize and work under pressure with an excellent analytical leadership and support skills Experience in working with agile methodologies and suggesting process improvements in agile Used JIRA for an issue and project tracking Loaded data from flat data files into SQL Server 2008 database tables using bulk insert and table exportimport loaded data from flat files and excel sheet into Oracle database using SQLLoader Provide Consulting to Customers in identifying Big Data use cases and guiding them to implementation RDBMS experience includes Oracle PostgreSQL MySQL and programming using PLSQL SQL Load and transform large sets of structured semi structured and unstructured data Technical Skills Data Analytics SAS 93 Tableau Apache Hadoop 263 Spark HDFS Hbase MapReduce R Sqoop Flume Avrotools Pig Hbase oozi LanguagesWeb Technologies Java C Pythonpackage TensorFlow Anaconda Numpy C Net HTML XML Java Script JSON JSP CUDA Scala R packages Bioconductor random forest kernlab nnet and carert Angular JS WebApplication Servers Apache Tomcat Oracle VM Database MySQL SQL server 2005 HIVE Impala GitHub code Management Developer tools Eclipse RStudio Operating System Linux Windows Mac",
    "unique_id": "08c25965-30c4-4be4-ad97-92d8ffb967dd"
}