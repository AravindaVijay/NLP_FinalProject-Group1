{
    "clean_data": "SparkScala Developer SparkScala span lDeveloperspan SparkScala Developer Subaru Piscataway NJ Extensive IT experience in Big Data technologies Data ManagementAnalytics Data visualization and javabased enterprise application using JAVAJ2EE Worked in domains like e commerce healthcare automotive industries etc Extensive experience of Big Data Ecosystem including Hadoop2X HDFS YARN MapReduce  HIVE 21 Impala 12 Hbase 10 SQOOP 14 Flume 17 Kafka 12 Oozie 30 and Zookeeper 34 Experience in programming languages namely Java 8 Scala 21 SQL Experienced with realtime data processing mechanism in Big Data Ecosystem such as Apache Kafka and Spark Streaming Experienced in Spark Scala API Spark Python API to transfer process and analyse data in different formats and structures Experienced in writing HiveQL and developing Hive UDFs in Java to process and analyse data Implemented Sqoop and Flume jobs for large sets of structured and semistructured data migration between HDFS andor other data storage like Hive or RDBMS Conducted transformation of data in formats like Avro and Parquet Adept at using Sqoop to migrate data between RDBMS NoSQL and HDFS Knowledge of LinuxUnix Shell Commands Good knowledge of scheduling batch job workflow using Oozie Worked with RDBMS including MySQL MsSql Oracle and knowledge of SQL Server 2008 R2 and over and NoSQL databases including HBase Cassandra and MongoDB Very Good understanding and Working Knowledge of ObjectOriented Programming OOPS Core Java concepts J2EE 8 JDBC Javascript and jQuery Working knowledge of workflows and ETL batch jobs using SSIS TSQL Informatica and Talend Experience in database design using Stored Procedure Functions Triggers and strong experience in writing complex queries for DB2 SQL Server Experience with SQL Server Reporting Services Power BI and Tableau Knowledge of Software Development Life Cycle SDLC methodology like Agile Waterfall Familiarity with project management tools like GIT Microsoft Team foundation server 2015 Knowledge of Unit Testing with ScalaCheck ScalaTest JUnit and MRUnit also used JIRA for basic issue tracking Jenkins for continuous integration and AB testing for certain projects Excellent interpersonal and communication skills Creative dataoriented problem shooting enthusiastic learner Work Experience SparkScala Developer Subaru Piscataway NJ March 2019 to Present Location Piscataway NJ Role SparkScala Developer Subaru is Japanese multinational corporation and conglomerate primarily involved in both terrestrial and aerospace transport manufacturing it is best known for the automobile industry The team was responsible to track changes quality of work production process as well as the safety of the products and its parts This identifies which part of vehicle needs constant upgrades or repairs replacements to make high quality upgrades and help cost reduction in long run Responsibilities Importing and exporting large amount of data using Sqoop and real time data using Flume and Kafka Uploaded data to Hadoop HIVE and combined new tables with existing databases Created various hive external tables staging tables and joined the tables as per the requirement Implemented static Partitioning Dynamic partitioning and Bucketing in Hive using internal and external table Written transformations and actions on data frames used Spark SQL on data frames to access hive tables into spark for faster processing of data Developed Spark applications using Scala utilizing Data frames and Spark SQL API for faster processing of data Used Talend to migrate historical data from Oracle SQL and SQL Server to HDFS and HIVE Extracted data from oracle SQL server and MYSQL databases to HDFS using SQOOP Experienced in handling large datasets using Partitions Spark in Memory capabilities Broadcasts in Spark Effective efficient Joins Transformations and other during ingestion process itself Used Scala to convert HiveSQL queries into RDD transformations in Apache Spark Implemented the workflows using Apache Oozie framework to automate tasks Used Zookeeper to coordinate cluster services Created visualization reports using tableau Designed and built a custom and generic ETL framework Spark application using Scala for data loading and transformations Used Git for version control JIRA for issue tracking and Jenkins for continuous integration Environment Hadoop2X Cloudera CDH HDFS Java 8 Python Scala 21  HIVE 21 Kafka 12 SQOOP 14 Flume 17 Talend Zookeeper 34 Oozie 30 Git JIRA Tableau Project Name Supply management and logistics Business Intelligence Developer Northern Safety and industrial Utica NY February 2018 to October 2018 The company main business is based on construction maintenance agricultural food preparation and handling public service works medical hazardous materials handling and most uptodate safety and industrial supplies The team was focused on migrating the data from database to database which included a large set of ecommerce data of industrial equipment Responsibilities Experience in TSQL programming DDL DML skills like creating Stored Procedures User Defined Functions indexes Views Tables Created aggregate Merge Join Sort Execute SQL Task Data Flow Task and Execute Package Task etc to generate underlying data for reports and to export cleaned data from Excel Spreadsheets Text file MS Access and CSV files to data warehouse Configure and maintain Report Manager and Report Server for SSRS Created visual reports like pie charts bar graphs of companys product sales using Power BI Environment SparkHadoop Developer Analysis of Insurance dataset using Hadoop Utica NY September 2017 to September 2018 WINDOWS 10 VISUAL STUDIO 2017 MS SQL Server 2016 MS Access Microsoft Team Foundation Server TFS Project Name Analysis of Insurance dataset using Hadoop Data Analyst Hyderabad Telangana June 2015 to June 2016 This project was focused on eliminating bogus votingmultiple votes by the same person by creating a database that will not allow the person to vote again in the election Responsibilities Designed and coded certain application modules and components Designed the logical and physical data model generated DDL DML scripts Designed userinterface and used JavaScript to check validations Wrote SQL queries stored procedures and database triggers on the database objects Wrote SQL queries to extract data from archives using complex joins Developed various Java classes SQL queries and procedures to retrieve and manipulate the data from backend database using JDBC Analysis and Reporting of data using SSRS Enabled reporting access to the archives for reporting tools and created documentation Environment Net Cnet IIS ASP JavaScript SQL Server 2008R2 SQLServer SSRS Project Name Railway Stipulation System Java Developer Hyderabad Telangana May 2014 to May 2015 The objective of Railway Stipulation system is to empower the passenger to book tickets online It also enables them to book the tickets without getting into the queue at the comfort of their home It also enables them to swap the tickets with other passenger without cancelling the actual ticket Responsibilities Designed and coded GUI based application to facilitate the ticket booking Created an interface where the user can swap seats with another passenger online via request Used JDBC for database connectivity Designed the logical and physical data model generated DDL DML scripts Designed userinterface and used JavaScript to check validations Wrote SQL queries stored procedures and database triggers on the database objects Environment Java 8 JDBC Tomcat 70 HTML CSS JavaScript JSP SQL Server 2008R2 Education Masters Skills DATA ANALYSIS DATABASE SQL SERVER SQL SERVER 2008 SQL SERVER 2008 R2 Linux HTML Jquery XML Javascript TECHNICAL SKILLS Hadoop Ecosystem Cloud Platform Hadoop2X  MapReduce Hive21 Google Cloud Platform Dataproc Compute Impala12 Sqoop14 Flume17 Kafka12 Engine Bucket SQL Amazon Web Service Hbase10  Zookeeper34 EC2 S3 EMR Databricks Cloud Community Programming Language Operating Systems Java 8 C Scala21 Linux Ubuntu Mac OS CentOS Windows Web Development Database JavaScript jQuery AngularJS HTML CSS MySQL5X Oracle11g PostgreSQL9X Nodejs Netezza7X MongoDB32 HBase098 IDE Application Data Analysis Visualization NetBeans Eclipse Visual Studio Code Python R Tableau Matplotlib  IntelliJ Idea SQL Server 2008 R2 Scripting Language Machine Learning UNIX Shell HTML XML CSS JSP SQL Regression Decision Tree Random Forest Markdown KMeans Neural Networks SVM NLP Environment Collaboration Agile Scrum waterfall Git Microsoft TFS JIRA Jenkins 5 years CertificationsLicenses Drivers License",
    "entities": [
        "Partitions Spark",
        "SQL Server",
        "Working Knowledge of",
        "JDBC Analysis",
        "Spark Streaming Experienced",
        "CSV",
        "ETL",
        "API",
        "GUI",
        "VISUAL",
        "Sqoop",
        "HIVE",
        "Spark Effective",
        "Power BI",
        "Impala",
        "Railway Stipulation",
        "Spark SQL",
        "Created",
        "JavaScript",
        "Excel Spreadsheets Text",
        "jQuery Working",
        "SSRS Created",
        "SQOOP Experienced",
        "Responsibilities Importing",
        "MS Access",
        "SQL Server Reporting Services Power BI",
        "Data ManagementAnalytics Data",
        "Idea SQL Server",
        "ASP",
        "GIT Microsoft Team",
        "Big Data Ecosystem",
        "Zookeeper 34",
        "CSS",
        "SparkScala Developer",
        "Oozie",
        "SSRS",
        "DB2 SQL Server",
        "JSP",
        "Oozie Worked",
        "Tableau Knowledge of Software Development Life Cycle",
        "SQL",
        "JSP SQL Regression",
        "Oracle SQL",
        "Hadoop",
        "RDD",
        "MRUnit",
        "AB",
        "Access Microsoft Team Foundation",
        "MapReduce",
        "R2 Scripting Language Machine Learning",
        "CertificationsLicenses",
        "NoSQL",
        "SQL Experienced",
        "Work Experience SparkScala Developer Subaru Piscataway NJ",
        "Spark SQL API",
        "Utica NY",
        "Configure",
        "Present Location Piscataway",
        "MS",
        "Big Data",
        "Hive",
        "SQOOP",
        "ScalaCheck ScalaTest JUnit",
        "Spark",
        "Hadoop Data Analyst Hyderabad",
        "Git JIRA Tableau Project Name Supply"
    ],
    "experience": "Experience in programming languages namely Java 8 Scala 21 SQL Experienced with realtime data processing mechanism in Big Data Ecosystem such as Apache Kafka and Spark Streaming Experienced in Spark Scala API Spark Python API to transfer process and analyse data in different formats and structures Experienced in writing HiveQL and developing Hive UDFs in Java to process and analyse data Implemented Sqoop and Flume jobs for large sets of structured and semistructured data migration between HDFS andor other data storage like Hive or RDBMS Conducted transformation of data in formats like Avro and Parquet Adept at using Sqoop to migrate data between RDBMS NoSQL and HDFS Knowledge of LinuxUnix Shell Commands Good knowledge of scheduling batch job workflow using Oozie Worked with RDBMS including MySQL MsSql Oracle and knowledge of SQL Server 2008 R2 and over and NoSQL databases including HBase Cassandra and MongoDB Very Good understanding and Working Knowledge of ObjectOriented Programming OOPS Core Java concepts J2EE 8 JDBC Javascript and jQuery Working knowledge of workflows and ETL batch jobs using SSIS TSQL Informatica and Talend Experience in database design using Stored Procedure Functions Triggers and strong experience in writing complex queries for DB2 SQL Server Experience with SQL Server Reporting Services Power BI and Tableau Knowledge of Software Development Life Cycle SDLC methodology like Agile Waterfall Familiarity with project management tools like GIT Microsoft Team foundation server 2015 Knowledge of Unit Testing with ScalaCheck ScalaTest JUnit and MRUnit also used JIRA for basic issue tracking Jenkins for continuous integration and AB testing for certain projects Excellent interpersonal and communication skills Creative dataoriented problem shooting enthusiastic learner Work Experience SparkScala Developer Subaru Piscataway NJ March 2019 to Present Location Piscataway NJ Role SparkScala Developer Subaru is Japanese multinational corporation and conglomerate primarily involved in both terrestrial and aerospace transport manufacturing it is best known for the automobile industry The team was responsible to track changes quality of work production process as well as the safety of the products and its parts This identifies which part of vehicle needs constant upgrades or repairs replacements to make high quality upgrades and help cost reduction in long run Responsibilities Importing and exporting large amount of data using Sqoop and real time data using Flume and Kafka Uploaded data to Hadoop HIVE and combined new tables with existing databases Created various hive external tables staging tables and joined the tables as per the requirement Implemented static Partitioning Dynamic partitioning and Bucketing in Hive using internal and external table Written transformations and actions on data frames used Spark SQL on data frames to access hive tables into spark for faster processing of data Developed Spark applications using Scala utilizing Data frames and Spark SQL API for faster processing of data Used Talend to migrate historical data from Oracle SQL and SQL Server to HDFS and HIVE Extracted data from oracle SQL server and MYSQL databases to HDFS using SQOOP Experienced in handling large datasets using Partitions Spark in Memory capabilities Broadcasts in Spark Effective efficient Joins Transformations and other during ingestion process itself Used Scala to convert HiveSQL queries into RDD transformations in Apache Spark Implemented the workflows using Apache Oozie framework to automate tasks Used Zookeeper to coordinate cluster services Created visualization reports using tableau Designed and built a custom and generic ETL framework Spark application using Scala for data loading and transformations Used Git for version control JIRA for issue tracking and Jenkins for continuous integration Environment Hadoop2X Cloudera CDH HDFS Java 8 Python Scala 21   HIVE 21 Kafka 12 SQOOP 14 Flume 17 Talend Zookeeper 34 Oozie 30 Git JIRA Tableau Project Name Supply management and logistics Business Intelligence Developer Northern Safety and industrial Utica NY February 2018 to October 2018 The company main business is based on construction maintenance agricultural food preparation and handling public service works medical hazardous materials handling and most uptodate safety and industrial supplies The team was focused on migrating the data from database to database which included a large set of ecommerce data of industrial equipment Responsibilities Experience in TSQL programming DDL DML skills like creating Stored Procedures User Defined Functions indexes Views Tables Created aggregate Merge Join Sort Execute SQL Task Data Flow Task and Execute Package Task etc to generate underlying data for reports and to export cleaned data from Excel Spreadsheets Text file MS Access and CSV files to data warehouse Configure and maintain Report Manager and Report Server for SSRS Created visual reports like pie charts bar graphs of companys product sales using Power BI Environment SparkHadoop Developer Analysis of Insurance dataset using Hadoop Utica NY September 2017 to September 2018 WINDOWS 10 VISUAL STUDIO 2017 MS SQL Server 2016 MS Access Microsoft Team Foundation Server TFS Project Name Analysis of Insurance dataset using Hadoop Data Analyst Hyderabad Telangana June 2015 to June 2016 This project was focused on eliminating bogus votingmultiple votes by the same person by creating a database that will not allow the person to vote again in the election Responsibilities Designed and coded certain application modules and components Designed the logical and physical data model generated DDL DML scripts Designed userinterface and used JavaScript to check validations Wrote SQL queries stored procedures and database triggers on the database objects Wrote SQL queries to extract data from archives using complex joins Developed various Java classes SQL queries and procedures to retrieve and manipulate the data from backend database using JDBC Analysis and Reporting of data using SSRS Enabled reporting access to the archives for reporting tools and created documentation Environment Net Cnet IIS ASP JavaScript SQL Server 2008R2 SQLServer SSRS Project Name Railway Stipulation System Java Developer Hyderabad Telangana May 2014 to May 2015 The objective of Railway Stipulation system is to empower the passenger to book tickets online It also enables them to book the tickets without getting into the queue at the comfort of their home It also enables them to swap the tickets with other passenger without cancelling the actual ticket Responsibilities Designed and coded GUI based application to facilitate the ticket booking Created an interface where the user can swap seats with another passenger online via request Used JDBC for database connectivity Designed the logical and physical data model generated DDL DML scripts Designed userinterface and used JavaScript to check validations Wrote SQL queries stored procedures and database triggers on the database objects Environment Java 8 JDBC Tomcat 70 HTML CSS JavaScript JSP SQL Server 2008R2 Education Masters Skills DATA ANALYSIS DATABASE SQL SERVER SQL SERVER 2008 SQL SERVER 2008 R2 Linux HTML Jquery XML Javascript TECHNICAL SKILLS Hadoop Ecosystem Cloud Platform Hadoop2X   MapReduce Hive21 Google Cloud Platform Dataproc Compute Impala12 Sqoop14 Flume17 Kafka12 Engine Bucket SQL Amazon Web Service Hbase10   Zookeeper34 EC2 S3 EMR Databricks Cloud Community Programming Language Operating Systems Java 8 C Scala21 Linux Ubuntu Mac OS CentOS Windows Web Development Database JavaScript jQuery AngularJS HTML CSS MySQL5X Oracle11 g PostgreSQL9X Nodejs Netezza7X MongoDB32 HBase098 IDE Application Data Analysis Visualization NetBeans Eclipse Visual Studio Code Python R Tableau Matplotlib   IntelliJ Idea SQL Server 2008 R2 Scripting Language Machine Learning UNIX Shell HTML XML CSS JSP SQL Regression Decision Tree Random Forest Markdown KMeans Neural Networks SVM NLP Environment Collaboration Agile Scrum waterfall Git Microsoft TFS JIRA Jenkins 5 years CertificationsLicenses Drivers License",
    "extracted_keywords": [
        "SparkScala",
        "Developer",
        "SparkScala",
        "span",
        "lDeveloperspan",
        "SparkScala",
        "Developer",
        "Subaru",
        "Piscataway",
        "NJ",
        "IT",
        "experience",
        "Big",
        "Data",
        "technologies",
        "Data",
        "ManagementAnalytics",
        "Data",
        "visualization",
        "enterprise",
        "application",
        "JAVAJ2EE",
        "domains",
        "e",
        "commerce",
        "healthcare",
        "automotive",
        "industries",
        "experience",
        "Big",
        "Data",
        "Ecosystem",
        "Hadoop2X",
        "HDFS",
        "YARN",
        "MapReduce",
        "HIVE",
        "Impala",
        "Hbase",
        "SQOOP",
        "Flume",
        "Kafka",
        "Oozie",
        "Zookeeper",
        "Experience",
        "programming",
        "languages",
        "Java",
        "Scala",
        "SQL",
        "data",
        "processing",
        "mechanism",
        "Big",
        "Data",
        "Ecosystem",
        "Apache",
        "Kafka",
        "Spark",
        "Streaming",
        "Spark",
        "Scala",
        "API",
        "Spark",
        "Python",
        "API",
        "process",
        "analyse",
        "data",
        "formats",
        "structures",
        "Hive",
        "UDFs",
        "Java",
        "analyse",
        "data",
        "Sqoop",
        "Flume",
        "jobs",
        "sets",
        "data",
        "migration",
        "data",
        "storage",
        "Hive",
        "Conducted",
        "transformation",
        "data",
        "formats",
        "Avro",
        "Parquet",
        "Adept",
        "Sqoop",
        "data",
        "RDBMS",
        "NoSQL",
        "HDFS",
        "Knowledge",
        "LinuxUnix",
        "Shell",
        "knowledge",
        "scheduling",
        "batch",
        "job",
        "workflow",
        "Oozie",
        "Worked",
        "RDBMS",
        "MySQL",
        "MsSql",
        "Oracle",
        "knowledge",
        "SQL",
        "Server",
        "R2",
        "NoSQL",
        "databases",
        "HBase",
        "Cassandra",
        "MongoDB",
        "understanding",
        "Working",
        "Knowledge",
        "ObjectOriented",
        "Programming",
        "Core",
        "Java",
        "J2EE",
        "JDBC",
        "Javascript",
        "jQuery",
        "Working",
        "knowledge",
        "workflows",
        "ETL",
        "batch",
        "jobs",
        "SSIS",
        "TSQL",
        "Informatica",
        "Talend",
        "Experience",
        "database",
        "design",
        "Procedure",
        "Functions",
        "Triggers",
        "experience",
        "queries",
        "DB2",
        "SQL",
        "Server",
        "Experience",
        "SQL",
        "Server",
        "Reporting",
        "Services",
        "Power",
        "BI",
        "Tableau",
        "Knowledge",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "SDLC",
        "methodology",
        "Agile",
        "Waterfall",
        "Familiarity",
        "project",
        "management",
        "tools",
        "GIT",
        "Microsoft",
        "Team",
        "foundation",
        "server",
        "Knowledge",
        "Unit",
        "Testing",
        "ScalaCheck",
        "ScalaTest",
        "JUnit",
        "MRUnit",
        "JIRA",
        "issue",
        "Jenkins",
        "integration",
        "AB",
        "testing",
        "projects",
        "communication",
        "skills",
        "problem",
        "learner",
        "Work",
        "Experience",
        "SparkScala",
        "Developer",
        "Subaru",
        "Piscataway",
        "NJ",
        "March",
        "Present",
        "Location",
        "Piscataway",
        "NJ",
        "Role",
        "SparkScala",
        "Developer",
        "Subaru",
        "corporation",
        "conglomerate",
        "aerospace",
        "transport",
        "automobile",
        "industry",
        "team",
        "changes",
        "quality",
        "work",
        "production",
        "process",
        "safety",
        "products",
        "parts",
        "identifies",
        "part",
        "vehicle",
        "upgrades",
        "repairs",
        "replacements",
        "quality",
        "upgrades",
        "cost",
        "reduction",
        "run",
        "Responsibilities",
        "amount",
        "data",
        "Sqoop",
        "time",
        "data",
        "Flume",
        "Kafka",
        "Uploaded",
        "data",
        "Hadoop",
        "HIVE",
        "tables",
        "databases",
        "tables",
        "tables",
        "tables",
        "requirement",
        "Partitioning",
        "Dynamic",
        "partitioning",
        "Bucketing",
        "Hive",
        "table",
        "transformations",
        "actions",
        "data",
        "frames",
        "Spark",
        "SQL",
        "data",
        "frames",
        "tables",
        "spark",
        "processing",
        "data",
        "Spark",
        "applications",
        "Scala",
        "Data",
        "frames",
        "Spark",
        "SQL",
        "API",
        "processing",
        "data",
        "Talend",
        "data",
        "Oracle",
        "SQL",
        "SQL",
        "Server",
        "HDFS",
        "HIVE",
        "data",
        "oracle",
        "SQL",
        "server",
        "MYSQL",
        "HDFS",
        "SQOOP",
        "datasets",
        "Partitions",
        "Spark",
        "Memory",
        "capabilities",
        "Broadcasts",
        "Spark",
        "Effective",
        "Joins",
        "Transformations",
        "ingestion",
        "process",
        "Scala",
        "HiveSQL",
        "queries",
        "RDD",
        "transformations",
        "Apache",
        "Spark",
        "workflows",
        "Apache",
        "Oozie",
        "framework",
        "tasks",
        "Zookeeper",
        "cluster",
        "services",
        "visualization",
        "reports",
        "tableau",
        "custom",
        "ETL",
        "framework",
        "Spark",
        "application",
        "Scala",
        "data",
        "loading",
        "transformations",
        "Git",
        "version",
        "control",
        "JIRA",
        "issue",
        "tracking",
        "Jenkins",
        "integration",
        "Environment",
        "Hadoop2X",
        "Cloudera",
        "CDH",
        "HDFS",
        "Java",
        "Python",
        "Scala",
        "HIVE",
        "Kafka",
        "SQOOP",
        "Flume",
        "Talend",
        "Zookeeper",
        "Oozie",
        "Git",
        "JIRA",
        "Tableau",
        "Project",
        "Name",
        "Supply",
        "management",
        "logistics",
        "Business",
        "Intelligence",
        "Developer",
        "Northern",
        "Safety",
        "Utica",
        "NY",
        "February",
        "October",
        "company",
        "business",
        "construction",
        "maintenance",
        "food",
        "preparation",
        "service",
        "materials",
        "handling",
        "safety",
        "supplies",
        "team",
        "data",
        "database",
        "database",
        "set",
        "ecommerce",
        "data",
        "equipment",
        "Responsibilities",
        "Experience",
        "TSQL",
        "DDL",
        "DML",
        "skills",
        "Stored",
        "Procedures",
        "User",
        "Defined",
        "Functions",
        "Views",
        "Tables",
        "aggregate",
        "Merge",
        "Join",
        "Sort",
        "SQL",
        "Task",
        "Data",
        "Flow",
        "Task",
        "Execute",
        "Package",
        "Task",
        "data",
        "reports",
        "data",
        "Excel",
        "Spreadsheets",
        "Text",
        "file",
        "MS",
        "Access",
        "CSV",
        "files",
        "data",
        "warehouse",
        "Configure",
        "Report",
        "Manager",
        "Report",
        "Server",
        "SSRS",
        "reports",
        "pie",
        "charts",
        "bar",
        "graphs",
        "companys",
        "product",
        "sales",
        "Power",
        "BI",
        "Environment",
        "SparkHadoop",
        "Developer",
        "Analysis",
        "Insurance",
        "dataset",
        "Hadoop",
        "Utica",
        "NY",
        "September",
        "September",
        "WINDOWS",
        "VISUAL",
        "STUDIO",
        "MS",
        "SQL",
        "Server",
        "MS",
        "Access",
        "Microsoft",
        "Team",
        "Foundation",
        "Server",
        "TFS",
        "Project",
        "Name",
        "Analysis",
        "Insurance",
        "dataset",
        "Hadoop",
        "Data",
        "Analyst",
        "Hyderabad",
        "Telangana",
        "June",
        "June",
        "project",
        "votes",
        "person",
        "database",
        "person",
        "election",
        "Responsibilities",
        "application",
        "modules",
        "components",
        "data",
        "model",
        "DDL",
        "DML",
        "userinterface",
        "JavaScript",
        "validations",
        "Wrote",
        "SQL",
        "procedures",
        "database",
        "triggers",
        "database",
        "Wrote",
        "SQL",
        "data",
        "archives",
        "Java",
        "classes",
        "SQL",
        "procedures",
        "data",
        "database",
        "JDBC",
        "Analysis",
        "Reporting",
        "data",
        "SSRS",
        "access",
        "archives",
        "tools",
        "documentation",
        "Environment",
        "Net",
        "Cnet",
        "IIS",
        "ASP",
        "JavaScript",
        "SQL",
        "Server",
        "2008R2",
        "SQLServer",
        "SSRS",
        "Project",
        "Name",
        "Railway",
        "Stipulation",
        "System",
        "Java",
        "Developer",
        "Hyderabad",
        "Telangana",
        "May",
        "May",
        "objective",
        "Railway",
        "Stipulation",
        "system",
        "passenger",
        "book",
        "tickets",
        "tickets",
        "queue",
        "comfort",
        "home",
        "tickets",
        "passenger",
        "ticket",
        "Responsibilities",
        "GUI",
        "application",
        "ticket",
        "booking",
        "interface",
        "user",
        "seats",
        "passenger",
        "request",
        "JDBC",
        "database",
        "connectivity",
        "data",
        "model",
        "DDL",
        "DML",
        "userinterface",
        "JavaScript",
        "validations",
        "Wrote",
        "SQL",
        "procedures",
        "database",
        "triggers",
        "database",
        "Environment",
        "Java",
        "JDBC",
        "Tomcat",
        "HTML",
        "CSS",
        "JavaScript",
        "JSP",
        "SQL",
        "Server",
        "2008R2",
        "Education",
        "Masters",
        "Skills",
        "DATA",
        "DATABASE",
        "SQL",
        "SERVER",
        "SQL",
        "SERVER",
        "SQL",
        "SERVER",
        "R2",
        "Linux",
        "HTML",
        "Jquery",
        "XML",
        "Javascript",
        "TECHNICAL",
        "SKILLS",
        "Hadoop",
        "Ecosystem",
        "Cloud",
        "Platform",
        "Hadoop2X",
        "MapReduce",
        "Hive21",
        "Google",
        "Cloud",
        "Platform",
        "Dataproc",
        "Compute",
        "Impala12",
        "Sqoop14",
        "Flume17",
        "Kafka12",
        "Engine",
        "Bucket",
        "SQL",
        "Amazon",
        "Web",
        "Service",
        "Hbase10",
        "Zookeeper34",
        "EC2",
        "S3",
        "EMR",
        "Databricks",
        "Cloud",
        "Community",
        "Programming",
        "Language",
        "Operating",
        "Systems",
        "Java",
        "C",
        "Scala21",
        "Linux",
        "Ubuntu",
        "Mac",
        "OS",
        "CentOS",
        "Windows",
        "Web",
        "Development",
        "Database",
        "JavaScript",
        "jQuery",
        "HTML",
        "CSS",
        "MySQL5X",
        "Oracle11",
        "g",
        "PostgreSQL9X",
        "Nodejs",
        "MongoDB32",
        "HBase098",
        "IDE",
        "Application",
        "Data",
        "Analysis",
        "Visualization",
        "NetBeans",
        "Eclipse",
        "Visual",
        "Studio",
        "Code",
        "Python",
        "R",
        "Tableau",
        "Matplotlib",
        "IntelliJ",
        "Idea",
        "SQL",
        "Server",
        "R2",
        "Scripting",
        "Language",
        "Machine",
        "Learning",
        "UNIX",
        "Shell",
        "HTML",
        "CSS",
        "JSP",
        "SQL",
        "Regression",
        "Decision",
        "Tree",
        "Random",
        "Forest",
        "Markdown",
        "KMeans",
        "Neural",
        "Networks",
        "SVM",
        "NLP",
        "Environment",
        "Collaboration",
        "Agile",
        "Scrum",
        "waterfall",
        "Git",
        "Microsoft",
        "TFS",
        "JIRA",
        "Jenkins",
        "years",
        "CertificationsLicenses",
        "Drivers",
        "License"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:07:43.668047",
    "resume_data": "SparkScala Developer SparkScala span lDeveloperspan SparkScala Developer Subaru Piscataway NJ Extensive IT experience in Big Data technologies Data ManagementAnalytics Data visualization and javabased enterprise application using JAVAJ2EE Worked in domains like e commerce healthcare automotive industries etc Extensive experience of Big Data Ecosystem including Hadoop2X HDFS YARN MapReduce Spark14 HIVE 21 Impala 12 Hbase 10 SQOOP 14 Flume 17 Kafka 12 Oozie 30 and Zookeeper 34 Experience in programming languages namely Java 8 Scala 21 SQL Experienced with realtime data processing mechanism in Big Data Ecosystem such as Apache Kafka and Spark Streaming Experienced in Spark Scala API Spark Python API to transfer process and analyse data in different formats and structures Experienced in writing HiveQL and developing Hive UDFs in Java to process and analyse data Implemented Sqoop and Flume jobs for large sets of structured and semistructured data migration between HDFS andor other data storage like Hive or RDBMS Conducted transformation of data in formats like Avro and Parquet Adept at using Sqoop to migrate data between RDBMS NoSQL and HDFS Knowledge of LinuxUnix Shell Commands Good knowledge of scheduling batch job workflow using Oozie Worked with RDBMS including MySQL MsSql Oracle and knowledge of SQL Server 2008 R2 and over and NoSQL databases including HBase Cassandra and MongoDB Very Good understanding and Working Knowledge of ObjectOriented Programming OOPS Core Java concepts J2EE 8 JDBC Javascript and jQuery Working knowledge of workflows and ETL batch jobs using SSIS TSQL Informatica and Talend Experience in database design using Stored Procedure Functions Triggers and strong experience in writing complex queries for DB2 SQL Server Experience with SQL Server Reporting Services Power BI and Tableau Knowledge of Software Development Life Cycle SDLC methodology like Agile Waterfall Familiarity with project management tools like GIT Microsoft Team foundation server 2015 Knowledge of Unit Testing with ScalaCheck ScalaTest JUnit and MRUnit also used JIRA for basic issue tracking Jenkins for continuous integration and AB testing for certain projects Excellent interpersonal and communication skills Creative dataoriented problem shooting enthusiastic learner Work Experience SparkScala Developer Subaru Piscataway NJ March 2019 to Present Location Piscataway NJ Role SparkScala Developer Subaru is Japanese multinational corporation and conglomerate primarily involved in both terrestrial and aerospace transport manufacturing it is best known for the automobile industry The team was responsible to track changes quality of work production process as well as the safety of the products and its parts This identifies which part of vehicle needs constant upgrades or repairs replacements to make high quality upgrades and help cost reduction in long run Responsibilities Importing and exporting large amount of data using Sqoop and real time data using Flume and Kafka Uploaded data to Hadoop HIVE and combined new tables with existing databases Created various hive external tables staging tables and joined the tables as per the requirement Implemented static Partitioning Dynamic partitioning and Bucketing in Hive using internal and external table Written transformations and actions on data frames used Spark SQL on data frames to access hive tables into spark for faster processing of data Developed Spark applications using Scala utilizing Data frames and Spark SQL API for faster processing of data Used Talend to migrate historical data from Oracle SQL and SQL Server to HDFS and HIVE Extracted data from oracle SQL server and MYSQL databases to HDFS using SQOOP Experienced in handling large datasets using Partitions Spark in Memory capabilities Broadcasts in Spark Effective efficient Joins Transformations and other during ingestion process itself Used Scala to convert HiveSQL queries into RDD transformations in Apache Spark Implemented the workflows using Apache Oozie framework to automate tasks Used Zookeeper to coordinate cluster services Created visualization reports using tableau Designed and built a custom and generic ETL framework Spark application using Scala for data loading and transformations Used Git for version control JIRA for issue tracking and Jenkins for continuous integration Environment Hadoop2X Cloudera CDH HDFS Java 8 Python Scala 21 Spark14 HIVE 21 Kafka 12 SQOOP 14 Flume 17 Talend Zookeeper 34 Oozie 30 Git JIRA Tableau Project Name Supply management and logistics Business Intelligence Developer Northern Safety and industrial Utica NY February 2018 to October 2018 The company main business is based on construction maintenance agricultural food preparation and handling public service works medical hazardous materials handling and most uptodate safety and industrial supplies The team was focused on migrating the data from database to database which included a large set of ecommerce data of industrial equipment Responsibilities Experience in TSQL programming DDL DML skills like creating Stored Procedures User Defined Functions indexes Views Tables Created aggregate Merge Join Sort Execute SQL Task Data Flow Task and Execute Package Task etc to generate underlying data for reports and to export cleaned data from Excel Spreadsheets Text file MS Access and CSV files to data warehouse Configure and maintain Report Manager and Report Server for SSRS Created visual reports like pie charts bar graphs of companys product sales using Power BI Environment SparkHadoop Developer Analysis of Insurance dataset using Hadoop Utica NY September 2017 to September 2018 WINDOWS 10 VISUAL STUDIO 2017 MS SQL Server 2016 MS Access Microsoft Team Foundation Server TFS Project Name Analysis of Insurance dataset using Hadoop Data Analyst Hyderabad Telangana June 2015 to June 2016 This project was focused on eliminating bogus votingmultiple votes by the same person by creating a database that will not allow the person to vote again in the election Responsibilities Designed and coded certain application modules and components Designed the logical and physical data model generated DDL DML scripts Designed userinterface and used JavaScript to check validations Wrote SQL queries stored procedures and database triggers on the database objects Wrote SQL queries to extract data from archives using complex joins Developed various Java classes SQL queries and procedures to retrieve and manipulate the data from backend database using JDBC Analysis and Reporting of data using SSRS Enabled reporting access to the archives for reporting tools and created documentation Environment Net Cnet IIS ASP JavaScript SQL Server 2008R2 SQLServer SSRS Project Name Railway Stipulation System Java Developer Hyderabad Telangana May 2014 to May 2015 The objective of Railway Stipulation system is to empower the passenger to book tickets online It also enables them to book the tickets without getting into the queue at the comfort of their home It also enables them to swap the tickets with other passenger without cancelling the actual ticket Responsibilities Designed and coded GUI based application to facilitate the ticket booking Created an interface where the user can swap seats with another passenger online via request Used JDBC for database connectivity Designed the logical and physical data model generated DDL DML scripts Designed userinterface and used JavaScript to check validations Wrote SQL queries stored procedures and database triggers on the database objects Environment Java 8 JDBC Tomcat 70 HTML CSS JavaScript JSP SQL Server 2008R2 Education Masters Skills DATA ANALYSIS DATABASE SQL SERVER SQL SERVER 2008 SQL SERVER 2008 R2 Linux HTML Jquery XML Javascript TECHNICAL SKILLS Hadoop Ecosystem Cloud Platform Hadoop2X Spark14 MapReduce Hive21 Google Cloud Platform Dataproc Compute Impala12 Sqoop14 Flume17 Kafka12 Engine Bucket SQL Amazon Web Service Hbase10 Oozie30 Zookeeper34 EC2 S3 EMR Databricks Cloud Community Programming Language Operating Systems Java 8 C Scala21 Linux Ubuntu Mac OS CentOS Windows Web Development Database JavaScript jQuery AngularJS HTML CSS MySQL5X Oracle11g PostgreSQL9X Nodejs Netezza7X MongoDB32 HBase098 IDE Application Data Analysis Visualization NetBeans Eclipse Visual Studio Code Python R Tableau Matplotlib D3js IntelliJ Idea SQL Server 2008 R2 Scripting Language Machine Learning UNIX Shell HTML XML CSS JSP SQL Regression Decision Tree Random Forest Markdown KMeans Neural Networks SVM NLP Environment Collaboration Agile Scrum waterfall Git Microsoft TFS JIRA Jenkins 5 years CertificationsLicenses Drivers License",
    "unique_id": "ff031cd6-1a47-41f7-a660-818a712143a7"
}