{
    "clean_data": "Python Developer span lPythonspan span lDeveloperspan Python Developer Amazon New York NY Work Experience Python Developer Amazon Seattle WA July 2018 to Present Responsibilities Developed webbased applications using Python Django PHP AngularJs Reactjs XML CSS HTML JavaScript and jQuery Developed Consumerbased custom features and applications using Python Django and HTML Involved in building database Model APIs and Views utilizing python in order to build an interactive webbased solution and used Django Database APIs to access database objects Designed and Developed various Angular Components ngModule Services observablepromises Directives and Pipes via TypeScript Developed build and deployment scripts using ANT MAVEN as build tools in Jenkins to move from one environment to other environments Designed front end and backend of the application utilizing Python on Django Web Framework Automated builds using Maven and scheduled automated nightly builds using Heroku and Jenkins Built Jenkins pipeline to drive all microservices builds out to the Docker registry and then deployed to Kubernetes Build an ETL pipeline using Pentaho Spoon Spark Hadoop HDFS for customers with large data volume Worked on analyzing Hadoop stack and different big data analytic tools including Pig Hive HBase database and DynamoDB Implemented various screens for the front end using Reactjs and used various predefined components from NPM Node Package Manager and redux library Developed RDDsData Frames in Spark using Scala and Python and applied several transformation logics to load data from Hadoop Data Lake to Cassandra DB Used WebPack Babel and gulp for transpilationcompilation configuration for Typescript to be converted to JavaScript ETL process for continuously bulk importing catalog data from MySQL into Elastic search Experience in Implementation of MVC MVW architecture using Servlet Django and RESTful SOAP web service and SOAPUI Installed JenkinsPlugins for GIT Repository Setup SCM Polling for Immediate Build with Maven and Maven Repository and Deployment of apps using custom modules through Puppet as a CICD Process Configured and maintained Jenkins to implement the CI process and integrated the tool with ANT and Maven to schedule the builds Performed joins group by and other operations in MapReduce using Python Modified existing scala code to connect different system and database as well as proficient at using Spark APIs to explore cleanse aggregate transform and store machine sensor data Worked on Spark Scripts to find the most trending products daywise and weekwise using Scala and deployed third partys applications using various CI tools like Jenkins Involved in development of Web Services using and REST for sending and getting data from the external interface in XML and JSON format Implemented advanced procedures like text analytics and processing using the inmemory computing capabilities like Apache Spark Developed and Tested features of dashboard using CSS JavaScript Django and Bootstrap Launched Kubernetes to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts Expertise in JavaScript frameworks to replace frontend of a Flask application and began implementing a React solution Developed consumerbased features and applications using Python Django pyramid Flask Web2py HTML and other web technologies Designed and implemented a dedicated MySQL database server to drive the web apps and report on daily progress Involved in installing software using pip command for python libraries like Beautiful Soup NumPy SciPy pythontwitter RabbitMQ Celery matplotlib Pandas dataframe and used the PEP8 coding convention Implemented mapStateToProps mapDispatchToProps for the interactions between Redux and React Proficient in developing Apache ANT and Maven scripts to build J2EE enterprise applications Created web services using WTP tool plugin to the eclipse IDE which is deployed as a separate application using Maven scripts Developed views and templates with Python and Djangos view controller and templating language to create a userfriendly website interface Developed Kafka producer and consumers HBase clients Spark shark Streams and Hadoop MapReduce jobs along with components on HDFS Hive Installed configured and managed the ELK Elastic Search Log Facilitated Scrum ceremonies like Sprint planning retrospectives Daily standups etc Stash and Kibana for Log management within EC2 Elastic Load Balancer ELB for Elastic search Using JDK maven and STS IDE used for development and building the application Developed Terraform scripts for EC2 instances Elastic Load balancers and S3 buckets Designed datasets using Panda data frames and MySQL queried MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Implemented RESTful WebServices for sending and receiving the data between multiple systems Worked on Jenkins by installing configuring and maintaining for Continuous integration CI and for End to End automation for all build and deployments Implemented advanced procedures like text analytics and processing using the inmemory computing capabilities like Apache Spark written in Scala Launched Kubernetes to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts Developed Test Cases and Test Scripts in selenium web driver with Java using Cucumber framework with build management tool Maven Developed the notification service by posting the JSON request in AWS API Gateway AWS Glue Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS Implemented advanced procedures like text analytics and processing using the inmemory computing capabilities like Apache Spark written in Scala Connected applications to SignalRHub using Angular Typescript to provide real time charts for CPU Memory Ethernet and Disk usage Implemented REST APIs in Python using microframework like Flask with SQL Alchemy in the backend for management of data center resources on which OpenStack would be deployed Python Developer Early Warning San Francisco CA October 2015 to December 2017 Implemented responsive user interface and standards throughout the development and maintenance of the website using the HTML CSS JavaScript JQuery Developed the notification service by posting the JSON request in AWS API Gateway AWS Glue Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS Developed views and templates with Python and Djangos to create a userfriendly website interface Proficient in developing frontend with ReactRedux HTML JSX CSS SCSS Bootstrap TypeScript ES6 and Webpack Expertise in configuration management automation tools such as Chef Puppet and Salt Good coding experience with scripting languages like Perl Ruby and Bash Proficient with structures semistructured and unstructured data using a broad range of data science programming languages and big data tools including R Python Spark SQL Scikit Learn Hadoop Map Reduce Proficient in Routine Linux application testingupgrades new product evaluation and system impact analysis Supported Apache Server on Linux Platform Developed complex web middleware and back end systems in Python SQL for Linux and Windows Designed recognition models for both handwritten and textbased characters capable of continuous learning using deep neural networks leveraging keras Proficient working with Bot Frameworks IBM Watson Google Cloud PlatformTensor Flow or Amazon Web Services Sagemaker and open source Designed RESTful Webservices using FLASK with emphasis on improved Security for the service using FLASKHTTPAuth with HTTPS Built Elastic search Log stash and Kibana ELK to store logs and metrics into S3 bucket using Lambda function Implemented Single page Application using React Redux and Flux architectures Hosted GPU based Apache spark jobs using Scala for faster data processing and used spark SQL for querying Worked on analyzing Hadoop stack and different big data analytic tools including Pig Hive HBase database and DynamoDB Proficient in Reactjs framework to develop the SPA and working with React Flux and Redux architecture Implemented various screens for the front end using Reactjs and used various predefined components from NPM Node Package Manager and redux library Involved in converting HiveSQL queries into Spark transformations using Spark RDDs Python and Scala as well as used Scala to convert HiveSQL queries into RDD transformations in Apache Spark Worked on migrating MapReduce programs into Spark transformations using Scala Responsible for building scalable distributed data solutions using Hadoop Developed SonarQube for code quality check and Nexus repository and integrated them into Jenkins to achieve Continuous Integration Development of Python APIs to dump the array structures in the Processor at the failure point for debugging Involved in analysis specification design and implementation and testing phases of Software Development Life Cycle SDLC and used agile methodology for developing application Developed a fully automated continuous integration system using Git Jenkins MySQL and custom tools developed in Python and Bash Implemented Multithreading module and complex networking operations like race route SMTP mail server and web server Using Python Automated RabbitMQ cluster installations and configuration using PythonBash Created Terraform scripts for EC2 instances Elastic Load balancers and S3 buckets Implemented Terraform to manage the AWS infrastructure and managed servers using configuration management tools like Chef and Ansible Recording of Scripts Web Services HTML using Vugen and SoapUI and script validation through co correlations parameterizations and other methods Used GO Lang scripts for uploading a file to S3 and deploying them and creating GO serverless application and deploying it to AWS lambda Worked with RDBMS like Oracle 11g10i and MySQL databases to query and read data Developed various Python scripts to find vulnerabilities with SQL Queries by doing SQL injection permission checks and performance analysis Installed and configured configuration tool such as Chef Serverworkstation and nodes via CLI tools to AWS nodes Deployed Python scripts with Cloud Formation templates to automate installation of Auto scaling EC2 VPC DynamoDB cloud formation Beautiful soup and other services Used Spark API over Hortonworks Hadoop YARN to perform analytics on data in Hive Performed Unit testing Integration Testing GUI testing using Pytest and web application testing using Selenium Python bindings Proficient in specialization areas related to Chef for Cloud Automation Automated the cloud deployments using chef Python boot fabric and AWS Cloud Formation Templates Placed data into JSON files using Python to test Django websites and used Python scripts to update the content in database and manipulate files Built development environment with Kubernetes and Docker in AWS using JupyterHub Helped maintain existing Python Django and Flask applications Interfaced with infrastructure services like Amazon AWS S3 SQS and used tools like Sold RabbitMQ Python Developer Amdocs INDIA August 2013 to September 2015 Created Python and Bash tools to increase efficiency of application system and operations data conversion scripts AMQPRabbitMQ REST JSON and CRUD scripts for API Integration Used Go Lang to create backend servers Developed Micro services using Go language and developed corresponding test cases Developed and Deployed the Application on WebSphere using ANT buildxml script Build Web pages that are more userinteractive using AJAX JavaScript and ReactJS Redux Designed JQuery libraries for all clientside JavaScript manipulations as well as used maven for building creating JPA based entity objects and compiling GWT and GXT application Experience in designing and developing applications in Spark using Scala Expertise in developing API services in PythonTornado NodeJS while leveraging AMQP and RabbitMQ for distributed architectures Application of various learning algorithms and statistical modeling like decision trees text analytics natural language processing NLP supervised and unsupervised regression models social network analysis neural networks deep learning SVM clustering to identify Volume using scikitlearn package in python Matlab Implemented various screens for the front end using Reactjs and used various predefined components from NPM Node Package Manager and redux library Automated builds using Maven and scheduled automated nightly builds using Jenkins Built Jenkins pipeline to drive all microservices builds out to the Docker registry and then deployed to Kubernetes Automated RabbitMQ cluster installations and configuration using PythonBash Used Test driven approach TDD for developing services required for the application and Implemented Integration test cases and Developing predictive analytic using Apache Spark Scala APIs Used Pandas as API to put the data as time series and tabular format for manipulation and retrieval of data Proficient working with Redis RabbitMQ for task queues and Celery to manage Asynchronous tasks Created RDDs performed analysis and ran queries in Python and Apache Spark based on retrospective and groups Executed Terraform to manage the AWS infrastructure and managed servers using configuration management tools like Chef and Anisole Managed worldwide data in Omniture for data collection and analysis and also worked on the library like pandas NumPy SciPy Docker Wrote with objectoriented Python AWSFlask SQL Beautiful Soup httplib2 Jinja2 HTMLCSS Bootstrap jQuery Linux Sublime Text GIT Worked on Python OpenStack APIs and used Numpy for Numerical analysis Proficient in Container management using Docker by writing Docker files and set up the automated build on Docker HUB and installing and configuring Kubernetes Carried out various mathematical operations for calculation purpose using python pandas libraries Uses Edward is a Python library for probabilistic modeling inference and criticism It is a testbed for fast experimentation and research with probabilistic models Designed and implemented open source AI frameworks Pytorch TensorFlow Scikitlearn Apache Open Source Kafka Storm Spark for NLP and ML Algorithms Developed serverbased web traffic statistical analysis tool using Flask Pandas Utilized Python libraries like NumPy and matplotlib for generating graphical reports Worked on the development of SQL and stored procedures for normalization and denormalization in MYSQL Developed the notification service by posting the request in AWS API Gateway Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS Worked with redux saga along with redux thunk to handle asynchronous calls efficiently Configured Spark streaming to receive real time data from Kafka and store the stream data to HDFS for persistence and Hive for real time reporting Implemented the application in LINUX environment and comfortable with all its commands Executed MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Education Masters Skills Git MYSQL Javascript PHP CSS",
    "entities": [
        "Hosted",
        "Bash Implemented Multithreading",
        "Implementation of MVC MVW",
        "Hortonworks Hadoop",
        "Chef and Anisole Managed",
        "Pentaho Spoon Spark Hadoop HDFS",
        "ReactRedux",
        "Bash Proficient",
        "REST JSON",
        "JSON",
        "GIT Repository Setup",
        "OpenStack",
        "Designed RESTful Webservices",
        "FLASKHTTPAuth",
        "Heroku",
        "Panda",
        "Kubernetes Build",
        "Amazon Web Services Sagemaker",
        "RDD",
        "Hadoop",
        "XML",
        "Flask Pandas Utilized Python",
        "Scala Responsible",
        "Software Development Life Cycle SDLC",
        "Chef Serverworkstation",
        "JSX CSS",
        "Kubernetes Automated",
        "Implemented Terraform",
        "HBase",
        "Reactjs",
        "API Integration Used Go Lang",
        "Automated",
        "Apache Spark",
        "Maven Repository and Deployment",
        "Routine Linux",
        "ELK",
        "Python",
        "Salt Good",
        "Jenkins",
        "Bash",
        "Developed and Deployed the Application on WebSphere",
        "Created Python",
        "Jenkins Involved",
        "San Francisco",
        "Puppet",
        "Hadoop MapReduce",
        "Oracle 11g10i",
        "Present Responsibilities Developed",
        "GXT",
        "Hadoop Data Lake",
        "Angular Components ngModule Services",
        "Linux",
        "jQuery Developed Consumerbased",
        "Perl Ruby",
        "Maven Developed",
        "Flask",
        "Hadoop Developed SonarQube",
        "SQL Queries",
        "Jenkins Built Jenkins",
        "Bot Frameworks IBM",
        "SVM",
        "Docker",
        "AJAX JavaScript",
        "Nexus",
        "PEP8",
        "Views",
        "CLI",
        "STS",
        "Python Developer Early Warning",
        "Spark",
        "Chef Puppet",
        "Redux",
        "Pytorch TensorFlow Scikitlearn Apache Open",
        "HTML CSS",
        "PythonBash Created Terraform",
        "API",
        "WTP",
        "Developed Terraform",
        "LINUX",
        "Created",
        "AI",
        "AWS",
        "Developed Micro",
        "Stash",
        "Developed Test Cases",
        "SQL",
        "Hive Performed Unit",
        "React Flux",
        "NLP",
        "lPythonspan",
        "Kubernetes",
        "GPU",
        "FLASK",
        "Amazon AWS S3 SQS",
        "SQL Alchemy",
        "AWS SNS Implemented",
        "CI",
        "Integration Testing GUI",
        "Typescript",
        "CPU Memory Ethernet and Disk",
        "JupyterHub",
        "Chef for Cloud Automation Automated",
        "Python AWSFlask SQL Beautiful Soup httplib2 Jinja2",
        "Pandas",
        "Omniture",
        "NPM Node Package",
        "ETL",
        "CRUD",
        "Flux",
        "Maven",
        "Performed",
        "GWT",
        "Djangos",
        "JavaScript",
        "ANT",
        "Spark shark Streams",
        "SMTP",
        "Executed Terraform",
        "CSS",
        "Implemented Integration",
        "SPA",
        "REST",
        "Implemented Single page Application",
        "MapReduce",
        "TDD",
        "Selenium Python",
        "Directives and Pipes",
        "Kubernetes Carried",
        "Sprint",
        "JQuery",
        "PythonTornado",
        "Implemented RESTful WebServices"
    ],
    "experience": "Experience Python Developer Amazon Seattle WA July 2018 to Present Responsibilities Developed webbased applications using Python Django PHP AngularJs Reactjs XML CSS HTML JavaScript and jQuery Developed Consumerbased custom features and applications using Python Django and HTML Involved in building database Model APIs and Views utilizing python in order to build an interactive webbased solution and used Django Database APIs to access database objects Designed and Developed various Angular Components ngModule Services observablepromises Directives and Pipes via TypeScript Developed build and deployment scripts using ANT MAVEN as build tools in Jenkins to move from one environment to other environments Designed front end and backend of the application utilizing Python on Django Web Framework Automated builds using Maven and scheduled automated nightly builds using Heroku and Jenkins Built Jenkins pipeline to drive all microservices builds out to the Docker registry and then deployed to Kubernetes Build an ETL pipeline using Pentaho Spoon Spark Hadoop HDFS for customers with large data volume Worked on analyzing Hadoop stack and different big data analytic tools including Pig Hive HBase database and DynamoDB Implemented various screens for the front end using Reactjs and used various predefined components from NPM Node Package Manager and redux library Developed RDDsData Frames in Spark using Scala and Python and applied several transformation logics to load data from Hadoop Data Lake to Cassandra DB Used WebPack Babel and gulp for transpilationcompilation configuration for Typescript to be converted to JavaScript ETL process for continuously bulk importing catalog data from MySQL into Elastic search Experience in Implementation of MVC MVW architecture using Servlet Django and RESTful SOAP web service and SOAPUI Installed JenkinsPlugins for GIT Repository Setup SCM Polling for Immediate Build with Maven and Maven Repository and Deployment of apps using custom modules through Puppet as a CICD Process Configured and maintained Jenkins to implement the CI process and integrated the tool with ANT and Maven to schedule the builds Performed joins group by and other operations in MapReduce using Python Modified existing scala code to connect different system and database as well as proficient at using Spark APIs to explore cleanse aggregate transform and store machine sensor data Worked on Spark Scripts to find the most trending products daywise and weekwise using Scala and deployed third partys applications using various CI tools like Jenkins Involved in development of Web Services using and REST for sending and getting data from the external interface in XML and JSON format Implemented advanced procedures like text analytics and processing using the inmemory computing capabilities like Apache Spark Developed and Tested features of dashboard using CSS JavaScript Django and Bootstrap Launched Kubernetes to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts Expertise in JavaScript frameworks to replace frontend of a Flask application and began implementing a React solution Developed consumerbased features and applications using Python Django pyramid Flask Web2py HTML and other web technologies Designed and implemented a dedicated MySQL database server to drive the web apps and report on daily progress Involved in installing software using pip command for python libraries like Beautiful Soup NumPy SciPy pythontwitter RabbitMQ Celery matplotlib Pandas dataframe and used the PEP8 coding convention Implemented mapStateToProps mapDispatchToProps for the interactions between Redux and React Proficient in developing Apache ANT and Maven scripts to build J2EE enterprise applications Created web services using WTP tool plugin to the eclipse IDE which is deployed as a separate application using Maven scripts Developed views and templates with Python and Djangos view controller and templating language to create a userfriendly website interface Developed Kafka producer and consumers HBase clients Spark shark Streams and Hadoop MapReduce jobs along with components on HDFS Hive Installed configured and managed the ELK Elastic Search Log Facilitated Scrum ceremonies like Sprint planning retrospectives Daily standups etc Stash and Kibana for Log management within EC2 Elastic Load Balancer ELB for Elastic search Using JDK maven and STS IDE used for development and building the application Developed Terraform scripts for EC2 instances Elastic Load balancers and S3 buckets Designed datasets using Panda data frames and MySQL queried MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Implemented RESTful WebServices for sending and receiving the data between multiple systems Worked on Jenkins by installing configuring and maintaining for Continuous integration CI and for End to End automation for all build and deployments Implemented advanced procedures like text analytics and processing using the inmemory computing capabilities like Apache Spark written in Scala Launched Kubernetes to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts Developed Test Cases and Test Scripts in selenium web driver with Java using Cucumber framework with build management tool Maven Developed the notification service by posting the JSON request in AWS API Gateway AWS Glue Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS Implemented advanced procedures like text analytics and processing using the inmemory computing capabilities like Apache Spark written in Scala Connected applications to SignalRHub using Angular Typescript to provide real time charts for CPU Memory Ethernet and Disk usage Implemented REST APIs in Python using microframework like Flask with SQL Alchemy in the backend for management of data center resources on which OpenStack would be deployed Python Developer Early Warning San Francisco CA October 2015 to December 2017 Implemented responsive user interface and standards throughout the development and maintenance of the website using the HTML CSS JavaScript JQuery Developed the notification service by posting the JSON request in AWS API Gateway AWS Glue Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS Developed views and templates with Python and Djangos to create a userfriendly website interface Proficient in developing frontend with ReactRedux HTML JSX CSS SCSS Bootstrap TypeScript ES6 and Webpack Expertise in configuration management automation tools such as Chef Puppet and Salt Good coding experience with scripting languages like Perl Ruby and Bash Proficient with structures semistructured and unstructured data using a broad range of data science programming languages and big data tools including R Python Spark SQL Scikit Learn Hadoop Map Reduce Proficient in Routine Linux application testingupgrades new product evaluation and system impact analysis Supported Apache Server on Linux Platform Developed complex web middleware and back end systems in Python SQL for Linux and Windows Designed recognition models for both handwritten and textbased characters capable of continuous learning using deep neural networks leveraging keras Proficient working with Bot Frameworks IBM Watson Google Cloud PlatformTensor Flow or Amazon Web Services Sagemaker and open source Designed RESTful Webservices using FLASK with emphasis on improved Security for the service using FLASKHTTPAuth with HTTPS Built Elastic search Log stash and Kibana ELK to store logs and metrics into S3 bucket using Lambda function Implemented Single page Application using React Redux and Flux architectures Hosted GPU based Apache spark jobs using Scala for faster data processing and used spark SQL for querying Worked on analyzing Hadoop stack and different big data analytic tools including Pig Hive HBase database and DynamoDB Proficient in Reactjs framework to develop the SPA and working with React Flux and Redux architecture Implemented various screens for the front end using Reactjs and used various predefined components from NPM Node Package Manager and redux library Involved in converting HiveSQL queries into Spark transformations using Spark RDDs Python and Scala as well as used Scala to convert HiveSQL queries into RDD transformations in Apache Spark Worked on migrating MapReduce programs into Spark transformations using Scala Responsible for building scalable distributed data solutions using Hadoop Developed SonarQube for code quality check and Nexus repository and integrated them into Jenkins to achieve Continuous Integration Development of Python APIs to dump the array structures in the Processor at the failure point for debugging Involved in analysis specification design and implementation and testing phases of Software Development Life Cycle SDLC and used agile methodology for developing application Developed a fully automated continuous integration system using Git Jenkins MySQL and custom tools developed in Python and Bash Implemented Multithreading module and complex networking operations like race route SMTP mail server and web server Using Python Automated RabbitMQ cluster installations and configuration using PythonBash Created Terraform scripts for EC2 instances Elastic Load balancers and S3 buckets Implemented Terraform to manage the AWS infrastructure and managed servers using configuration management tools like Chef and Ansible Recording of Scripts Web Services HTML using Vugen and SoapUI and script validation through co correlations parameterizations and other methods Used GO Lang scripts for uploading a file to S3 and deploying them and creating GO serverless application and deploying it to AWS lambda Worked with RDBMS like Oracle 11g10i and MySQL databases to query and read data Developed various Python scripts to find vulnerabilities with SQL Queries by doing SQL injection permission checks and performance analysis Installed and configured configuration tool such as Chef Serverworkstation and nodes via CLI tools to AWS nodes Deployed Python scripts with Cloud Formation templates to automate installation of Auto scaling EC2 VPC DynamoDB cloud formation Beautiful soup and other services Used Spark API over Hortonworks Hadoop YARN to perform analytics on data in Hive Performed Unit testing Integration Testing GUI testing using Pytest and web application testing using Selenium Python bindings Proficient in specialization areas related to Chef for Cloud Automation Automated the cloud deployments using chef Python boot fabric and AWS Cloud Formation Templates Placed data into JSON files using Python to test Django websites and used Python scripts to update the content in database and manipulate files Built development environment with Kubernetes and Docker in AWS using JupyterHub Helped maintain existing Python Django and Flask applications Interfaced with infrastructure services like Amazon AWS S3 SQS and used tools like Sold RabbitMQ Python Developer Amdocs INDIA August 2013 to September 2015 Created Python and Bash tools to increase efficiency of application system and operations data conversion scripts AMQPRabbitMQ REST JSON and CRUD scripts for API Integration Used Go Lang to create backend servers Developed Micro services using Go language and developed corresponding test cases Developed and Deployed the Application on WebSphere using ANT buildxml script Build Web pages that are more userinteractive using AJAX JavaScript and ReactJS Redux Designed JQuery libraries for all clientside JavaScript manipulations as well as used maven for building creating JPA based entity objects and compiling GWT and GXT application Experience in designing and developing applications in Spark using Scala Expertise in developing API services in PythonTornado NodeJS while leveraging AMQP and RabbitMQ for distributed architectures Application of various learning algorithms and statistical modeling like decision trees text analytics natural language processing NLP supervised and unsupervised regression models social network analysis neural networks deep learning SVM clustering to identify Volume using scikitlearn package in python Matlab Implemented various screens for the front end using Reactjs and used various predefined components from NPM Node Package Manager and redux library Automated builds using Maven and scheduled automated nightly builds using Jenkins Built Jenkins pipeline to drive all microservices builds out to the Docker registry and then deployed to Kubernetes Automated RabbitMQ cluster installations and configuration using PythonBash Used Test driven approach TDD for developing services required for the application and Implemented Integration test cases and Developing predictive analytic using Apache Spark Scala APIs Used Pandas as API to put the data as time series and tabular format for manipulation and retrieval of data Proficient working with Redis RabbitMQ for task queues and Celery to manage Asynchronous tasks Created RDDs performed analysis and ran queries in Python and Apache Spark based on retrospective and groups Executed Terraform to manage the AWS infrastructure and managed servers using configuration management tools like Chef and Anisole Managed worldwide data in Omniture for data collection and analysis and also worked on the library like pandas NumPy SciPy Docker Wrote with objectoriented Python AWSFlask SQL Beautiful Soup httplib2 Jinja2 HTMLCSS Bootstrap jQuery Linux Sublime Text GIT Worked on Python OpenStack APIs and used Numpy for Numerical analysis Proficient in Container management using Docker by writing Docker files and set up the automated build on Docker HUB and installing and configuring Kubernetes Carried out various mathematical operations for calculation purpose using python pandas libraries Uses Edward is a Python library for probabilistic modeling inference and criticism It is a testbed for fast experimentation and research with probabilistic models Designed and implemented open source AI frameworks Pytorch TensorFlow Scikitlearn Apache Open Source Kafka Storm Spark for NLP and ML Algorithms Developed serverbased web traffic statistical analysis tool using Flask Pandas Utilized Python libraries like NumPy and matplotlib for generating graphical reports Worked on the development of SQL and stored procedures for normalization and denormalization in MYSQL Developed the notification service by posting the request in AWS API Gateway Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS Worked with redux saga along with redux thunk to handle asynchronous calls efficiently Configured Spark streaming to receive real time data from Kafka and store the stream data to HDFS for persistence and Hive for real time reporting Implemented the application in LINUX environment and comfortable with all its commands Executed MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Education Masters Skills Git MYSQL Javascript PHP CSS",
    "extracted_keywords": [
        "Python",
        "Developer",
        "lPythonspan",
        "span",
        "lDeveloperspan",
        "Python",
        "Developer",
        "Amazon",
        "New",
        "York",
        "NY",
        "Work",
        "Experience",
        "Python",
        "Developer",
        "Amazon",
        "Seattle",
        "WA",
        "July",
        "Present",
        "Responsibilities",
        "applications",
        "Python",
        "Django",
        "PHP",
        "AngularJs",
        "Reactjs",
        "XML",
        "CSS",
        "HTML",
        "JavaScript",
        "jQuery",
        "Developed",
        "Consumerbased",
        "custom",
        "features",
        "applications",
        "Python",
        "Django",
        "HTML",
        "database",
        "Model",
        "APIs",
        "Views",
        "python",
        "order",
        "solution",
        "Django",
        "Database",
        "APIs",
        "database",
        "Angular",
        "Components",
        "ngModule",
        "Services",
        "Directives",
        "Pipes",
        "TypeScript",
        "build",
        "deployment",
        "scripts",
        "ANT",
        "MAVEN",
        "build",
        "tools",
        "Jenkins",
        "environment",
        "environments",
        "end",
        "backend",
        "application",
        "Python",
        "Django",
        "Web",
        "Framework",
        "Automated",
        "builds",
        "Maven",
        "builds",
        "Heroku",
        "Jenkins",
        "Jenkins",
        "pipeline",
        "microservices",
        "Docker",
        "registry",
        "Kubernetes",
        "ETL",
        "pipeline",
        "Pentaho",
        "Spoon",
        "Spark",
        "Hadoop",
        "HDFS",
        "customers",
        "data",
        "volume",
        "Hadoop",
        "stack",
        "data",
        "tools",
        "Pig",
        "Hive",
        "HBase",
        "database",
        "screens",
        "end",
        "Reactjs",
        "components",
        "NPM",
        "Node",
        "Package",
        "Manager",
        "redux",
        "library",
        "RDDsData",
        "Frames",
        "Spark",
        "Scala",
        "Python",
        "transformation",
        "logics",
        "data",
        "Hadoop",
        "Data",
        "Lake",
        "Cassandra",
        "DB",
        "WebPack",
        "Babel",
        "gulp",
        "transpilationcompilation",
        "configuration",
        "Typescript",
        "JavaScript",
        "ETL",
        "process",
        "bulk",
        "catalog",
        "data",
        "MySQL",
        "search",
        "Experience",
        "Implementation",
        "MVC",
        "MVW",
        "architecture",
        "Servlet",
        "Django",
        "SOAP",
        "web",
        "service",
        "SOAPUI",
        "Installed",
        "JenkinsPlugins",
        "GIT",
        "Repository",
        "Setup",
        "SCM",
        "Polling",
        "Immediate",
        "Build",
        "Maven",
        "Maven",
        "Repository",
        "Deployment",
        "apps",
        "custom",
        "modules",
        "Puppet",
        "CICD",
        "Process",
        "Configured",
        "Jenkins",
        "CI",
        "process",
        "tool",
        "ANT",
        "Maven",
        "builds",
        "Performed",
        "group",
        "operations",
        "MapReduce",
        "Python",
        "Modified",
        "scala",
        "code",
        "system",
        "database",
        "Spark",
        "APIs",
        "cleanse",
        "aggregate",
        "transform",
        "store",
        "machine",
        "sensor",
        "data",
        "Spark",
        "Scripts",
        "products",
        "daywise",
        "weekwise",
        "Scala",
        "applications",
        "CI",
        "tools",
        "Jenkins",
        "development",
        "Web",
        "Services",
        "REST",
        "data",
        "interface",
        "XML",
        "format",
        "procedures",
        "text",
        "analytics",
        "processing",
        "inmemory",
        "computing",
        "capabilities",
        "Apache",
        "Spark",
        "Developed",
        "features",
        "dashboard",
        "CSS",
        "JavaScript",
        "Django",
        "Bootstrap",
        "Kubernetes",
        "platform",
        "deployment",
        "scaling",
        "operations",
        "application",
        "containers",
        "clusters",
        "hosts",
        "Expertise",
        "JavaScript",
        "frameworks",
        "frontend",
        "Flask",
        "application",
        "React",
        "solution",
        "features",
        "applications",
        "Python",
        "Django",
        "Flask",
        "Web2py",
        "HTML",
        "web",
        "technologies",
        "MySQL",
        "database",
        "server",
        "web",
        "apps",
        "report",
        "progress",
        "software",
        "pip",
        "command",
        "python",
        "libraries",
        "Beautiful",
        "Soup",
        "NumPy",
        "SciPy",
        "pythontwitter",
        "Celery",
        "matplotlib",
        "Pandas",
        "dataframe",
        "PEP8",
        "convention",
        "mapStateToProps",
        "mapDispatchToProps",
        "interactions",
        "Redux",
        "React",
        "Proficient",
        "Apache",
        "ANT",
        "Maven",
        "scripts",
        "J2EE",
        "enterprise",
        "applications",
        "web",
        "services",
        "WTP",
        "tool",
        "eclipse",
        "IDE",
        "application",
        "Maven",
        "scripts",
        "views",
        "templates",
        "Python",
        "Djangos",
        "controller",
        "templating",
        "language",
        "website",
        "interface",
        "Developed",
        "Kafka",
        "producer",
        "consumers",
        "HBase",
        "Spark",
        "shark",
        "Streams",
        "Hadoop",
        "MapReduce",
        "jobs",
        "components",
        "HDFS",
        "Hive",
        "Installed",
        "ELK",
        "Elastic",
        "Search",
        "Log",
        "Facilitated",
        "Scrum",
        "ceremonies",
        "Sprint",
        "planning",
        "Daily",
        "standups",
        "Stash",
        "Kibana",
        "Log",
        "management",
        "EC2",
        "Elastic",
        "Load",
        "Balancer",
        "ELB",
        "search",
        "JDK",
        "maven",
        "STS",
        "IDE",
        "development",
        "application",
        "Terraform",
        "scripts",
        "EC2",
        "instances",
        "Elastic",
        "Load",
        "balancers",
        "S3",
        "buckets",
        "datasets",
        "Panda",
        "data",
        "frames",
        "MySQL",
        "MYSQL",
        "database",
        "python",
        "PythonMySQL",
        "connector",
        "MySQL",
        "package",
        "information",
        "WebServices",
        "data",
        "systems",
        "Jenkins",
        "configuring",
        "integration",
        "CI",
        "End",
        "End",
        "automation",
        "build",
        "deployments",
        "procedures",
        "text",
        "analytics",
        "processing",
        "inmemory",
        "computing",
        "capabilities",
        "Apache",
        "Spark",
        "Scala",
        "Kubernetes",
        "platform",
        "deployment",
        "scaling",
        "operations",
        "application",
        "containers",
        "clusters",
        "hosts",
        "Test",
        "Cases",
        "Test",
        "Scripts",
        "selenium",
        "web",
        "driver",
        "Java",
        "Cucumber",
        "framework",
        "build",
        "management",
        "tool",
        "Maven",
        "notification",
        "service",
        "request",
        "AWS",
        "API",
        "Gateway",
        "AWS",
        "Glue",
        "response",
        "Lambda",
        "data",
        "DynamoDB",
        "notification",
        "AWS",
        "SNS",
        "procedures",
        "text",
        "analytics",
        "processing",
        "inmemory",
        "computing",
        "capabilities",
        "Apache",
        "Spark",
        "Scala",
        "Connected",
        "applications",
        "Angular",
        "Typescript",
        "time",
        "charts",
        "CPU",
        "Memory",
        "Ethernet",
        "Disk",
        "usage",
        "REST",
        "APIs",
        "Python",
        "microframework",
        "Flask",
        "SQL",
        "Alchemy",
        "backend",
        "management",
        "data",
        "center",
        "resources",
        "OpenStack",
        "Python",
        "Developer",
        "Warning",
        "San",
        "Francisco",
        "CA",
        "October",
        "December",
        "user",
        "interface",
        "standards",
        "development",
        "maintenance",
        "website",
        "HTML",
        "CSS",
        "JavaScript",
        "JQuery",
        "notification",
        "service",
        "request",
        "AWS",
        "API",
        "Gateway",
        "AWS",
        "Glue",
        "response",
        "Lambda",
        "data",
        "DynamoDB",
        "notification",
        "AWS",
        "SNS",
        "views",
        "templates",
        "Python",
        "Djangos",
        "website",
        "interface",
        "Proficient",
        "frontend",
        "ReactRedux",
        "HTML",
        "JSX",
        "CSS",
        "SCSS",
        "Bootstrap",
        "TypeScript",
        "ES6",
        "Webpack",
        "Expertise",
        "configuration",
        "management",
        "automation",
        "tools",
        "Chef",
        "Puppet",
        "Salt",
        "Good",
        "experience",
        "scripting",
        "languages",
        "Perl",
        "Ruby",
        "Bash",
        "Proficient",
        "structures",
        "data",
        "range",
        "data",
        "science",
        "programming",
        "languages",
        "data",
        "tools",
        "R",
        "Python",
        "Spark",
        "SQL",
        "Scikit",
        "Learn",
        "Hadoop",
        "Map",
        "Proficient",
        "Routine",
        "Linux",
        "application",
        "product",
        "evaluation",
        "system",
        "impact",
        "analysis",
        "Apache",
        "Server",
        "Linux",
        "Platform",
        "web",
        "middleware",
        "end",
        "systems",
        "Python",
        "SQL",
        "Linux",
        "Windows",
        "recognition",
        "models",
        "characters",
        "learning",
        "networks",
        "keras",
        "Proficient",
        "Bot",
        "Frameworks",
        "IBM",
        "Watson",
        "Google",
        "Cloud",
        "PlatformTensor",
        "Flow",
        "Amazon",
        "Web",
        "Services",
        "Sagemaker",
        "source",
        "RESTful",
        "Webservices",
        "FLASK",
        "emphasis",
        "Security",
        "service",
        "FLASKHTTPAuth",
        "HTTPS",
        "search",
        "stash",
        "Kibana",
        "ELK",
        "logs",
        "metrics",
        "S3",
        "bucket",
        "Lambda",
        "function",
        "page",
        "Application",
        "React",
        "Redux",
        "Flux",
        "Hosted",
        "GPU",
        "Apache",
        "spark",
        "jobs",
        "Scala",
        "data",
        "processing",
        "spark",
        "SQL",
        "Worked",
        "Hadoop",
        "stack",
        "data",
        "tools",
        "Pig",
        "Hive",
        "HBase",
        "database",
        "DynamoDB",
        "Proficient",
        "Reactjs",
        "framework",
        "SPA",
        "React",
        "Flux",
        "Redux",
        "architecture",
        "screens",
        "end",
        "Reactjs",
        "components",
        "NPM",
        "Node",
        "Package",
        "Manager",
        "redux",
        "library",
        "HiveSQL",
        "queries",
        "Spark",
        "transformations",
        "Spark",
        "RDDs",
        "Python",
        "Scala",
        "Scala",
        "HiveSQL",
        "queries",
        "RDD",
        "transformations",
        "Apache",
        "Spark",
        "MapReduce",
        "programs",
        "Spark",
        "transformations",
        "Scala",
        "Responsible",
        "data",
        "solutions",
        "Hadoop",
        "Developed",
        "SonarQube",
        "code",
        "quality",
        "check",
        "Nexus",
        "repository",
        "Jenkins",
        "Continuous",
        "Integration",
        "Development",
        "Python",
        "APIs",
        "array",
        "structures",
        "Processor",
        "failure",
        "point",
        "analysis",
        "specification",
        "design",
        "implementation",
        "phases",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "SDLC",
        "methodology",
        "application",
        "integration",
        "system",
        "Git",
        "Jenkins",
        "MySQL",
        "custom",
        "tools",
        "Python",
        "Bash",
        "Multithreading",
        "module",
        "networking",
        "operations",
        "race",
        "route",
        "SMTP",
        "mail",
        "server",
        "web",
        "server",
        "Python",
        "Automated",
        "RabbitMQ",
        "cluster",
        "installations",
        "configuration",
        "PythonBash",
        "Created",
        "Terraform",
        "scripts",
        "EC2",
        "instances",
        "Elastic",
        "Load",
        "balancers",
        "S3",
        "buckets",
        "Terraform",
        "AWS",
        "infrastructure",
        "servers",
        "configuration",
        "management",
        "tools",
        "Chef",
        "Ansible",
        "Recording",
        "Scripts",
        "Web",
        "Services",
        "HTML",
        "Vugen",
        "SoapUI",
        "script",
        "validation",
        "co",
        "correlations",
        "parameterizations",
        "methods",
        "GO",
        "Lang",
        "scripts",
        "file",
        "S3",
        "GO",
        "serverless",
        "application",
        "AWS",
        "lambda",
        "RDBMS",
        "Oracle",
        "11g10i",
        "MySQL",
        "data",
        "Python",
        "scripts",
        "vulnerabilities",
        "SQL",
        "Queries",
        "SQL",
        "injection",
        "permission",
        "checks",
        "performance",
        "analysis",
        "configuration",
        "tool",
        "Chef",
        "Serverworkstation",
        "nodes",
        "CLI",
        "tools",
        "AWS",
        "nodes",
        "Python",
        "scripts",
        "Cloud",
        "Formation",
        "installation",
        "Auto",
        "EC2",
        "VPC",
        "DynamoDB",
        "cloud",
        "Beautiful",
        "soup",
        "services",
        "Spark",
        "API",
        "Hortonworks",
        "Hadoop",
        "YARN",
        "analytics",
        "data",
        "Hive",
        "Performed",
        "Unit",
        "testing",
        "Integration",
        "Testing",
        "GUI",
        "testing",
        "Pytest",
        "web",
        "application",
        "testing",
        "Selenium",
        "Python",
        "bindings",
        "Proficient",
        "specialization",
        "areas",
        "Chef",
        "Cloud",
        "Automation",
        "cloud",
        "deployments",
        "chef",
        "Python",
        "boot",
        "fabric",
        "AWS",
        "Cloud",
        "Formation",
        "Templates",
        "data",
        "files",
        "Python",
        "Django",
        "websites",
        "Python",
        "scripts",
        "content",
        "database",
        "manipulate",
        "files",
        "development",
        "environment",
        "Kubernetes",
        "Docker",
        "AWS",
        "JupyterHub",
        "Python",
        "Django",
        "Flask",
        "applications",
        "infrastructure",
        "services",
        "Amazon",
        "AWS",
        "S3",
        "SQS",
        "tools",
        "Python",
        "Developer",
        "Amdocs",
        "INDIA",
        "August",
        "September",
        "Created",
        "Python",
        "Bash",
        "tools",
        "efficiency",
        "application",
        "system",
        "operations",
        "data",
        "conversion",
        "scripts",
        "AMQPRabbitMQ",
        "REST",
        "JSON",
        "CRUD",
        "scripts",
        "API",
        "Integration",
        "Go",
        "Lang",
        "servers",
        "Developed",
        "Micro",
        "services",
        "Go",
        "language",
        "test",
        "cases",
        "Application",
        "WebSphere",
        "ANT",
        "buildxml",
        "script",
        "Build",
        "Web",
        "pages",
        "AJAX",
        "JavaScript",
        "ReactJS",
        "Redux",
        "Designed",
        "JQuery",
        "JavaScript",
        "manipulations",
        "maven",
        "JPA",
        "entity",
        "GWT",
        "GXT",
        "application",
        "Experience",
        "applications",
        "Spark",
        "Scala",
        "Expertise",
        "API",
        "services",
        "PythonTornado",
        "NodeJS",
        "AMQP",
        "architectures",
        "Application",
        "learning",
        "algorithms",
        "modeling",
        "decision",
        "trees",
        "text",
        "analytics",
        "language",
        "processing",
        "NLP",
        "regression",
        "models",
        "network",
        "analysis",
        "networks",
        "SVM",
        "Volume",
        "package",
        "python",
        "Matlab",
        "screens",
        "end",
        "Reactjs",
        "components",
        "NPM",
        "Node",
        "Package",
        "Manager",
        "redux",
        "library",
        "Automated",
        "Maven",
        "builds",
        "Jenkins",
        "Built",
        "Jenkins",
        "pipeline",
        "microservices",
        "Docker",
        "registry",
        "Kubernetes",
        "Automated",
        "RabbitMQ",
        "cluster",
        "installations",
        "configuration",
        "PythonBash",
        "Used",
        "Test",
        "approach",
        "TDD",
        "services",
        "application",
        "Implemented",
        "Integration",
        "test",
        "cases",
        "analytic",
        "Apache",
        "Spark",
        "Scala",
        "APIs",
        "Pandas",
        "API",
        "data",
        "time",
        "series",
        "format",
        "manipulation",
        "retrieval",
        "data",
        "Proficient",
        "Redis",
        "RabbitMQ",
        "task",
        "queues",
        "Celery",
        "tasks",
        "RDDs",
        "analysis",
        "queries",
        "Python",
        "Apache",
        "Spark",
        "groups",
        "Terraform",
        "AWS",
        "infrastructure",
        "servers",
        "configuration",
        "management",
        "tools",
        "Chef",
        "Anisole",
        "Managed",
        "data",
        "Omniture",
        "data",
        "collection",
        "analysis",
        "library",
        "NumPy",
        "SciPy",
        "Docker",
        "Python",
        "AWSFlask",
        "SQL",
        "Beautiful",
        "Soup",
        "httplib2",
        "Jinja2",
        "HTMLCSS",
        "Bootstrap",
        "jQuery",
        "Linux",
        "Sublime",
        "Text",
        "GIT",
        "Python",
        "OpenStack",
        "APIs",
        "Numpy",
        "Numerical",
        "analysis",
        "Proficient",
        "Container",
        "management",
        "Docker",
        "Docker",
        "files",
        "build",
        "Docker",
        "HUB",
        "Kubernetes",
        "operations",
        "calculation",
        "purpose",
        "python",
        "pandas",
        "Uses",
        "Edward",
        "Python",
        "library",
        "modeling",
        "inference",
        "criticism",
        "experimentation",
        "research",
        "models",
        "source",
        "AI",
        "Pytorch",
        "TensorFlow",
        "Scikitlearn",
        "Apache",
        "Open",
        "Source",
        "Kafka",
        "Storm",
        "Spark",
        "NLP",
        "ML",
        "Algorithms",
        "Developed",
        "web",
        "traffic",
        "analysis",
        "tool",
        "Flask",
        "Pandas",
        "Python",
        "NumPy",
        "matplotlib",
        "reports",
        "development",
        "SQL",
        "procedures",
        "normalization",
        "denormalization",
        "MYSQL",
        "notification",
        "service",
        "request",
        "AWS",
        "API",
        "Gateway",
        "response",
        "Lambda",
        "data",
        "DynamoDB",
        "notification",
        "AWS",
        "SNS",
        "Worked",
        "redux",
        "saga",
        "redux",
        "thunk",
        "calls",
        "Spark",
        "streaming",
        "time",
        "data",
        "Kafka",
        "stream",
        "data",
        "HDFS",
        "persistence",
        "Hive",
        "time",
        "application",
        "LINUX",
        "environment",
        "commands",
        "MYSQL",
        "database",
        "python",
        "PythonMySQL",
        "connector",
        "MySQL",
        "package",
        "information",
        "Education",
        "Masters",
        "Skills",
        "Git",
        "MYSQL",
        "Javascript",
        "PHP",
        "CSS"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:55:37.489695",
    "resume_data": "Python Developer span lPythonspan span lDeveloperspan Python Developer Amazon New York NY Work Experience Python Developer Amazon Seattle WA July 2018 to Present Responsibilities Developed webbased applications using Python Django PHP AngularJs Reactjs XML CSS HTML JavaScript and jQuery Developed Consumerbased custom features and applications using Python Django and HTML Involved in building database Model APIs and Views utilizing python in order to build an interactive webbased solution and used Django Database APIs to access database objects Designed and Developed various Angular Components ngModule Services observablepromises Directives and Pipes via TypeScript Developed build and deployment scripts using ANT MAVEN as build tools in Jenkins to move from one environment to other environments Designed front end and backend of the application utilizing Python on Django Web Framework Automated builds using Maven and scheduled automated nightly builds using Heroku and Jenkins Built Jenkins pipeline to drive all microservices builds out to the Docker registry and then deployed to Kubernetes Build an ETL pipeline using Pentaho Spoon Spark Hadoop HDFS for customers with large data volume Worked on analyzing Hadoop stack and different big data analytic tools including Pig Hive HBase database and DynamoDB Implemented various screens for the front end using Reactjs and used various predefined components from NPM Node Package Manager and redux library Developed RDDsData Frames in Spark using Scala and Python and applied several transformation logics to load data from Hadoop Data Lake to Cassandra DB Used WebPack Babel and gulp for transpilationcompilation configuration for Typescript to be converted to JavaScript ETL process for continuously bulk importing catalog data from MySQL into Elastic search Experience in Implementation of MVC MVW architecture using Servlet Django and RESTful SOAP web service and SOAPUI Installed JenkinsPlugins for GIT Repository Setup SCM Polling for Immediate Build with Maven and Maven Repository and Deployment of apps using custom modules through Puppet as a CICD Process Configured and maintained Jenkins to implement the CI process and integrated the tool with ANT and Maven to schedule the builds Performed joins group by and other operations in MapReduce using Python Modified existing scala code to connect different system and database as well as proficient at using Spark APIs to explore cleanse aggregate transform and store machine sensor data Worked on Spark Scripts to find the most trending products daywise and weekwise using Scala and deployed third partys applications using various CI tools like Jenkins Involved in development of Web Services using and REST for sending and getting data from the external interface in XML and JSON format Implemented advanced procedures like text analytics and processing using the inmemory computing capabilities like Apache Spark Developed and Tested features of dashboard using CSS JavaScript Django and Bootstrap Launched Kubernetes to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts Expertise in JavaScript frameworks to replace frontend of a Flask application and began implementing a React solution Developed consumerbased features and applications using Python Django pyramid Flask Web2py HTML and other web technologies Designed and implemented a dedicated MySQL database server to drive the web apps and report on daily progress Involved in installing software using pip command for python libraries like Beautiful Soup NumPy SciPy pythontwitter RabbitMQ Celery matplotlib Pandas dataframe and used the PEP8 coding convention Implemented mapStateToProps mapDispatchToProps for the interactions between Redux and React Proficient in developing Apache ANT and Maven scripts to build J2EE enterprise applications Created web services using WTP tool plugin to the eclipse IDE which is deployed as a separate application using Maven scripts Developed views and templates with Python and Djangos view controller and templating language to create a userfriendly website interface Developed Kafka producer and consumers HBase clients Spark shark Streams and Hadoop MapReduce jobs along with components on HDFS Hive Installed configured and managed the ELK Elastic Search Log Facilitated Scrum ceremonies like Sprint planning retrospectives Daily standups etc Stash and Kibana for Log management within EC2 Elastic Load Balancer ELB for Elastic search Using JDK maven and STS IDE used for development and building the application Developed Terraform scripts for EC2 instances Elastic Load balancers and S3 buckets Designed datasets using Panda data frames and MySQL queried MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Implemented RESTful WebServices for sending and receiving the data between multiple systems Worked on Jenkins by installing configuring and maintaining for Continuous integration CI and for End to End automation for all build and deployments Implemented advanced procedures like text analytics and processing using the inmemory computing capabilities like Apache Spark written in Scala Launched Kubernetes to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts Developed Test Cases and Test Scripts in selenium web driver with Java using Cucumber framework with build management tool Maven Developed the notification service by posting the JSON request in AWS API Gateway AWS Glue Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS Implemented advanced procedures like text analytics and processing using the inmemory computing capabilities like Apache Spark written in Scala Connected applications to SignalRHub using Angular Typescript to provide real time charts for CPU Memory Ethernet and Disk usage Implemented REST APIs in Python using microframework like Flask with SQL Alchemy in the backend for management of data center resources on which OpenStack would be deployed Python Developer Early Warning San Francisco CA October 2015 to December 2017 Implemented responsive user interface and standards throughout the development and maintenance of the website using the HTML CSS JavaScript JQuery Developed the notification service by posting the JSON request in AWS API Gateway AWS Glue Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS Developed views and templates with Python and Djangos to create a userfriendly website interface Proficient in developing frontend with ReactRedux HTML JSX CSS SCSS Bootstrap TypeScript ES6 and Webpack Expertise in configuration management automation tools such as Chef Puppet and Salt Good coding experience with scripting languages like Perl Ruby and Bash Proficient with structures semistructured and unstructured data using a broad range of data science programming languages and big data tools including R Python Spark SQL Scikit Learn Hadoop Map Reduce Proficient in Routine Linux application testingupgrades new product evaluation and system impact analysis Supported Apache Server on Linux Platform Developed complex web middleware and back end systems in Python SQL for Linux and Windows Designed recognition models for both handwritten and textbased characters capable of continuous learning using deep neural networks leveraging keras Proficient working with Bot Frameworks IBM Watson Google Cloud PlatformTensor Flow or Amazon Web Services Sagemaker and open source Designed RESTful Webservices using FLASK with emphasis on improved Security for the service using FLASKHTTPAuth with HTTPS Built Elastic search Log stash and Kibana ELK to store logs and metrics into S3 bucket using Lambda function Implemented Single page Application using React Redux and Flux architectures Hosted GPU based Apache spark jobs using Scala for faster data processing and used spark SQL for querying Worked on analyzing Hadoop stack and different big data analytic tools including Pig Hive HBase database and DynamoDB Proficient in Reactjs framework to develop the SPA and working with React Flux and Redux architecture Implemented various screens for the front end using Reactjs and used various predefined components from NPM Node Package Manager and redux library Involved in converting HiveSQL queries into Spark transformations using Spark RDDs Python and Scala as well as used Scala to convert HiveSQL queries into RDD transformations in Apache Spark Worked on migrating MapReduce programs into Spark transformations using Scala Responsible for building scalable distributed data solutions using Hadoop Developed SonarQube for code quality check and Nexus repository and integrated them into Jenkins to achieve Continuous Integration Development of Python APIs to dump the array structures in the Processor at the failure point for debugging Involved in analysis specification design and implementation and testing phases of Software Development Life Cycle SDLC and used agile methodology for developing application Developed a fully automated continuous integration system using Git Jenkins MySQL and custom tools developed in Python and Bash Implemented Multithreading module and complex networking operations like race route SMTP mail server and web server Using Python Automated RabbitMQ cluster installations and configuration using PythonBash Created Terraform scripts for EC2 instances Elastic Load balancers and S3 buckets Implemented Terraform to manage the AWS infrastructure and managed servers using configuration management tools like Chef and Ansible Recording of Scripts Web Services HTML using Vugen and SoapUI and script validation through co correlations parameterizations and other methods Used GO Lang scripts for uploading a file to S3 and deploying them and creating GO serverless application and deploying it to AWS lambda Worked with RDBMS like Oracle 11g10i and MySQL databases to query and read data Developed various Python scripts to find vulnerabilities with SQL Queries by doing SQL injection permission checks and performance analysis Installed and configured configuration tool such as Chef Serverworkstation and nodes via CLI tools to AWS nodes Deployed Python scripts with Cloud Formation templates to automate installation of Auto scaling EC2 VPC DynamoDB cloud formation Beautiful soup and other services Used Spark API over Hortonworks Hadoop YARN to perform analytics on data in Hive Performed Unit testing Integration Testing GUI testing using Pytest and web application testing using Selenium Python bindings Proficient in specialization areas related to Chef for Cloud Automation Automated the cloud deployments using chef Python boot fabric and AWS Cloud Formation Templates Placed data into JSON files using Python to test Django websites and used Python scripts to update the content in database and manipulate files Built development environment with Kubernetes and Docker in AWS using JupyterHub Helped maintain existing Python Django and Flask applications Interfaced with infrastructure services like Amazon AWS S3 SQS and used tools like Sold RabbitMQ Python Developer Amdocs INDIA August 2013 to September 2015 Created Python and Bash tools to increase efficiency of application system and operations data conversion scripts AMQPRabbitMQ REST JSON and CRUD scripts for API Integration Used Go Lang to create backend servers Developed Micro services using Go language and developed corresponding test cases Developed and Deployed the Application on WebSphere using ANT buildxml script Build Web pages that are more userinteractive using AJAX JavaScript and ReactJS Redux Designed JQuery libraries for all clientside JavaScript manipulations as well as used maven for building creating JPA based entity objects and compiling GWT and GXT application Experience in designing and developing applications in Spark using Scala Expertise in developing API services in PythonTornado NodeJS while leveraging AMQP and RabbitMQ for distributed architectures Application of various learning algorithms and statistical modeling like decision trees text analytics natural language processing NLP supervised and unsupervised regression models social network analysis neural networks deep learning SVM clustering to identify Volume using scikitlearn package in python Matlab Implemented various screens for the front end using Reactjs and used various predefined components from NPM Node Package Manager and redux library Automated builds using Maven and scheduled automated nightly builds using Jenkins Built Jenkins pipeline to drive all microservices builds out to the Docker registry and then deployed to Kubernetes Automated RabbitMQ cluster installations and configuration using PythonBash Used Test driven approach TDD for developing services required for the application and Implemented Integration test cases and Developing predictive analytic using Apache Spark Scala APIs Used Pandas as API to put the data as time series and tabular format for manipulation and retrieval of data Proficient working with Redis RabbitMQ for task queues and Celery to manage Asynchronous tasks Created RDDs performed analysis and ran queries in Python and Apache Spark based on retrospective and groups Executed Terraform to manage the AWS infrastructure and managed servers using configuration management tools like Chef and Anisole Managed worldwide data in Omniture for data collection and analysis and also worked on the library like pandas NumPy SciPy Docker Wrote with objectoriented Python AWSFlask SQL Beautiful Soup httplib2 Jinja2 HTMLCSS Bootstrap jQuery Linux Sublime Text GIT Worked on Python OpenStack APIs and used Numpy for Numerical analysis Proficient in Container management using Docker by writing Docker files and set up the automated build on Docker HUB and installing and configuring Kubernetes Carried out various mathematical operations for calculation purpose using python pandas libraries Uses Edward is a Python library for probabilistic modeling inference and criticism It is a testbed for fast experimentation and research with probabilistic models Designed and implemented open source AI frameworks Pytorch TensorFlow Scikitlearn Apache Open Source Kafka Storm Spark for NLP and ML Algorithms Developed serverbased web traffic statistical analysis tool using Flask Pandas Utilized Python libraries like NumPy and matplotlib for generating graphical reports Worked on the development of SQL and stored procedures for normalization and denormalization in MYSQL Developed the notification service by posting the request in AWS API Gateway Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS Worked with redux saga along with redux thunk to handle asynchronous calls efficiently Configured Spark streaming to receive real time data from Kafka and store the stream data to HDFS for persistence and Hive for real time reporting Implemented the application in LINUX environment and comfortable with all its commands Executed MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Education Masters Skills Git MYSQL Javascript PHP CSS",
    "unique_id": "a32c79b6-4fc0-4634-acc3-65587b99e46c"
}