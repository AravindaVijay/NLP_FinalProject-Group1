{
    "clean_data": "Python Developer span lPythonspan span lDeveloperspan Python Developer IBM Remote Heidelberg PA Software Developer around 7 years of experience in software development with a deep understanding of technology trends with expertise in the core of complex technologies Skillful involvement in Python by developing softwares utilizing new tools libraries utilized Beautiful Soup NumPy SciPy PySide Pandas Requests xmltodict Matplotlib Pickle Pandas data frame urllib3 MySQL DB to improve software development process Experience in developing Web Services SOAP Restful APIs in Python using XML and JAVA Experience in working with various version control systems like GIT CVS and SVN Hands on experience in developing business processes and system solutions utilizing prototype development system development and deployment Experience in using editors like Eclipse sublime text NetBeans PyCharm PyScripter Spyder PyStudio and PyDev Used Django evolution and manual SQL modifications to retain all the data while the site is in production Experience in Linux Bash Scripting and PEP guidelines in python Expertise in developing webbased open stack applications for large dataset analysis using Python and Django Used Python Unit test framework for developing and implementing the unit tests using Test driven approach Analyzed instrument pricing and modeling methodologies and documented how instrument prices move as a change in the market data source Good Hands on experience in establishing connections for Java and Python by configuring packages like MySQL Python JDBC Hands on experience in monitoring developing and transforming data using SQL Server Integration ServiceSSIS and SQL Service Analysis ServiceSSAS Experienced in writing custom queries through database connectors Hands on experience with databases using ORMsDOMs for integrating with Oracle MySQL PostgreSQL Good knowledge in working with Webapplication server Apache Tomcat 60 70 80 Tornado CherryPy Experienced with Object Oriented design methodology and Agile Methodology in software development Used Pandas API to put the data as time series and tabular form for east timestamp data retrieval and manipulation and for statistical analysis Authorized to work in the US for any employer Work Experience Python Developer IBM Remote January 2018 to Present Description The International Business Machines Corporation is an American multinational technology company headquartered in Armonk New York United States with operations in over 170 countries IBM manufactures and markets computer hardware middleware and software and provides hosting and consulting services in areas ranging from mainframe computers to nanotechnology Responsibilities Developed Speech to text conversion using Google API Developed a script which can convert JSON to CSV Used pandas to convert a Python list of sentences to a series object using tolist method Extracting data using regex and validations Worked with Latin characters using unidecode and simplejson libraries as a json decoder which can handles Unicode characters libraries Used Unidcode to decode the Unicode string Worked on xml parser file Developed codes which can fetch the data from two different REST APIs and update the list of contact information in the desired API Developed a different class which can perform adddelete members functionalities Used requests library to access the information from APIs using get request method Authorizing the APIs using HTTP BasicAuth library Passing the arguments from command line to pull out the data based on modified date Using my script as a base and inheriting the client file to access the APIs URLs and client credentials from property file Creating a new IBM Blue Pages group where user can store all his personal information Accessing that created groups and giving access that group API to invoke to other users and use the information on demand Involved in mapping the data from CSV and updating the list of data in API using REST services Setting up the IBM Data Science Experience in local machines Created Jupyter notebook under DSX and executed the scripts by splitting the code as per the requirement Involved in the execution of CSV files in Data Science Experience Major part is like being a part of the project importing the converted CSV file to IBM internal API which is InfoSphere Information Governance Catalog Experienced with GIT version control and deployed the project to DSX Knowledgeable with GIT version control Written a wrapper class that will allow any group to update list of usernames based on demand using property file with CSV Updating the information in JIRA with required details and uploading necessary information to finish that particular story Supporting my team members in performance testing using JMeter and running the scripts in parallel Environment Python 37 JavaScript CSV JSON JIRA DSX Jupyter HTTPBasicAuth Pandas GitHub Requests xmltodict HTTP BasicAuth Python Engineer Nike OR May 2017 to December 2017 Description Nike is an American multinational corporation that is engaged in the design development manufacturing and worldwide marketing and sales of footwear apparel equipment accessories and services It is the worlds largest supplier of athletic shoes and apparel and a major manufacturer of sports equipment Responsibilities Converted data from PDF to XML using python script in two ways ie from raw xml to processed xml and from processed xml to CSV files Developing a generic script for the regulatory documents Used python Element Tree ET to parse through the XML which is derived from PDF files Data which is stored in sqlite3 data file db were accessed using the python and extracted the metadata tables and data from tables and converted the tables to respective CSV tables Used the XML tags and attributes to isolate headings sideheadings and subheadings to each row in CSV file Converted data from HTML to XML for couple of PDF regulatory documents Used Beautiful Soup for web scraping Parsing the data Developed the code to capture the description which comes under headings of index section to the description column of CSV row Used some other python libraries like PDFMiner PyPDF2 PDF Query and Sqlite3 Converted the Unicode to nearest possible string ASCII value using Unidecode module Adding a column to each CSV row which gives the parent Index number of the given row Examined framework determined specifications and had client interaction with requirements specifications Used Pandas API to put the data as time series and tabular format for east timestamp data manipulation and retrieval Experience on Jenkins continuous integration CI tool for deployment of the project Used MySQL database for simple queries and writing Stored Procedures for normalization and denormalization Involved in development of Web Services using SOAP for sending and getting data from the external interface in the XML format Experience in using collections in Python for manipulating and looping through different userdefined objects Knowledge of Test Driven Development TDD Pair Programming with PyUnit Junit and PythonUnittest Used Pandas API to put the data as time series and tabular format for east timestamp data manipulation and retrieval Executed MYSQL database queries from python using PythonMySQL connector and MySQL  package to retrieve information Generated Python Django Forms to record data of online users Used Python and Django creating graphics XML processing data exchange and business logic implementation Designed and developed communication between client and server using Secured Web services such as Djangorestframework Documented the design solutions and created stories for client requirements Utilized Python libraries like NumPy and Matplotlib for generating graphical reports Build SQL queries for performing various CRUD operations like create update read and delete Experience in working with a team of developers on python applications for RISK management Improved code reuse and performance by making effective use of various design patterns Environment Python27 35 HTML5 CSS JavaScript AJAX JSON JIRA Django REST API jQuery MS Access MS SQL Server GitHub Shell Scripting Python Developer AMEX NY New York NY September 2016 to April 2017 Description The American Express Company also known as Amex is an American multinational financial services corporation headquartered in Three World Financial Center in New York City Project developed was a Business Tool focused to expand the customer base Its a web based application which send emails to all the registered users on the deals and new products which are placed on the web and also predicting the values upon the matriculations Responsibilities Wrote Python routines to log into the websites and fetch data for selected options Used Python modules such as requests urllib urllib2 for web crawling Used other packages such as Beautiful Soup for data parsing Worked on writing and as well as read data from csv and excel file formats Webservices backend development using Python CherryPy Django SQLAlchemy Worked on resulting reports of the application and Tableau reports Worked on HTML5 CSS3 JavaScript Git REST API Mongo DB IntelliJIdea Design and Setting up of the environment of Mongo  with shards and replica sets DevTest and Production Private VPN using Ubuntu Python Django Postgres Redis Bootstrap jQuery Mongo Git Tenjin Selenium Performed QA testing on the application Developed approaches for improving NLP pipeline Create custom VB scripts for repackaging applications as needed NLP File Prep SettlementPrepare files for review for Settlement Held meetings with client and worked all alone for the entire project with limited help from the client Managed and reviewed Hadoop log file and worked in analyzing SQL scripts and designed the solution for the process using PySpark Actively involved in developing the methods for Create Read Update and Delete CRUD in Active Record Designing mobile search application system requirements and coded backend and frontend in Python Developed rich user interface using CSS HTML JavaScript and jQuery Created a Pythonbased GUI application For Freight Tracking and processing Used Django framework for application development Excellent knowledge of distributed storages HDFS and distributed processing MapReduce Yarn Developed and maintained various automated web tools for reducing manual effort and increasing efficiency of the Global Shipping Team Developed an automated testing framework for commandline based tests on Linux using Objected Oriented Perl and for seleniumbased tests using Python Created database using MySQL wrote several queries to extract data from the database Setup automated Cron jobs to upload data into the database generate graphs bar charts upload these charts to the wiki and backup the database Wrote scripts in Python for extracting data from HTML file Environment MySQL HTML Python Django HTML5 CSS XML MySQL MS SQL Server JavaScript AWS Linux Shell Scripting AJAX urllib urllib2 Json CherryPy Unix Redis Bootstrap Mongo  SQLAlchemy jQuery Python Developer NBC Universal December 2015 to August 2016 Description NBC Universal Media LLC a media and entertainment company develops produces and distributes entertainment news and information sports and other content for audiences worldwide The company operates in four segments Cable Networks Broadcast Television Filmed Entertainment and Theme Parks The Cable Networks segment offers a portfolio of cable television networks including national cable entertainment networks such as USA Network Syfy E Bravo Oxygen Sprout Esquire Network Chiller Universal HD and Cloo national cable news and information networks comprising MSNBC CNBC and CNBC World Responsibilities Django Framework that was used in developing web applications to implement the model view controller architecture Exposure to MultiThreading factory to distribute learning process backtesting and the into various worker processes Performed efficient delivery of code based on principles of Test Driven Development TDD and continuous integration to keep in line with Agile Software Methodology principles Different testing methodologies like unit testing Integration testing web application testing PythonDjango based web application PostgreSQL DB and integrations with 3rd party emailmessaging storage services Developed a fully automated continuous integration system using Git Gerrit Jenkins MySQL and custom tools developed in Python and Bash Design and implement custom scripts Extensive use of version controller Team Foundation Server TFS Delivered automated solutions for science models Managed developed and designed a dashboard control panel for customers and Administrators using Django Oracle DB and PostgreSQL Implemented configuration changes for data models Maintained and updated existing automated solutions Handled potential points of failure through error handling and communication of failure Troubleshoot the process execution and worked with other team members to correct them Actively worked as a part of a team with managers and other staff to meet the goals of the project in the stipulated time Performed troubleshooting fixed and deployed many Python bug fixes of the two main applications that were the main source of data for both customers and internal customer service team Used Pandas library for statistics Analysis Managed large datasets using Panda data frames and MySQL Used advanced packages in AON PATHWISE for performing the unit test and deploying data models Extensively used Python modules such as requests urllib urllib2 for web crawling Developed GUI using webapp2 for dynamically displaying the test block documentation and other features of Python code using a web browser Developed the required XML Schema documents and implemented the framework for parsing XML documents Different testing methodologies like unit testing Integration testing web application testing selenium testing was performed Used Django framework for application development Developed user interface using CSS HTML JavaScript and jQuery Ruby on rails Assisted in the reduction of cost and optimization of supplier selection for the CRM Applications Debug of custom software running on Windows and Linux operating systems Professional minded with the ambition to advance both the product as well as themselves Responsible for user validations on client side as well as server side Automated the existing scripts for performance calculations using NumPy and SQLAlchemy Interacted with QA to develop test plans for highlevel design documentation Environment Python 27 Django 14 HTML5 CSS XML MySQL JavaScript Angular JS Backbone JS jQuery CSS Bootstrap Mongo DB TSQL JavaScript Eclipse Git GitHub AWS Linux Shell Scripting Data AnalystData Modeler Accenture Bengaluru Karnataka May 2012 to July 2015 Description Accenture PLC is a global management consulting and professional services company that provides strategy consulting digital technology and operations Responsibilities Developed end to end enterprise Applications using Spring MVC REST and JDBC Template Modules Written well designed testable efficient java code Understanding and analyzing complex issues and addressing challenges arising during the software development process both conceptually and technically Implemented best practices of Automated Build Test and Deployment Developed design patterns data structures and algorithms based on project need Worked on multiple tools such as Toad Eclipse SVN Apache and Tomcat Deployed models via APIs into applications or workflows Worked on User Interface technologies like HTML5 CSSSCSS Wrote Stored procedure and SQL queries based on project need Deployed built jar into application server Created Automated Unit Tests using FlexibleOpen Source Frameworks Developed Multithreaded and Transaction Handling code JMS Database Environment Java Spring MVC Hibernate MS HTML5 CSSSCSS Junit Eclipse Tomcat and Oracle Education Bachelors Skills HTML JAVASCRIPT BOOTSTRAP NODEJS PYTHON MATPLOTLIB NUMPY PANDAS SCRIPTING XML DATABASE DB2 MYSQL ORACLE PLSQL SQL SQLITE CSS SOA TOMCAT",
    "entities": [
        "CSS HTML JavaScript",
        "NLP File Prep SettlementPrepare",
        "Responsibilities Converted",
        "Responsibilities Developed",
        "sqlite3",
        "GitHub Shell Scripting Python",
        "Test Driven Development TDD",
        "ORMsDOMs",
        "New York",
        "JavaScript AWS Linux Shell Scripting AJAX",
        "BasicAuth",
        "Developed GUI",
        "Agile Software Methodology",
        "the Global Shipping Team Developed",
        "webapp2",
        "Knowledge of Test Driven Development TDD Pair Programming",
        "USA Network Syfy",
        "Beautiful Soup",
        "IBM",
        "PythonUnittest",
        "jQuery Created a Pythonbased",
        "Panda",
        "Agile Methodology",
        "Hadoop",
        "XML",
        "SOAP",
        "Bash Design",
        "Maintained",
        "csv",
        "Cable Networks",
        "Automated",
        "Cable Networks Broadcast Television Filmed Entertainment",
        "Extracting",
        "ASCII",
        "Data Science Experience Major",
        "Python",
        "DSX Knowledgeable",
        "Secured Web",
        "Stored Procedures",
        "Developed",
        "Unicode",
        "Mongo",
        "Jenkins",
        "PyUnit Junit",
        "PEP",
        "MultiThreading",
        "CSV Updating",
        "Windows",
        "jQuery Ruby",
        "PySpark Actively",
        "New York City Project",
        "Automated Build Test and Deployment Developed",
        "API Developed",
        "Linux",
        "Redis Bootstrap Mongo  SQLAlchemy jQuery Python Developer",
        "Team Foundation",
        "MVC",
        "PythonDjango",
        "DSX",
        "HTML file Environment MySQL HTML Python Django HTML5 CSS XML",
        "GIT",
        "User Interface",
        "CSV",
        "API",
        "US",
        "QA",
        "PDF",
        "SVN Hands",
        "Three World Financial Center",
        "the IBM Data Science Experience",
        "The International Business Machines Corporation",
        "Present Description",
        "Unidecode",
        "PDF Query",
        "MSNBC CNBC",
        "Amex",
        "Generated Python Django Forms",
        "SQL Service",
        "HTML",
        "Cron",
        "SQL",
        "Django Oracle DB",
        "NLP",
        "lPythonspan",
        "Administrators",
        "GIT CVS",
        "Webapplication",
        "Ubuntu Python Django Postgres Redis Bootstrap jQuery Mongo Git Tenjin Selenium Performed",
        "The American Express Company",
        "Oracle MySQL PostgreSQL Good",
        "CNBC World Responsibilities Django Framework",
        "Utilized Python",
        "Pandas",
        "United States",
        "CRUD",
        "JAVA",
        "Performed",
        "PDFMiner",
        "TOMCAT",
        "InfoSphere Information Governance Catalog Experienced",
        "Description Accenture PLC",
        "Created Automated",
        "SVN",
        "Armonk",
        "Expertise",
        "Tomcat Deployed",
        "REST",
        "Toad",
        "Djangorestframework Documented",
        "Tableau",
        "Google API Developed",
        "Python Developed",
        "Integration",
        "SQL Server Integration ServiceSSIS",
        "Python Created",
        "Troubleshoot",
        "DevTest"
    ],
    "experience": "Experience in developing Web Services SOAP Restful APIs in Python using XML and JAVA Experience in working with various version control systems like GIT CVS and SVN Hands on experience in developing business processes and system solutions utilizing prototype development system development and deployment Experience in using editors like Eclipse sublime text NetBeans PyCharm PyScripter Spyder PyStudio and PyDev Used Django evolution and manual SQL modifications to retain all the data while the site is in production Experience in Linux Bash Scripting and PEP guidelines in python Expertise in developing webbased open stack applications for large dataset analysis using Python and Django Used Python Unit test framework for developing and implementing the unit tests using Test driven approach Analyzed instrument pricing and modeling methodologies and documented how instrument prices move as a change in the market data source Good Hands on experience in establishing connections for Java and Python by configuring packages like MySQL Python JDBC Hands on experience in monitoring developing and transforming data using SQL Server Integration ServiceSSIS and SQL Service Analysis ServiceSSAS Experienced in writing custom queries through database connectors Hands on experience with databases using ORMsDOMs for integrating with Oracle MySQL PostgreSQL Good knowledge in working with Webapplication server Apache Tomcat 60 70 80 Tornado CherryPy Experienced with Object Oriented design methodology and Agile Methodology in software development Used Pandas API to put the data as time series and tabular form for east timestamp data retrieval and manipulation and for statistical analysis Authorized to work in the US for any employer Work Experience Python Developer IBM Remote January 2018 to Present Description The International Business Machines Corporation is an American multinational technology company headquartered in Armonk New York United States with operations in over 170 countries IBM manufactures and markets computer hardware middleware and software and provides hosting and consulting services in areas ranging from mainframe computers to nanotechnology Responsibilities Developed Speech to text conversion using Google API Developed a script which can convert JSON to CSV Used pandas to convert a Python list of sentences to a series object using tolist method Extracting data using regex and validations Worked with Latin characters using unidecode and simplejson libraries as a json decoder which can handles Unicode characters libraries Used Unidcode to decode the Unicode string Worked on xml parser file Developed codes which can fetch the data from two different REST APIs and update the list of contact information in the desired API Developed a different class which can perform adddelete members functionalities Used requests library to access the information from APIs using get request method Authorizing the APIs using HTTP BasicAuth library Passing the arguments from command line to pull out the data based on modified date Using my script as a base and inheriting the client file to access the APIs URLs and client credentials from property file Creating a new IBM Blue Pages group where user can store all his personal information Accessing that created groups and giving access that group API to invoke to other users and use the information on demand Involved in mapping the data from CSV and updating the list of data in API using REST services Setting up the IBM Data Science Experience in local machines Created Jupyter notebook under DSX and executed the scripts by splitting the code as per the requirement Involved in the execution of CSV files in Data Science Experience Major part is like being a part of the project importing the converted CSV file to IBM internal API which is InfoSphere Information Governance Catalog Experienced with GIT version control and deployed the project to DSX Knowledgeable with GIT version control Written a wrapper class that will allow any group to update list of usernames based on demand using property file with CSV Updating the information in JIRA with required details and uploading necessary information to finish that particular story Supporting my team members in performance testing using JMeter and running the scripts in parallel Environment Python 37 JavaScript CSV JSON JIRA DSX Jupyter HTTPBasicAuth Pandas GitHub Requests xmltodict HTTP BasicAuth Python Engineer Nike OR May 2017 to December 2017 Description Nike is an American multinational corporation that is engaged in the design development manufacturing and worldwide marketing and sales of footwear apparel equipment accessories and services It is the worlds largest supplier of athletic shoes and apparel and a major manufacturer of sports equipment Responsibilities Converted data from PDF to XML using python script in two ways ie from raw xml to processed xml and from processed xml to CSV files Developing a generic script for the regulatory documents Used python Element Tree ET to parse through the XML which is derived from PDF files Data which is stored in sqlite3 data file db were accessed using the python and extracted the metadata tables and data from tables and converted the tables to respective CSV tables Used the XML tags and attributes to isolate headings sideheadings and subheadings to each row in CSV file Converted data from HTML to XML for couple of PDF regulatory documents Used Beautiful Soup for web scraping Parsing the data Developed the code to capture the description which comes under headings of index section to the description column of CSV row Used some other python libraries like PDFMiner PyPDF2 PDF Query and Sqlite3 Converted the Unicode to nearest possible string ASCII value using Unidecode module Adding a column to each CSV row which gives the parent Index number of the given row Examined framework determined specifications and had client interaction with requirements specifications Used Pandas API to put the data as time series and tabular format for east timestamp data manipulation and retrieval Experience on Jenkins continuous integration CI tool for deployment of the project Used MySQL database for simple queries and writing Stored Procedures for normalization and denormalization Involved in development of Web Services using SOAP for sending and getting data from the external interface in the XML format Experience in using collections in Python for manipulating and looping through different userdefined objects Knowledge of Test Driven Development TDD Pair Programming with PyUnit Junit and PythonUnittest Used Pandas API to put the data as time series and tabular format for east timestamp data manipulation and retrieval Executed MYSQL database queries from python using PythonMySQL connector and MySQL   package to retrieve information Generated Python Django Forms to record data of online users Used Python and Django creating graphics XML processing data exchange and business logic implementation Designed and developed communication between client and server using Secured Web services such as Djangorestframework Documented the design solutions and created stories for client requirements Utilized Python libraries like NumPy and Matplotlib for generating graphical reports Build SQL queries for performing various CRUD operations like create update read and delete Experience in working with a team of developers on python applications for RISK management Improved code reuse and performance by making effective use of various design patterns Environment Python27 35 HTML5 CSS JavaScript AJAX JSON JIRA Django REST API jQuery MS Access MS SQL Server GitHub Shell Scripting Python Developer AMEX NY New York NY September 2016 to April 2017 Description The American Express Company also known as Amex is an American multinational financial services corporation headquartered in Three World Financial Center in New York City Project developed was a Business Tool focused to expand the customer base Its a web based application which send emails to all the registered users on the deals and new products which are placed on the web and also predicting the values upon the matriculations Responsibilities Wrote Python routines to log into the websites and fetch data for selected options Used Python modules such as requests urllib urllib2 for web crawling Used other packages such as Beautiful Soup for data parsing Worked on writing and as well as read data from csv and excel file formats Webservices backend development using Python CherryPy Django SQLAlchemy Worked on resulting reports of the application and Tableau reports Worked on HTML5 CSS3 JavaScript Git REST API Mongo DB IntelliJIdea Design and Setting up of the environment of Mongo   with shards and replica sets DevTest and Production Private VPN using Ubuntu Python Django Postgres Redis Bootstrap jQuery Mongo Git Tenjin Selenium Performed QA testing on the application Developed approaches for improving NLP pipeline Create custom VB scripts for repackaging applications as needed NLP File Prep SettlementPrepare files for review for Settlement Held meetings with client and worked all alone for the entire project with limited help from the client Managed and reviewed Hadoop log file and worked in analyzing SQL scripts and designed the solution for the process using PySpark Actively involved in developing the methods for Create Read Update and Delete CRUD in Active Record Designing mobile search application system requirements and coded backend and frontend in Python Developed rich user interface using CSS HTML JavaScript and jQuery Created a Pythonbased GUI application For Freight Tracking and processing Used Django framework for application development Excellent knowledge of distributed storages HDFS and distributed processing MapReduce Yarn Developed and maintained various automated web tools for reducing manual effort and increasing efficiency of the Global Shipping Team Developed an automated testing framework for commandline based tests on Linux using Objected Oriented Perl and for seleniumbased tests using Python Created database using MySQL wrote several queries to extract data from the database Setup automated Cron jobs to upload data into the database generate graphs bar charts upload these charts to the wiki and backup the database Wrote scripts in Python for extracting data from HTML file Environment MySQL HTML Python Django HTML5 CSS XML MySQL MS SQL Server JavaScript AWS Linux Shell Scripting AJAX urllib urllib2 Json CherryPy Unix Redis Bootstrap Mongo   SQLAlchemy jQuery Python Developer NBC Universal December 2015 to August 2016 Description NBC Universal Media LLC a media and entertainment company develops produces and distributes entertainment news and information sports and other content for audiences worldwide The company operates in four segments Cable Networks Broadcast Television Filmed Entertainment and Theme Parks The Cable Networks segment offers a portfolio of cable television networks including national cable entertainment networks such as USA Network Syfy E Bravo Oxygen Sprout Esquire Network Chiller Universal HD and Cloo national cable news and information networks comprising MSNBC CNBC and CNBC World Responsibilities Django Framework that was used in developing web applications to implement the model view controller architecture Exposure to MultiThreading factory to distribute learning process backtesting and the into various worker processes Performed efficient delivery of code based on principles of Test Driven Development TDD and continuous integration to keep in line with Agile Software Methodology principles Different testing methodologies like unit testing Integration testing web application testing PythonDjango based web application PostgreSQL DB and integrations with 3rd party emailmessaging storage services Developed a fully automated continuous integration system using Git Gerrit Jenkins MySQL and custom tools developed in Python and Bash Design and implement custom scripts Extensive use of version controller Team Foundation Server TFS Delivered automated solutions for science models Managed developed and designed a dashboard control panel for customers and Administrators using Django Oracle DB and PostgreSQL Implemented configuration changes for data models Maintained and updated existing automated solutions Handled potential points of failure through error handling and communication of failure Troubleshoot the process execution and worked with other team members to correct them Actively worked as a part of a team with managers and other staff to meet the goals of the project in the stipulated time Performed troubleshooting fixed and deployed many Python bug fixes of the two main applications that were the main source of data for both customers and internal customer service team Used Pandas library for statistics Analysis Managed large datasets using Panda data frames and MySQL Used advanced packages in AON PATHWISE for performing the unit test and deploying data models Extensively used Python modules such as requests urllib urllib2 for web crawling Developed GUI using webapp2 for dynamically displaying the test block documentation and other features of Python code using a web browser Developed the required XML Schema documents and implemented the framework for parsing XML documents Different testing methodologies like unit testing Integration testing web application testing selenium testing was performed Used Django framework for application development Developed user interface using CSS HTML JavaScript and jQuery Ruby on rails Assisted in the reduction of cost and optimization of supplier selection for the CRM Applications Debug of custom software running on Windows and Linux operating systems Professional minded with the ambition to advance both the product as well as themselves Responsible for user validations on client side as well as server side Automated the existing scripts for performance calculations using NumPy and SQLAlchemy Interacted with QA to develop test plans for highlevel design documentation Environment Python 27 Django 14 HTML5 CSS XML MySQL JavaScript Angular JS Backbone JS jQuery CSS Bootstrap Mongo DB TSQL JavaScript Eclipse Git GitHub AWS Linux Shell Scripting Data AnalystData Modeler Accenture Bengaluru Karnataka May 2012 to July 2015 Description Accenture PLC is a global management consulting and professional services company that provides strategy consulting digital technology and operations Responsibilities Developed end to end enterprise Applications using Spring MVC REST and JDBC Template Modules Written well designed testable efficient java code Understanding and analyzing complex issues and addressing challenges arising during the software development process both conceptually and technically Implemented best practices of Automated Build Test and Deployment Developed design patterns data structures and algorithms based on project need Worked on multiple tools such as Toad Eclipse SVN Apache and Tomcat Deployed models via APIs into applications or workflows Worked on User Interface technologies like HTML5 CSSSCSS Wrote Stored procedure and SQL queries based on project need Deployed built jar into application server Created Automated Unit Tests using FlexibleOpen Source Frameworks Developed Multithreaded and Transaction Handling code JMS Database Environment Java Spring MVC Hibernate MS HTML5 CSSSCSS Junit Eclipse Tomcat and Oracle Education Bachelors Skills HTML JAVASCRIPT BOOTSTRAP NODEJS PYTHON MATPLOTLIB NUMPY PANDAS SCRIPTING XML DATABASE DB2 MYSQL ORACLE PLSQL SQL SQLITE CSS SOA TOMCAT",
    "extracted_keywords": [
        "Python",
        "Developer",
        "lPythonspan",
        "span",
        "lDeveloperspan",
        "Python",
        "Developer",
        "IBM",
        "Remote",
        "Heidelberg",
        "PA",
        "Software",
        "Developer",
        "years",
        "experience",
        "software",
        "development",
        "understanding",
        "technology",
        "trends",
        "expertise",
        "core",
        "technologies",
        "involvement",
        "Python",
        "softwares",
        "tools",
        "libraries",
        "Beautiful",
        "Soup",
        "NumPy",
        "SciPy",
        "PySide",
        "Pandas",
        "Requests",
        "xmltodict",
        "Matplotlib",
        "Pickle",
        "Pandas",
        "data",
        "frame",
        "urllib3",
        "MySQL",
        "DB",
        "software",
        "development",
        "process",
        "Experience",
        "Web",
        "Services",
        "APIs",
        "Python",
        "XML",
        "Experience",
        "version",
        "control",
        "systems",
        "GIT",
        "CVS",
        "SVN",
        "Hands",
        "experience",
        "business",
        "processes",
        "system",
        "solutions",
        "prototype",
        "development",
        "system",
        "development",
        "deployment",
        "Experience",
        "editors",
        "Eclipse",
        "text",
        "NetBeans",
        "PyCharm",
        "PyScripter",
        "Spyder",
        "PyStudio",
        "PyDev",
        "Django",
        "evolution",
        "SQL",
        "modifications",
        "data",
        "site",
        "production",
        "Experience",
        "Linux",
        "Bash",
        "Scripting",
        "PEP",
        "guidelines",
        "python",
        "Expertise",
        "stack",
        "applications",
        "analysis",
        "Python",
        "Django",
        "Python",
        "Unit",
        "test",
        "framework",
        "unit",
        "tests",
        "Test",
        "approach",
        "instrument",
        "pricing",
        "modeling",
        "methodologies",
        "prices",
        "change",
        "market",
        "data",
        "source",
        "Good",
        "Hands",
        "experience",
        "connections",
        "Java",
        "Python",
        "packages",
        "MySQL",
        "Python",
        "JDBC",
        "Hands",
        "experience",
        "data",
        "SQL",
        "Server",
        "Integration",
        "SQL",
        "Service",
        "Analysis",
        "ServiceSSAS",
        "custom",
        "queries",
        "database",
        "connectors",
        "Hands",
        "experience",
        "databases",
        "ORMsDOMs",
        "Oracle",
        "MySQL",
        "PostgreSQL",
        "knowledge",
        "Webapplication",
        "server",
        "Apache",
        "Tomcat",
        "Tornado",
        "CherryPy",
        "Object",
        "design",
        "methodology",
        "Agile",
        "Methodology",
        "software",
        "development",
        "Pandas",
        "API",
        "data",
        "time",
        "series",
        "form",
        "east",
        "timestamp",
        "data",
        "retrieval",
        "manipulation",
        "analysis",
        "US",
        "employer",
        "Work",
        "Experience",
        "Python",
        "Developer",
        "IBM",
        "Remote",
        "January",
        "Present",
        "Description",
        "International",
        "Business",
        "Machines",
        "Corporation",
        "technology",
        "company",
        "Armonk",
        "New",
        "York",
        "United",
        "States",
        "operations",
        "countries",
        "IBM",
        "manufactures",
        "markets",
        "computer",
        "hardware",
        "middleware",
        "software",
        "services",
        "areas",
        "mainframe",
        "computers",
        "nanotechnology",
        "Responsibilities",
        "Speech",
        "conversion",
        "Google",
        "API",
        "script",
        "JSON",
        "CSV",
        "pandas",
        "Python",
        "list",
        "sentences",
        "series",
        "object",
        "method",
        "data",
        "regex",
        "validations",
        "characters",
        "unidecode",
        "simplejson",
        "json",
        "decoder",
        "Unicode",
        "characters",
        "Unidcode",
        "Unicode",
        "string",
        "xml",
        "parser",
        "file",
        "codes",
        "data",
        "REST",
        "APIs",
        "list",
        "contact",
        "information",
        "API",
        "class",
        "members",
        "functionalities",
        "requests",
        "library",
        "information",
        "APIs",
        "request",
        "method",
        "APIs",
        "HTTP",
        "BasicAuth",
        "library",
        "arguments",
        "command",
        "line",
        "data",
        "date",
        "script",
        "base",
        "client",
        "file",
        "APIs",
        "URLs",
        "client",
        "credentials",
        "property",
        "file",
        "IBM",
        "Blue",
        "Pages",
        "group",
        "user",
        "information",
        "Accessing",
        "groups",
        "access",
        "group",
        "API",
        "users",
        "information",
        "demand",
        "data",
        "CSV",
        "list",
        "data",
        "API",
        "REST",
        "services",
        "IBM",
        "Data",
        "Science",
        "Experience",
        "machines",
        "Jupyter",
        "notebook",
        "DSX",
        "scripts",
        "code",
        "requirement",
        "execution",
        "CSV",
        "files",
        "Data",
        "Science",
        "Experience",
        "Major",
        "part",
        "part",
        "project",
        "CSV",
        "file",
        "IBM",
        "API",
        "InfoSphere",
        "Information",
        "Governance",
        "Catalog",
        "GIT",
        "version",
        "control",
        "project",
        "DSX",
        "Knowledgeable",
        "GIT",
        "version",
        "control",
        "wrapper",
        "class",
        "group",
        "list",
        "usernames",
        "demand",
        "property",
        "file",
        "CSV",
        "information",
        "JIRA",
        "details",
        "information",
        "story",
        "team",
        "members",
        "performance",
        "testing",
        "JMeter",
        "scripts",
        "Environment",
        "Python",
        "JavaScript",
        "CSV",
        "JSON",
        "JIRA",
        "DSX",
        "Jupyter",
        "HTTPBasicAuth",
        "GitHub",
        "Requests",
        "HTTP",
        "BasicAuth",
        "Python",
        "Engineer",
        "Nike",
        "May",
        "December",
        "Description",
        "Nike",
        "corporation",
        "design",
        "development",
        "manufacturing",
        "marketing",
        "sales",
        "footwear",
        "apparel",
        "equipment",
        "accessories",
        "services",
        "worlds",
        "supplier",
        "shoes",
        "apparel",
        "manufacturer",
        "sports",
        "equipment",
        "Responsibilities",
        "data",
        "PDF",
        "python",
        "script",
        "ways",
        "raw",
        "xml",
        "xml",
        "xml",
        "CSV",
        "files",
        "script",
        "documents",
        "python",
        "Element",
        "Tree",
        "ET",
        "XML",
        "PDF",
        "files",
        "Data",
        "sqlite3",
        "data",
        "file",
        "db",
        "python",
        "metadata",
        "tables",
        "data",
        "tables",
        "tables",
        "CSV",
        "tables",
        "XML",
        "tags",
        "attributes",
        "headings",
        "sideheadings",
        "subheadings",
        "row",
        "CSV",
        "file",
        "data",
        "HTML",
        "couple",
        "PDF",
        "documents",
        "Beautiful",
        "Soup",
        "web",
        "data",
        "code",
        "description",
        "headings",
        "index",
        "section",
        "description",
        "column",
        "CSV",
        "row",
        "python",
        "libraries",
        "PDFMiner",
        "PyPDF2",
        "PDF",
        "Query",
        "Unicode",
        "string",
        "ASCII",
        "value",
        "Unidecode",
        "module",
        "column",
        "CSV",
        "row",
        "parent",
        "Index",
        "number",
        "row",
        "framework",
        "specifications",
        "client",
        "interaction",
        "requirements",
        "specifications",
        "Pandas",
        "API",
        "data",
        "time",
        "series",
        "format",
        "east",
        "timestamp",
        "data",
        "manipulation",
        "retrieval",
        "Experience",
        "Jenkins",
        "integration",
        "CI",
        "tool",
        "deployment",
        "project",
        "MySQL",
        "database",
        "queries",
        "Procedures",
        "normalization",
        "denormalization",
        "development",
        "Web",
        "Services",
        "SOAP",
        "data",
        "interface",
        "XML",
        "format",
        "Experience",
        "collections",
        "Python",
        "objects",
        "Knowledge",
        "Test",
        "Driven",
        "Development",
        "TDD",
        "Pair",
        "Programming",
        "PyUnit",
        "Junit",
        "PythonUnittest",
        "Pandas",
        "API",
        "data",
        "time",
        "series",
        "format",
        "east",
        "timestamp",
        "data",
        "manipulation",
        "retrieval",
        "MYSQL",
        "database",
        "python",
        "PythonMySQL",
        "connector",
        "MySQL",
        "package",
        "information",
        "Python",
        "Django",
        "Forms",
        "data",
        "users",
        "Python",
        "Django",
        "graphics",
        "XML",
        "processing",
        "data",
        "exchange",
        "business",
        "logic",
        "implementation",
        "communication",
        "client",
        "server",
        "Secured",
        "Web",
        "services",
        "Djangorestframework",
        "design",
        "solutions",
        "stories",
        "client",
        "requirements",
        "Python",
        "NumPy",
        "Matplotlib",
        "reports",
        "Build",
        "SQL",
        "CRUD",
        "operations",
        "update",
        "read",
        "Experience",
        "team",
        "developers",
        "applications",
        "RISK",
        "management",
        "Improved",
        "code",
        "reuse",
        "performance",
        "use",
        "design",
        "patterns",
        "Environment",
        "Python27",
        "HTML5",
        "CSS",
        "JavaScript",
        "AJAX",
        "JSON",
        "JIRA",
        "Django",
        "REST",
        "API",
        "jQuery",
        "MS",
        "Access",
        "MS",
        "SQL",
        "Server",
        "GitHub",
        "Shell",
        "Scripting",
        "Python",
        "Developer",
        "AMEX",
        "NY",
        "New",
        "York",
        "NY",
        "September",
        "April",
        "Description",
        "American",
        "Express",
        "Company",
        "Amex",
        "services",
        "corporation",
        "Three",
        "World",
        "Financial",
        "Center",
        "New",
        "York",
        "City",
        "Project",
        "Business",
        "Tool",
        "customer",
        "base",
        "web",
        "application",
        "emails",
        "users",
        "deals",
        "products",
        "web",
        "values",
        "matriculations",
        "Responsibilities",
        "Python",
        "websites",
        "data",
        "options",
        "Python",
        "modules",
        "requests",
        "urllib2",
        "web",
        "packages",
        "Beautiful",
        "Soup",
        "data",
        "writing",
        "data",
        "csv",
        "file",
        "formats",
        "Webservices",
        "development",
        "Python",
        "CherryPy",
        "Django",
        "SQLAlchemy",
        "reports",
        "application",
        "Tableau",
        "HTML5",
        "CSS3",
        "JavaScript",
        "Git",
        "REST",
        "API",
        "Mongo",
        "DB",
        "IntelliJIdea",
        "Design",
        "environment",
        "Mongo",
        "shards",
        "replica",
        "DevTest",
        "Production",
        "VPN",
        "Ubuntu",
        "Python",
        "Django",
        "Postgres",
        "Redis",
        "Bootstrap",
        "jQuery",
        "Mongo",
        "Git",
        "Tenjin",
        "Selenium",
        "Performed",
        "QA",
        "testing",
        "application",
        "approaches",
        "NLP",
        "pipeline",
        "custom",
        "VB",
        "scripts",
        "applications",
        "NLP",
        "File",
        "Prep",
        "SettlementPrepare",
        "review",
        "Settlement",
        "meetings",
        "client",
        "project",
        "help",
        "client",
        "Managed",
        "Hadoop",
        "log",
        "file",
        "SQL",
        "scripts",
        "solution",
        "process",
        "PySpark",
        "methods",
        "Create",
        "Read",
        "Update",
        "Delete",
        "CRUD",
        "Active",
        "Record",
        "Designing",
        "search",
        "application",
        "system",
        "requirements",
        "backend",
        "frontend",
        "Python",
        "user",
        "interface",
        "CSS",
        "HTML",
        "JavaScript",
        "jQuery",
        "GUI",
        "application",
        "Freight",
        "Tracking",
        "processing",
        "Django",
        "framework",
        "application",
        "development",
        "Excellent",
        "knowledge",
        "storages",
        "MapReduce",
        "Yarn",
        "Developed",
        "web",
        "tools",
        "effort",
        "efficiency",
        "Global",
        "Shipping",
        "Team",
        "testing",
        "framework",
        "commandline",
        "tests",
        "Linux",
        "Objected",
        "Oriented",
        "Perl",
        "tests",
        "Python",
        "Created",
        "database",
        "MySQL",
        "queries",
        "data",
        "database",
        "Setup",
        "Cron",
        "jobs",
        "data",
        "database",
        "graphs",
        "bar",
        "charts",
        "charts",
        "wiki",
        "database",
        "scripts",
        "Python",
        "data",
        "HTML",
        "file",
        "Environment",
        "MySQL",
        "HTML",
        "Python",
        "Django",
        "HTML5",
        "CSS",
        "XML",
        "MySQL",
        "MS",
        "SQL",
        "Server",
        "JavaScript",
        "Linux",
        "Shell",
        "Scripting",
        "AJAX",
        "urllib2",
        "Json",
        "CherryPy",
        "Unix",
        "Redis",
        "Bootstrap",
        "Mongo",
        "SQLAlchemy",
        "jQuery",
        "Python",
        "Developer",
        "NBC",
        "Universal",
        "December",
        "August",
        "Description",
        "NBC",
        "Universal",
        "Media",
        "LLC",
        "media",
        "entertainment",
        "company",
        "entertainment",
        "news",
        "information",
        "sports",
        "content",
        "audiences",
        "company",
        "segments",
        "Cable",
        "Networks",
        "Broadcast",
        "Television",
        "Filmed",
        "Entertainment",
        "Theme",
        "Parks",
        "Cable",
        "Networks",
        "segment",
        "portfolio",
        "cable",
        "television",
        "networks",
        "cable",
        "entertainment",
        "networks",
        "USA",
        "Network",
        "Syfy",
        "E",
        "Bravo",
        "Oxygen",
        "Sprout",
        "Esquire",
        "Network",
        "Chiller",
        "Universal",
        "HD",
        "Cloo",
        "cable",
        "news",
        "information",
        "networks",
        "MSNBC",
        "CNBC",
        "CNBC",
        "World",
        "Responsibilities",
        "Django",
        "Framework",
        "web",
        "applications",
        "model",
        "view",
        "controller",
        "architecture",
        "Exposure",
        "MultiThreading",
        "factory",
        "learning",
        "process",
        "worker",
        "processes",
        "delivery",
        "code",
        "principles",
        "Test",
        "Driven",
        "Development",
        "TDD",
        "integration",
        "line",
        "Agile",
        "Software",
        "Methodology",
        "testing",
        "methodologies",
        "unit",
        "testing",
        "Integration",
        "testing",
        "web",
        "application",
        "testing",
        "PythonDjango",
        "web",
        "application",
        "PostgreSQL",
        "DB",
        "integrations",
        "party",
        "emailmessaging",
        "storage",
        "services",
        "integration",
        "system",
        "Git",
        "Gerrit",
        "Jenkins",
        "MySQL",
        "custom",
        "tools",
        "Python",
        "Bash",
        "Design",
        "custom",
        "scripts",
        "use",
        "version",
        "controller",
        "Team",
        "Foundation",
        "Server",
        "TFS",
        "solutions",
        "science",
        "models",
        "dashboard",
        "control",
        "panel",
        "customers",
        "Administrators",
        "Django",
        "Oracle",
        "DB",
        "PostgreSQL",
        "configuration",
        "changes",
        "data",
        "models",
        "solutions",
        "points",
        "failure",
        "error",
        "handling",
        "communication",
        "failure",
        "Troubleshoot",
        "process",
        "execution",
        "team",
        "members",
        "part",
        "team",
        "managers",
        "staff",
        "goals",
        "project",
        "time",
        "Performed",
        "troubleshooting",
        "Python",
        "bug",
        "fixes",
        "applications",
        "source",
        "data",
        "customers",
        "customer",
        "service",
        "team",
        "Pandas",
        "library",
        "statistics",
        "Analysis",
        "datasets",
        "Panda",
        "data",
        "frames",
        "MySQL",
        "packages",
        "AON",
        "unit",
        "test",
        "data",
        "models",
        "Python",
        "modules",
        "requests",
        "urllib2",
        "web",
        "Developed",
        "GUI",
        "webapp2",
        "test",
        "block",
        "documentation",
        "features",
        "Python",
        "code",
        "web",
        "browser",
        "XML",
        "Schema",
        "documents",
        "framework",
        "XML",
        "documents",
        "testing",
        "methodologies",
        "unit",
        "testing",
        "Integration",
        "testing",
        "web",
        "application",
        "testing",
        "selenium",
        "testing",
        "Used",
        "Django",
        "framework",
        "application",
        "development",
        "user",
        "interface",
        "CSS",
        "HTML",
        "JavaScript",
        "jQuery",
        "Ruby",
        "rails",
        "reduction",
        "cost",
        "optimization",
        "supplier",
        "selection",
        "CRM",
        "Applications",
        "Debug",
        "custom",
        "software",
        "Windows",
        "Linux",
        "operating",
        "systems",
        "Professional",
        "ambition",
        "product",
        "user",
        "validations",
        "client",
        "side",
        "server",
        "side",
        "scripts",
        "performance",
        "calculations",
        "NumPy",
        "SQLAlchemy",
        "Interacted",
        "QA",
        "test",
        "plans",
        "highlevel",
        "design",
        "documentation",
        "Environment",
        "Python",
        "Django",
        "HTML5",
        "CSS",
        "XML",
        "MySQL",
        "JavaScript",
        "Angular",
        "JS",
        "Backbone",
        "JS",
        "jQuery",
        "CSS",
        "Bootstrap",
        "Mongo",
        "DB",
        "TSQL",
        "JavaScript",
        "Eclipse",
        "Git",
        "GitHub",
        "AWS",
        "Linux",
        "Shell",
        "Scripting",
        "Data",
        "AnalystData",
        "Modeler",
        "Accenture",
        "Bengaluru",
        "Karnataka",
        "May",
        "July",
        "Description",
        "Accenture",
        "PLC",
        "management",
        "consulting",
        "services",
        "company",
        "strategy",
        "technology",
        "operations",
        "Responsibilities",
        "end",
        "enterprise",
        "Applications",
        "Spring",
        "MVC",
        "REST",
        "JDBC",
        "Template",
        "Modules",
        "code",
        "Understanding",
        "issues",
        "challenges",
        "software",
        "development",
        "process",
        "practices",
        "Automated",
        "Build",
        "Test",
        "Deployment",
        "Developed",
        "design",
        "patterns",
        "data",
        "structures",
        "algorithms",
        "project",
        "tools",
        "Toad",
        "Eclipse",
        "SVN",
        "Apache",
        "Tomcat",
        "models",
        "APIs",
        "applications",
        "workflows",
        "User",
        "Interface",
        "technologies",
        "HTML5",
        "CSSSCSS",
        "procedure",
        "SQL",
        "queries",
        "project",
        "Deployed",
        "jar",
        "application",
        "server",
        "Automated",
        "Unit",
        "Tests",
        "FlexibleOpen",
        "Source",
        "Frameworks",
        "Multithreaded",
        "Transaction",
        "Handling",
        "code",
        "JMS",
        "Database",
        "Environment",
        "Java",
        "Spring",
        "MVC",
        "Hibernate",
        "MS",
        "HTML5",
        "CSSSCSS",
        "Junit",
        "Eclipse",
        "Tomcat",
        "Oracle",
        "Education",
        "Bachelors",
        "Skills",
        "HTML",
        "JAVASCRIPT",
        "BOOTSTRAP",
        "NODEJS",
        "PYTHON",
        "MATPLOTLIB",
        "NUMPY",
        "SCRIPTING",
        "XML",
        "DATABASE",
        "DB2",
        "MYSQL",
        "ORACLE",
        "PLSQL",
        "SQL",
        "SQLITE",
        "CSS",
        "SOA",
        "TOMCAT"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T21:18:57.439528",
    "resume_data": "Python Developer span lPythonspan span lDeveloperspan Python Developer IBM Remote Heidelberg PA Software Developer around 7 years of experience in software development with a deep understanding of technology trends with expertise in the core of complex technologies Skillful involvement in Python by developing softwares utilizing new tools libraries utilized Beautiful Soup NumPy SciPy PySide Pandas Requests xmltodict Matplotlib Pickle Pandas data frame urllib3 MySQL DB to improve software development process Experience in developing Web Services SOAP Restful APIs in Python using XML and JAVA Experience in working with various version control systems like GIT CVS and SVN Hands on experience in developing business processes and system solutions utilizing prototype development system development and deployment Experience in using editors like Eclipse sublime text NetBeans PyCharm PyScripter Spyder PyStudio and PyDev Used Django evolution and manual SQL modifications to retain all the data while the site is in production Experience in Linux Bash Scripting and PEP guidelines in python Expertise in developing webbased open stack applications for large dataset analysis using Python and Django Used Python Unit test framework for developing and implementing the unit tests using Test driven approach Analyzed instrument pricing and modeling methodologies and documented how instrument prices move as a change in the market data source Good Hands on experience in establishing connections for Java and Python by configuring packages like MySQL Python JDBC Hands on experience in monitoring developing and transforming data using SQL Server Integration ServiceSSIS and SQL Service Analysis ServiceSSAS Experienced in writing custom queries through database connectors Hands on experience with databases using ORMsDOMs for integrating with Oracle MySQL PostgreSQL Good knowledge in working with Webapplication server Apache Tomcat 60 70 80 Tornado CherryPy Experienced with Object Oriented design methodology and Agile Methodology in software development Used Pandas API to put the data as time series and tabular form for east timestamp data retrieval and manipulation and for statistical analysis Authorized to work in the US for any employer Work Experience Python Developer IBM Remote January 2018 to Present Description The International Business Machines Corporation is an American multinational technology company headquartered in Armonk New York United States with operations in over 170 countries IBM manufactures and markets computer hardware middleware and software and provides hosting and consulting services in areas ranging from mainframe computers to nanotechnology Responsibilities Developed Speech to text conversion using Google API Developed a script which can convert JSON to CSV Used pandas to convert a Python list of sentences to a series object using tolist method Extracting data using regex and validations Worked with Latin characters using unidecode and simplejson libraries as a json decoder which can handles Unicode characters libraries Used Unidcode to decode the Unicode string Worked on xml parser file Developed codes which can fetch the data from two different REST APIs and update the list of contact information in the desired API Developed a different class which can perform adddelete members functionalities Used requests library to access the information from APIs using get request method Authorizing the APIs using HTTP BasicAuth library Passing the arguments from command line to pull out the data based on modified date Using my script as a base and inheriting the client file to access the APIs URLs and client credentials from property file Creating a new IBM Blue Pages group where user can store all his personal information Accessing that created groups and giving access that group API to invoke to other users and use the information on demand Involved in mapping the data from CSV and updating the list of data in API using REST services Setting up the IBM Data Science Experience in local machines Created Jupyter notebook under DSX and executed the scripts by splitting the code as per the requirement Involved in the execution of CSV files in Data Science Experience Major part is like being a part of the project importing the converted CSV file to IBM internal API which is InfoSphere Information Governance Catalog Experienced with GIT version control and deployed the project to DSX Knowledgeable with GIT version control Written a wrapper class that will allow any group to update list of usernames based on demand using property file with CSV Updating the information in JIRA with required details and uploading necessary information to finish that particular story Supporting my team members in performance testing using JMeter and running the scripts in parallel Environment Python 37 JavaScript CSV JSON JIRA DSX Jupyter HTTPBasicAuth Pandas GitHub Requests xmltodict HTTP BasicAuth Python Engineer Nike OR May 2017 to December 2017 Description Nike is an American multinational corporation that is engaged in the design development manufacturing and worldwide marketing and sales of footwear apparel equipment accessories and services It is the worlds largest supplier of athletic shoes and apparel and a major manufacturer of sports equipment Responsibilities Converted data from PDF to XML using python script in two ways ie from raw xml to processed xml and from processed xml to CSV files Developing a generic script for the regulatory documents Used python Element Tree ET to parse through the XML which is derived from PDF files Data which is stored in sqlite3 data file db were accessed using the python and extracted the metadata tables and data from tables and converted the tables to respective CSV tables Used the XML tags and attributes to isolate headings sideheadings and subheadings to each row in CSV file Converted data from HTML to XML for couple of PDF regulatory documents Used Beautiful Soup for web scraping Parsing the data Developed the code to capture the description which comes under headings of index section to the description column of CSV row Used some other python libraries like PDFMiner PyPDF2 PDF Query and Sqlite3 Converted the Unicode to nearest possible string ASCII value using Unidecode module Adding a column to each CSV row which gives the parent Index number of the given row Examined framework determined specifications and had client interaction with requirements specifications Used Pandas API to put the data as time series and tabular format for east timestamp data manipulation and retrieval Experience on Jenkins continuous integration CI tool for deployment of the project Used MySQL database for simple queries and writing Stored Procedures for normalization and denormalization Involved in development of Web Services using SOAP for sending and getting data from the external interface in the XML format Experience in using collections in Python for manipulating and looping through different userdefined objects Knowledge of Test Driven Development TDD Pair Programming with PyUnit Junit and PythonUnittest Used Pandas API to put the data as time series and tabular format for east timestamp data manipulation and retrieval Executed MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Generated Python Django Forms to record data of online users Used Python and Django creating graphics XML processing data exchange and business logic implementation Designed and developed communication between client and server using Secured Web services such as Djangorestframework Documented the design solutions and created stories for client requirements Utilized Python libraries like NumPy and Matplotlib for generating graphical reports Build SQL queries for performing various CRUD operations like create update read and delete Experience in working with a team of developers on python applications for RISK management Improved code reuse and performance by making effective use of various design patterns Environment Python27 35 HTML5 CSS JavaScript AJAX JSON JIRA Django REST API jQuery MS Access MS SQL Server GitHub Shell Scripting Python Developer AMEX NY New York NY September 2016 to April 2017 Description The American Express Company also known as Amex is an American multinational financial services corporation headquartered in Three World Financial Center in New York City Project developed was a Business Tool focused to expand the customer base Its a web based application which send emails to all the registered users on the deals and new products which are placed on the web and also predicting the values upon the matriculations Responsibilities Wrote Python routines to log into the websites and fetch data for selected options Used Python modules such as requests urllib urllib2 for web crawling Used other packages such as Beautiful Soup for data parsing Worked on writing and as well as read data from csv and excel file formats Webservices backend development using Python CherryPy Django SQLAlchemy Worked on resulting reports of the application and Tableau reports Worked on HTML5 CSS3 JavaScript Git REST API Mongo DB IntelliJIdea Design and Setting up of the environment of Mongo dB with shards and replica sets DevTest and Production Private VPN using Ubuntu Python Django Postgres Redis Bootstrap jQuery Mongo Git Tenjin Selenium Performed QA testing on the application Developed approaches for improving NLP pipeline Create custom VB scripts for repackaging applications as needed NLP File Prep SettlementPrepare files for review for Settlement Held meetings with client and worked all alone for the entire project with limited help from the client Managed and reviewed Hadoop log file and worked in analyzing SQL scripts and designed the solution for the process using PySpark Actively involved in developing the methods for Create Read Update and Delete CRUD in Active Record Designing mobile search application system requirements and coded backend and frontend in Python Developed rich user interface using CSS HTML JavaScript and jQuery Created a Pythonbased GUI application For Freight Tracking and processing Used Django framework for application development Excellent knowledge of distributed storages HDFS and distributed processing MapReduce Yarn Developed and maintained various automated web tools for reducing manual effort and increasing efficiency of the Global Shipping Team Developed an automated testing framework for commandline based tests on Linux using Objected Oriented Perl and for seleniumbased tests using Python Created database using MySQL wrote several queries to extract data from the database Setup automated Cron jobs to upload data into the database generate graphs bar charts upload these charts to the wiki and backup the database Wrote scripts in Python for extracting data from HTML file Environment MySQL HTML Python Django HTML5 CSS XML MySQL MS SQL Server JavaScript AWS Linux Shell Scripting AJAX urllib urllib2 Json CherryPy Unix Redis Bootstrap Mongo dB SQLAlchemy jQuery Python Developer NBC Universal December 2015 to August 2016 Description NBC Universal Media LLC a media and entertainment company develops produces and distributes entertainment news and information sports and other content for audiences worldwide The company operates in four segments Cable Networks Broadcast Television Filmed Entertainment and Theme Parks The Cable Networks segment offers a portfolio of cable television networks including national cable entertainment networks such as USA Network Syfy E Bravo Oxygen Sprout Esquire Network Chiller Universal HD and Cloo national cable news and information networks comprising MSNBC CNBC and CNBC World Responsibilities Django Framework that was used in developing web applications to implement the model view controller architecture Exposure to MultiThreading factory to distribute learning process backtesting and the into various worker processes Performed efficient delivery of code based on principles of Test Driven Development TDD and continuous integration to keep in line with Agile Software Methodology principles Different testing methodologies like unit testing Integration testing web application testing PythonDjango based web application PostgreSQL DB and integrations with 3rd party emailmessaging storage services Developed a fully automated continuous integration system using Git Gerrit Jenkins MySQL and custom tools developed in Python and Bash Design and implement custom scripts Extensive use of version controller Team Foundation Server TFS Delivered automated solutions for science models Managed developed and designed a dashboard control panel for customers and Administrators using Django Oracle DB and PostgreSQL Implemented configuration changes for data models Maintained and updated existing automated solutions Handled potential points of failure through error handling and communication of failure Troubleshoot the process execution and worked with other team members to correct them Actively worked as a part of a team with managers and other staff to meet the goals of the project in the stipulated time Performed troubleshooting fixed and deployed many Python bug fixes of the two main applications that were the main source of data for both customers and internal customer service team Used Pandas library for statistics Analysis Managed large datasets using Panda data frames and MySQL Used advanced packages in AON PATHWISE for performing the unit test and deploying data models Extensively used Python modules such as requests urllib urllib2 for web crawling Developed GUI using webapp2 for dynamically displaying the test block documentation and other features of Python code using a web browser Developed the required XML Schema documents and implemented the framework for parsing XML documents Different testing methodologies like unit testing Integration testing web application testing selenium testing was performed Used Django framework for application development Developed user interface using CSS HTML JavaScript and jQuery Ruby on rails Assisted in the reduction of cost and optimization of supplier selection for the CRM Applications Debug of custom software running on Windows and Linux operating systems Professional minded with the ambition to advance both the product as well as themselves Responsible for user validations on client side as well as server side Automated the existing scripts for performance calculations using NumPy and SQLAlchemy Interacted with QA to develop test plans for highlevel design documentation Environment Python 27 Django 14 HTML5 CSS XML MySQL JavaScript Angular JS Backbone JS jQuery CSS Bootstrap Mongo DB TSQL JavaScript Eclipse Git GitHub AWS Linux Shell Scripting Data AnalystData Modeler Accenture Bengaluru Karnataka May 2012 to July 2015 Description Accenture PLC is a global management consulting and professional services company that provides strategy consulting digital technology and operations Responsibilities Developed end to end enterprise Applications using Spring MVC REST and JDBC Template Modules Written well designed testable efficient java code Understanding and analyzing complex issues and addressing challenges arising during the software development process both conceptually and technically Implemented best practices of Automated Build Test and Deployment Developed design patterns data structures and algorithms based on project need Worked on multiple tools such as Toad Eclipse SVN Apache and Tomcat Deployed models via APIs into applications or workflows Worked on User Interface technologies like HTML5 CSSSCSS Wrote Stored procedure and SQL queries based on project need Deployed built jar into application server Created Automated Unit Tests using FlexibleOpen Source Frameworks Developed Multithreaded and Transaction Handling code JMS Database Environment Java Spring MVC Hibernate MS HTML5 CSSSCSS Junit Eclipse Tomcat and Oracle Education Bachelors Skills HTML JAVASCRIPT BOOTSTRAP NODEJS PYTHON MATPLOTLIB NUMPY PANDAS SCRIPTING XML DATABASE DB2 MYSQL ORACLE PLSQL SQL SQLITE CSS SOA TOMCAT",
    "unique_id": "faf4d451-cdce-4968-a754-027ef9f362f9"
}