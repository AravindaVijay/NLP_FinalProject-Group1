{
    "clean_data": "Database Consultant span lDatabasespan Consultant Database Consultant Coppell TX Multi skilled professional with track record of managing complex projects in various environments 10 years in Information Technology with expertise in Database design development and maintenance of complex data related applications Exposure in overall SDLC including requirement gathering development testing debugging deployment documentation production support and Extensive experience in Project Management methodologies Experience in extracting transforming and loading ETL data from spreadsheets database tables and other sources using PLSQL Informatica ODIOWB Work Experience Database Consultant BNP Paribas Consulting Jersey City May 2018 to September 2018 Worked on the REG YY reporting project This is part of the FED reporting requirement Designed the entire project from the ground up and developed the data model required for the project Developed the detailed data flow and lineage documents to understand the data from all the source system Developed the ETL process to load the data and transform it to the requirements of the REG YY reports Developed the tableau report to show the trends and also any discrepancies in the data balances assetliability and net funding ratios with reference to the corresponding last 1 year data Informatica Administrator at Charles Schwab Infosys Dallas TX February 2018 to May 2018 Administered the DEV and PROD informatics system Verified all the pre deployment checklists before signing off for the production deployment Deployed the mappings and workflows into the Production system Onboarded new applications onto informatics by creating the necessary project related artifacts and defining the user access and creating the necessary connections Worked on setting up the parallel infrastructure in the Disaster recovery site Database Consultant BNP Paribas Consulting Jersey City October 2015 to November 2017 Architect the data consolidation from various source systems to feed into Feds Reporting system to generate the 5G Liquidity and collateral reports Wrote an exhaustive pre validation process to capture all possible XML validation errors based on the XML schema defined by the Feds Worked on the data quality data transformation and data encryption module to send the data to IntelliMatch system which is netting engine and QRM which is a cashflow forecasting engine Designed and developed the traceability features in key reports to help trace the data back to its origin This was needed for the Audit purpose This helped managers to answer the audit related questions very easily and quickly Before this it would take weeks to handle these questions Developed Oracle ODI scripts to integrate data from various sources Earlier the integration was handled thru PLSQL scripts and Informatica workflows Moving to ODI improved the turnaround time and also the visibility of how the data integration was moving along Data analyst and Developer Bank Of America Consulting Jersey City March 2015 to October 2015 Worked on designing and developing Actimize model to track solicited parties trades and generating alert reports for the compliance officers Worked with Informatica ETL team to get the data needed for the solicited party surveillance Developed complex procedures to support the business logic of the surveillance models Did the data analysis on the source data to verify that the date requirements for the model is fulfilled Streamlined the existing code to make it more efficient by removing redundancy and consolidated multiple inserts and deletes on the same object Developed the project specific documents like scopingassessment high level definition and low level definition and got the buy in from the stakeholders Worked with the QAUAT team and developed mock data to test all the aspects of the model Data Developer Credit Suisse Consulting New York NY October 2013 to January 2015 Managed the database related operations of the reference data hub Reference data provides the golden source for all the reporting and compliance purpose Created data governance and data privacy policy and implemented data obfuscation to hide sensitive data Led an engagement to review poorly performing reports and feed generations there by reducing the daily batch time Designed and reviewed all the database related changes to make sure they are compliant with the SOX standards and the project coding standards Performed root cause analysis to fix the service interruptions and provided permanent fix As part of the organic data growth and retention policy implemented the data compression on all the historical partitions which resulted in saving space and at the same time making historical data available online Forecasted the data growth as part of the space management and data availability Led a project to move the data transfers to all the downstream applications to use the secure FTPS Lead database developer HoffmannLa Roche Inc October 2002 to October 2013 Designed and developed data model for the ELN applications Developed PLSQL based integration process created database packages and procedures to handle complex business logic and used the latest constructs like multi table inserts merge operations pipelined functions analytical functions and bulk collect Developed PLSQL based ETL to extract data from variety of sources for the Kinase data mart The sources where protein database MySQL chemistry database and flat files provided by the vendor The ETL also extracts the protein structure and chemical structure and also the associated graph calculations and documents Served as a lead ETL Informatica developer in the enhancement of an existing ETL frame work that collected and cleansed and integrated the companys research data The entire project was migrated to Informatica Power Center Interfaced with the MDM systems for getting the proper biology and chemical terms to validate the data The enhancements were part of the overall initiative to improve the existing process This improved the overall cycle time and data quality The source was Electronic Lab Notebooks ELN which was accessible using web service and from different geographic locations Used analytical functions for aggregating the data and loading into summary table Created materialized views on the summary table for fast access from the UI applications Tuned PLSQL and SQL performance using the dbms_profiler v views execution plan and statistics Developed an ELN plug in to get the chemical properties of a compound It makes a web service call to the chemistry database calculates molecular weight and other formulas and stores in the ELN Developed a submission module for chemistry ELN Chemist can request for mass spectrometer and chromatography for their compound Uses web service to create a new request in the lab database and returns a URL for the chemist to monitor the progress Automated all the routine jobs using Informatica workflow scheduler UNIX scripts and Oracle scheduler Documented all the complex ETL processes explaining the SourceTarget data sets the data flow diagr ams transformation mappings and quality checkconstraints that are performed Position Held Sr Systems Analyst Worked as a production support lead to maintain a large data warehousing system Developed and enhanced the existing ETL process Analyzed the data issue quality issues and availability issues and worked with the stakeholders to resolve the issues Developed several scripts to automate most of the critical reporting tasks and developed a dashboard to track the progressstatus of several processes This helped the global team to easily track their data and correct the problem and maintain the agreed upon SLA of 24 hours Took up the responsibility of maintaining and developing the content management website from the vendor thereby saving 15000000 to the company Supervised and trained new members in support processes and activities and enhanced the onboarding process Education BE in Computer Science and Engineering Marathwada University Links httpwwwlinkedincominjayvajramani Additional Information Database Oracle 12c 11 10 9 in RAC clusters Modeling tool ERWin ETL Tools Informatica Power Center PLSQL Oracle Warehouse Builder Oracle ODI BI Tools Business Objects LanguagesScripts J2EE JSF Perl UNIX Scripts PLSQL and ProC Source Control CVS SVN SourceSafe WebApp Server Apache Microsoft IIS Scheduling ControlM and Autosys",
    "entities": [
        "QRM",
        "PROD",
        "Data Developer Credit Suisse Consulting",
        "Audit",
        "Position Held Sr Systems",
        "MDM",
        "ETL",
        "Developed",
        "Informatica",
        "Database",
        "RAC",
        "New York",
        "ProC Source Control CVS SVN",
        "Dallas",
        "G Liquidity",
        "Information Technology",
        "Created",
        "UNIX",
        "SourceTarget",
        "DEV",
        "UI",
        "Oracle",
        "HoffmannLa Roche Inc",
        "Microsoft",
        "Project Management",
        "Feds Reporting",
        "ERWin",
        "Jersey City",
        "Developer Bank Of America Consulting",
        "the Feds Worked",
        "Charles Schwab Infosys",
        "SQL",
        "Data",
        "XML",
        "Informatica Power Center PLSQL Oracle Warehouse Builder Oracle ODI BI Tools Business",
        "SOX",
        "Informatica Administrator",
        "Modeling",
        "Autosys",
        "Informatica Power Center Interfaced",
        "TX",
        "FED",
        "REG YY",
        "Actimize"
    ],
    "experience": "Experience in extracting transforming and loading ETL data from spreadsheets database tables and other sources using PLSQL Informatica ODIOWB Work Experience Database Consultant BNP Paribas Consulting Jersey City May 2018 to September 2018 Worked on the REG YY reporting project This is part of the FED reporting requirement Designed the entire project from the ground up and developed the data model required for the project Developed the detailed data flow and lineage documents to understand the data from all the source system Developed the ETL process to load the data and transform it to the requirements of the REG YY reports Developed the tableau report to show the trends and also any discrepancies in the data balances assetliability and net funding ratios with reference to the corresponding last 1 year data Informatica Administrator at Charles Schwab Infosys Dallas TX February 2018 to May 2018 Administered the DEV and PROD informatics system Verified all the pre deployment checklists before signing off for the production deployment Deployed the mappings and workflows into the Production system Onboarded new applications onto informatics by creating the necessary project related artifacts and defining the user access and creating the necessary connections Worked on setting up the parallel infrastructure in the Disaster recovery site Database Consultant BNP Paribas Consulting Jersey City October 2015 to November 2017 Architect the data consolidation from various source systems to feed into Feds Reporting system to generate the 5 G Liquidity and collateral reports Wrote an exhaustive pre validation process to capture all possible XML validation errors based on the XML schema defined by the Feds Worked on the data quality data transformation and data encryption module to send the data to IntelliMatch system which is netting engine and QRM which is a cashflow forecasting engine Designed and developed the traceability features in key reports to help trace the data back to its origin This was needed for the Audit purpose This helped managers to answer the audit related questions very easily and quickly Before this it would take weeks to handle these questions Developed Oracle ODI scripts to integrate data from various sources Earlier the integration was handled thru PLSQL scripts and Informatica workflows Moving to ODI improved the turnaround time and also the visibility of how the data integration was moving along Data analyst and Developer Bank Of America Consulting Jersey City March 2015 to October 2015 Worked on designing and developing Actimize model to track solicited parties trades and generating alert reports for the compliance officers Worked with Informatica ETL team to get the data needed for the solicited party surveillance Developed complex procedures to support the business logic of the surveillance models Did the data analysis on the source data to verify that the date requirements for the model is fulfilled Streamlined the existing code to make it more efficient by removing redundancy and consolidated multiple inserts and deletes on the same object Developed the project specific documents like scopingassessment high level definition and low level definition and got the buy in from the stakeholders Worked with the QAUAT team and developed mock data to test all the aspects of the model Data Developer Credit Suisse Consulting New York NY October 2013 to January 2015 Managed the database related operations of the reference data hub Reference data provides the golden source for all the reporting and compliance purpose Created data governance and data privacy policy and implemented data obfuscation to hide sensitive data Led an engagement to review poorly performing reports and feed generations there by reducing the daily batch time Designed and reviewed all the database related changes to make sure they are compliant with the SOX standards and the project coding standards Performed root cause analysis to fix the service interruptions and provided permanent fix As part of the organic data growth and retention policy implemented the data compression on all the historical partitions which resulted in saving space and at the same time making historical data available online Forecasted the data growth as part of the space management and data availability Led a project to move the data transfers to all the downstream applications to use the secure FTPS Lead database developer HoffmannLa Roche Inc October 2002 to October 2013 Designed and developed data model for the ELN applications Developed PLSQL based integration process created database packages and procedures to handle complex business logic and used the latest constructs like multi table inserts merge operations pipelined functions analytical functions and bulk collect Developed PLSQL based ETL to extract data from variety of sources for the Kinase data mart The sources where protein database MySQL chemistry database and flat files provided by the vendor The ETL also extracts the protein structure and chemical structure and also the associated graph calculations and documents Served as a lead ETL Informatica developer in the enhancement of an existing ETL frame work that collected and cleansed and integrated the companys research data The entire project was migrated to Informatica Power Center Interfaced with the MDM systems for getting the proper biology and chemical terms to validate the data The enhancements were part of the overall initiative to improve the existing process This improved the overall cycle time and data quality The source was Electronic Lab Notebooks ELN which was accessible using web service and from different geographic locations Used analytical functions for aggregating the data and loading into summary table Created materialized views on the summary table for fast access from the UI applications Tuned PLSQL and SQL performance using the dbms_profiler v views execution plan and statistics Developed an ELN plug in to get the chemical properties of a compound It makes a web service call to the chemistry database calculates molecular weight and other formulas and stores in the ELN Developed a submission module for chemistry ELN Chemist can request for mass spectrometer and chromatography for their compound Uses web service to create a new request in the lab database and returns a URL for the chemist to monitor the progress Automated all the routine jobs using Informatica workflow scheduler UNIX scripts and Oracle scheduler Documented all the complex ETL processes explaining the SourceTarget data sets the data flow diagr ams transformation mappings and quality checkconstraints that are performed Position Held Sr Systems Analyst Worked as a production support lead to maintain a large data warehousing system Developed and enhanced the existing ETL process Analyzed the data issue quality issues and availability issues and worked with the stakeholders to resolve the issues Developed several scripts to automate most of the critical reporting tasks and developed a dashboard to track the progressstatus of several processes This helped the global team to easily track their data and correct the problem and maintain the agreed upon SLA of 24 hours Took up the responsibility of maintaining and developing the content management website from the vendor thereby saving 15000000 to the company Supervised and trained new members in support processes and activities and enhanced the onboarding process Education BE in Computer Science and Engineering Marathwada University Links httpwwwlinkedincominjayvajramani Additional Information Database Oracle 12c 11 10 9 in RAC clusters Modeling tool ERWin ETL Tools Informatica Power Center PLSQL Oracle Warehouse Builder Oracle ODI BI Tools Business Objects LanguagesScripts J2EE JSF Perl UNIX Scripts PLSQL and ProC Source Control CVS SVN SourceSafe WebApp Server Apache Microsoft IIS Scheduling ControlM and Autosys",
    "extracted_keywords": [
        "Database",
        "Consultant",
        "span",
        "lDatabasespan",
        "Consultant",
        "Database",
        "Consultant",
        "Coppell",
        "TX",
        "Multi",
        "professional",
        "track",
        "record",
        "projects",
        "environments",
        "years",
        "Information",
        "Technology",
        "expertise",
        "Database",
        "design",
        "development",
        "maintenance",
        "data",
        "applications",
        "Exposure",
        "SDLC",
        "requirement",
        "development",
        "testing",
        "deployment",
        "documentation",
        "production",
        "support",
        "experience",
        "Project",
        "Management",
        "methodologies",
        "Experience",
        "transforming",
        "loading",
        "ETL",
        "data",
        "spreadsheets",
        "database",
        "tables",
        "sources",
        "PLSQL",
        "Informatica",
        "ODIOWB",
        "Work",
        "Experience",
        "Database",
        "Consultant",
        "BNP",
        "Paribas",
        "Consulting",
        "Jersey",
        "City",
        "May",
        "September",
        "REG",
        "YY",
        "reporting",
        "project",
        "part",
        "FED",
        "reporting",
        "requirement",
        "project",
        "ground",
        "data",
        "model",
        "project",
        "data",
        "flow",
        "lineage",
        "documents",
        "data",
        "source",
        "system",
        "ETL",
        "process",
        "data",
        "requirements",
        "REG",
        "YY",
        "reports",
        "tableau",
        "report",
        "trends",
        "discrepancies",
        "data",
        "balances",
        "assetliability",
        "funding",
        "ratios",
        "reference",
        "year",
        "data",
        "Informatica",
        "Administrator",
        "Charles",
        "Schwab",
        "Infosys",
        "Dallas",
        "TX",
        "February",
        "May",
        "DEV",
        "informatics",
        "system",
        "deployment",
        "checklists",
        "production",
        "deployment",
        "mappings",
        "workflows",
        "Production",
        "system",
        "applications",
        "informatics",
        "project",
        "artifacts",
        "user",
        "access",
        "connections",
        "infrastructure",
        "Disaster",
        "recovery",
        "site",
        "Database",
        "Consultant",
        "BNP",
        "Paribas",
        "Consulting",
        "Jersey",
        "City",
        "October",
        "November",
        "data",
        "consolidation",
        "source",
        "systems",
        "Feds",
        "Reporting",
        "system",
        "G",
        "Liquidity",
        "reports",
        "validation",
        "process",
        "XML",
        "validation",
        "errors",
        "XML",
        "schema",
        "Feds",
        "data",
        "quality",
        "data",
        "transformation",
        "data",
        "encryption",
        "module",
        "data",
        "IntelliMatch",
        "system",
        "engine",
        "QRM",
        "forecasting",
        "engine",
        "traceability",
        "features",
        "reports",
        "data",
        "origin",
        "Audit",
        "purpose",
        "managers",
        "audit",
        "questions",
        "weeks",
        "questions",
        "Oracle",
        "ODI",
        "scripts",
        "data",
        "sources",
        "integration",
        "PLSQL",
        "scripts",
        "Informatica",
        "ODI",
        "turnaround",
        "time",
        "visibility",
        "data",
        "integration",
        "Data",
        "analyst",
        "Developer",
        "Bank",
        "America",
        "Consulting",
        "Jersey",
        "City",
        "March",
        "October",
        "Actimize",
        "model",
        "parties",
        "trades",
        "alert",
        "reports",
        "compliance",
        "officers",
        "Informatica",
        "ETL",
        "team",
        "data",
        "party",
        "surveillance",
        "procedures",
        "business",
        "logic",
        "surveillance",
        "models",
        "data",
        "analysis",
        "source",
        "data",
        "date",
        "requirements",
        "model",
        "code",
        "redundancy",
        "inserts",
        "deletes",
        "object",
        "project",
        "documents",
        "level",
        "definition",
        "level",
        "definition",
        "buy",
        "stakeholders",
        "team",
        "data",
        "aspects",
        "model",
        "Data",
        "Developer",
        "Credit",
        "Suisse",
        "Consulting",
        "New",
        "York",
        "NY",
        "October",
        "January",
        "database",
        "operations",
        "reference",
        "data",
        "hub",
        "Reference",
        "data",
        "source",
        "reporting",
        "compliance",
        "purpose",
        "data",
        "governance",
        "data",
        "privacy",
        "policy",
        "data",
        "obfuscation",
        "data",
        "engagement",
        "reports",
        "feed",
        "generations",
        "batch",
        "time",
        "database",
        "changes",
        "SOX",
        "standards",
        "project",
        "standards",
        "Performed",
        "root",
        "analysis",
        "service",
        "interruptions",
        "fix",
        "part",
        "data",
        "growth",
        "retention",
        "policy",
        "data",
        "compression",
        "partitions",
        "space",
        "time",
        "data",
        "Forecasted",
        "data",
        "growth",
        "part",
        "space",
        "management",
        "data",
        "availability",
        "project",
        "data",
        "transfers",
        "applications",
        "FTPS",
        "Lead",
        "database",
        "developer",
        "HoffmannLa",
        "Roche",
        "Inc",
        "October",
        "October",
        "data",
        "model",
        "ELN",
        "applications",
        "integration",
        "process",
        "database",
        "packages",
        "procedures",
        "business",
        "logic",
        "constructs",
        "multi",
        "table",
        "inserts",
        "operations",
        "functions",
        "functions",
        "bulk",
        "Developed",
        "PLSQL",
        "ETL",
        "data",
        "variety",
        "sources",
        "Kinase",
        "data",
        "mart",
        "sources",
        "protein",
        "database",
        "MySQL",
        "chemistry",
        "database",
        "files",
        "vendor",
        "ETL",
        "protein",
        "structure",
        "chemical",
        "structure",
        "graph",
        "calculations",
        "documents",
        "lead",
        "ETL",
        "Informatica",
        "developer",
        "enhancement",
        "ETL",
        "frame",
        "work",
        "companys",
        "research",
        "data",
        "project",
        "Informatica",
        "Power",
        "Center",
        "MDM",
        "systems",
        "biology",
        "chemical",
        "terms",
        "data",
        "enhancements",
        "part",
        "initiative",
        "process",
        "cycle",
        "time",
        "data",
        "quality",
        "source",
        "Lab",
        "Notebooks",
        "ELN",
        "web",
        "service",
        "locations",
        "functions",
        "data",
        "loading",
        "summary",
        "table",
        "Created",
        "views",
        "summary",
        "table",
        "access",
        "UI",
        "applications",
        "PLSQL",
        "SQL",
        "performance",
        "dbms_profiler",
        "v",
        "views",
        "execution",
        "plan",
        "statistics",
        "ELN",
        "plug",
        "properties",
        "compound",
        "web",
        "service",
        "call",
        "chemistry",
        "database",
        "weight",
        "formulas",
        "stores",
        "ELN",
        "submission",
        "module",
        "chemistry",
        "ELN",
        "Chemist",
        "spectrometer",
        "chromatography",
        "compound",
        "Uses",
        "web",
        "service",
        "request",
        "lab",
        "database",
        "URL",
        "chemist",
        "progress",
        "jobs",
        "Informatica",
        "workflow",
        "UNIX",
        "scripts",
        "Oracle",
        "scheduler",
        "ETL",
        "processes",
        "SourceTarget",
        "data",
        "data",
        "flow",
        "diagr",
        "transformation",
        "mappings",
        "quality",
        "checkconstraints",
        "Position",
        "Held",
        "Sr",
        "Systems",
        "Analyst",
        "production",
        "support",
        "data",
        "warehousing",
        "system",
        "ETL",
        "process",
        "data",
        "issue",
        "quality",
        "issues",
        "availability",
        "issues",
        "stakeholders",
        "issues",
        "scripts",
        "reporting",
        "tasks",
        "dashboard",
        "progressstatus",
        "processes",
        "team",
        "data",
        "problem",
        "SLA",
        "hours",
        "responsibility",
        "content",
        "management",
        "website",
        "vendor",
        "company",
        "members",
        "support",
        "processes",
        "activities",
        "onboarding",
        "process",
        "Education",
        "Computer",
        "Science",
        "Engineering",
        "Marathwada",
        "University",
        "Links",
        "Additional",
        "Information",
        "Database",
        "Oracle",
        "RAC",
        "clusters",
        "Modeling",
        "tool",
        "ERWin",
        "ETL",
        "Tools",
        "Informatica",
        "Power",
        "Center",
        "PLSQL",
        "Oracle",
        "Warehouse",
        "Builder",
        "Oracle",
        "ODI",
        "BI",
        "Tools",
        "Business",
        "LanguagesScripts",
        "J2EE",
        "JSF",
        "Perl",
        "UNIX",
        "Scripts",
        "PLSQL",
        "ProC",
        "Source",
        "Control",
        "CVS",
        "SVN",
        "SourceSafe",
        "WebApp",
        "Server",
        "Apache",
        "Microsoft",
        "IIS",
        "Scheduling",
        "ControlM",
        "Autosys"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T21:31:25.584566",
    "resume_data": "Database Consultant span lDatabasespan Consultant Database Consultant Coppell TX Multi skilled professional with track record of managing complex projects in various environments 10 years in Information Technology with expertise in Database design development and maintenance of complex data related applications Exposure in overall SDLC including requirement gathering development testing debugging deployment documentation production support and Extensive experience in Project Management methodologies Experience in extracting transforming and loading ETL data from spreadsheets database tables and other sources using PLSQL Informatica ODIOWB Work Experience Database Consultant BNP Paribas Consulting Jersey City May 2018 to September 2018 Worked on the REG YY reporting project This is part of the FED reporting requirement Designed the entire project from the ground up and developed the data model required for the project Developed the detailed data flow and lineage documents to understand the data from all the source system Developed the ETL process to load the data and transform it to the requirements of the REG YY reports Developed the tableau report to show the trends and also any discrepancies in the data balances assetliability and net funding ratios with reference to the corresponding last 1 year data Informatica Administrator at Charles Schwab Infosys Dallas TX February 2018 to May 2018 Administered the DEV and PROD informatics system Verified all the pre deployment checklists before signing off for the production deployment Deployed the mappings and workflows into the Production system Onboarded new applications onto informatics by creating the necessary project related artifacts and defining the user access and creating the necessary connections Worked on setting up the parallel infrastructure in the Disaster recovery site Database Consultant BNP Paribas Consulting Jersey City October 2015 to November 2017 Architect the data consolidation from various source systems to feed into Feds Reporting system to generate the 5G Liquidity and collateral reports Wrote an exhaustive pre validation process to capture all possible XML validation errors based on the XML schema defined by the Feds Worked on the data quality data transformation and data encryption module to send the data to IntelliMatch system which is netting engine and QRM which is a cashflow forecasting engine Designed and developed the traceability features in key reports to help trace the data back to its origin This was needed for the Audit purpose This helped managers to answer the audit related questions very easily and quickly Before this it would take weeks to handle these questions Developed Oracle ODI scripts to integrate data from various sources Earlier the integration was handled thru PLSQL scripts and Informatica workflows Moving to ODI improved the turnaround time and also the visibility of how the data integration was moving along Data analyst and Developer Bank Of America Consulting Jersey City March 2015 to October 2015 Worked on designing and developing Actimize model to track solicited parties trades and generating alert reports for the compliance officers Worked with Informatica ETL team to get the data needed for the solicited party surveillance Developed complex procedures to support the business logic of the surveillance models Did the data analysis on the source data to verify that the date requirements for the model is fulfilled Streamlined the existing code to make it more efficient by removing redundancy and consolidated multiple inserts and deletes on the same object Developed the project specific documents like scopingassessment high level definition and low level definition and got the buy in from the stakeholders Worked with the QAUAT team and developed mock data to test all the aspects of the model Data Developer Credit Suisse Consulting New York NY October 2013 to January 2015 Managed the database related operations of the reference data hub Reference data provides the golden source for all the reporting and compliance purpose Created data governance and data privacy policy and implemented data obfuscation to hide sensitive data Led an engagement to review poorly performing reports and feed generations there by reducing the daily batch time Designed and reviewed all the database related changes to make sure they are compliant with the SOX standards and the project coding standards Performed root cause analysis to fix the service interruptions and provided permanent fix As part of the organic data growth and retention policy implemented the data compression on all the historical partitions which resulted in saving space and at the same time making historical data available online Forecasted the data growth as part of the space management and data availability Led a project to move the data transfers to all the downstream applications to use the secure FTPS Lead database developer HoffmannLa Roche Inc October 2002 to October 2013 Designed and developed data model for the ELN applications Developed PLSQL based integration process created database packages and procedures to handle complex business logic and used the latest constructs like multi table inserts merge operations pipelined functions analytical functions and bulk collect Developed PLSQL based ETL to extract data from variety of sources for the Kinase data mart The sources where protein database MySQL chemistry database and flat files provided by the vendor The ETL also extracts the protein structure and chemical structure and also the associated graph calculations and documents Served as a lead ETL Informatica developer in the enhancement of an existing ETL frame work that collected and cleansed and integrated the companys research data The entire project was migrated to Informatica Power Center Interfaced with the MDM systems for getting the proper biology and chemical terms to validate the data The enhancements were part of the overall initiative to improve the existing process This improved the overall cycle time and data quality The source was Electronic Lab Notebooks ELN which was accessible using web service and from different geographic locations Used analytical functions for aggregating the data and loading into summary table Created materialized views on the summary table for fast access from the UI applications Tuned PLSQL and SQL performance using the dbms_profiler v views execution plan and statistics Developed an ELN plug in to get the chemical properties of a compound It makes a web service call to the chemistry database calculates molecular weight and other formulas and stores in the ELN Developed a submission module for chemistry ELN Chemist can request for mass spectrometer and chromatography for their compound Uses web service to create a new request in the lab database and returns a URL for the chemist to monitor the progress Automated all the routine jobs using Informatica workflow scheduler UNIX scripts and Oracle scheduler Documented all the complex ETL processes explaining the SourceTarget data sets the data flow diagr ams transformation mappings and quality checkconstraints that are performed Position Held Sr Systems Analyst Worked as a production support lead to maintain a large data warehousing system Developed and enhanced the existing ETL process Analyzed the data issue quality issues and availability issues and worked with the stakeholders to resolve the issues Developed several scripts to automate most of the critical reporting tasks and developed a dashboard to track the progressstatus of several processes This helped the global team to easily track their data and correct the problem and maintain the agreed upon SLA of 24 hours Took up the responsibility of maintaining and developing the content management website from the vendor thereby saving 15000000 to the company Supervised and trained new members in support processes and activities and enhanced the onboarding process Education BE in Computer Science and Engineering Marathwada University Links httpwwwlinkedincominjayvajramani Additional Information Database Oracle 12c 11 10 9 in RAC clusters Modeling tool ERWin ETL Tools Informatica Power Center PLSQL Oracle Warehouse Builder Oracle ODI BI Tools Business Objects LanguagesScripts J2EE JSF Perl UNIX Scripts PLSQL and ProC Source Control CVS SVN SourceSafe WebApp Server Apache Microsoft IIS Scheduling ControlM and Autosys",
    "unique_id": "293d415c-47b3-4fc3-a7ff-787f135e3562"
}