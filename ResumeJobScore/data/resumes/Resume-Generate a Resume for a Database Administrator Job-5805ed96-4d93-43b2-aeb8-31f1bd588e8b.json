{
    "clean_data": "Big Data Engineer SQL ETL Big Query Big Data Engineer SQL ETL Big Query Vancouver WA WA Innovative and selfmotivated I create robust solutions to unique challenges using open source software Work Experience Big Data Engineer SQL ETL Big Query Billcom Palo Alto CA April 2019 to Present Developed Google Big Query SQL scripts to extract and transform data for BillComs Product Growth Unit Department Created ETL scripts that extracted data from MixPanel MP using MPs API scripted in Google Cloud Shell and converted to Google Big Query tables for the Data Analytics teams Extracted raw JSON data from MixPanel and converted to Google Big Query tables using Linux Debian commands such as JQ BQ CURL SED BASH Automated ETL for AB Web Experiments so Analysts could see results of experiments automatically without needing to preprocess their data Extracted data from Google Big Query and ran Linear and Polynomial Regression analysis using R Created Google Data Studio and Google Sheets graphs such as GeoMaps Scatter Plots and Bubble Charts to display and analyze data extracted Created SQL scripts using Googles Advanced Window Analytic Functions Senior SSIS SQL Server Data Migration Integration Engineer Contract Role Enable Networks Limited Christchurch Canterbury September 2018 to November 2018 Developed Microsoft SSIS ETL scripts to automate the creation of purchase order lines from SQL Server and legacy applications into Microsoft Dynamics NAV This involved creating XML API calls and handling API responses including errors and exceptions Developed Microsoft SSIS ETL scripts to automate creation of new leads into Sales Rabbit for door to door sales This involved creating JSON API calls and handling API responses including errors and exceptions Created SQL Server queries views functions and procedures to import cleanse and move data from multiple external systems into and out of Microsoft SQL Server Linux Debian Python MySQL SQL SSIS Data Migration Data Science ETL Integration API Parts Quarry LLC Wilmington DE 2007 to 2018 Developed a large data warehouse Kimball Method which connected to the US Defense Logistics Information System DLIS Developed a US Military supply parts business conceptualizing the company from inception including managing a team of 10 data entry 1 contract administrator and 1 warehouse operator all remotely Developed Microsoft SQL Server MySQL MariaDb SQL Procedures for automating large complex data migration ETL processes The information was refreshed and maintained automatically using Linux Bash scripts and SQL procedures Extensive use of SQL Procedure writing including query tuning and optimization index analysis and optimization slow and general query log analysis Scripted hot backups of MySQL and MariaDb Scripted the creation of and maintained multiple Linux distributions including Debian Centos Ubuntu and Linux Mint Created Microsoft SQL Server MySQL MariaDb backup and restoration procedures Developed and maintained remote server backup processes in Linux using rclonersyncssh allowing for fast server to server transfer speeds DropBox and Google Drive among others Designed a mechanism using Linux Bash and SQL to import all open RFQs Request for Quote received by US Military for Foreign Military Sales within NATO Maintained DNS records including DKIM and SPF1 records used for email security Mapped the processes of the data entry department optimized those processes and developed a PHP MySQL web based data entry system used for an overseas data entry team which reduced data entry costs by 90 and errors by 99 Created a quote requesting system that automatically faxed and emailed tailored RFQs to specific vendors tied directly to the data warehouse This created the workload for the overseas data entry team of 20000 pages of quotes a month Developed reports in Microsoft Visual Studio Optimized profit and revenue by developing a Monte Carlo Simulation on historical quotation data The resulting analysis led to the recreation of our pricing and sourcing policies which decreased work load by 80 and allowed the company to keep 95 of net profit compared to preoptimization Mapped the processes of the contract administrator optimized those processes and developed a PHP MySQL web based contract administration management system This resulted in reducing contract administration costs by 60 and eliminated errors Mapped the processes of the parts packaging department optimized those processes and recreated the workflow Developed all the software needed to encode the RFID shipping tags automate the production of DD250 forms and all needed milspec packaging forms and all shipping labels This software ensured the compliance with government contract regulations and guidelines Automated invoice generation with the US Defense Departments Wide Area Workflow WAWF website using the DLAs sftp flat file upload schema to Ogden Utah Developed a batch file creator to import data into and synchronize contract administration system with QuickBooks and MySQL Algorithmic Trading Systems Developer Python Interactive Brokers Self Christchurch Canterbury 1996 to 2018 Developed a personal server cluster for backtesting 50 years of historical Chicago Mercantile Exchange Futures data for automated algorithmic trading systems This allowed for backtesting trading strategies on Live Cattle Lean Hogs and certain spread trading on the Soybean Crush Developed and scripted the creation of 1000 Cloud Servers using Digital Ocean AWS and Google Cloud Compute This allowed for the backtesting of 60 years of data to find every possible 15 day patterns that lead to large movements in the underlying instruments Developed automated trading systems that are currently trading in the Forex and Equities Markets using Python Linux Bash and MariaDb all in the cloud Developed automated trading systems using Interactive Brokers API and ibPy python wrapper Developed automated trading systems using Oandas API This included JSON calls and data extraction methods stop market stop limit orders BI Developer Consultant Information Technologies Group Inc Anchorage AK 2002 to 2007 Mapped specific accounting processes for British Petroleum BP to facilitate the consolidation of Philips Petroleum accounting processes in Dallas Texas from Anchorage Alaska Developed and scripted the creation of 500 cloud servers using Amazon AWS Google Cloud Compute and Digital Ocean used for an affiliate marketing sales company These processes created 500 separate and unique web carts using XCart that worked with Google Shopping The result scaled a single webcart and website to 500 webcarts and websites for a larger market profile Conducted needs and requirements analyses with clients for GCI in Anchorage Alaska I defined areas of opportunities for efficiency gains and conceived and implemented innovative solutions to document key personnel processes for faster training of new personnel Oversaw the elimination of ongoing labor costs for Petroleum Equipment Services creating automation routines Analyzed historical data for City of Anchorages Worker Training Program Managed a team of data entry clerks that collated all data and created reports EDI Mapping Oracle Project Migration ETL Developer Houston Contracting Anchorage AK 2000 to 2002 Developed all ETL processes and procedures along with a custom EDI invoicing system This involved extensive procedure writing in SQL and extensive mapping from Houstons databases to ARCOs Cost Expenditure Invoicing System Worked directly with Oracle Projects developers in Seattle to map and integrate Houstons legacy database financial software into Oracle Projects using Oracles API This involved extensive use of SQL and data mapping as well Managed all project deliverables as Project Lead for the upgrade of the legacy systems to Oracle Created custom reports for SQL queries MS Access Reports and Crystal Reports used by ARCOs financial auditors and Houstons Controller Education Bachelors in Finance Business University of Alaska Anchorage Anchorage AK 1996 to 2002 Partial in MBA University of Alaska Anchorage Anchorage AK 1996 to 1997 Skills Linux Debian SQL ETL EDI SSIS Data Migration API JSON XML Python Algorithmic Trading Data Simulation MySQL SQL Server Bash PHP SSRS BI Google Big Query 1 year Links httplinkedincominb4b67364 CertificationsLicenses NACE National Association of Corrosion Engineers Underground Corrosion Control Using Cathodic Protection Devices",
    "entities": [
        "Google Shopping",
        "Petroleum Equipment Services",
        "Created Google Data Studio",
        "Oracle Created",
        "BillComs Product Growth Unit Department Created",
        "Links httplinkedincominb4b67364 CertificationsLicenses NACE National Association of Corrosion Engineers Underground Corrosion Control Using Cathodic Protection Devices",
        "EDI Mapping Oracle Project Migration ETL",
        "Created SQL Server",
        "JQ BQ CURL SED BASH Automated",
        "Digital Ocean AWS",
        "Big Query Big Data",
        "Automated",
        "Oracle Projects",
        "Amazon",
        "SQL Server",
        "Scripted",
        "Big Data Engineer SQL ETL",
        "Developed",
        "Conducted",
        "Skills",
        "Google Sheets",
        "Google Cloud Shell",
        "Dallas",
        "DKIM",
        "RFID",
        "Google Drive",
        "the US Defense Logistics Information System",
        "Data Migration Data Science ETL Integration",
        "Anchorage",
        "Linux",
        "MixPanel",
        "Work Experience Big Data",
        "Data Analytics",
        "Ogden Utah Developed",
        "Google Big Query",
        "City of Anchorages Worker Training Program",
        "Developed Microsoft SSIS",
        "API",
        "US",
        "MariaDb Scripted",
        "AB Web Experiments so Analysts",
        "Created SQL",
        "GCI",
        "Microsoft Dynamics NAV",
        "Seattle",
        "DNS",
        "Chicago Mercantile Exchange Futures",
        "DropBox",
        "BI Developer Consultant Information Technologies Group Inc Anchorage AK 2002 to",
        "Data Migration Integration Engineer Contract Role Enable Networks Limited Christchurch",
        "SQL",
        "Oversaw",
        "Kimball Method",
        "MySQL Algorithmic Trading Systems Developer Python Interactive Brokers Self Christchurch Canterbury",
        "QuickBooks",
        "NATO",
        "British Petroleum BP",
        "Google Cloud Compute",
        "Developed Microsoft",
        "Linear and Polynomial Regression",
        "Interactive Brokers API",
        "Live Cattle Lean Hogs",
        "ETL",
        "XCart",
        "Philips Petroleum",
        "MariaDb",
        "EDI",
        "US Military for Foreign Military Sales",
        "Microsoft",
        "Texas",
        "Alaska",
        "Bash PHP SSRS",
        "the Soybean Crush Developed",
        "Present Developed Google Big Query SQL",
        "PHP",
        "Microsoft Visual Studio",
        "Finance Business University"
    ],
    "experience": "Experience Big Data Engineer SQL ETL Big Query Billcom Palo Alto CA April 2019 to Present Developed Google Big Query SQL scripts to extract and transform data for BillComs Product Growth Unit Department Created ETL scripts that extracted data from MixPanel MP using MPs API scripted in Google Cloud Shell and converted to Google Big Query tables for the Data Analytics teams Extracted raw JSON data from MixPanel and converted to Google Big Query tables using Linux Debian commands such as JQ BQ CURL SED BASH Automated ETL for AB Web Experiments so Analysts could see results of experiments automatically without needing to preprocess their data Extracted data from Google Big Query and ran Linear and Polynomial Regression analysis using R Created Google Data Studio and Google Sheets graphs such as GeoMaps Scatter Plots and Bubble Charts to display and analyze data extracted Created SQL scripts using Googles Advanced Window Analytic Functions Senior SSIS SQL Server Data Migration Integration Engineer Contract Role Enable Networks Limited Christchurch Canterbury September 2018 to November 2018 Developed Microsoft SSIS ETL scripts to automate the creation of purchase order lines from SQL Server and legacy applications into Microsoft Dynamics NAV This involved creating XML API calls and handling API responses including errors and exceptions Developed Microsoft SSIS ETL scripts to automate creation of new leads into Sales Rabbit for door to door sales This involved creating JSON API calls and handling API responses including errors and exceptions Created SQL Server queries views functions and procedures to import cleanse and move data from multiple external systems into and out of Microsoft SQL Server Linux Debian Python MySQL SQL SSIS Data Migration Data Science ETL Integration API Parts Quarry LLC Wilmington DE 2007 to 2018 Developed a large data warehouse Kimball Method which connected to the US Defense Logistics Information System DLIS Developed a US Military supply parts business conceptualizing the company from inception including managing a team of 10 data entry 1 contract administrator and 1 warehouse operator all remotely Developed Microsoft SQL Server MySQL MariaDb SQL Procedures for automating large complex data migration ETL processes The information was refreshed and maintained automatically using Linux Bash scripts and SQL procedures Extensive use of SQL Procedure writing including query tuning and optimization index analysis and optimization slow and general query log analysis Scripted hot backups of MySQL and MariaDb Scripted the creation of and maintained multiple Linux distributions including Debian Centos Ubuntu and Linux Mint Created Microsoft SQL Server MySQL MariaDb backup and restoration procedures Developed and maintained remote server backup processes in Linux using rclonersyncssh allowing for fast server to server transfer speeds DropBox and Google Drive among others Designed a mechanism using Linux Bash and SQL to import all open RFQs Request for Quote received by US Military for Foreign Military Sales within NATO Maintained DNS records including DKIM and SPF1 records used for email security Mapped the processes of the data entry department optimized those processes and developed a PHP MySQL web based data entry system used for an overseas data entry team which reduced data entry costs by 90 and errors by 99 Created a quote requesting system that automatically faxed and emailed tailored RFQs to specific vendors tied directly to the data warehouse This created the workload for the overseas data entry team of 20000 pages of quotes a month Developed reports in Microsoft Visual Studio Optimized profit and revenue by developing a Monte Carlo Simulation on historical quotation data The resulting analysis led to the recreation of our pricing and sourcing policies which decreased work load by 80 and allowed the company to keep 95 of net profit compared to preoptimization Mapped the processes of the contract administrator optimized those processes and developed a PHP MySQL web based contract administration management system This resulted in reducing contract administration costs by 60 and eliminated errors Mapped the processes of the parts packaging department optimized those processes and recreated the workflow Developed all the software needed to encode the RFID shipping tags automate the production of DD250 forms and all needed milspec packaging forms and all shipping labels This software ensured the compliance with government contract regulations and guidelines Automated invoice generation with the US Defense Departments Wide Area Workflow WAWF website using the DLAs sftp flat file upload schema to Ogden Utah Developed a batch file creator to import data into and synchronize contract administration system with QuickBooks and MySQL Algorithmic Trading Systems Developer Python Interactive Brokers Self Christchurch Canterbury 1996 to 2018 Developed a personal server cluster for backtesting 50 years of historical Chicago Mercantile Exchange Futures data for automated algorithmic trading systems This allowed for backtesting trading strategies on Live Cattle Lean Hogs and certain spread trading on the Soybean Crush Developed and scripted the creation of 1000 Cloud Servers using Digital Ocean AWS and Google Cloud Compute This allowed for the backtesting of 60 years of data to find every possible 15 day patterns that lead to large movements in the underlying instruments Developed automated trading systems that are currently trading in the Forex and Equities Markets using Python Linux Bash and MariaDb all in the cloud Developed automated trading systems using Interactive Brokers API and ibPy python wrapper Developed automated trading systems using Oandas API This included JSON calls and data extraction methods stop market stop limit orders BI Developer Consultant Information Technologies Group Inc Anchorage AK 2002 to 2007 Mapped specific accounting processes for British Petroleum BP to facilitate the consolidation of Philips Petroleum accounting processes in Dallas Texas from Anchorage Alaska Developed and scripted the creation of 500 cloud servers using Amazon AWS Google Cloud Compute and Digital Ocean used for an affiliate marketing sales company These processes created 500 separate and unique web carts using XCart that worked with Google Shopping The result scaled a single webcart and website to 500 webcarts and websites for a larger market profile Conducted needs and requirements analyses with clients for GCI in Anchorage Alaska I defined areas of opportunities for efficiency gains and conceived and implemented innovative solutions to document key personnel processes for faster training of new personnel Oversaw the elimination of ongoing labor costs for Petroleum Equipment Services creating automation routines Analyzed historical data for City of Anchorages Worker Training Program Managed a team of data entry clerks that collated all data and created reports EDI Mapping Oracle Project Migration ETL Developer Houston Contracting Anchorage AK 2000 to 2002 Developed all ETL processes and procedures along with a custom EDI invoicing system This involved extensive procedure writing in SQL and extensive mapping from Houstons databases to ARCOs Cost Expenditure Invoicing System Worked directly with Oracle Projects developers in Seattle to map and integrate Houstons legacy database financial software into Oracle Projects using Oracles API This involved extensive use of SQL and data mapping as well Managed all project deliverables as Project Lead for the upgrade of the legacy systems to Oracle Created custom reports for SQL queries MS Access Reports and Crystal Reports used by ARCOs financial auditors and Houstons Controller Education Bachelors in Finance Business University of Alaska Anchorage Anchorage AK 1996 to 2002 Partial in MBA University of Alaska Anchorage Anchorage AK 1996 to 1997 Skills Linux Debian SQL ETL EDI SSIS Data Migration API JSON XML Python Algorithmic Trading Data Simulation MySQL SQL Server Bash PHP SSRS BI Google Big Query 1 year Links httplinkedincominb4b67364 CertificationsLicenses NACE National Association of Corrosion Engineers Underground Corrosion Control Using Cathodic Protection Devices",
    "extracted_keywords": [
        "Big",
        "Data",
        "Engineer",
        "SQL",
        "ETL",
        "Query",
        "Big",
        "Data",
        "Engineer",
        "SQL",
        "ETL",
        "Big",
        "Query",
        "Vancouver",
        "WA",
        "WA",
        "Innovative",
        "solutions",
        "challenges",
        "source",
        "software",
        "Work",
        "Experience",
        "Big",
        "Data",
        "Engineer",
        "SQL",
        "ETL",
        "Big",
        "Query",
        "Billcom",
        "Palo",
        "Alto",
        "CA",
        "April",
        "Present",
        "Google",
        "Big",
        "Query",
        "SQL",
        "scripts",
        "data",
        "BillComs",
        "Product",
        "Growth",
        "Unit",
        "Department",
        "Created",
        "ETL",
        "scripts",
        "data",
        "MixPanel",
        "MP",
        "MPs",
        "API",
        "Google",
        "Cloud",
        "Shell",
        "Google",
        "Big",
        "Query",
        "Data",
        "Analytics",
        "teams",
        "data",
        "MixPanel",
        "Google",
        "Big",
        "Query",
        "tables",
        "Linux",
        "commands",
        "JQ",
        "BQ",
        "CURL",
        "SED",
        "BASH",
        "Automated",
        "ETL",
        "AB",
        "Web",
        "Experiments",
        "Analysts",
        "results",
        "experiments",
        "data",
        "data",
        "Google",
        "Big",
        "Query",
        "Linear",
        "Polynomial",
        "Regression",
        "analysis",
        "R",
        "Google",
        "Data",
        "Studio",
        "Google",
        "Sheets",
        "graphs",
        "GeoMaps",
        "Scatter",
        "Plots",
        "Bubble",
        "Charts",
        "data",
        "Created",
        "SQL",
        "scripts",
        "Googles",
        "Advanced",
        "Window",
        "Analytic",
        "Functions",
        "SSIS",
        "SQL",
        "Server",
        "Data",
        "Migration",
        "Integration",
        "Engineer",
        "Contract",
        "Role",
        "Enable",
        "Networks",
        "Limited",
        "Christchurch",
        "Canterbury",
        "September",
        "November",
        "Microsoft",
        "SSIS",
        "ETL",
        "scripts",
        "creation",
        "purchase",
        "order",
        "lines",
        "SQL",
        "Server",
        "legacy",
        "applications",
        "Microsoft",
        "Dynamics",
        "NAV",
        "XML",
        "API",
        "API",
        "responses",
        "errors",
        "exceptions",
        "Microsoft",
        "SSIS",
        "ETL",
        "scripts",
        "creation",
        "leads",
        "Sales",
        "Rabbit",
        "door",
        "door",
        "sales",
        "API",
        "calls",
        "API",
        "responses",
        "errors",
        "exceptions",
        "SQL",
        "Server",
        "views",
        "functions",
        "procedures",
        "cleanse",
        "data",
        "systems",
        "Microsoft",
        "SQL",
        "Server",
        "Linux",
        "Debian",
        "Python",
        "MySQL",
        "SQL",
        "SSIS",
        "Data",
        "Migration",
        "Data",
        "Science",
        "ETL",
        "Integration",
        "API",
        "Parts",
        "Quarry",
        "LLC",
        "Wilmington",
        "DE",
        "data",
        "warehouse",
        "Kimball",
        "Method",
        "US",
        "Defense",
        "Logistics",
        "Information",
        "System",
        "DLIS",
        "US",
        "supply",
        "parts",
        "business",
        "company",
        "inception",
        "team",
        "data",
        "entry",
        "contract",
        "administrator",
        "warehouse",
        "operator",
        "Microsoft",
        "SQL",
        "Server",
        "MySQL",
        "MariaDb",
        "SQL",
        "Procedures",
        "data",
        "migration",
        "ETL",
        "information",
        "Linux",
        "Bash",
        "scripts",
        "SQL",
        "use",
        "SQL",
        "Procedure",
        "writing",
        "query",
        "tuning",
        "optimization",
        "index",
        "analysis",
        "optimization",
        "query",
        "log",
        "analysis",
        "backups",
        "MySQL",
        "MariaDb",
        "creation",
        "Linux",
        "distributions",
        "Debian",
        "Centos",
        "Ubuntu",
        "Linux",
        "Mint",
        "Microsoft",
        "SQL",
        "Server",
        "MySQL",
        "MariaDb",
        "backup",
        "restoration",
        "procedures",
        "server",
        "backup",
        "processes",
        "Linux",
        "rclonersyncssh",
        "server",
        "server",
        "transfer",
        "speeds",
        "DropBox",
        "Google",
        "Drive",
        "others",
        "mechanism",
        "Linux",
        "Bash",
        "SQL",
        "RFQs",
        "Request",
        "Quote",
        "US",
        "Military",
        "Foreign",
        "Military",
        "Sales",
        "NATO",
        "DNS",
        "records",
        "DKIM",
        "SPF1",
        "records",
        "email",
        "security",
        "processes",
        "data",
        "entry",
        "department",
        "processes",
        "PHP",
        "MySQL",
        "web",
        "data",
        "entry",
        "system",
        "data",
        "entry",
        "team",
        "data",
        "entry",
        "costs",
        "errors",
        "quote",
        "system",
        "RFQs",
        "vendors",
        "data",
        "warehouse",
        "workload",
        "data",
        "entry",
        "team",
        "pages",
        "quotes",
        "month",
        "reports",
        "Microsoft",
        "Visual",
        "Studio",
        "profit",
        "revenue",
        "Monte",
        "Carlo",
        "Simulation",
        "quotation",
        "data",
        "analysis",
        "recreation",
        "pricing",
        "policies",
        "work",
        "load",
        "company",
        "profit",
        "preoptimization",
        "processes",
        "contract",
        "administrator",
        "processes",
        "PHP",
        "MySQL",
        "web",
        "contract",
        "administration",
        "management",
        "system",
        "contract",
        "administration",
        "costs",
        "errors",
        "processes",
        "parts",
        "packaging",
        "department",
        "processes",
        "workflow",
        "software",
        "RFID",
        "shipping",
        "tags",
        "production",
        "DD250",
        "forms",
        "packaging",
        "forms",
        "shipping",
        "labels",
        "software",
        "compliance",
        "government",
        "contract",
        "regulations",
        "guidelines",
        "generation",
        "US",
        "Defense",
        "Departments",
        "Wide",
        "Area",
        "Workflow",
        "WAWF",
        "website",
        "DLAs",
        "sftp",
        "file",
        "upload",
        "schema",
        "Ogden",
        "Utah",
        "batch",
        "file",
        "creator",
        "data",
        "contract",
        "administration",
        "system",
        "QuickBooks",
        "MySQL",
        "Algorithmic",
        "Trading",
        "Systems",
        "Developer",
        "Python",
        "Interactive",
        "Brokers",
        "Self",
        "Christchurch",
        "Canterbury",
        "server",
        "cluster",
        "years",
        "Chicago",
        "Mercantile",
        "Exchange",
        "Futures",
        "data",
        "trading",
        "systems",
        "trading",
        "strategies",
        "Cattle",
        "Lean",
        "Hogs",
        "trading",
        "Soybean",
        "Crush",
        "creation",
        "Cloud",
        "Servers",
        "Digital",
        "Ocean",
        "AWS",
        "Google",
        "Cloud",
        "Compute",
        "backtesting",
        "years",
        "data",
        "day",
        "patterns",
        "movements",
        "instruments",
        "trading",
        "systems",
        "Forex",
        "Equities",
        "Markets",
        "Python",
        "Linux",
        "Bash",
        "MariaDb",
        "cloud",
        "trading",
        "systems",
        "Interactive",
        "Brokers",
        "API",
        "ibPy",
        "python",
        "wrapper",
        "trading",
        "systems",
        "Oandas",
        "API",
        "calls",
        "data",
        "extraction",
        "methods",
        "market",
        "stop",
        "limit",
        "orders",
        "BI",
        "Developer",
        "Consultant",
        "Information",
        "Technologies",
        "Group",
        "Inc",
        "Anchorage",
        "AK",
        "accounting",
        "processes",
        "British",
        "Petroleum",
        "BP",
        "consolidation",
        "Philips",
        "Petroleum",
        "accounting",
        "processes",
        "Dallas",
        "Texas",
        "Anchorage",
        "Alaska",
        "Developed",
        "creation",
        "servers",
        "Amazon",
        "AWS",
        "Google",
        "Cloud",
        "Compute",
        "Digital",
        "Ocean",
        "affiliate",
        "marketing",
        "sales",
        "company",
        "processes",
        "web",
        "carts",
        "XCart",
        "Google",
        "Shopping",
        "result",
        "webcart",
        "website",
        "webcarts",
        "websites",
        "market",
        "profile",
        "Conducted",
        "requirements",
        "clients",
        "GCI",
        "Anchorage",
        "Alaska",
        "areas",
        "opportunities",
        "efficiency",
        "gains",
        "solutions",
        "personnel",
        "processes",
        "training",
        "personnel",
        "Oversaw",
        "elimination",
        "labor",
        "costs",
        "Petroleum",
        "Equipment",
        "Services",
        "automation",
        "routines",
        "data",
        "City",
        "Anchorages",
        "Worker",
        "Training",
        "Program",
        "team",
        "data",
        "entry",
        "clerks",
        "data",
        "reports",
        "EDI",
        "Mapping",
        "Oracle",
        "Project",
        "Migration",
        "ETL",
        "Developer",
        "Houston",
        "Contracting",
        "Anchorage",
        "AK",
        "ETL",
        "processes",
        "procedures",
        "custom",
        "EDI",
        "invoicing",
        "system",
        "procedure",
        "writing",
        "SQL",
        "mapping",
        "Houstons",
        "databases",
        "Cost",
        "Expenditure",
        "Invoicing",
        "System",
        "Oracle",
        "Projects",
        "developers",
        "Seattle",
        "Houstons",
        "legacy",
        "database",
        "software",
        "Oracle",
        "Projects",
        "Oracles",
        "API",
        "use",
        "SQL",
        "data",
        "mapping",
        "project",
        "deliverables",
        "Project",
        "Lead",
        "upgrade",
        "legacy",
        "systems",
        "Oracle",
        "custom",
        "reports",
        "SQL",
        "MS",
        "Access",
        "Reports",
        "Crystal",
        "Reports",
        "ARCOs",
        "auditors",
        "Houstons",
        "Controller",
        "Education",
        "Bachelors",
        "Finance",
        "Business",
        "University",
        "Alaska",
        "Anchorage",
        "Anchorage",
        "AK",
        "Partial",
        "MBA",
        "University",
        "Alaska",
        "Anchorage",
        "Anchorage",
        "AK",
        "Skills",
        "Linux",
        "SQL",
        "ETL",
        "EDI",
        "SSIS",
        "Data",
        "Migration",
        "API",
        "JSON",
        "XML",
        "Python",
        "Algorithmic",
        "Trading",
        "Data",
        "Simulation",
        "MySQL",
        "SQL",
        "Server",
        "Bash",
        "PHP",
        "SSRS",
        "BI",
        "Google",
        "Big",
        "Query",
        "year",
        "Links",
        "CertificationsLicenses",
        "NACE",
        "National",
        "Association",
        "Corrosion",
        "Engineers",
        "Underground",
        "Corrosion",
        "Control",
        "Cathodic",
        "Protection",
        "Devices"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T19:47:47.537158",
    "resume_data": "Big Data Engineer SQL ETL Big Query Big Data Engineer SQL ETL Big Query Vancouver WA WA Innovative and selfmotivated I create robust solutions to unique challenges using open source software Work Experience Big Data Engineer SQL ETL Big Query Billcom Palo Alto CA April 2019 to Present Developed Google Big Query SQL scripts to extract and transform data for BillComs Product Growth Unit Department Created ETL scripts that extracted data from MixPanel MP using MPs API scripted in Google Cloud Shell and converted to Google Big Query tables for the Data Analytics teams Extracted raw JSON data from MixPanel and converted to Google Big Query tables using Linux Debian commands such as JQ BQ CURL SED BASH Automated ETL for AB Web Experiments so Analysts could see results of experiments automatically without needing to preprocess their data Extracted data from Google Big Query and ran Linear and Polynomial Regression analysis using R Created Google Data Studio and Google Sheets graphs such as GeoMaps Scatter Plots and Bubble Charts to display and analyze data extracted Created SQL scripts using Googles Advanced Window Analytic Functions Senior SSIS SQL Server Data Migration Integration Engineer Contract Role Enable Networks Limited Christchurch Canterbury September 2018 to November 2018 Developed Microsoft SSIS ETL scripts to automate the creation of purchase order lines from SQL Server and legacy applications into Microsoft Dynamics NAV This involved creating XML API calls and handling API responses including errors and exceptions Developed Microsoft SSIS ETL scripts to automate creation of new leads into Sales Rabbit for door to door sales This involved creating JSON API calls and handling API responses including errors and exceptions Created SQL Server queries views functions and procedures to import cleanse and move data from multiple external systems into and out of Microsoft SQL Server Linux Debian Python MySQL SQL SSIS Data Migration Data Science ETL Integration API Parts Quarry LLC Wilmington DE 2007 to 2018 Developed a large data warehouse Kimball Method which connected to the US Defense Logistics Information System DLIS Developed a US Military supply parts business conceptualizing the company from inception including managing a team of 10 data entry 1 contract administrator and 1 warehouse operator all remotely Developed Microsoft SQL Server MySQL MariaDb SQL Procedures for automating large complex data migration ETL processes The information was refreshed and maintained automatically using Linux Bash scripts and SQL procedures Extensive use of SQL Procedure writing including query tuning and optimization index analysis and optimization slow and general query log analysis Scripted hot backups of MySQL and MariaDb Scripted the creation of and maintained multiple Linux distributions including Debian Centos Ubuntu and Linux Mint Created Microsoft SQL Server MySQL MariaDb backup and restoration procedures Developed and maintained remote server backup processes in Linux using rclonersyncssh allowing for fast server to server transfer speeds DropBox and Google Drive among others Designed a mechanism using Linux Bash and SQL to import all open RFQs Request for Quote received by US Military for Foreign Military Sales within NATO Maintained DNS records including DKIM and SPF1 records used for email security Mapped the processes of the data entry department optimized those processes and developed a PHP MySQL web based data entry system used for an overseas data entry team which reduced data entry costs by 90 and errors by 99 Created a quote requesting system that automatically faxed and emailed tailored RFQs to specific vendors tied directly to the data warehouse This created the workload for the overseas data entry team of 20000 pages of quotes a month Developed reports in Microsoft Visual Studio Optimized profit and revenue by developing a Monte Carlo Simulation on historical quotation data The resulting analysis led to the recreation of our pricing and sourcing policies which decreased work load by 80 and allowed the company to keep 95 of net profit compared to preoptimization Mapped the processes of the contract administrator optimized those processes and developed a PHP MySQL web based contract administration management system This resulted in reducing contract administration costs by 60 and eliminated errors Mapped the processes of the parts packaging department optimized those processes and recreated the workflow Developed all the software needed to encode the RFID shipping tags automate the production of DD250 forms and all needed milspec packaging forms and all shipping labels This software ensured the compliance with government contract regulations and guidelines Automated invoice generation with the US Defense Departments Wide Area Workflow WAWF website using the DLAs sftp flat file upload schema to Ogden Utah Developed a batch file creator to import data into and synchronize contract administration system with QuickBooks and MySQL Algorithmic Trading Systems Developer Python Interactive Brokers Self Christchurch Canterbury 1996 to 2018 Developed a personal server cluster for backtesting 50 years of historical Chicago Mercantile Exchange Futures data for automated algorithmic trading systems This allowed for backtesting trading strategies on Live Cattle Lean Hogs and certain spread trading on the Soybean Crush Developed and scripted the creation of 1000 Cloud Servers using Digital Ocean AWS and Google Cloud Compute This allowed for the backtesting of 60 years of data to find every possible 15 day patterns that lead to large movements in the underlying instruments Developed automated trading systems that are currently trading in the Forex and Equities Markets using Python Linux Bash and MariaDb all in the cloud Developed automated trading systems using Interactive Brokers API and ibPy python wrapper Developed automated trading systems using Oandas API This included JSON calls and data extraction methods stop market stop limit orders BI Developer Consultant Information Technologies Group Inc Anchorage AK 2002 to 2007 Mapped specific accounting processes for British Petroleum BP to facilitate the consolidation of Philips Petroleum accounting processes in Dallas Texas from Anchorage Alaska Developed and scripted the creation of 500 cloud servers using Amazon AWS Google Cloud Compute and Digital Ocean used for an affiliate marketing sales company These processes created 500 separate and unique web carts using XCart that worked with Google Shopping The result scaled a single webcart and website to 500 webcarts and websites for a larger market profile Conducted needs and requirements analyses with clients for GCI in Anchorage Alaska I defined areas of opportunities for efficiency gains and conceived and implemented innovative solutions to document key personnel processes for faster training of new personnel Oversaw the elimination of ongoing labor costs for Petroleum Equipment Services creating automation routines Analyzed historical data for City of Anchorages Worker Training Program Managed a team of data entry clerks that collated all data and created reports EDI Mapping Oracle Project Migration ETL Developer Houston Contracting Anchorage AK 2000 to 2002 Developed all ETL processes and procedures along with a custom EDI invoicing system This involved extensive procedure writing in SQL and extensive mapping from Houstons databases to ARCOs Cost Expenditure Invoicing System Worked directly with Oracle Projects developers in Seattle to map and integrate Houstons legacy database financial software into Oracle Projects using Oracles API This involved extensive use of SQL and data mapping as well Managed all project deliverables as Project Lead for the upgrade of the legacy systems to Oracle Created custom reports for SQL queries MS Access Reports and Crystal Reports used by ARCOs financial auditors and Houstons Controller Education Bachelors in Finance Business University of Alaska Anchorage Anchorage AK 1996 to 2002 Partial in MBA University of Alaska Anchorage Anchorage AK 1996 to 1997 Skills Linux Debian SQL ETL EDI SSIS Data Migration API JSON XML Python Algorithmic Trading Data Simulation MySQL SQL Server Bash PHP SSRS BI Google Big Query 1 year Links httplinkedincominb4b67364 CertificationsLicenses NACE National Association of Corrosion Engineers Underground Corrosion Control Using Cathodic Protection Devices",
    "unique_id": "5805ed96-4d93-43b2-aeb8-31f1bd588e8b"
}