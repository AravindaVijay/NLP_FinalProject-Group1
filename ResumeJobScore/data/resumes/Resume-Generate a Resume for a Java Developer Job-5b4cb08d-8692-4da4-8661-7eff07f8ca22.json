{
    "clean_data": "Database Administrator Database span lAdministratorspan Database Administrator Unissant Inc Woodbridge VA 15402 Weldin Dr Woodbridge VA 22193 Phone  Email stanleyreddygmailcom Active DHS Full BI Security Clearance Customs Border Protection suitability determination validity till 12122022 Public Trust Level 4 Security Clearance Office of Personnel Management Completed BI waiting adjudication in OPM IBM Certified DB2 for zOS Database Administrator IBM Certified Database Associate IBM Certified Application Developer Oracle SQL Server MySQL NoSQL DB2 Database Admin Hortonworks Hadoop Admin academic credential Hortonworks HDP Developer Enterprise Apache Spark academic credential Hortonworks HDP Developer Apache Pig Hive academic credential MongoDB for DBAs MongoDB University academic credential Database Administrator Unissant Inc 12901 Worldgate Dr 600 Herndon VA 20170 Client Office of Personnel Management 1900 E St NW Washington DC 20415 Oct 2018 Current Data Engineer ManTech International Corporation 2250 Corporate Park Dr Herndon VA 20171 Client Customs Border Protection 5971 Kingstowne Village Parkway Alexandria VA 22315 Oct 2017 Sept 2018 Database Administrator Randstad Technologies 150 Presidential Way Woburn MA 01801Client Anthem BlueCross Blue Shield of Ohio 4361 Irwin Simpson Rd Mason OH 45040 Aug 2017 Sept 2017 Database Administrator Blue Cross Blue Shield of IL HCSC 300 E Randolph St Chicago IL 60601 Feb 2007 May 2017 Database Administrator Ciber Inc 205 N Main St Bloomington IL 61701 Client STATEFARM Corporate SouthSF Bloomington IL 61701 Jun 2006 Feb 2007 Database Administrator Apex Systems Inc Columbia MD 21045 Client Lockheed Martin Social Security Administration Baltimore MD 21244 May 2006 Jun 2006 Information Systems Engineer Blue Cross Blue Shield of SC I20 Alpine Rd Columbia SC 29219 Jan 1999 Feb 2006 Work Experience Database Administrator Unissant Inc Herndon VA October 2018 to Present 12901 Worldgate Dr 600 Herndon VA 20170 Client Office of Personnel Management 1900 E St NW Washington DC 20415 Oct 2018 Current Data Engineer ManTech International Corporation Herndon VA October 2017 to September 2018 2250 Corporate Park Dr Herndon VA 20171 Client Customs Border Protection 5971 Kingstowne Village Parkway Alexandria VA 22315 Oct 2017 Sept 2018 Database Administrator Randstad Technologies Woburn MA August 2017 to September 2017 150 Presidential Way Woburn MA 01801Client Anthem BlueCross Blue Shield of Ohio 4361 Irwin Simpson Rd Mason OH 45040 Aug 2017 Sept 2017 Database Administrator Blue Cross Blue Shield of IL Chicago IL February 2007 to May 2017 Database Administrator Ciber Inc Bloomington IL June 2006 to February 2007 205 N Main St Bloomington IL 61701 Client STATEFARM Corporate SouthSF Bloomington IL 61701 Jun 2006 Feb 2007 Database Administrator Apex Systems Inc Columbia MD May 2006 to June 2006 Columbia MD 21045 Client Lockheed Martin Social Security Administration Baltimore MD 21244 May 2006 Jun 2006 Information Systems Engineer Blue Cross Blue Shield of SC Columbia SC January 1999 to February 2006 Unissant Inc Client OIG of Office of Personnel Management Washington DC Database Admin Systems Admin Data Modeler Data Architect Lead Database Administrator to Create Cloud AWS platform for DB2 V 1114 on Linux BLU Data analytics and migrate existing SAS based DBMS system to DB2 on Linux RDSPostgreSQL 111 Setup Install DB2 V1111 on AWS RHEL 76x86_64 applied Mod4 Fixpack patches to upgrade to V1114 Did install Data Server Manager V2152 Prepare Data Architecture Data Migration Data Security Documents for the Clients Working to setting up Configuring HADR on DB2 for Linux for Failover on AWS Cloud Working to setting up Configuring IBM Security Guardium 1060 Database Activity Monitoring DAM Setup Configure PostgreSQL 111 upgraded from PostgreSQL 106 with pgAdmin 4 v36 in AWS Cloud and associate it as a Data hub repository for erwin Data Modeler Workgroup Edition Concurrent User License 2018 R1 Provide client connectivity using with DataStage V117 IBM DataStudio client V41 SQuirreL SQL Client V39 Installation Configuration setup and deployment of Hortonworks HDP Hadoop cluster 7 Data nodes 2 Master Nodes 4 Edge nodes in AWS Cloud Installation Configuration setup and deployment of Cloudera Hadoop cluster 5 Data nodes 2 Master Nodes 4 Edge nodes in AWS Cloud Installation Configuration setup 2 node Microsoft Windows Server enabling Kerberos constrained delegation with Active Directory support feature to specify and enforce application trust boundaries by limiting the scope where application services can act in AWS Cloud Mantech International CorporationClient Customs and Border Protection Alexandria Data Engineer Part of Data Engineering group to capture document the data sources provenance and Architecture of the CBP EMIS data warehouse This effort should provide better tools for data mining and Data Science for Data warehouse Big Data efforts Involved in developing reengineering PLSQL procedures with Regular Expressions for very critical analytics project Involved with analyzing the Metadata Data structures Relationships Data Sources for both Cargo Passenger Systems Involved as Database Engineer providing support to BigData Oracle for OLAP Importing data from Multiple sources into Data Lake Delta Lake using Talend Kafka Apache NiFi Data mining Analtics Visualzation using Anaconda Python R Elastic Search Elastic Lucene etc Randstad Technologies Client Blue Cross Blue Shield of OH Anthem Mason OH Consultant Database Administrator I was involved as Database Administrator with Modernization expert of Legacy IMS DB2 database systems to Oracle in addition to everyday monitoring maintenance enhancements and new project development for applications Blue Cross Blue Shield of IL HCSC Chicago IL Sr Database Administrator HCSC is one of Nations Premier Healthcare Insurance provider with a membership of over 13 million am currently involved as Database Administrator with zero down time and supporting with maintenance enhancements and new Database development for applications Database Migrations DBMS Systems Performance Tuning Capacity planning of applications DB2 Oracle Hadoop MongoDB DBMS systems Responsible for High Availability accessibility of databases This effort involves 24X7 support of 230 million per day OLTP Health Claims transactions in DB2 oracle Sub systems on zOS AIX RHEL Worked supported development teams Integrated Medical Management develop Python applications to come up with pricing models for firsttime uninsured health insurance subscribers to generate pricing for actuarial team Tuples of firsttime insurers were mined from historical data for generating health costs associated with those health subscribers for first three years with age range Was part of teamIntegrated Medical Management to analyze the impacts of migration of ICD7 to ICD10 Implementation on Health claims by providers institutions utilizing Python Python applications were also developed to make old claims to be compatible to new format of medical procedure codes Extending support to Oracle Hadoop MongoDB along with DB2 to embrace multi DBMS support concept and embrace paradigm of management for Open Source Software Commodity Hardware to reduce costs Install configure setup 3 Master Node 47 Slave Node 15 Edge Node Cluster Developed process to ingest Structured Semistructured data into HDFS using Scoop Talend Elastic Search KAFKA Helped in supporting Flume Ingestion and configuring Source Channel Sink setup automated backups using Oozie etc Ciber Inc Client Statefarm Corporate South Bloomington IL DB2 Oracle Database Administrator Data Specialist State Farm Corporate South is a centralized headquarters for its data processing functions Statefarm is the Nations leading auto insurer Was involved as project DBA in FSS group with maintenance enhancements and new Database development for applications Responsible for Physical database design development of databases maintenance Jobs Performance validations involving Unicode Ebcdic Ascii translations using SQL Developer and Power BI Apex Systems Inc Client Lockheed Martin Social Security Administration Baltimore DB2 Database Administrator High Performance Design Analyst Lockheed Martin supports the complete range of services related to Social Security Administrations major systems modernization initiatives Involved with analysis and design of implementation of DB2 Ver 8 Release on very large Social Security Administration databases and migration of databases from BDAM to DB2 The objective is to migrate with zero issues to DB2 Version 8 and analyzing its impact on Applications and DB2 systems with version upgrade DB2 Administration Tool CA tools Platinum Products BMC Mainview BMC tools IBM tools Blue Cross Blue Shield of SC Columbia SC Information Systems Engineer Modernization of systems for 24X7 availability of systems adjudication of health claims Smart Health card Migration of VSAM to DB2 in line with the paradigm of the organization to have a single data infrastructure for growing business and technical needs like faster processing of Claims access of Data by customers and deployment of new applications consistency in quality of data real time availability of data 24X7 facilitating running of Sysplex environments and concurrency in data updates between online and batch Skills Database administration Database Db2 Dbms Sql server Sql server 2008 Mysql Oracle Plsql Postgres Postgresql Sql Stored procedures Vsam Ambari Hdfs Mahout Mapreduce Oozie Sqoop Additional Information TECHNICAL PROFILE Be proactively engaged in new methodologies like Agile DevOps SCRUM Waterfall Extreme Programming CICD Work Flow GIT Jenkins etc The future state of Architecture has contained Legacy transition to Open Source Platforms Architectures Adept at managing multiple concurrent projects being attentive to detail and maintaining the ability to make rational decisions in pressure situations Willingness to own responsibility and work to resolve issues Ability to work with commitment passion and thrust to exceed Customers expectation both as an Individual and as a Team member with the knowledge that each Customers expectations are unique DB2 for LUW V 1114 on Linux PostgreSQL V 114 pgAdmin v410 Oracle V 122 MySQL V 80 Red Hat Enterprise Linux 75 SQL Server 2008 2008 R2 2012 2014 Hadoop V24 V26 V28 V30 Cloudera Horton works Legacy zOS systems IMS DB2 IDMS to Oracle Oracle PLSQL Development expertise Administration of Anaconda Enterprise My responsibilities include installation configuration and management of the application proficiently navigating within the linux Create custom python environments and install and maintain them on various Hadoop clusters Work with Data Scientists as they launch python and pyspark jobs or deploy models that interact with data on hdfs and hive Engage with users transitioning from traditional data sources to Python Working to migrate a SAS Data warehouse on premise to AWS Clouds RDS DB2 by building data pipelines using NiFi Developed ETL and analytics focused Spark Core applications in Python including Spark SQL applications to interact with HIVE tables Building data pipelines to migrate data from Teradata to Hadoop env HDP Initiated poc to automate data pipelines using Oozie Worked towards building a Data Lake that is discoverable accessible and usable given diverse constraints onprem hybrid and cloud environments Ensure that data hydrating into the data lake has appropriate metadatatags with it using various enterprise metadata management tools Capture metadata throughout the data life cycle and consolidate it so as to enable searchbrowsesample data Import of unstructured data into HDFS using Flume using both File and Memory channels Develop Pig Latin scripts and writing UDFs in Python when needed to extract transform and mine data Write Hive Queries for analyzing data in Hive warehouse using Hive Query Language HQL Develop novel Abstract Data Structures and Functional Abstractions to process data text analysis humanmachine interactions weblogs and social media streaming Apply principles of Object Oriented Programming in designing and implementing applications with a specific focus on controlling complexity Focused on creating warehouses databases to meet the rapidly changing needs of various business units Create execute and schedule both master and standalone jobs with a focus on parallel execution when writing large files onto databases Extensive experience in supporting MultiDBMS data migrations IMS to DB2 Migration VSAM to DB2 Migration CAIDMS to DB2 Migration SAS to DB2 for Linux V111 Migration Legacy to AMS Migration DB2 to Oracle migration DB2 to SQL Server Migration High proficiency in designing building and administering Oracle clustered server configurations supporting 11g and 12c Real Application Clusters RAC installations on Linux AIX Ability to work on developing stored procedures Functions and Triggers PLSQL procedures Korn shell scripts Installing configuring Oracle cluster ware Database Software Troubleshooting handling common issues that arise during integration of the whole bugs network issues configuration files issues OCR issue deinstallation cleanup of cluster ware Ability to Work with customers for various RAC related issue RAC recovery RMAN ASM OCR corruptions voting disk loss etc Troubleshoot performance issues for the RAC instances GC events Backup and Recovery issues related loss of OCR Voting Disk and Oracle cluster ware also issues with corruption of individual disk data blocks loss of OS configuration files loss of net configuration files Also used the Merge backup for backing terabyte databases Issues with block change tracking also flash recovery area Add or Remove Node from RAC Importing Ingesting data from Multiple sources into Data Lake Delta Lake using Talend Kafka Apache NiFi Flume Automated all the jobs thru Zena scheduler for extracting the data from different Data Sources like DB2 Oracle MongoDB MySQL Postgres to pushing the result set data to Hadoop Distributed File System Installation Configuration setup and deployment of Hadoop cluster 46 Data nodes 2 Master Nodes 15 Edge nodes Configured High Availability cluster for Automatic failover Creates a SOLR schema from the Indexer settings Implemented SOLR index cron jobs Experience in writing SOLR queries for various search documents Responsible for defining the data flow within Hadoop eco system and implement them MongoDB DBA Administration MongoDB Schema Design Installation Configuration and Deployment of MongoDB Ability to Support creating shards replica sets monitoring and projections for Mongo Systems SQL Server 2008 2008 R2 2012 2014 Database Administration and support TSQL SSIS SSRS HADR TECHNICAL PROFESSIONAL EXPERIZE Data Tools Hadoop Cloudera Hortonworks V27 V30 Spark V20 MapReduce Yarn Hive HDFS Pig Hbase Flume Sqoop R Regression Predictive Analysis Data Mining Sentiment Analysis Hue Apache Ambari NIFI SOLR RapidMiner R Mahout Tableau SQL TSQL PLSQL MySQL Hive SQL PostreSQL Python Data frames Lab Juniper PyCharm IDLE Anaconda IPython PyScripter Pig HCatalog Java JSP Eclipse Maven SparkSQL HTML XML etc Oracle 12C SQL Server 2008 2008 R2 2012 2014 MYSQL V8 DB2 for LUW V1114 DB2 for zOS V13 IMS V13 PostGreSQL V108 Amazon RDS Red Hat Enterprise Linux 75 Operating Systems LUW AIX IBM z 13 Series Red Hat Enterprise Linux Hortonworks Data Platform Spark V1 V2 Systems AWS Cloud Computing Clustered Computing Distributed File Systems Business Intelligence Systems Data Mining Systems Reporting and Dash boarding Systems",
    "entities": [
        "Randstad Technologies Client Blue Cross Blue Shield",
        "BDAM",
        "Red Hat",
        "Object Oriented Programming",
        "Office of Personnel Management",
        "Functional Abstractions",
        "LUW",
        "OH Anthem Mason OH",
        "Merge",
        "Abstract Data Structures",
        "Mongo Systems",
        "Spark Core",
        "Responsible for Physical",
        "SC Columbia",
        "AIX",
        "SAS Data",
        "SQL Developer and Power BI Apex Systems Inc",
        "teamIntegrated Medical Management",
        "Data Sources",
        "Agile DevOps",
        "SOLR",
        "Multiple",
        "IBM",
        "IDMS",
        "Database Administrator Unissant Inc",
        "SC I20 Alpine Rd Columbia",
        "Data Server",
        "V39 Installation Configuration",
        "Data Engineering",
        "Data Science for Data",
        "DB2 V 1114",
        "Hadoop",
        "Data Modeler Workgroup Edition Concurrent User License",
        "Cargo Passenger Systems Involved",
        "Data Lake Delta Lake",
        "Nations Premier Healthcare Insurance",
        "IL",
        "DataStage",
        "CBP",
        "Python Working",
        "Linux BLU Data",
        "Schema Design Installation Configuration and Deployment of",
        "Cloudera Hadoop",
        "Oracle MongoDB MySQL Postgres",
        "Create",
        "Database Software Troubleshooting",
        "SparkSQL",
        "Kerberos",
        "Database Administrator Randstad Technologies Woburn",
        "Database Administrator Apex Systems Inc",
        "Backup and Recovery",
        "V41",
        "Python R Elastic Search",
        "Oracle V",
        "Columbia",
        "Structured Semistructured",
        "Social Security Administrations",
        "Active Directory",
        "Database Administrator",
        "Skills Database",
        "Mysql Oracle Plsql Postgres Postgresql",
        "Hortonworks HDP Developer Apache Pig Hive",
        "Configuring IBM Security Guardium",
        "GC",
        "IL HCSC Chicago IL Sr Database Administrator HCSC",
        "Oracle Hadoop",
        "NiFi Developed ETL",
        "Linux AIX Ability",
        "Oozie Worked",
        "DB2 Version 8",
        "FSS",
        "Waterfall Extreme Programming CICD Work Flow GIT Jenkins",
        "lAdministratorspan Database Administrator Unissant Inc",
        "Talend",
        "Integrated Medical Management",
        "DBA",
        "Architecture",
        "DHS Full BI Security Clearance Customs Border Protection",
        "HDP Initiated",
        "TSQL SSIS SSRS HADR TECHNICAL PROFESSIONAL EXPERIZE Data Tools Hadoop",
        "Herndon VA 20170 Client Office of Personnel Management",
        "Database Migrations DBMS Systems",
        "OCR Voting Disk",
        "20171 Client Customs Border Protection",
        "SC Columbia SC Information Systems Engineer Modernization",
        "Database",
        "HIVE",
        "Configuring HADR on DB2 for Linux for Failover",
        "Oracle Oracle PLSQL Development expertise Administration of Anaconda Enterprise",
        "CA",
        "IMS",
        "zOS V13 IMS V13 PostGreSQL",
        "AWS Cloud Mantech International CorporationClient Customs and Border Protection Alexandria Data",
        "Oracle",
        "Hortonworks HDP Hadoop",
        "Oozie etc Ciber Inc",
        "DBMS",
        "SAS",
        "RAC Importing Ingesting",
        "AMS Migration DB2",
        "Database Engineer",
        "SQL",
        "Troubleshoot",
        "MD",
        "DBA Administration",
        "Hadoop Distributed File System Installation Configuration",
        "Metadata Data",
        "Database Administration",
        "Randolph St Chicago IL 60601 Feb",
        "AWS Clouds RDS DB2",
        "Social Security Administration",
        "OCR",
        "Unicode Ebcdic Ascii",
        "Anaconda",
        "Hive",
        "Relationships Data Sources",
        "Prepare Data Architecture Data Migration Data Security Documents",
        "NiFi Data",
        "OPM IBM Certified",
        "Linux V111 Migration",
        "V26",
        "Database Administrator Blue Cross Blue Shield",
        "VA",
        "BigData Oracle",
        "2 Master Nodes",
        "MultiDBMS",
        "RAC",
        "Platinum Products BMC Mainview BMC",
        "Blue Cross Blue Shield",
        "Maven",
        "Database Administrator Ciber Inc",
        "Hortonworks HDP Developer Enterprise Apache Spark",
        "Oracle Database Administrator Data Specialist State Farm Corporate South",
        "Martin Social Security Administration",
        "Database Administrator Randstad Technologies",
        "Spark SQL",
        "Bloomington IL 61701 Jun 2006 Feb",
        "Microsoft",
        "Smart Health",
        "IL Chicago",
        "2 Master Nodes 4 Edge",
        "Data",
        "Edge",
        "Team",
        "NoSQL",
        "Hive Query Language HQL Develop",
        "Teradata",
        "Database Administrator with Modernization",
        "Open Source Platforms Architectures Adept",
        "Node",
        "Ohio",
        "Anthem BlueCross Blue Shield",
        "Oracle 12C"
    ],
    "experience": "Experience Database Administrator Unissant Inc Herndon VA October 2018 to Present 12901 Worldgate Dr 600 Herndon VA 20170 Client Office of Personnel Management 1900 E St NW Washington DC 20415 Oct 2018 Current Data Engineer ManTech International Corporation Herndon VA October 2017 to September 2018 2250 Corporate Park Dr Herndon VA 20171 Client Customs Border Protection 5971 Kingstowne Village Parkway Alexandria VA 22315 Oct 2017 Sept 2018 Database Administrator Randstad Technologies Woburn MA August 2017 to September 2017 150 Presidential Way Woburn MA 01801Client Anthem BlueCross Blue Shield of Ohio 4361 Irwin Simpson Rd Mason OH 45040 Aug 2017 Sept 2017 Database Administrator Blue Cross Blue Shield of IL Chicago IL February 2007 to May 2017 Database Administrator Ciber Inc Bloomington IL June 2006 to February 2007 205 N Main St Bloomington IL 61701 Client STATEFARM Corporate SouthSF Bloomington IL 61701 Jun 2006 Feb 2007 Database Administrator Apex Systems Inc Columbia MD May 2006 to June 2006 Columbia MD 21045 Client Lockheed Martin Social Security Administration Baltimore MD 21244 May 2006 Jun 2006 Information Systems Engineer Blue Cross Blue Shield of SC Columbia SC January 1999 to February 2006 Unissant Inc Client OIG of Office of Personnel Management Washington DC Database Admin Systems Admin Data Modeler Data Architect Lead Database Administrator to Create Cloud AWS platform for DB2 V 1114 on Linux BLU Data analytics and migrate existing SAS based DBMS system to DB2 on Linux RDSPostgreSQL 111 Setup Install DB2 V1111 on AWS RHEL 76x86_64 applied Mod4 Fixpack patches to upgrade to V1114 Did install Data Server Manager V2152 Prepare Data Architecture Data Migration Data Security Documents for the Clients Working to setting up Configuring HADR on DB2 for Linux for Failover on AWS Cloud Working to setting up Configuring IBM Security Guardium 1060 Database Activity Monitoring DAM Setup Configure PostgreSQL 111 upgraded from PostgreSQL 106 with pgAdmin 4 v36 in AWS Cloud and associate it as a Data hub repository for erwin Data Modeler Workgroup Edition Concurrent User License 2018 R1 Provide client connectivity using with DataStage V117 IBM DataStudio client V41 SQuirreL SQL Client V39 Installation Configuration setup and deployment of Hortonworks HDP Hadoop cluster 7 Data nodes 2 Master Nodes 4 Edge nodes in AWS Cloud Installation Configuration setup and deployment of Cloudera Hadoop cluster 5 Data nodes 2 Master Nodes 4 Edge nodes in AWS Cloud Installation Configuration setup 2 node Microsoft Windows Server enabling Kerberos constrained delegation with Active Directory support feature to specify and enforce application trust boundaries by limiting the scope where application services can act in AWS Cloud Mantech International CorporationClient Customs and Border Protection Alexandria Data Engineer Part of Data Engineering group to capture document the data sources provenance and Architecture of the CBP EMIS data warehouse This effort should provide better tools for data mining and Data Science for Data warehouse Big Data efforts Involved in developing reengineering PLSQL procedures with Regular Expressions for very critical analytics project Involved with analyzing the Metadata Data structures Relationships Data Sources for both Cargo Passenger Systems Involved as Database Engineer providing support to BigData Oracle for OLAP Importing data from Multiple sources into Data Lake Delta Lake using Talend Kafka Apache NiFi Data mining Analtics Visualzation using Anaconda Python R Elastic Search Elastic Lucene etc Randstad Technologies Client Blue Cross Blue Shield of OH Anthem Mason OH Consultant Database Administrator I was involved as Database Administrator with Modernization expert of Legacy IMS DB2 database systems to Oracle in addition to everyday monitoring maintenance enhancements and new project development for applications Blue Cross Blue Shield of IL HCSC Chicago IL Sr Database Administrator HCSC is one of Nations Premier Healthcare Insurance provider with a membership of over 13 million am currently involved as Database Administrator with zero down time and supporting with maintenance enhancements and new Database development for applications Database Migrations DBMS Systems Performance Tuning Capacity planning of applications DB2 Oracle Hadoop MongoDB DBMS systems Responsible for High Availability accessibility of databases This effort involves 24X7 support of 230 million per day OLTP Health Claims transactions in DB2 oracle Sub systems on zOS AIX RHEL Worked supported development teams Integrated Medical Management develop Python applications to come up with pricing models for firsttime uninsured health insurance subscribers to generate pricing for actuarial team Tuples of firsttime insurers were mined from historical data for generating health costs associated with those health subscribers for first three years with age range Was part of teamIntegrated Medical Management to analyze the impacts of migration of ICD7 to ICD10 Implementation on Health claims by providers institutions utilizing Python Python applications were also developed to make old claims to be compatible to new format of medical procedure codes Extending support to Oracle Hadoop MongoDB along with DB2 to embrace multi DBMS support concept and embrace paradigm of management for Open Source Software Commodity Hardware to reduce costs Install configure setup 3 Master Node 47 Slave Node 15 Edge Node Cluster Developed process to ingest Structured Semistructured data into HDFS using Scoop Talend Elastic Search KAFKA Helped in supporting Flume Ingestion and configuring Source Channel Sink setup automated backups using Oozie etc Ciber Inc Client Statefarm Corporate South Bloomington IL DB2 Oracle Database Administrator Data Specialist State Farm Corporate South is a centralized headquarters for its data processing functions Statefarm is the Nations leading auto insurer Was involved as project DBA in FSS group with maintenance enhancements and new Database development for applications Responsible for Physical database design development of databases maintenance Jobs Performance validations involving Unicode Ebcdic Ascii translations using SQL Developer and Power BI Apex Systems Inc Client Lockheed Martin Social Security Administration Baltimore DB2 Database Administrator High Performance Design Analyst Lockheed Martin supports the complete range of services related to Social Security Administrations major systems modernization initiatives Involved with analysis and design of implementation of DB2 Ver 8 Release on very large Social Security Administration databases and migration of databases from BDAM to DB2 The objective is to migrate with zero issues to DB2 Version 8 and analyzing its impact on Applications and DB2 systems with version upgrade DB2 Administration Tool CA tools Platinum Products BMC Mainview BMC tools IBM tools Blue Cross Blue Shield of SC Columbia SC Information Systems Engineer Modernization of systems for 24X7 availability of systems adjudication of health claims Smart Health card Migration of VSAM to DB2 in line with the paradigm of the organization to have a single data infrastructure for growing business and technical needs like faster processing of Claims access of Data by customers and deployment of new applications consistency in quality of data real time availability of data 24X7 facilitating running of Sysplex environments and concurrency in data updates between online and batch Skills Database administration Database Db2 Dbms Sql server Sql server 2008 Mysql Oracle Plsql Postgres Postgresql Sql Stored procedures Vsam Ambari Hdfs Mahout Mapreduce Oozie Sqoop Additional Information TECHNICAL PROFILE Be proactively engaged in new methodologies like Agile DevOps SCRUM Waterfall Extreme Programming CICD Work Flow GIT Jenkins etc The future state of Architecture has contained Legacy transition to Open Source Platforms Architectures Adept at managing multiple concurrent projects being attentive to detail and maintaining the ability to make rational decisions in pressure situations Willingness to own responsibility and work to resolve issues Ability to work with commitment passion and thrust to exceed Customers expectation both as an Individual and as a Team member with the knowledge that each Customers expectations are unique DB2 for LUW V 1114 on Linux PostgreSQL V 114 pgAdmin v410 Oracle V 122 MySQL V 80 Red Hat Enterprise Linux 75 SQL Server 2008 2008 R2 2012 2014 Hadoop V24 V26 V28 V30 Cloudera Horton works Legacy zOS systems IMS DB2 IDMS to Oracle Oracle PLSQL Development expertise Administration of Anaconda Enterprise My responsibilities include installation configuration and management of the application proficiently navigating within the linux Create custom python environments and install and maintain them on various Hadoop clusters Work with Data Scientists as they launch python and pyspark jobs or deploy models that interact with data on hdfs and hive Engage with users transitioning from traditional data sources to Python Working to migrate a SAS Data warehouse on premise to AWS Clouds RDS DB2 by building data pipelines using NiFi Developed ETL and analytics focused Spark Core applications in Python including Spark SQL applications to interact with HIVE tables Building data pipelines to migrate data from Teradata to Hadoop env HDP Initiated poc to automate data pipelines using Oozie Worked towards building a Data Lake that is discoverable accessible and usable given diverse constraints onprem hybrid and cloud environments Ensure that data hydrating into the data lake has appropriate metadatatags with it using various enterprise metadata management tools Capture metadata throughout the data life cycle and consolidate it so as to enable searchbrowsesample data Import of unstructured data into HDFS using Flume using both File and Memory channels Develop Pig Latin scripts and writing UDFs in Python when needed to extract transform and mine data Write Hive Queries for analyzing data in Hive warehouse using Hive Query Language HQL Develop novel Abstract Data Structures and Functional Abstractions to process data text analysis humanmachine interactions weblogs and social media streaming Apply principles of Object Oriented Programming in designing and implementing applications with a specific focus on controlling complexity Focused on creating warehouses databases to meet the rapidly changing needs of various business units Create execute and schedule both master and standalone jobs with a focus on parallel execution when writing large files onto databases Extensive experience in supporting MultiDBMS data migrations IMS to DB2 Migration VSAM to DB2 Migration CAIDMS to DB2 Migration SAS to DB2 for Linux V111 Migration Legacy to AMS Migration DB2 to Oracle migration DB2 to SQL Server Migration High proficiency in designing building and administering Oracle clustered server configurations supporting 11 g and 12c Real Application Clusters RAC installations on Linux AIX Ability to work on developing stored procedures Functions and Triggers PLSQL procedures Korn shell scripts Installing configuring Oracle cluster ware Database Software Troubleshooting handling common issues that arise during integration of the whole bugs network issues configuration files issues OCR issue deinstallation cleanup of cluster ware Ability to Work with customers for various RAC related issue RAC recovery RMAN ASM OCR corruptions voting disk loss etc Troubleshoot performance issues for the RAC instances GC events Backup and Recovery issues related loss of OCR Voting Disk and Oracle cluster ware also issues with corruption of individual disk data blocks loss of OS configuration files loss of net configuration files Also used the Merge backup for backing terabyte databases Issues with block change tracking also flash recovery area Add or Remove Node from RAC Importing Ingesting data from Multiple sources into Data Lake Delta Lake using Talend Kafka Apache NiFi Flume Automated all the jobs thru Zena scheduler for extracting the data from different Data Sources like DB2 Oracle MongoDB MySQL Postgres to pushing the result set data to Hadoop Distributed File System Installation Configuration setup and deployment of Hadoop cluster 46 Data nodes 2 Master Nodes 15 Edge nodes Configured High Availability cluster for Automatic failover Creates a SOLR schema from the Indexer settings Implemented SOLR index cron jobs Experience in writing SOLR queries for various search documents Responsible for defining the data flow within Hadoop eco system and implement them MongoDB DBA Administration MongoDB Schema Design Installation Configuration and Deployment of MongoDB Ability to Support creating shards replica sets monitoring and projections for Mongo Systems SQL Server 2008 2008 R2 2012 2014 Database Administration and support TSQL SSIS SSRS HADR TECHNICAL PROFESSIONAL EXPERIZE Data Tools Hadoop Cloudera Hortonworks V27 V30 Spark V20 MapReduce Yarn Hive HDFS Pig Hbase Flume Sqoop R Regression Predictive Analysis Data Mining Sentiment Analysis Hue Apache Ambari NIFI SOLR RapidMiner R Mahout Tableau SQL TSQL PLSQL MySQL Hive SQL PostreSQL Python Data frames Lab Juniper PyCharm IDLE Anaconda IPython PyScripter Pig HCatalog Java JSP Eclipse Maven SparkSQL HTML XML etc Oracle 12C SQL Server 2008 2008 R2 2012 2014 MYSQL V8 DB2 for LUW V1114 DB2 for zOS V13 IMS V13 PostGreSQL V108 Amazon RDS Red Hat Enterprise Linux 75 Operating Systems LUW AIX IBM z 13 Series Red Hat Enterprise Linux Hortonworks Data Platform Spark V1 V2 Systems AWS Cloud Computing Clustered Computing Distributed File Systems Business Intelligence Systems Data Mining Systems Reporting and Dash boarding Systems",
    "extracted_keywords": [
        "Database",
        "Administrator",
        "Database",
        "lAdministratorspan",
        "Database",
        "Administrator",
        "Unissant",
        "Inc",
        "Woodbridge",
        "VA",
        "Weldin",
        "Dr",
        "Woodbridge",
        "VA",
        "Phone",
        "Email",
        "stanleyreddygmailcom",
        "DHS",
        "BI",
        "Security",
        "Clearance",
        "Customs",
        "Border",
        "Protection",
        "suitability",
        "determination",
        "validity",
        "Public",
        "Trust",
        "Level",
        "Security",
        "Clearance",
        "Office",
        "Personnel",
        "Management",
        "Completed",
        "BI",
        "adjudication",
        "OPM",
        "IBM",
        "DB2",
        "zOS",
        "Database",
        "Administrator",
        "IBM",
        "Certified",
        "Database",
        "Associate",
        "IBM",
        "Certified",
        "Application",
        "Developer",
        "Oracle",
        "SQL",
        "Server",
        "MySQL",
        "NoSQL",
        "DB2",
        "Database",
        "Admin",
        "Hortonworks",
        "Hadoop",
        "Admin",
        "credential",
        "Hortonworks",
        "HDP",
        "Developer",
        "Enterprise",
        "Apache",
        "Spark",
        "credential",
        "Hortonworks",
        "HDP",
        "Developer",
        "Apache",
        "Pig",
        "Hive",
        "credential",
        "MongoDB",
        "DBAs",
        "University",
        "credential",
        "Database",
        "Administrator",
        "Unissant",
        "Inc",
        "Worldgate",
        "Dr",
        "Herndon",
        "VA",
        "Client",
        "Office",
        "Personnel",
        "Management",
        "E",
        "St",
        "NW",
        "Washington",
        "DC",
        "Oct",
        "Current",
        "Data",
        "Engineer",
        "ManTech",
        "International",
        "Corporation",
        "Corporate",
        "Park",
        "Dr",
        "Herndon",
        "VA",
        "Client",
        "Customs",
        "Border",
        "Protection",
        "Kingstowne",
        "Village",
        "Parkway",
        "Alexandria",
        "VA",
        "Oct",
        "Sept",
        "Database",
        "Administrator",
        "Randstad",
        "Technologies",
        "Way",
        "Woburn",
        "MA",
        "01801Client",
        "Anthem",
        "BlueCross",
        "Blue",
        "Shield",
        "Ohio",
        "Irwin",
        "Simpson",
        "Rd",
        "Mason",
        "OH",
        "Aug",
        "Sept",
        "Database",
        "Administrator",
        "Blue",
        "Cross",
        "Blue",
        "Shield",
        "IL",
        "HCSC",
        "E",
        "Randolph",
        "St",
        "Chicago",
        "IL",
        "Feb",
        "May",
        "Database",
        "Administrator",
        "Ciber",
        "Inc",
        "N",
        "Main",
        "St",
        "Bloomington",
        "IL",
        "Client",
        "STATEFARM",
        "Corporate",
        "SouthSF",
        "Bloomington",
        "IL",
        "Jun",
        "Feb",
        "Database",
        "Administrator",
        "Apex",
        "Systems",
        "Inc",
        "Columbia",
        "MD",
        "Client",
        "Lockheed",
        "Martin",
        "Social",
        "Security",
        "Administration",
        "Baltimore",
        "MD",
        "May",
        "Jun",
        "Information",
        "Systems",
        "Engineer",
        "Blue",
        "Cross",
        "Blue",
        "Shield",
        "SC",
        "I20",
        "Alpine",
        "Rd",
        "Columbia",
        "SC",
        "Jan",
        "Feb",
        "Work",
        "Experience",
        "Database",
        "Administrator",
        "Unissant",
        "Inc",
        "Herndon",
        "VA",
        "October",
        "Present",
        "Worldgate",
        "Dr",
        "Herndon",
        "VA",
        "Client",
        "Office",
        "Personnel",
        "Management",
        "E",
        "St",
        "NW",
        "Washington",
        "DC",
        "Oct",
        "Current",
        "Data",
        "Engineer",
        "ManTech",
        "International",
        "Corporation",
        "Herndon",
        "VA",
        "October",
        "September",
        "Corporate",
        "Park",
        "Dr",
        "Herndon",
        "VA",
        "Client",
        "Customs",
        "Border",
        "Protection",
        "Kingstowne",
        "Village",
        "Parkway",
        "Alexandria",
        "VA",
        "Oct",
        "Sept",
        "Database",
        "Administrator",
        "Randstad",
        "Technologies",
        "Woburn",
        "MA",
        "August",
        "September",
        "Way",
        "Woburn",
        "MA",
        "01801Client",
        "Anthem",
        "BlueCross",
        "Blue",
        "Shield",
        "Ohio",
        "Irwin",
        "Simpson",
        "Rd",
        "Mason",
        "OH",
        "Aug",
        "Sept",
        "Database",
        "Administrator",
        "Blue",
        "Cross",
        "Blue",
        "Shield",
        "IL",
        "Chicago",
        "IL",
        "February",
        "May",
        "Database",
        "Administrator",
        "Ciber",
        "Inc",
        "Bloomington",
        "IL",
        "June",
        "February",
        "Main",
        "St",
        "Bloomington",
        "IL",
        "Client",
        "STATEFARM",
        "Corporate",
        "SouthSF",
        "Bloomington",
        "IL",
        "Jun",
        "Feb",
        "Database",
        "Administrator",
        "Apex",
        "Systems",
        "Inc",
        "Columbia",
        "MD",
        "May",
        "June",
        "Columbia",
        "MD",
        "Client",
        "Lockheed",
        "Martin",
        "Social",
        "Security",
        "Administration",
        "Baltimore",
        "MD",
        "May",
        "Jun",
        "Information",
        "Systems",
        "Engineer",
        "Blue",
        "Cross",
        "Blue",
        "Shield",
        "SC",
        "Columbia",
        "SC",
        "January",
        "February",
        "Unissant",
        "Inc",
        "Client",
        "OIG",
        "Office",
        "Personnel",
        "Management",
        "Washington",
        "DC",
        "Database",
        "Admin",
        "Systems",
        "Admin",
        "Data",
        "Modeler",
        "Data",
        "Architect",
        "Lead",
        "Database",
        "Administrator",
        "Cloud",
        "AWS",
        "platform",
        "DB2",
        "V",
        "Linux",
        "BLU",
        "Data",
        "analytics",
        "SAS",
        "DBMS",
        "system",
        "DB2",
        "Linux",
        "RDSPostgreSQL",
        "Setup",
        "Install",
        "DB2",
        "V1111",
        "AWS",
        "RHEL",
        "76x86_64",
        "Fixpack",
        "V1114",
        "Data",
        "Server",
        "Manager",
        "V2152",
        "Prepare",
        "Data",
        "Architecture",
        "Data",
        "Migration",
        "Data",
        "Security",
        "Documents",
        "Clients",
        "Configuring",
        "HADR",
        "DB2",
        "Linux",
        "Failover",
        "AWS",
        "Cloud",
        "Working",
        "Configuring",
        "IBM",
        "Security",
        "Guardium",
        "Database",
        "Activity",
        "Monitoring",
        "DAM",
        "Setup",
        "Configure",
        "PostgreSQL",
        "PostgreSQL",
        "pgAdmin",
        "v36",
        "AWS",
        "Cloud",
        "Data",
        "hub",
        "repository",
        "erwin",
        "Data",
        "Modeler",
        "Workgroup",
        "Edition",
        "Concurrent",
        "User",
        "License",
        "R1",
        "client",
        "connectivity",
        "DataStage",
        "V117",
        "IBM",
        "DataStudio",
        "client",
        "V41",
        "SQL",
        "Client",
        "V39",
        "Installation",
        "Configuration",
        "setup",
        "deployment",
        "Hortonworks",
        "HDP",
        "Hadoop",
        "cluster",
        "Data",
        "nodes",
        "Master",
        "Nodes",
        "Edge",
        "nodes",
        "AWS",
        "Cloud",
        "Installation",
        "Configuration",
        "setup",
        "deployment",
        "Cloudera",
        "Hadoop",
        "cluster",
        "Data",
        "nodes",
        "Master",
        "Nodes",
        "Edge",
        "nodes",
        "AWS",
        "Cloud",
        "Installation",
        "Configuration",
        "setup",
        "node",
        "Microsoft",
        "Windows",
        "Server",
        "Kerberos",
        "delegation",
        "Active",
        "Directory",
        "support",
        "application",
        "trust",
        "boundaries",
        "scope",
        "application",
        "services",
        "AWS",
        "Cloud",
        "Mantech",
        "International",
        "CorporationClient",
        "Customs",
        "Border",
        "Protection",
        "Alexandria",
        "Data",
        "Engineer",
        "Part",
        "Data",
        "Engineering",
        "group",
        "document",
        "data",
        "sources",
        "provenance",
        "Architecture",
        "CBP",
        "EMIS",
        "data",
        "warehouse",
        "effort",
        "tools",
        "data",
        "mining",
        "Data",
        "Science",
        "Data",
        "warehouse",
        "Big",
        "Data",
        "efforts",
        "PLSQL",
        "procedures",
        "Regular",
        "Expressions",
        "analytics",
        "project",
        "Metadata",
        "Data",
        "structures",
        "Relationships",
        "Data",
        "Sources",
        "Cargo",
        "Passenger",
        "Systems",
        "Database",
        "Engineer",
        "support",
        "BigData",
        "Oracle",
        "OLAP",
        "data",
        "sources",
        "Data",
        "Lake",
        "Delta",
        "Lake",
        "Talend",
        "Kafka",
        "Apache",
        "NiFi",
        "Data",
        "mining",
        "Analtics",
        "Visualzation",
        "Anaconda",
        "Python",
        "R",
        "Elastic",
        "Search",
        "Elastic",
        "Lucene",
        "Randstad",
        "Technologies",
        "Client",
        "Blue",
        "Cross",
        "Blue",
        "Shield",
        "OH",
        "Anthem",
        "Mason",
        "OH",
        "Consultant",
        "Database",
        "Administrator",
        "Database",
        "Administrator",
        "Modernization",
        "expert",
        "Legacy",
        "IMS",
        "DB2",
        "database",
        "systems",
        "Oracle",
        "addition",
        "maintenance",
        "enhancements",
        "project",
        "development",
        "applications",
        "Blue",
        "Cross",
        "Blue",
        "Shield",
        "IL",
        "HCSC",
        "Chicago",
        "IL",
        "Sr",
        "Database",
        "Administrator",
        "HCSC",
        "Nations",
        "Premier",
        "Healthcare",
        "Insurance",
        "provider",
        "membership",
        "Database",
        "Administrator",
        "time",
        "maintenance",
        "enhancements",
        "Database",
        "development",
        "applications",
        "Database",
        "Migrations",
        "DBMS",
        "Systems",
        "Performance",
        "Capacity",
        "planning",
        "applications",
        "DB2",
        "Oracle",
        "Hadoop",
        "MongoDB",
        "DBMS",
        "systems",
        "Availability",
        "accessibility",
        "databases",
        "effort",
        "support",
        "day",
        "OLTP",
        "Health",
        "Claims",
        "transactions",
        "DB2",
        "oracle",
        "Sub",
        "systems",
        "zOS",
        "AIX",
        "RHEL",
        "Worked",
        "development",
        "teams",
        "Integrated",
        "Medical",
        "Management",
        "Python",
        "applications",
        "pricing",
        "models",
        "firsttime",
        "health",
        "insurance",
        "subscribers",
        "pricing",
        "team",
        "Tuples",
        "firsttime",
        "insurers",
        "data",
        "health",
        "costs",
        "health",
        "subscribers",
        "years",
        "age",
        "range",
        "part",
        "Medical",
        "Management",
        "impacts",
        "migration",
        "ICD7",
        "ICD10",
        "Implementation",
        "Health",
        "claims",
        "providers",
        "institutions",
        "Python",
        "Python",
        "applications",
        "claims",
        "format",
        "procedure",
        "codes",
        "support",
        "Oracle",
        "Hadoop",
        "MongoDB",
        "DB2",
        "multi",
        "DBMS",
        "support",
        "concept",
        "paradigm",
        "management",
        "Open",
        "Source",
        "Software",
        "Commodity",
        "Hardware",
        "costs",
        "configure",
        "setup",
        "Master",
        "Node",
        "Slave",
        "Node",
        "Edge",
        "Node",
        "Cluster",
        "process",
        "Structured",
        "Semistructured",
        "data",
        "HDFS",
        "Scoop",
        "Talend",
        "Elastic",
        "Search",
        "KAFKA",
        "Flume",
        "Ingestion",
        "Source",
        "Channel",
        "Sink",
        "setup",
        "backups",
        "Oozie",
        "Ciber",
        "Inc",
        "Client",
        "Statefarm",
        "Corporate",
        "South",
        "Bloomington",
        "IL",
        "DB2",
        "Oracle",
        "Database",
        "Administrator",
        "Data",
        "Specialist",
        "State",
        "Farm",
        "Corporate",
        "South",
        "headquarters",
        "data",
        "processing",
        "functions",
        "Statefarm",
        "Nations",
        "auto",
        "insurer",
        "project",
        "DBA",
        "FSS",
        "group",
        "maintenance",
        "enhancements",
        "Database",
        "development",
        "applications",
        "database",
        "design",
        "development",
        "databases",
        "maintenance",
        "Jobs",
        "Performance",
        "validations",
        "Unicode",
        "Ebcdic",
        "Ascii",
        "translations",
        "SQL",
        "Developer",
        "Power",
        "BI",
        "Apex",
        "Systems",
        "Inc",
        "Client",
        "Lockheed",
        "Martin",
        "Social",
        "Security",
        "Administration",
        "Baltimore",
        "DB2",
        "Database",
        "Administrator",
        "High",
        "Performance",
        "Design",
        "Analyst",
        "Lockheed",
        "Martin",
        "range",
        "services",
        "Social",
        "Security",
        "Administrations",
        "systems",
        "modernization",
        "initiatives",
        "analysis",
        "design",
        "implementation",
        "DB2",
        "Ver",
        "Release",
        "Social",
        "Security",
        "Administration",
        "databases",
        "migration",
        "databases",
        "BDAM",
        "DB2",
        "objective",
        "issues",
        "DB2",
        "Version",
        "impact",
        "Applications",
        "DB2",
        "systems",
        "version",
        "upgrade",
        "DB2",
        "Administration",
        "Tool",
        "CA",
        "Platinum",
        "Products",
        "BMC",
        "Mainview",
        "BMC",
        "tools",
        "IBM",
        "tools",
        "Blue",
        "Cross",
        "Blue",
        "Shield",
        "SC",
        "Columbia",
        "SC",
        "Information",
        "Systems",
        "Engineer",
        "Modernization",
        "systems",
        "availability",
        "systems",
        "adjudication",
        "health",
        "Smart",
        "Health",
        "card",
        "Migration",
        "VSAM",
        "DB2",
        "line",
        "paradigm",
        "organization",
        "data",
        "infrastructure",
        "business",
        "needs",
        "processing",
        "Claims",
        "access",
        "Data",
        "customers",
        "deployment",
        "applications",
        "consistency",
        "quality",
        "data",
        "time",
        "availability",
        "data",
        "24X7",
        "running",
        "Sysplex",
        "environments",
        "concurrency",
        "data",
        "updates",
        "Skills",
        "Database",
        "administration",
        "Database",
        "Db2",
        "Dbms",
        "Sql",
        "server",
        "Sql",
        "server",
        "Mysql",
        "Oracle",
        "Plsql",
        "Postgres",
        "Postgresql",
        "Sql",
        "procedures",
        "Vsam",
        "Ambari",
        "Hdfs",
        "Mahout",
        "Mapreduce",
        "Oozie",
        "Sqoop",
        "Additional",
        "Information",
        "TECHNICAL",
        "PROFILE",
        "methodologies",
        "Agile",
        "DevOps",
        "Waterfall",
        "Extreme",
        "Programming",
        "CICD",
        "Work",
        "Flow",
        "GIT",
        "Jenkins",
        "state",
        "Architecture",
        "Legacy",
        "transition",
        "Open",
        "Source",
        "Platforms",
        "Adept",
        "projects",
        "ability",
        "decisions",
        "pressure",
        "situations",
        "Willingness",
        "responsibility",
        "work",
        "issues",
        "Ability",
        "commitment",
        "passion",
        "thrust",
        "Customers",
        "expectation",
        "Individual",
        "Team",
        "member",
        "knowledge",
        "Customers",
        "expectations",
        "DB2",
        "LUW",
        "V",
        "Linux",
        "PostgreSQL",
        "V",
        "v410",
        "Oracle",
        "V",
        "MySQL",
        "V",
        "Red",
        "Hat",
        "Enterprise",
        "Linux",
        "SQL",
        "Server",
        "R2",
        "Hadoop",
        "V24",
        "V26",
        "V28",
        "V30",
        "Cloudera",
        "Horton",
        "Legacy",
        "zOS",
        "systems",
        "IMS",
        "DB2",
        "IDMS",
        "Oracle",
        "Oracle",
        "PLSQL",
        "Development",
        "expertise",
        "Administration",
        "Anaconda",
        "Enterprise",
        "responsibilities",
        "installation",
        "configuration",
        "management",
        "application",
        "linux",
        "custom",
        "python",
        "environments",
        "Hadoop",
        "clusters",
        "Data",
        "Scientists",
        "python",
        "pyspark",
        "jobs",
        "models",
        "data",
        "hdfs",
        "hive",
        "Engage",
        "users",
        "data",
        "sources",
        "Python",
        "Working",
        "SAS",
        "Data",
        "warehouse",
        "premise",
        "AWS",
        "Clouds",
        "RDS",
        "DB2",
        "data",
        "pipelines",
        "NiFi",
        "Developed",
        "ETL",
        "analytics",
        "Spark",
        "Core",
        "applications",
        "Python",
        "Spark",
        "SQL",
        "applications",
        "HIVE",
        "tables",
        "data",
        "pipelines",
        "data",
        "Teradata",
        "Hadoop",
        "env",
        "HDP",
        "Initiated",
        "poc",
        "data",
        "pipelines",
        "Oozie",
        "Worked",
        "Data",
        "Lake",
        "constraints",
        "onprem",
        "hybrid",
        "environments",
        "data",
        "data",
        "lake",
        "metadatatags",
        "enterprise",
        "metadata",
        "management",
        "tools",
        "Capture",
        "metadata",
        "data",
        "life",
        "cycle",
        "data",
        "Import",
        "data",
        "HDFS",
        "Flume",
        "File",
        "Memory",
        "channels",
        "Develop",
        "Pig",
        "Latin",
        "scripts",
        "UDFs",
        "Python",
        "transform",
        "mine",
        "data",
        "Write",
        "Hive",
        "Queries",
        "data",
        "Hive",
        "warehouse",
        "Hive",
        "Query",
        "Language",
        "HQL",
        "Develop",
        "novel",
        "Abstract",
        "Data",
        "Structures",
        "Functional",
        "Abstractions",
        "data",
        "text",
        "analysis",
        "humanmachine",
        "interactions",
        "weblogs",
        "media",
        "streaming",
        "principles",
        "Object",
        "Programming",
        "applications",
        "focus",
        "complexity",
        "warehouses",
        "databases",
        "needs",
        "business",
        "units",
        "execute",
        "master",
        "jobs",
        "focus",
        "execution",
        "files",
        "databases",
        "experience",
        "data",
        "migrations",
        "IMS",
        "DB2",
        "Migration",
        "VSAM",
        "DB2",
        "Migration",
        "CAIDMS",
        "DB2",
        "Migration",
        "SAS",
        "DB2",
        "Linux",
        "V111",
        "Migration",
        "Legacy",
        "AMS",
        "Migration",
        "DB2",
        "Oracle",
        "migration",
        "DB2",
        "SQL",
        "Server",
        "Migration",
        "proficiency",
        "building",
        "Oracle",
        "server",
        "configurations",
        "g",
        "Real",
        "Application",
        "Clusters",
        "RAC",
        "installations",
        "Linux",
        "AIX",
        "Ability",
        "procedures",
        "Functions",
        "Triggers",
        "PLSQL",
        "Korn",
        "shell",
        "scripts",
        "Oracle",
        "cluster",
        "ware",
        "Database",
        "Software",
        "Troubleshooting",
        "issues",
        "integration",
        "bugs",
        "network",
        "issues",
        "configuration",
        "files",
        "issues",
        "OCR",
        "issue",
        "deinstallation",
        "cleanup",
        "cluster",
        "Ability",
        "customers",
        "RAC",
        "issue",
        "RAC",
        "recovery",
        "RMAN",
        "ASM",
        "OCR",
        "corruptions",
        "disk",
        "loss",
        "Troubleshoot",
        "performance",
        "issues",
        "RAC",
        "instances",
        "GC",
        "events",
        "Backup",
        "Recovery",
        "issues",
        "loss",
        "OCR",
        "Voting",
        "Disk",
        "Oracle",
        "cluster",
        "ware",
        "corruption",
        "disk",
        "data",
        "loss",
        "OS",
        "configuration",
        "files",
        "loss",
        "configuration",
        "files",
        "Merge",
        "backup",
        "terabyte",
        "Issues",
        "block",
        "change",
        "tracking",
        "recovery",
        "area",
        "Add",
        "Remove",
        "Node",
        "RAC",
        "Importing",
        "data",
        "sources",
        "Data",
        "Lake",
        "Delta",
        "Lake",
        "Talend",
        "Kafka",
        "Apache",
        "NiFi",
        "Flume",
        "jobs",
        "Zena",
        "scheduler",
        "data",
        "Data",
        "Sources",
        "DB2",
        "Oracle",
        "MongoDB",
        "MySQL",
        "Postgres",
        "result",
        "data",
        "Hadoop",
        "Distributed",
        "File",
        "System",
        "Installation",
        "Configuration",
        "setup",
        "deployment",
        "Hadoop",
        "cluster",
        "Data",
        "nodes",
        "Master",
        "Nodes",
        "Edge",
        "nodes",
        "Configured",
        "High",
        "Availability",
        "cluster",
        "failover",
        "SOLR",
        "schema",
        "Indexer",
        "settings",
        "SOLR",
        "index",
        "cron",
        "jobs",
        "Experience",
        "SOLR",
        "queries",
        "search",
        "documents",
        "data",
        "flow",
        "Hadoop",
        "eco",
        "system",
        "MongoDB",
        "DBA",
        "Administration",
        "MongoDB",
        "Schema",
        "Design",
        "Installation",
        "Configuration",
        "Deployment",
        "Ability",
        "shards",
        "replica",
        "monitoring",
        "projections",
        "Mongo",
        "Systems",
        "SQL",
        "Server",
        "R2",
        "Database",
        "Administration",
        "TSQL",
        "SSIS",
        "SSRS",
        "HADR",
        "TECHNICAL",
        "PROFESSIONAL",
        "EXPERIZE",
        "Data",
        "Tools",
        "Hadoop",
        "Cloudera",
        "Hortonworks",
        "V27",
        "V30",
        "Spark",
        "V20",
        "MapReduce",
        "Yarn",
        "Hive",
        "HDFS",
        "Pig",
        "Hbase",
        "Flume",
        "Sqoop",
        "R",
        "Regression",
        "Predictive",
        "Analysis",
        "Data",
        "Mining",
        "Sentiment",
        "Analysis",
        "Hue",
        "Apache",
        "Ambari",
        "NIFI",
        "SOLR",
        "RapidMiner",
        "R",
        "Mahout",
        "Tableau",
        "SQL",
        "TSQL",
        "PLSQL",
        "MySQL",
        "Hive",
        "SQL",
        "PostreSQL",
        "Python",
        "Data",
        "Lab",
        "Juniper",
        "PyCharm",
        "IDLE",
        "Anaconda",
        "IPython",
        "PyScripter",
        "Pig",
        "HCatalog",
        "Java",
        "JSP",
        "Eclipse",
        "Maven",
        "SparkSQL",
        "HTML",
        "XML",
        "Oracle",
        "SQL",
        "Server",
        "R2",
        "MYSQL",
        "V8",
        "DB2",
        "LUW",
        "V1114",
        "DB2",
        "zOS",
        "V13",
        "IMS",
        "V13",
        "PostGreSQL",
        "V108",
        "Amazon",
        "RDS",
        "Red",
        "Hat",
        "Enterprise",
        "Linux",
        "Operating",
        "Systems",
        "LUW",
        "AIX",
        "IBM",
        "z",
        "Series",
        "Red",
        "Hat",
        "Enterprise",
        "Linux",
        "Hortonworks",
        "Data",
        "Platform",
        "Spark",
        "V1",
        "V2",
        "Systems",
        "AWS",
        "Cloud",
        "Computing",
        "Clustered",
        "Computing",
        "Distributed",
        "File",
        "Systems",
        "Business",
        "Intelligence",
        "Systems",
        "Data",
        "Mining",
        "Systems",
        "Reporting",
        "Dash",
        "boarding",
        "Systems"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:04:08.765643",
    "resume_data": "Database Administrator Database span lAdministratorspan Database Administrator Unissant Inc Woodbridge VA 15402 Weldin Dr Woodbridge VA 22193 Phone 847 3319062 Email stanleyreddygmailcom Active DHS Full BI Security Clearance Customs Border Protection suitability determination validity till 12122022 Public Trust Level 4 Security Clearance Office of Personnel Management Completed BI waiting adjudication in OPM IBM Certified DB2 for zOS Database Administrator IBM Certified Database Associate IBM Certified Application Developer Oracle SQL Server MySQL NoSQL DB2 Database Admin Hortonworks Hadoop Admin academic credential Hortonworks HDP Developer Enterprise Apache Spark academic credential Hortonworks HDP Developer Apache Pig Hive academic credential MongoDB for DBAs MongoDB University academic credential Database Administrator Unissant Inc 12901 Worldgate Dr 600 Herndon VA 20170 Client Office of Personnel Management 1900 E St NW Washington DC 20415 Oct 2018 Current Data Engineer ManTech International Corporation 2250 Corporate Park Dr Herndon VA 20171 Client Customs Border Protection 5971 Kingstowne Village Parkway Alexandria VA 22315 Oct 2017 Sept 2018 Database Administrator Randstad Technologies 150 Presidential Way Woburn MA 01801Client Anthem BlueCross Blue Shield of Ohio 4361 Irwin Simpson Rd Mason OH 45040 Aug 2017 Sept 2017 Database Administrator Blue Cross Blue Shield of IL HCSC 300 E Randolph St Chicago IL 60601 Feb 2007 May 2017 Database Administrator Ciber Inc 205 N Main St Bloomington IL 61701 Client STATEFARM Corporate SouthSF Bloomington IL 61701 Jun 2006 Feb 2007 Database Administrator Apex Systems Inc Columbia MD 21045 Client Lockheed Martin Social Security Administration Baltimore MD 21244 May 2006 Jun 2006 Information Systems Engineer Blue Cross Blue Shield of SC I20 Alpine Rd Columbia SC 29219 Jan 1999 Feb 2006 Work Experience Database Administrator Unissant Inc Herndon VA October 2018 to Present 12901 Worldgate Dr 600 Herndon VA 20170 Client Office of Personnel Management 1900 E St NW Washington DC 20415 Oct 2018 Current Data Engineer ManTech International Corporation Herndon VA October 2017 to September 2018 2250 Corporate Park Dr Herndon VA 20171 Client Customs Border Protection 5971 Kingstowne Village Parkway Alexandria VA 22315 Oct 2017 Sept 2018 Database Administrator Randstad Technologies Woburn MA August 2017 to September 2017 150 Presidential Way Woburn MA 01801Client Anthem BlueCross Blue Shield of Ohio 4361 Irwin Simpson Rd Mason OH 45040 Aug 2017 Sept 2017 Database Administrator Blue Cross Blue Shield of IL Chicago IL February 2007 to May 2017 Database Administrator Ciber Inc Bloomington IL June 2006 to February 2007 205 N Main St Bloomington IL 61701 Client STATEFARM Corporate SouthSF Bloomington IL 61701 Jun 2006 Feb 2007 Database Administrator Apex Systems Inc Columbia MD May 2006 to June 2006 Columbia MD 21045 Client Lockheed Martin Social Security Administration Baltimore MD 21244 May 2006 Jun 2006 Information Systems Engineer Blue Cross Blue Shield of SC Columbia SC January 1999 to February 2006 Unissant Inc Client OIG of Office of Personnel Management Washington DC Database Admin Systems Admin Data Modeler Data Architect Lead Database Administrator to Create Cloud AWS platform for DB2 V 1114 on Linux BLU Data analytics and migrate existing SAS based DBMS system to DB2 on Linux RDSPostgreSQL 111 Setup Install DB2 V1111 on AWS RHEL 76x86_64 applied Mod4 Fixpack patches to upgrade to V1114 Did install Data Server Manager V2152 Prepare Data Architecture Data Migration Data Security Documents for the Clients Working to setting up Configuring HADR on DB2 for Linux for Failover on AWS Cloud Working to setting up Configuring IBM Security Guardium 1060 Database Activity Monitoring DAM Setup Configure PostgreSQL 111 upgraded from PostgreSQL 106 with pgAdmin 4 v36 in AWS Cloud and associate it as a Data hub repository for erwin Data Modeler Workgroup Edition Concurrent User License 2018 R1 Provide client connectivity using with DataStage V117 IBM DataStudio client V41 SQuirreL SQL Client V39 Installation Configuration setup and deployment of Hortonworks HDP Hadoop cluster 7 Data nodes 2 Master Nodes 4 Edge nodes in AWS Cloud Installation Configuration setup and deployment of Cloudera Hadoop cluster 5 Data nodes 2 Master Nodes 4 Edge nodes in AWS Cloud Installation Configuration setup 2 node Microsoft Windows Server enabling Kerberos constrained delegation with Active Directory support feature to specify and enforce application trust boundaries by limiting the scope where application services can act in AWS Cloud Mantech International CorporationClient Customs and Border Protection Alexandria Data Engineer Part of Data Engineering group to capture document the data sources provenance and Architecture of the CBP EMIS data warehouse This effort should provide better tools for data mining and Data Science for Data warehouse Big Data efforts Involved in developing reengineering PLSQL procedures with Regular Expressions for very critical analytics project Involved with analyzing the Metadata Data structures Relationships Data Sources for both Cargo Passenger Systems Involved as Database Engineer providing support to BigData Oracle for OLAP Importing data from Multiple sources into Data Lake Delta Lake using Talend Kafka Apache NiFi Data mining Analtics Visualzation using Anaconda Python R Elastic Search Elastic Lucene etc Randstad Technologies Client Blue Cross Blue Shield of OH Anthem Mason OH Consultant Database Administrator I was involved as Database Administrator with Modernization expert of Legacy IMS DB2 database systems to Oracle in addition to everyday monitoring maintenance enhancements and new project development for applications Blue Cross Blue Shield of IL HCSC Chicago IL Sr Database Administrator HCSC is one of Nations Premier Healthcare Insurance provider with a membership of over 13 million am currently involved as Database Administrator with zero down time and supporting with maintenance enhancements and new Database development for applications Database Migrations DBMS Systems Performance Tuning Capacity planning of applications DB2 Oracle Hadoop MongoDB DBMS systems Responsible for High Availability accessibility of databases This effort involves 24X7 support of 230 million per day OLTP Health Claims transactions in DB2 oracle Sub systems on zOS AIX RHEL Worked supported development teams Integrated Medical Management develop Python applications to come up with pricing models for firsttime uninsured health insurance subscribers to generate pricing for actuarial team Tuples of firsttime insurers were mined from historical data for generating health costs associated with those health subscribers for first three years with age range Was part of teamIntegrated Medical Management to analyze the impacts of migration of ICD7 to ICD10 Implementation on Health claims by providers institutions utilizing Python Python applications were also developed to make old claims to be compatible to new format of medical procedure codes Extending support to Oracle Hadoop MongoDB along with DB2 to embrace multi DBMS support concept and embrace paradigm of management for Open Source Software Commodity Hardware to reduce costs Install configure setup 3 Master Node 47 Slave Node 15 Edge Node Cluster Developed process to ingest Structured Semistructured data into HDFS using Scoop Talend Elastic Search KAFKA Helped in supporting Flume Ingestion and configuring Source Channel Sink setup automated backups using Oozie etc Ciber Inc Client Statefarm Corporate South Bloomington IL DB2 Oracle Database Administrator Data Specialist State Farm Corporate South is a centralized headquarters for its data processing functions Statefarm is the Nations leading auto insurer Was involved as project DBA in FSS group with maintenance enhancements and new Database development for applications Responsible for Physical database design development of databases maintenance Jobs Performance validations involving Unicode Ebcdic Ascii translations using SQL Developer and Power BI Apex Systems Inc Client Lockheed Martin Social Security Administration Baltimore DB2 Database Administrator High Performance Design Analyst Lockheed Martin supports the complete range of services related to Social Security Administrations major systems modernization initiatives Involved with analysis and design of implementation of DB2 Ver 8 Release on very large Social Security Administration databases and migration of databases from BDAM to DB2 The objective is to migrate with zero issues to DB2 Version 8 and analyzing its impact on Applications and DB2 systems with version upgrade DB2 Administration Tool CA tools Platinum Products BMC Mainview BMC tools IBM tools Blue Cross Blue Shield of SC Columbia SC Information Systems Engineer Modernization of systems for 24X7 availability of systems adjudication of health claims Smart Health card Migration of VSAM to DB2 in line with the paradigm of the organization to have a single data infrastructure for growing business and technical needs like faster processing of Claims access of Data by customers and deployment of new applications consistency in quality of data real time availability of data 24X7 facilitating running of Sysplex environments and concurrency in data updates between online and batch Skills Database administration Database Db2 Dbms Sql server Sql server 2008 Mysql Oracle Plsql Postgres Postgresql Sql Stored procedures Vsam Ambari Hdfs Mahout Mapreduce Oozie Sqoop Additional Information TECHNICAL PROFILE Be proactively engaged in new methodologies like Agile DevOps SCRUM Waterfall Extreme Programming CICD Work Flow GIT Jenkins etc The future state of Architecture has contained Legacy transition to Open Source Platforms Architectures Adept at managing multiple concurrent projects being attentive to detail and maintaining the ability to make rational decisions in pressure situations Willingness to own responsibility and work to resolve issues Ability to work with commitment passion and thrust to exceed Customers expectation both as an Individual and as a Team member with the knowledge that each Customers expectations are unique DB2 for LUW V 1114 on Linux PostgreSQL V 114 pgAdmin v410 Oracle V 122 MySQL V 80 Red Hat Enterprise Linux 75 SQL Server 2008 2008 R2 2012 2014 Hadoop V24 V26 V28 V30 Cloudera Horton works Legacy zOS systems IMS DB2 IDMS to Oracle Oracle PLSQL Development expertise Administration of Anaconda Enterprise My responsibilities include installation configuration and management of the application proficiently navigating within the linux Create custom python environments and install and maintain them on various Hadoop clusters Work with Data Scientists as they launch python and pyspark jobs or deploy models that interact with data on hdfs and hive Engage with users transitioning from traditional data sources to Python Working to migrate a SAS Data warehouse on premise to AWS Clouds RDS DB2 by building data pipelines using NiFi Developed ETL and analytics focused Spark Core applications in Python including Spark SQL applications to interact with HIVE tables Building data pipelines to migrate data from Teradata to Hadoop env HDP Initiated poc to automate data pipelines using Oozie Worked towards building a Data Lake that is discoverable accessible and usable given diverse constraints onprem hybrid and cloud environments Ensure that data hydrating into the data lake has appropriate metadatatags with it using various enterprise metadata management tools Capture metadata throughout the data life cycle and consolidate it so as to enable searchbrowsesample data Import of unstructured data into HDFS using Flume using both File and Memory channels Develop Pig Latin scripts and writing UDFs in Python when needed to extract transform and mine data Write Hive Queries for analyzing data in Hive warehouse using Hive Query Language HQL Develop novel Abstract Data Structures and Functional Abstractions to process data text analysis humanmachine interactions weblogs and social media streaming Apply principles of Object Oriented Programming in designing and implementing applications with a specific focus on controlling complexity Focused on creating warehouses databases to meet the rapidly changing needs of various business units Create execute and schedule both master and standalone jobs with a focus on parallel execution when writing large files onto databases Extensive experience in supporting MultiDBMS data migrations IMS to DB2 Migration VSAM to DB2 Migration CAIDMS to DB2 Migration SAS to DB2 for Linux V111 Migration Legacy to AMS Migration DB2 to Oracle migration DB2 to SQL Server Migration High proficiency in designing building and administering Oracle clustered server configurations supporting 11g and 12c Real Application Clusters RAC installations on Linux AIX Ability to work on developing stored procedures Functions and Triggers PLSQL procedures Korn shell scripts Installing configuring Oracle cluster ware Database Software Troubleshooting handling common issues that arise during integration of the whole bugs network issues configuration files issues OCR issue deinstallation cleanup of cluster ware Ability to Work with customers for various RAC related issue RAC recovery RMAN ASM OCR corruptions voting disk loss etc Troubleshoot performance issues for the RAC instances GC events Backup and Recovery issues related loss of OCR Voting Disk and Oracle cluster ware also issues with corruption of individual disk data blocks loss of OS configuration files loss of net configuration files Also used the Merge backup for backing terabyte databases Issues with block change tracking also flash recovery area Add or Remove Node from RAC Importing Ingesting data from Multiple sources into Data Lake Delta Lake using Talend Kafka Apache NiFi Flume Automated all the jobs thru Zena scheduler for extracting the data from different Data Sources like DB2 Oracle MongoDB MySQL Postgres to pushing the result set data to Hadoop Distributed File System Installation Configuration setup and deployment of Hadoop cluster 46 Data nodes 2 Master Nodes 15 Edge nodes Configured High Availability cluster for Automatic failover Creates a SOLR schema from the Indexer settings Implemented SOLR index cron jobs Experience in writing SOLR queries for various search documents Responsible for defining the data flow within Hadoop eco system and implement them MongoDB DBA Administration MongoDB Schema Design Installation Configuration and Deployment of MongoDB Ability to Support creating shards replica sets monitoring and projections for Mongo Systems SQL Server 2008 2008 R2 2012 2014 Database Administration and support TSQL SSIS SSRS HADR TECHNICAL PROFESSIONAL EXPERIZE Data Tools Hadoop Cloudera Hortonworks V27 V30 Spark V20 MapReduce Yarn Hive HDFS Pig Hbase Flume Sqoop R Regression Predictive Analysis Data Mining Sentiment Analysis Hue Apache Ambari NIFI SOLR RapidMiner R Mahout Tableau SQL TSQL PLSQL MySQL Hive SQL PostreSQL Python Data frames Lab Juniper PyCharm IDLE Anaconda IPython PyScripter Pig HCatalog Java JSP Eclipse Maven SparkSQL HTML XML etc Oracle 12C SQL Server 2008 2008 R2 2012 2014 MYSQL V8 DB2 for LUW V1114 DB2 for zOS V13 IMS V13 PostGreSQL V108 Amazon RDS Red Hat Enterprise Linux 75 Operating Systems LUW AIX IBM z 13 Series Red Hat Enterprise Linux Hortonworks Data Platform Spark V1 V2 Systems AWS Cloud Computing Clustered Computing Distributed File Systems Business Intelligence Systems Data Mining Systems Reporting and Dash boarding Systems",
    "unique_id": "5b4cb08d-8692-4da4-8661-7eff07f8ca22"
}