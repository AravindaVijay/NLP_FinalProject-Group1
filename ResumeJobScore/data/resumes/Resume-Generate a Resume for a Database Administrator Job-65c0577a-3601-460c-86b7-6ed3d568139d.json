{
    "clean_data": "Data Science Analyst Data Science Analyst Data Science Analyst San Francisco CA 7 Plus years of IT industry experience encompassing a wide range of skill set Over 4 plus years of experience with Statistics Data Analysis Machine Learning using Rlanguage and Python Strong with ETL Data warehousing Data Store concepts and OLAP technologies Worked in Amazon Web Services cloud computing environment Experienced in SQL programming and creation of relational database models Experienced in creating cutting edge data processing algorithms to meet project demands Worked with applications like R SPSS and Python to develop neural networkalgorithms cluster analysis Worked with packages like ggplot2 and shiny in R to understand data and developing applications Worked on Tableau QuickViewto create dashboards and visualizations Automated recurring reports using SQL and Python and visualized them on BI platform like Tableau or QuickView Strong experience working with SQL Server 2008 RStudio MATLABOracle10i Sybase Worked on Statistical models to create new theories and products Experience working with statistical and regression analysis multiobjective optimization Worked with python libraries like matPlotLib wxPython and numPY Designed and implemented supervised and unsupervised machine learning Identify problems and provide solutions to business problems using data processing data visualization and graphical data analysis Developed predictive models using Decision Tree Random Forest and Nave Bayes Solid knowledge of mathematics and experience in applying it to technical and research fields Identifying areas where optimization can be efficient Worked with clients to identify analytical needs and documented them for further use Developed predictive models using PythonR to predict customers churn and classification of customers Used spring framework to design architecture of the application as per requirements Query optimization execution plan and Performance tuning of queries for better performance in SQL Worked on Shiny and R application showcasing machine learning for improving the forecast of business Used technologies like JQuery for java script manipulations and bootstrap for the frontend html layout Worked on Designing and configuration of the database and back end applications and programs Developed user interface using HTMLCSS JavaScript and JQuery Hands on experience with Dimensional tables and Operational Data Store Excellent communication analytical troubleshooting skills Work Experience Data Science Analyst Medtronic North 2014 to October 2015 DescriptionAnalyze data reports to identify and intercept trends or patterns Communicate issues that affect productivity to Management and improving existing processes Responsibilities Grouping customers predicting churn rate for a car rideshare application Developed a movie recommender based on users movie ratings using matrix techniques Created a fraud prediction model for a ticketing site using a boosted tree classifier Development application UsingDjango framework and Flask framework Developed user interface using CSS HTML JavaScript and JQuery Worked on a reduction of cost and optimization of CRM Applications Cleaned and processed data using python libraries Worked with python libraries like matPlotLib wxPythonand numPY Built database mapping classes using Cassandra and Django models Used Pandas API for analyzing time series Designed and developed RDBMS using MySQL Used Panda API for east timestamp data manipulation and retrieval Creating regression test framework for new code Used technologies like JQuery for java script manipulations and bootstrap for the frontend html layout Took care of debugging and troubleshooting the web applications Developed tested and debugged tools utilized by clients and endusers Worked with internal teams within the project to convert end user feedbacks into improved solutions Coded programs and evaluated existing data processes Worked on Designing and configuration ofthe database and back end applications and programs Researched to identify and explore new technological platforms Resolved Several problems and documented troubleshooting documents Environment Python 27 scipy Pandas Bugzilla Red hat Linux Apache Spark Cassandra SVN Linux Eclipse Shell Scripting JQuery MySQL HTML5CSS SQL developer Owens Corning Toledo OH July 2013 to April 2014 Description Authored database procedures and triggers for data processing developed and modified applications Responsibilities Worked on requirements gathering analysis design change management and deployment Developed and Designed forms using Visual Basic with ODBC Automated the process of rebuilding indexes at regular interval for better performances Generated reports that can handle both dynamic grouping and sorting Generated reports using Crystal Reports Developed ER diagrams logical and physical using Erwin mapping the data into the database Worked in dimensional modeling to design the data warehouse Query optimization execution plan and Performance tuning of queries for better performance Worked with clients regarding system requirements and ensuring the development of customized products to user satisfaction Created Tables Indexes Table Spaces and integrity constraints Worked in UNIX Environment Environment SQL Developer SQL Navigator Informatica Power Center 9x Oracle 11g12c SQL PLSQL MySQL Workbench Oracle Hints UNIX Python Developer PIMCO New York NY November 2012 to June 2013 Description Designed and implemented predictive analytic models for monitoring the equipment using Python libraries like pandas NumPy and SciPy Responsibilities Programmed utilities in Python that uses packages like scipy numpy pandas Used spring framework to design architecture of the application as per requirements Estimation and Requirement Analysis of project timelines Developed batch processors based on python to produce and consume various feeds Generated Pdf reports daily and Monthly using Aspose PDF Kit Written python scripts to parse XML documents and load the relating data into a database Developed front end page using HTML CSS JavaScript and JQuery Generating property list each and every application using python Collecting the several functions and usage models from colleagues Developing and maintaining a tool that abstracts information for the customer Developing XMLs for components which maintain data for many registers Developed and designed SQL procedures and Linux shell scripts for data exportimport and for converting data Developed internal web apps using Python Flask framework with the help of HTML CSS framework Used Test Driven Development TDD for the project Written SQL Queries Store Procedures Triggers and functions for MySQL Databases Involved in Creation of database access layer using JDBC and PLSQL stored procedures Coordinate architects and senior technical staff to identify clients needs and document assumptions Buildout new requirements and move code through user acceptance testing Environment Python C HTML CSS TDD SQL MYSQL and Windows Data Analyst 5Cyient Ltd Hyderabad Andhra Pradesh January 2011 to October 2012 Worked on a project that classified images using a neural network My job included evaluating identifying and programming a utility to improve image classification performance I identified duplicate images manually and then programmed the detection utility in R and Python Identified the accuracy of detection across a range of input values Responsibilities Developed business process models using MS Visio to create case diagrams and flow diagrams to show flow of steps that are required Worked with other teams to analyze customers to analyze parameters of marketing Used MS Excel MS Access and SQL to write and run various queries Used traceabilitymatrix to trace the requirements of the organization Recommended structural changes and enhancements to systems and databases Environment UNIX SQL Oracle 11g12c MS Office MS Visio Data Stage Developer Birla Soft Hyderabad Andhra Pradesh 2009 to December 2010 Description Participated in designing system and coordinate with business groups in order to define the requirements and develop plans and schedules Responsibilities Developed ETL processes for data conversions and construction of data warehouse using IBM InfoSphere DataStage Used Star Schema and designed Mappings between sources to operational staging targets Provided Oncall Support for the project and gave a knowledge transfer for the clients Used Rational Application Developer RAD for version control Developed transformations using jobs like Filter Join Lookup Merge Hashed file Aggregator Transformer and Dataset Environment IBM Rational Clear Case Clear Quest and IBM InfoSphere Metadata Workbench 87IBM InfoSphere DataStage and Quality Stage  IBM InfoSphere CDC version 651 XML files R Programmer Data Scientist 1Actelion Pharmaceuticals San Francisco CA Description Worked as a part of Analytical Group and worked on development and designing of statistical models for the client Coordinated with end users on designing and implementing data solutions as per project requirements Responsibilities Conducted research on development and designing of sample methodologies and analyzed data for pricing of clientsproducts Investigated market sizing competitive analysis and positioning for product feasibility Worked on Business forecasting segmentation analysis and Data mining Automated Diagnosis of Blood Loss during Emergencies Developed Machine Learning algorithm to diagnose blood loss Generated graphs and reports using ggplot package in RStudio for analytical models Developed and implemented R and Shiny application which showcases machine learning for business forecasting Developed predictive models using Decision Tree Random Forest and Nave Bayes Performed time series analysis using Tableau Collaborating with devops teams for production deployment Worked in Amazon Web Services cloud computing environment Worked with Caffe Deep Learning Framework Developed various workbooks in Tableau from multiple data sources Created dashboards and visualizations using Tableau desktop Created dashboards in QuickView to visualize data Worked on R packages to interface with Caffe Deep Learning Framework Performed analysis using JMP Perform validation on machine learning output from R Written connectors to extract data from databases Environment R Python R Studio Shiny Excel 2013 Amazon Web Services Machine Learning Tableau QuickView JMP Segmentation analysis Education technology SRM University Chennai Tamil Nadu Skills databases 2 years Oracle 2 years Python 4 years SQL 3 years UNIX 2 years Additional Information TECHNICAL SKILLS Languages R C VBNET VC Java PLSQL Matlab Scripting Python Unix Shell Scripting Perl Development Tools RStudio Visual StudioNET 2015 Eclipse Quest SQL Navigator Tableau QuickView Data ScienceBig data Statistical Analysis Machine Learning Data Mining Hadoop 2x HBase 12 HDFS NoSql HBase Operating Systems Windows 100 UNIX with Sun Solaris 80 HPUnix Databases MS SQL Server 2005 Oracle 11g Sybase Web Technologies Silverlight AJAX ASPNET Java Script IIS 70 AWS Amazon Web Services Others NET 45 WPF WCF XAML LINQ MS Team Foundation ServerTFS SSRS InfragisticsTelerik Toolkit",
    "entities": [
        "CSS HTML JavaScript",
        "Python Flask",
        "Informatica Power Center",
        "Programmer Data Scientist 1Actelion Pharmaceuticals",
        "Identify",
        "Used Rational Application Developer RAD",
        "BI",
        "Created Tables Indexes Table Spaces",
        "JQuery Generating",
        "ODBC Automated",
        "Researched",
        "Tableau QuickViewto",
        "Written SQL Queries Store Procedures Triggers",
        "Query",
        "IBM",
        "Education",
        "XML",
        "Coordinate",
        "Estimation and Requirement Analysis",
        "Pandas Bugzilla Red",
        "Dataset Environment IBM Rational Clear Case Clear Quest",
        "Python",
        "Data Science Analyst Data",
        "Statistics Data Analysis Machine Learning",
        "Generated",
        "Developed",
        "Provided Oncall Support",
        "San Francisco",
        "Responsibilities Conducted",
        "Emergencies Developed Machine Learning",
        "Communicate",
        "Linux",
        "HPUnix",
        "Flask",
        "11g12c MS",
        "SRM University",
        "Responsibilities Grouping",
        "Data Store",
        "JMP Segmentation",
        "HTML CSS",
        "Worked on Business forecasting",
        "HTML CSS JavaScript",
        "QuickView",
        "Analytical Group",
        "Created",
        "Oracle",
        "Coded",
        "Coordinated",
        "JMP Perform",
        "Tableau Collaborating",
        "SQL",
        "Buildout",
        "Responsibilities Developed ETL",
        "DescriptionAnalyze",
        "Amazon Web Services",
        "Amazon Web Services Machine Learning Tableau QuickView",
        "Worked on Designing",
        "RStudio",
        "InfoSphere DataStage",
        "Sun Solaris",
        "Mappings",
        "Caffe Deep Learning Framework Performed",
        "Tableau QuickView Data",
        "NoSql HBase Operating",
        "Operational Data Store Excellent",
        "Windows Data",
        "Collecting",
        "OLAP",
        "Amazon Web Services Others",
        "Statistical Analysis Machine Learning Data Mining Hadoop",
        "CDC",
        "Toledo",
        "SQL Worked",
        "Filter Join Lookup",
        "Additional Information TECHNICAL SKILLS Languages R",
        "UsingDjango",
        "JQuery Hands",
        "Tableau",
        "Decision Tree Random Forest",
        "QuickView Strong",
        "ETL Data",
        "Used Test Driven Development TDD"
    ],
    "experience": "Experience working with statistical and regression analysis multiobjective optimization Worked with python libraries like matPlotLib wxPython and numPY Designed and implemented supervised and unsupervised machine learning Identify problems and provide solutions to business problems using data processing data visualization and graphical data analysis Developed predictive models using Decision Tree Random Forest and Nave Bayes Solid knowledge of mathematics and experience in applying it to technical and research fields Identifying areas where optimization can be efficient Worked with clients to identify analytical needs and documented them for further use Developed predictive models using PythonR to predict customers churn and classification of customers Used spring framework to design architecture of the application as per requirements Query optimization execution plan and Performance tuning of queries for better performance in SQL Worked on Shiny and R application showcasing machine learning for improving the forecast of business Used technologies like JQuery for java script manipulations and bootstrap for the frontend html layout Worked on Designing and configuration of the database and back end applications and programs Developed user interface using HTMLCSS JavaScript and JQuery Hands on experience with Dimensional tables and Operational Data Store Excellent communication analytical troubleshooting skills Work Experience Data Science Analyst Medtronic North 2014 to October 2015 DescriptionAnalyze data reports to identify and intercept trends or patterns Communicate issues that affect productivity to Management and improving existing processes Responsibilities Grouping customers predicting churn rate for a car rideshare application Developed a movie recommender based on users movie ratings using matrix techniques Created a fraud prediction model for a ticketing site using a boosted tree classifier Development application UsingDjango framework and Flask framework Developed user interface using CSS HTML JavaScript and JQuery Worked on a reduction of cost and optimization of CRM Applications Cleaned and processed data using python libraries Worked with python libraries like matPlotLib wxPythonand numPY Built database mapping classes using Cassandra and Django models Used Pandas API for analyzing time series Designed and developed RDBMS using MySQL Used Panda API for east timestamp data manipulation and retrieval Creating regression test framework for new code Used technologies like JQuery for java script manipulations and bootstrap for the frontend html layout Took care of debugging and troubleshooting the web applications Developed tested and debugged tools utilized by clients and endusers Worked with internal teams within the project to convert end user feedbacks into improved solutions Coded programs and evaluated existing data processes Worked on Designing and configuration ofthe database and back end applications and programs Researched to identify and explore new technological platforms Resolved Several problems and documented troubleshooting documents Environment Python 27 scipy Pandas Bugzilla Red hat Linux Apache Spark Cassandra SVN Linux Eclipse Shell Scripting JQuery MySQL HTML5CSS SQL developer Owens Corning Toledo OH July 2013 to April 2014 Description Authored database procedures and triggers for data processing developed and modified applications Responsibilities Worked on requirements gathering analysis design change management and deployment Developed and Designed forms using Visual Basic with ODBC Automated the process of rebuilding indexes at regular interval for better performances Generated reports that can handle both dynamic grouping and sorting Generated reports using Crystal Reports Developed ER diagrams logical and physical using Erwin mapping the data into the database Worked in dimensional modeling to design the data warehouse Query optimization execution plan and Performance tuning of queries for better performance Worked with clients regarding system requirements and ensuring the development of customized products to user satisfaction Created Tables Indexes Table Spaces and integrity constraints Worked in UNIX Environment Environment SQL Developer SQL Navigator Informatica Power Center 9x Oracle 11g12c SQL PLSQL MySQL Workbench Oracle Hints UNIX Python Developer PIMCO New York NY November 2012 to June 2013 Description Designed and implemented predictive analytic models for monitoring the equipment using Python libraries like pandas NumPy and SciPy Responsibilities Programmed utilities in Python that uses packages like scipy numpy pandas Used spring framework to design architecture of the application as per requirements Estimation and Requirement Analysis of project timelines Developed batch processors based on python to produce and consume various feeds Generated Pdf reports daily and Monthly using Aspose PDF Kit Written python scripts to parse XML documents and load the relating data into a database Developed front end page using HTML CSS JavaScript and JQuery Generating property list each and every application using python Collecting the several functions and usage models from colleagues Developing and maintaining a tool that abstracts information for the customer Developing XMLs for components which maintain data for many registers Developed and designed SQL procedures and Linux shell scripts for data exportimport and for converting data Developed internal web apps using Python Flask framework with the help of HTML CSS framework Used Test Driven Development TDD for the project Written SQL Queries Store Procedures Triggers and functions for MySQL Databases Involved in Creation of database access layer using JDBC and PLSQL stored procedures Coordinate architects and senior technical staff to identify clients needs and document assumptions Buildout new requirements and move code through user acceptance testing Environment Python C HTML CSS TDD SQL MYSQL and Windows Data Analyst 5Cyient Ltd Hyderabad Andhra Pradesh January 2011 to October 2012 Worked on a project that classified images using a neural network My job included evaluating identifying and programming a utility to improve image classification performance I identified duplicate images manually and then programmed the detection utility in R and Python Identified the accuracy of detection across a range of input values Responsibilities Developed business process models using MS Visio to create case diagrams and flow diagrams to show flow of steps that are required Worked with other teams to analyze customers to analyze parameters of marketing Used MS Excel MS Access and SQL to write and run various queries Used traceabilitymatrix to trace the requirements of the organization Recommended structural changes and enhancements to systems and databases Environment UNIX SQL Oracle 11g12c MS Office MS Visio Data Stage Developer Birla Soft Hyderabad Andhra Pradesh 2009 to December 2010 Description Participated in designing system and coordinate with business groups in order to define the requirements and develop plans and schedules Responsibilities Developed ETL processes for data conversions and construction of data warehouse using IBM InfoSphere DataStage Used Star Schema and designed Mappings between sources to operational staging targets Provided Oncall Support for the project and gave a knowledge transfer for the clients Used Rational Application Developer RAD for version control Developed transformations using jobs like Filter Join Lookup Merge Hashed file Aggregator Transformer and Dataset Environment IBM Rational Clear Case Clear Quest and IBM InfoSphere Metadata Workbench 87IBM InfoSphere DataStage and Quality Stage   IBM InfoSphere CDC version 651 XML files R Programmer Data Scientist 1Actelion Pharmaceuticals San Francisco CA Description Worked as a part of Analytical Group and worked on development and designing of statistical models for the client Coordinated with end users on designing and implementing data solutions as per project requirements Responsibilities Conducted research on development and designing of sample methodologies and analyzed data for pricing of clientsproducts Investigated market sizing competitive analysis and positioning for product feasibility Worked on Business forecasting segmentation analysis and Data mining Automated Diagnosis of Blood Loss during Emergencies Developed Machine Learning algorithm to diagnose blood loss Generated graphs and reports using ggplot package in RStudio for analytical models Developed and implemented R and Shiny application which showcases machine learning for business forecasting Developed predictive models using Decision Tree Random Forest and Nave Bayes Performed time series analysis using Tableau Collaborating with devops teams for production deployment Worked in Amazon Web Services cloud computing environment Worked with Caffe Deep Learning Framework Developed various workbooks in Tableau from multiple data sources Created dashboards and visualizations using Tableau desktop Created dashboards in QuickView to visualize data Worked on R packages to interface with Caffe Deep Learning Framework Performed analysis using JMP Perform validation on machine learning output from R Written connectors to extract data from databases Environment R Python R Studio Shiny Excel 2013 Amazon Web Services Machine Learning Tableau QuickView JMP Segmentation analysis Education technology SRM University Chennai Tamil Nadu Skills databases 2 years Oracle 2 years Python 4 years SQL 3 years UNIX 2 years Additional Information TECHNICAL SKILLS Languages R C VBNET VC Java PLSQL Matlab Scripting Python Unix Shell Scripting Perl Development Tools RStudio Visual StudioNET 2015 Eclipse Quest SQL Navigator Tableau QuickView Data ScienceBig data Statistical Analysis Machine Learning Data Mining Hadoop 2x HBase 12 HDFS NoSql HBase Operating Systems Windows 100 UNIX with Sun Solaris 80 HPUnix Databases MS SQL Server 2005 Oracle 11 g Sybase Web Technologies Silverlight AJAX ASPNET Java Script IIS 70 AWS Amazon Web Services Others NET 45 WPF WCF XAML LINQ MS Team Foundation ServerTFS SSRS InfragisticsTelerik Toolkit",
    "extracted_keywords": [
        "Data",
        "Science",
        "Analyst",
        "Data",
        "Science",
        "Analyst",
        "Data",
        "Science",
        "Analyst",
        "San",
        "Francisco",
        "CA",
        "years",
        "IT",
        "industry",
        "experience",
        "range",
        "skill",
        "years",
        "experience",
        "Statistics",
        "Data",
        "Analysis",
        "Machine",
        "Learning",
        "Rlanguage",
        "Python",
        "Strong",
        "ETL",
        "Data",
        "warehousing",
        "Data",
        "Store",
        "concepts",
        "OLAP",
        "technologies",
        "Amazon",
        "Web",
        "Services",
        "cloud",
        "computing",
        "environment",
        "SQL",
        "programming",
        "creation",
        "database",
        "models",
        "edge",
        "data",
        "processing",
        "algorithms",
        "project",
        "demands",
        "applications",
        "R",
        "SPSS",
        "Python",
        "networkalgorithms",
        "cluster",
        "analysis",
        "packages",
        "ggplot2",
        "R",
        "data",
        "applications",
        "Tableau",
        "QuickViewto",
        "dashboards",
        "visualizations",
        "reports",
        "SQL",
        "Python",
        "BI",
        "platform",
        "Tableau",
        "QuickView",
        "Strong",
        "experience",
        "SQL",
        "Server",
        "RStudio",
        "MATLABOracle10i",
        "Sybase",
        "Worked",
        "models",
        "theories",
        "products",
        "Experience",
        "analysis",
        "optimization",
        "python",
        "libraries",
        "matPlotLib",
        "wxPython",
        "numPY",
        "machine",
        "learning",
        "problems",
        "solutions",
        "business",
        "problems",
        "data",
        "processing",
        "data",
        "visualization",
        "data",
        "analysis",
        "models",
        "Decision",
        "Tree",
        "Random",
        "Forest",
        "Nave",
        "Bayes",
        "knowledge",
        "mathematics",
        "experience",
        "research",
        "fields",
        "areas",
        "optimization",
        "clients",
        "needs",
        "models",
        "PythonR",
        "customers",
        "classification",
        "customers",
        "spring",
        "framework",
        "architecture",
        "application",
        "requirements",
        "Query",
        "optimization",
        "execution",
        "plan",
        "Performance",
        "tuning",
        "queries",
        "performance",
        "SQL",
        "Worked",
        "Shiny",
        "R",
        "application",
        "machine",
        "forecast",
        "business",
        "technologies",
        "JQuery",
        "java",
        "script",
        "manipulations",
        "bootstrap",
        "frontend",
        "html",
        "layout",
        "Designing",
        "configuration",
        "database",
        "end",
        "applications",
        "programs",
        "user",
        "interface",
        "HTMLCSS",
        "JavaScript",
        "JQuery",
        "Hands",
        "experience",
        "tables",
        "Operational",
        "Data",
        "Store",
        "Excellent",
        "communication",
        "troubleshooting",
        "skills",
        "Work",
        "Experience",
        "Data",
        "Science",
        "Analyst",
        "Medtronic",
        "North",
        "October",
        "DescriptionAnalyze",
        "data",
        "trends",
        "patterns",
        "Communicate",
        "issues",
        "productivity",
        "Management",
        "processes",
        "Responsibilities",
        "customers",
        "churn",
        "rate",
        "car",
        "rideshare",
        "application",
        "movie",
        "recommender",
        "users",
        "movie",
        "ratings",
        "matrix",
        "techniques",
        "fraud",
        "prediction",
        "model",
        "ticketing",
        "site",
        "tree",
        "classifier",
        "Development",
        "application",
        "UsingDjango",
        "framework",
        "Flask",
        "user",
        "interface",
        "CSS",
        "HTML",
        "JavaScript",
        "JQuery",
        "reduction",
        "cost",
        "optimization",
        "CRM",
        "Applications",
        "data",
        "python",
        "libraries",
        "python",
        "libraries",
        "matPlotLib",
        "numPY",
        "database",
        "mapping",
        "classes",
        "Cassandra",
        "Django",
        "Pandas",
        "API",
        "time",
        "series",
        "RDBMS",
        "MySQL",
        "Panda",
        "API",
        "east",
        "timestamp",
        "data",
        "manipulation",
        "retrieval",
        "regression",
        "test",
        "framework",
        "code",
        "technologies",
        "JQuery",
        "java",
        "script",
        "manipulations",
        "bootstrap",
        "frontend",
        "html",
        "layout",
        "care",
        "web",
        "applications",
        "tools",
        "clients",
        "endusers",
        "teams",
        "project",
        "end",
        "user",
        "feedbacks",
        "solutions",
        "programs",
        "data",
        "processes",
        "Designing",
        "configuration",
        "ofthe",
        "database",
        "end",
        "applications",
        "programs",
        "platforms",
        "problems",
        "troubleshooting",
        "documents",
        "Environment",
        "Python",
        "Pandas",
        "Bugzilla",
        "Red",
        "hat",
        "Linux",
        "Apache",
        "Spark",
        "Cassandra",
        "SVN",
        "Linux",
        "Eclipse",
        "Shell",
        "Scripting",
        "JQuery",
        "MySQL",
        "HTML5CSS",
        "SQL",
        "developer",
        "Owens",
        "Corning",
        "Toledo",
        "OH",
        "July",
        "April",
        "Description",
        "Authored",
        "database",
        "procedures",
        "triggers",
        "data",
        "processing",
        "applications",
        "Responsibilities",
        "requirements",
        "analysis",
        "design",
        "change",
        "management",
        "deployment",
        "Developed",
        "forms",
        "Visual",
        "Basic",
        "ODBC",
        "Automated",
        "process",
        "indexes",
        "interval",
        "performances",
        "reports",
        "grouping",
        "reports",
        "Crystal",
        "Reports",
        "Developed",
        "ER",
        "diagrams",
        "Erwin",
        "mapping",
        "data",
        "database",
        "modeling",
        "data",
        "warehouse",
        "Query",
        "optimization",
        "execution",
        "plan",
        "Performance",
        "tuning",
        "queries",
        "performance",
        "clients",
        "system",
        "requirements",
        "development",
        "products",
        "user",
        "satisfaction",
        "Created",
        "Tables",
        "Indexes",
        "Table",
        "Spaces",
        "integrity",
        "constraints",
        "UNIX",
        "Environment",
        "Environment",
        "SQL",
        "Developer",
        "SQL",
        "Navigator",
        "Informatica",
        "Power",
        "Center",
        "9x",
        "Oracle",
        "SQL",
        "PLSQL",
        "MySQL",
        "Workbench",
        "Oracle",
        "Hints",
        "UNIX",
        "Python",
        "Developer",
        "PIMCO",
        "New",
        "York",
        "NY",
        "November",
        "June",
        "Description",
        "models",
        "equipment",
        "Python",
        "libraries",
        "pandas",
        "NumPy",
        "SciPy",
        "Responsibilities",
        "utilities",
        "Python",
        "packages",
        "pandas",
        "spring",
        "framework",
        "architecture",
        "application",
        "requirements",
        "Estimation",
        "Requirement",
        "Analysis",
        "project",
        "batch",
        "processors",
        "python",
        "feeds",
        "Generated",
        "Pdf",
        "Aspose",
        "PDF",
        "Kit",
        "python",
        "scripts",
        "XML",
        "documents",
        "data",
        "database",
        "end",
        "page",
        "HTML",
        "CSS",
        "JavaScript",
        "JQuery",
        "Generating",
        "property",
        "list",
        "application",
        "python",
        "functions",
        "usage",
        "models",
        "colleagues",
        "tool",
        "information",
        "customer",
        "XMLs",
        "components",
        "data",
        "registers",
        "SQL",
        "procedures",
        "Linux",
        "shell",
        "scripts",
        "data",
        "exportimport",
        "data",
        "web",
        "apps",
        "Python",
        "Flask",
        "framework",
        "help",
        "HTML",
        "CSS",
        "framework",
        "Test",
        "Driven",
        "Development",
        "TDD",
        "project",
        "SQL",
        "Queries",
        "Store",
        "Procedures",
        "Triggers",
        "functions",
        "MySQL",
        "Databases",
        "Creation",
        "database",
        "access",
        "layer",
        "JDBC",
        "procedures",
        "Coordinate",
        "architects",
        "staff",
        "clients",
        "needs",
        "document",
        "assumptions",
        "requirements",
        "code",
        "user",
        "acceptance",
        "testing",
        "Environment",
        "Python",
        "C",
        "HTML",
        "CSS",
        "TDD",
        "SQL",
        "MYSQL",
        "Windows",
        "Data",
        "Analyst",
        "5Cyient",
        "Ltd",
        "Hyderabad",
        "Andhra",
        "Pradesh",
        "January",
        "October",
        "project",
        "images",
        "network",
        "job",
        "utility",
        "image",
        "classification",
        "performance",
        "images",
        "detection",
        "utility",
        "R",
        "Python",
        "accuracy",
        "detection",
        "range",
        "input",
        "values",
        "Responsibilities",
        "business",
        "process",
        "models",
        "MS",
        "Visio",
        "case",
        "diagrams",
        "flow",
        "diagrams",
        "flow",
        "steps",
        "teams",
        "customers",
        "parameters",
        "MS",
        "Excel",
        "MS",
        "Access",
        "SQL",
        "queries",
        "traceabilitymatrix",
        "requirements",
        "organization",
        "changes",
        "enhancements",
        "systems",
        "Environment",
        "UNIX",
        "SQL",
        "Oracle",
        "MS",
        "Office",
        "MS",
        "Visio",
        "Data",
        "Stage",
        "Developer",
        "Birla",
        "Soft",
        "Hyderabad",
        "Andhra",
        "Pradesh",
        "December",
        "Description",
        "system",
        "business",
        "groups",
        "order",
        "requirements",
        "plans",
        "schedules",
        "Responsibilities",
        "ETL",
        "processes",
        "data",
        "conversions",
        "construction",
        "data",
        "warehouse",
        "IBM",
        "InfoSphere",
        "DataStage",
        "Star",
        "Schema",
        "Mappings",
        "sources",
        "staging",
        "targets",
        "Oncall",
        "Support",
        "project",
        "knowledge",
        "transfer",
        "clients",
        "Rational",
        "Application",
        "Developer",
        "RAD",
        "version",
        "control",
        "transformations",
        "jobs",
        "Filter",
        "Join",
        "Lookup",
        "Merge",
        "Hashed",
        "file",
        "Aggregator",
        "Transformer",
        "Dataset",
        "Environment",
        "IBM",
        "Rational",
        "Clear",
        "Case",
        "Clear",
        "Quest",
        "IBM",
        "InfoSphere",
        "Metadata",
        "Workbench",
        "87IBM",
        "InfoSphere",
        "DataStage",
        "Quality",
        "Stage",
        "IBM",
        "InfoSphere",
        "CDC",
        "version",
        "XML",
        "files",
        "R",
        "Programmer",
        "Data",
        "Scientist",
        "1Actelion",
        "Pharmaceuticals",
        "San",
        "Francisco",
        "CA",
        "Description",
        "part",
        "Analytical",
        "Group",
        "development",
        "designing",
        "models",
        "client",
        "end",
        "users",
        "data",
        "solutions",
        "project",
        "requirements",
        "Responsibilities",
        "research",
        "development",
        "designing",
        "sample",
        "methodologies",
        "data",
        "pricing",
        "clientsproducts",
        "market",
        "analysis",
        "positioning",
        "product",
        "feasibility",
        "Business",
        "forecasting",
        "segmentation",
        "analysis",
        "Data",
        "mining",
        "Automated",
        "Diagnosis",
        "Blood",
        "Loss",
        "Emergencies",
        "Developed",
        "Machine",
        "Learning",
        "algorithm",
        "blood",
        "loss",
        "graphs",
        "reports",
        "ggplot",
        "package",
        "RStudio",
        "models",
        "R",
        "application",
        "machine",
        "business",
        "forecasting",
        "models",
        "Decision",
        "Tree",
        "Random",
        "Forest",
        "Nave",
        "Bayes",
        "Performed",
        "time",
        "series",
        "analysis",
        "Tableau",
        "devops",
        "teams",
        "production",
        "deployment",
        "Amazon",
        "Web",
        "Services",
        "cloud",
        "computing",
        "environment",
        "Caffe",
        "Deep",
        "Learning",
        "Framework",
        "workbooks",
        "Tableau",
        "data",
        "sources",
        "dashboards",
        "visualizations",
        "Tableau",
        "desktop",
        "dashboards",
        "QuickView",
        "data",
        "R",
        "packages",
        "Caffe",
        "Deep",
        "Learning",
        "Framework",
        "Performed",
        "analysis",
        "JMP",
        "Perform",
        "validation",
        "machine",
        "output",
        "R",
        "Written",
        "connectors",
        "data",
        "databases",
        "Environment",
        "R",
        "Python",
        "R",
        "Studio",
        "Shiny",
        "Excel",
        "Amazon",
        "Web",
        "Services",
        "Machine",
        "Learning",
        "Tableau",
        "QuickView",
        "JMP",
        "Segmentation",
        "analysis",
        "Education",
        "technology",
        "SRM",
        "University",
        "Chennai",
        "Tamil",
        "Nadu",
        "Skills",
        "years",
        "Oracle",
        "years",
        "Python",
        "years",
        "SQL",
        "years",
        "UNIX",
        "years",
        "Additional",
        "Information",
        "TECHNICAL",
        "SKILLS",
        "Languages",
        "R",
        "C",
        "VBNET",
        "VC",
        "Java",
        "PLSQL",
        "Matlab",
        "Scripting",
        "Python",
        "Unix",
        "Shell",
        "Scripting",
        "Perl",
        "Development",
        "Tools",
        "RStudio",
        "Visual",
        "StudioNET",
        "Eclipse",
        "Quest",
        "SQL",
        "Navigator",
        "Tableau",
        "QuickView",
        "Data",
        "ScienceBig",
        "data",
        "Statistical",
        "Analysis",
        "Machine",
        "Learning",
        "Data",
        "Mining",
        "Hadoop",
        "2x",
        "HBase",
        "HDFS",
        "NoSql",
        "HBase",
        "Operating",
        "Systems",
        "Windows",
        "UNIX",
        "Sun",
        "Solaris",
        "HPUnix",
        "Databases",
        "MS",
        "SQL",
        "Server",
        "Oracle",
        "g",
        "Sybase",
        "Web",
        "Technologies",
        "Silverlight",
        "AJAX",
        "ASPNET",
        "Java",
        "Script",
        "IIS",
        "AWS",
        "Amazon",
        "Web",
        "Services",
        "Others",
        "NET",
        "WPF",
        "WCF",
        "XAML",
        "MS",
        "Team",
        "Foundation",
        "ServerTFS",
        "SSRS",
        "InfragisticsTelerik",
        "Toolkit"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T19:40:46.133185",
    "resume_data": "Data Science Analyst Data Science Analyst Data Science Analyst San Francisco CA 7 Plus years of IT industry experience encompassing a wide range of skill set Over 4 plus years of experience with Statistics Data Analysis Machine Learning using Rlanguage and Python Strong with ETL Data warehousing Data Store concepts and OLAP technologies Worked in Amazon Web Services cloud computing environment Experienced in SQL programming and creation of relational database models Experienced in creating cutting edge data processing algorithms to meet project demands Worked with applications like R SPSS and Python to develop neural networkalgorithms cluster analysis Worked with packages like ggplot2 and shiny in R to understand data and developing applications Worked on Tableau QuickViewto create dashboards and visualizations Automated recurring reports using SQL and Python and visualized them on BI platform like Tableau or QuickView Strong experience working with SQL Server 2008 RStudio MATLABOracle10i Sybase Worked on Statistical models to create new theories and products Experience working with statistical and regression analysis multiobjective optimization Worked with python libraries like matPlotLib wxPython and numPY Designed and implemented supervised and unsupervised machine learning Identify problems and provide solutions to business problems using data processing data visualization and graphical data analysis Developed predictive models using Decision Tree Random Forest and Nave Bayes Solid knowledge of mathematics and experience in applying it to technical and research fields Identifying areas where optimization can be efficient Worked with clients to identify analytical needs and documented them for further use Developed predictive models using PythonR to predict customers churn and classification of customers Used spring framework to design architecture of the application as per requirements Query optimization execution plan and Performance tuning of queries for better performance in SQL Worked on Shiny and R application showcasing machine learning for improving the forecast of business Used technologies like JQuery for java script manipulations and bootstrap for the frontend html layout Worked on Designing and configuration of the database and back end applications and programs Developed user interface using HTMLCSS JavaScript and JQuery Hands on experience with Dimensional tables and Operational Data Store Excellent communication analytical troubleshooting skills Work Experience Data Science Analyst Medtronic North 2014 to October 2015 DescriptionAnalyze data reports to identify and intercept trends or patterns Communicate issues that affect productivity to Management and improving existing processes Responsibilities Grouping customers predicting churn rate for a car rideshare application Developed a movie recommender based on users movie ratings using matrix techniques Created a fraud prediction model for a ticketing site using a boosted tree classifier Development application UsingDjango framework and Flask framework Developed user interface using CSS HTML JavaScript and JQuery Worked on a reduction of cost and optimization of CRM Applications Cleaned and processed data using python libraries Worked with python libraries like matPlotLib wxPythonand numPY Built database mapping classes using Cassandra and Django models Used Pandas API for analyzing time series Designed and developed RDBMS using MySQL Used Panda API for east timestamp data manipulation and retrieval Creating regression test framework for new code Used technologies like JQuery for java script manipulations and bootstrap for the frontend html layout Took care of debugging and troubleshooting the web applications Developed tested and debugged tools utilized by clients and endusers Worked with internal teams within the project to convert end user feedbacks into improved solutions Coded programs and evaluated existing data processes Worked on Designing and configuration ofthe database and back end applications and programs Researched to identify and explore new technological platforms Resolved Several problems and documented troubleshooting documents Environment Python 27 scipy Pandas Bugzilla Red hat Linux Apache Spark Cassandra SVN Linux Eclipse Shell Scripting JQuery MySQL HTML5CSS SQL developer Owens Corning Toledo OH July 2013 to April 2014 Description Authored database procedures and triggers for data processing developed and modified applications Responsibilities Worked on requirements gathering analysis design change management and deployment Developed and Designed forms using Visual Basic with ODBC Automated the process of rebuilding indexes at regular interval for better performances Generated reports that can handle both dynamic grouping and sorting Generated reports using Crystal Reports Developed ER diagrams logical and physical using Erwin mapping the data into the database Worked in dimensional modeling to design the data warehouse Query optimization execution plan and Performance tuning of queries for better performance Worked with clients regarding system requirements and ensuring the development of customized products to user satisfaction Created Tables Indexes Table Spaces and integrity constraints Worked in UNIX Environment Environment SQL Developer SQL Navigator Informatica Power Center 9x Oracle 11g12c SQL PLSQL MySQL Workbench Oracle Hints UNIX Python Developer PIMCO New York NY November 2012 to June 2013 Description Designed and implemented predictive analytic models for monitoring the equipment using Python libraries like pandas NumPy and SciPy Responsibilities Programmed utilities in Python that uses packages like scipy numpy pandas Used spring framework to design architecture of the application as per requirements Estimation and Requirement Analysis of project timelines Developed batch processors based on python to produce and consume various feeds Generated Pdf reports daily and Monthly using Aspose PDF Kit Written python scripts to parse XML documents and load the relating data into a database Developed front end page using HTML CSS JavaScript and JQuery Generating property list each and every application using python Collecting the several functions and usage models from colleagues Developing and maintaining a tool that abstracts information for the customer Developing XMLs for components which maintain data for many registers Developed and designed SQL procedures and Linux shell scripts for data exportimport and for converting data Developed internal web apps using Python Flask framework with the help of HTML CSS framework Used Test Driven Development TDD for the project Written SQL Queries Store Procedures Triggers and functions for MySQL Databases Involved in Creation of database access layer using JDBC and PLSQL stored procedures Coordinate architects and senior technical staff to identify clients needs and document assumptions Buildout new requirements and move code through user acceptance testing Environment Python C HTML CSS TDD SQL MYSQL and Windows Data Analyst 5Cyient Ltd Hyderabad Andhra Pradesh January 2011 to October 2012 Worked on a project that classified images using a neural network My job included evaluating identifying and programming a utility to improve image classification performance I identified duplicate images manually and then programmed the detection utility in R and Python Identified the accuracy of detection across a range of input values Responsibilities Developed business process models using MS Visio to create case diagrams and flow diagrams to show flow of steps that are required Worked with other teams to analyze customers to analyze parameters of marketing Used MS Excel MS Access and SQL to write and run various queries Used traceabilitymatrix to trace the requirements of the organization Recommended structural changes and enhancements to systems and databases Environment UNIX SQL Oracle 11g12c MS Office MS Visio Data Stage Developer Birla Soft Hyderabad Andhra Pradesh 2009 to December 2010 Description Participated in designing system and coordinate with business groups in order to define the requirements and develop plans and schedules Responsibilities Developed ETL processes for data conversions and construction of data warehouse using IBM InfoSphere DataStage Used Star Schema and designed Mappings between sources to operational staging targets Provided Oncall Support for the project and gave a knowledge transfer for the clients Used Rational Application Developer RAD for version control Developed transformations using jobs like Filter Join Lookup Merge Hashed file Aggregator Transformer and Dataset Environment IBM Rational Clear Case Clear Quest and IBM InfoSphere Metadata Workbench 87IBM InfoSphere DataStage and Quality Stage 8781801752 IBM InfoSphere CDC version 651 XML files R Programmer Data Scientist 1Actelion Pharmaceuticals San Francisco CA Description Worked as a part of Analytical Group and worked on development and designing of statistical models for the client Coordinated with end users on designing and implementing data solutions as per project requirements Responsibilities Conducted research on development and designing of sample methodologies and analyzed data for pricing of clientsproducts Investigated market sizing competitive analysis and positioning for product feasibility Worked on Business forecasting segmentation analysis and Data mining Automated Diagnosis of Blood Loss during Emergencies Developed Machine Learning algorithm to diagnose blood loss Generated graphs and reports using ggplot package in RStudio for analytical models Developed and implemented R and Shiny application which showcases machine learning for business forecasting Developed predictive models using Decision Tree Random Forest and Nave Bayes Performed time series analysis using Tableau Collaborating with devops teams for production deployment Worked in Amazon Web Services cloud computing environment Worked with Caffe Deep Learning Framework Developed various workbooks in Tableau from multiple data sources Created dashboards and visualizations using Tableau desktop Created dashboards in QuickView to visualize data Worked on R packages to interface with Caffe Deep Learning Framework Performed analysis using JMP Perform validation on machine learning output from R Written connectors to extract data from databases Environment R Python R Studio Shiny Excel 2013 Amazon Web Services Machine Learning Tableau QuickView JMP Segmentation analysis Education technology SRM University Chennai Tamil Nadu Skills databases 2 years Oracle 2 years Python 4 years SQL 3 years UNIX 2 years Additional Information TECHNICAL SKILLS Languages R C VBNET VC Java PLSQL Matlab Scripting Python Unix Shell Scripting Perl Development Tools RStudio Visual StudioNET 2015 Eclipse Quest SQL Navigator Tableau QuickView Data ScienceBig data Statistical Analysis Machine Learning Data Mining Hadoop 2x HBase 12 HDFS NoSql HBase Operating Systems Windows 100 UNIX with Sun Solaris 80 HPUnix Databases MS SQL Server 2005 Oracle 11g Sybase Web Technologies Silverlight AJAX ASPNET Java Script IIS 70 AWS Amazon Web Services Others NET 45 WPF WCF XAML LINQ MS Team Foundation ServerTFS SSRS InfragisticsTelerik Toolkit",
    "unique_id": "65c0577a-3601-460c-86b7-6ed3d568139d"
}