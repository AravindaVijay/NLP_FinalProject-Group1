{
    "clean_data": "Python Developer Python span lDeveloperspan Python Developer Citi Group CA Around 5 years of experience as a WebApplication Developer with deep understanding of technology trends with expertise in core of complex technologies Solid experience in Analysis Design and Development Testing Implementation production support and maintenance of various Web Applications using Python Django Skillful involvement in Python by developing softwares utilizing new tools libraries utilized Beautiful Soup NumPy SciPy PySide matplotlib Pickle Pandas data frame urllib2 MySQL DB to improve software development process Support developeroriented services such as Lambda API Gateway Amazon Connect Step Functions Used Django evolution and manual SQL modifications to retain all the data while site is in production Expertise in developing web based open stack applications for large dataset analysis using Python and Django Proficient in building Web User Interface UI using HTML5 DHTML XHTML AngularJS Hibernate CSSCSS3 and JavaScript Nodejs Backbonejs D3 jQuery that follows W3C Web Standards and are browser compatible Experience in working with AWS services like EC2 S3 RDS IAM CloudFormation Amazon Connect Lex chatbot Lambda Transcribe and Comprehend Experience in AWS Elastic Beanstalk for app deployments and worked on AWS lambda with Amazon kinesis Hands on experience in using Hadoop ecosystem components like Hadoop Hive Pig Sqoop HBase Cassandra Spark Spark Streaming Spark SQL Oozie ZooKeeper Kafka Flume MapReduce and Yarn Responsible for creating Hive tables and working on them using Hive QL Experienced in Working on Big Data Integration and Analytics based on Hadoop Spark and NoSQL databases like HBase and MongoDB Good involvement in creating web applications in Object Oriented Programming concepts like MultiThreading Exception Handling and Collections and also executing Model View Control design utilizing Django Framework Experience in developing Web Services SOAP Restful in Python using XML JSON Experience in working with various version control systems like GIT CVS and SVN Proficient in using editors like Eclipse sublime text Net beans PyCharm PyScripter spyder PyStudio and PyDev Used Python Unit test framework for developing and implementing the unit tests using Test driven approach Good Hands on experience in establishing connections for Java and Python by configuring packages like MySQLPython JDBC Successfully migrated the Django database from SQLite to MySQL to PostgreSQL with complete data integrity Hands on experience in monitoring developing and transforming data using SQL Server Integration Service SSIS and SQL Service Analysis Service SSAS Hands on experience with databases using ORMsDOMs for integrating with Oracle MySQL PostgreSQL Good knowledge in working with Webapplication server Apache Tomcat Tornado Cherrypy Chaussette Rocket Experience in infrastructure as service IaaS Platform as service PaaS Software as a service SaaS end user computing Used Pandas API to put the data as time series and tabular form for east timestamp data retrieval and manipulation and for statistical analysis Work Experience Python Developer Citi Group CA February 2018 to Present Responsibilities Involved in developing webbased application using Python Django JavaScript Express ReactJS Node JS Express AJAX CSS3 and HTML5 Currently working on a cloud base application that developed controls centered around the new search tool and Amazon Connect to ensure that calls are available recording consistently are retained properly in a cloud based application On SWNG application initiate TDD Test Driven Development approach to update Rest API from DRF Django Rest Framework to Rest API Developed custom Amazon Connect UI to provide Service Cloud agents with advanced enduser functionality using Lighting Components Worked on AWS services S3 EC2 and deployment services Lambda and RDS DynamoDB NoSQL Beanstalk SQS and Jenkins CICD Assist in server and network administration in corporate datacenter and Amazon cloud Developed Hadoop integrations for data ingestion data mapping and data processing Involved building Hadoop platforms maximizing business value by combining data science with big data Experience in Installing JenkinsPlugins for GIT Repository Setup SCM Polling for Immediate Build with Maven and Maven Repository and Deployment of apps using custom modules through Puppet as a CICD Process Capable of using AWS utilities such as EMR S3 and cloud watch to run and monitor Hadoop and spark jobs on AWS Designed and developed an entire module called CDC change data capture in python and deployed in AWS GLUE using pySpark library and python Loaded and transformed large sets of structured semistructured and unstructured data using HadoopBig Data concepts Wrote Lambda functions in python for AWSs Lambda Kinesis and Elastic Search which invokes python scripts to perform various transformations and analytics on large data sets in AMAZON EMR clusters Integrated AWSRDS Oracle and Aurora DBs to AWSHive EMR using DynamoDB with direct connect Used Python to write data into JSON files for testing Django Websites Created scripts for data modelling and data import and export Understanding of securecloud configuration Cloud Trail cloudsecurity technologies VPC Security Groups etc and cloudpermission systems IAM Developed POC using Scala deployed on Yarn cluster compared the performance of Spark with Hive and SQL Using Chef deployed and configured Elasticsearch Logstash and Kibana ELK for log analytics full text search application monitoring in integration with AWS Lambda and CloudWatch Build custom transformations using AWS Glue Lambda and Kinesis helped reduce costs in ETL tool onpremise infrastructure Documented the requirements including the available code which should be implemented using Spark Hive HDFS HBase and Elasticsearch Designing and creating HIVE external tables using shared metastore instead of the derby with partitioning dynamic partitioning and buckets Supported development of Web portals completed Database Modelling in PostgreSQL front end support in HTMLCSS jQuery Container management using Docker by writing Docker files and set up the automated build on Docker HUB and installed and configured Kubernetes Experienced in developing a portal to manage and entities in a content management system using Python and Django Golang Infrastructure Teams and Engineering Productivity utilizing Kubernetes Docker influx DB Ansible Spinnaker Worked on analyzing Hadoop stack and different big data analytic tools including Pig Hive HBase database and DynamoDB Used Amazon Elastic Beanstalk with Amazon EC2 instance to deploy Django project into AWS Configured continuous integration with Jenkins on Amazon EC2 Developed Serverside automation using Node JS scripting and connecting different types of SQL and NoSQL stores from Node JS Developed Scala R Python for regular expression regex project in the HadoopHive environment with LinuxWindows for big data resources Used Amazon Web Services AWS for improved efficiency of storage and fast access Used Celery with RabbitMQ MySQL Django and Flask to create a distributed worker framework Used automation Jenkins for continuous integration and continuous delivery CICD on Amazon EC2 Executed MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Designed and developed the framework to consume the web services hosted in AmazonEC2 Python Developer ASURION San Mateo CA October 2016 to December 2017 Responsibilities Developed the notification service by posting the JSON request in AWS API Gateway Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS experienced in querying data using SparkSQL on top of Spark engine for faster data sets processing Using Python included Boto3 to supplement automation provided by Ansible and Terraform for tasks such as encrypting EBS volumes backing AMIs and scheduling Lambda functions for routine AWS tasks Responsible for the global redesign of the Service Console including streamlining the overall support process researching new CTI telephony platforms BCMForce Amazon Connect and Bucher Suter and the introduction of Salesforce Einstein and other AI related technologies Worked extensively with importing metadata into Hive and migrated existing tables and applications to work on Hive and Spark Worked with Hadoop architecture and the daemons of Hadoop including NameNode Data Node Job Tracker Task Tracker and Resource Manager Created an Application was based on serviceoriented architecture and used Python Django JSF Spring Ajax HTML CSS for the frontend Implemented Stable React JS components and Standalone functions to be added to any future pages Launched Kubernetes to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts Worked with Hadoop architecture and the daemons of Hadoop including NameNode Data Node Job Tracker Task Tracker and Resource Manager Built Jenkins jobs to create AWS infrastructure from GitHub repos containing terraform code Wrote with objectoriented Python Flask SQL Beautiful Soup httplib2 Jinja2 HTMLCSS Bootstrap jQuery Linux Sublime Text GIT Worked on integrating Python with Web development tools for developing Web Services in python using XML JSON Worked on migrating MapReduce programs into Spark transformations using Scala Responsible for building scalable distributed data solutions using Hadoop Implemented user interface guidelines and standards throughout the development and maintenance of the website using the HTML CSS JavaScript and JQuery Involved in managing and reviewing Hadoop log files Used React JS in components like JSX creating React components Virtual DOM ReactProps Lifecycle methods working with the React States and Events Analysis the logs data and filter required columns by logstash configuration and send it to elasticsearch Design and developed the test cases for REST API Involved REST API test framework development Worked on serverside applications with Django using Python programming and used python libraries like Beautiful Soup matplotlib SciPy NumPy and Built efficient Nodejs backend for client web application Involved in using Python MongoDB and ReactJS for the design development and deployment of the application Used Elasticsearch Framework for developing web applications using model view control architecture Used Amazon Elastic Beanstalk with Amazon EC2 instance to deploy Django project into AWS Configured continuous integration with Jenkins on Amazon EC2 Automated the existing scripts for performance calculations using NumPy and SQLAlchemy Optimization of heavy load workflows via queues RabbitMQ for enhanced performance and less downtime for stakeholders Involved in working with Webservices backend development using Python CherryPy Django and SQLAlchemy Involved in development of Web Services using and REST for sending and getting data from the external interface in XML and JSON format Integrated AWSRDS Oracle and Aurora DBs to AWSHive EMR using DynamoDB with direct connect Deploying application in Docker Container for custom environment and hosting in Elastic Beanstalk Developed and tested many features for dashboard using Python ROBOT framework Bootstrap CSS and JavaScript Developed data pipeline using Flume Spark and Hive to ingest transform and analyzing data Maintained the Selenium and Python code and resources in source control like CVS SVN over the time for improvements and new features Python Developer Amazon September 2014 to December 2015 Responsibilities Used Python and Django to interface with the jQuery UI and manage the storage and deletion of content Involved in creating Hive tables as per requirement defined with appropriate static and dynamic partitions Worked on migrating MapReduce programs into Spark transformations using Scala Responsible for building scalable distributed data solutions using Hadoop Developed Scala based Spark applications for performing data cleansing data aggregation denormalization and data preparation needed for machine learning and reporting teams to consume Designed and developed data management system using MySQL Built application logic using Python Worked on Python Open stack APIs used Python scripts to update content in the database and manipulate files Designed and developed persistence layers to modify data for application using Django and PostgreSQL Worked on troubleshooting spark application to make them more error tolerant Implemented MVC architecture using Django Servlet and RESTful SOAP web service and SOAPUI Scraped and retrieved web data as JSON using Scrapy presented with Pandas library Developed web applications and RESTful web services and APIs using python Django Tornado and PHP Worked on JavaScript frameworks like Jest Jasmine and Karma and AngularJS test framework Protractor Developed Navigation bar Manu bar drop down list with React widgets and bootstrap Developed and tested many features for dashboard using Ruby on Rails RSpec Bootstrap and JavaScript Develop and executed unit test cases using JUnit and Mockito as mocking framework for mocking data Involved in Regression testing by following AgileScrum Kanban and Waterfall software development Worked in AWS Cloud platform and its features which include EC2 RDS DynamoDB S3 and CloudFormation Worked extensively with hip chat and Jira on UNIX platform for automation of application Software Engineer Accenture October 2013 to August 2014 Responsibilities Responsible for the design and development of different standalone applications based on clients requirements using Python programming C Pro C and Oracle Database Collaborated with a team of instructors and programmers to develop the curriculum and guidelines for workshops to teach the logic of programming Worked with JSON based REST Web services and Created a Git repository and added the project to GitHub Performing Unit testing Integration testing User acceptance testing and Functional testing along with debuggingtroubleshooting issues in complex applications Developed tools using Python Shell scripting XML to automate some of the menial tasks Interfacing with supervisors artists systems administrators and production to ensure production deadlines are met Analyzing and fixing of performance issues critical bugs and application crashes Work with team of developers on python applications for RISK management Creating unit testregression test framework for workingnew code Responsible for debugging and troubleshooting the application Tested all completed work to ensure proper and error free functionality Created Use Case diagrams Class diagrams Involved in entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Generated property list for every application dynamically using python Handling the day to day issues and fine tuning the applications for enhanced performance Worked in development of applications especially in UNIX environment and familiar with all of its commands",
    "entities": [
        "SQL Server Integration Service",
        "Resource",
        "AWS Elastic Beanstalk",
        "ORMsDOMs",
        "AmazonEC2 Python Developer ASURION San Mateo",
        "Nodejs",
        "UNIX",
        "Lighting Components Worked",
        "Interfacing",
        "HTMLCSS jQuery Container",
        "Scrapy",
        "JSON",
        "GIT Repository Setup",
        "Present Responsibilities Involved",
        "Hadoop Implemented",
        "CVS",
        "DB Ansible Spinnaker Worked",
        "Amazon Web Services AWS",
        "Worked with Hadoop",
        "Developed Hadoop",
        "Design Development and Deployment Testing and Implementation",
        "Hadoop",
        "XML",
        "Salesforce Einstein",
        "JavaScript Develop",
        "Spark Worked",
        "Python Flask SQL Beautiful Soup httplib2 Jinja2",
        "Functional",
        "Bootstrap CSS",
        "Scala Responsible",
        "JUnit",
        "Creating",
        "Shell",
        "HBase",
        "Amazon",
        "CTI",
        "Maven Repository and Deployment",
        "Spark with",
        "Hadoop Hive Pig Sqoop",
        "Python",
        "AWS GLUE",
        "Generated",
        "SparkSQL",
        "Developed",
        "AWS SNS",
        "Mockito",
        "Web Services SOAP Restful",
        "TDD Test Driven Development",
        "Puppet",
        "Yarn",
        "Waterfall",
        "Django Websites Created",
        "SQL Service Analysis Service SSAS Hands",
        "Designed",
        "HadoopBig Data",
        "Database Modelling",
        "Used Elasticsearch Framework",
        "Kinesis",
        "Flask",
        "Built",
        "Worked",
        "Docker",
        "RDS",
        "AWS Designed",
        "Created a Git",
        "Python Django JavaScript Express",
        "SVN Proficient",
        "Kubernetes Experienced",
        "Bucher Suter",
        "MVC",
        "Docker Container",
        "Spark",
        "Node JS",
        "JQuery Involved",
        "log analytics full text search",
        "Software Engineer Accenture",
        "Terraform",
        "HTML CSS JavaScript",
        "Jenkins CICD Assist",
        "HIVE",
        "LinuxWindows",
        "Python Django JSF Spring Ajax HTML CSS",
        "AI",
        "Python Developer Amazon",
        "JSX",
        "IAM Developed",
        "Kubernetes Docker",
        "Standalone",
        "SQL",
        "GitHub",
        "the React States and Events Analysis",
        "WebApplication Developer",
        "AWS Lambda and CloudWatch Build",
        "GIT CVS",
        "Webapplication",
        "Model View Control",
        "Hive",
        "CICD",
        "Oracle MySQL PostgreSQL Good",
        "Working on Big Data Integration and Analytics",
        "Pandas",
        "SQLite",
        "SQS",
        "ETL",
        "MultiThreading Exception Handling and Collections",
        "MySQLPython JDBC Successfully",
        "CloudFormation Worked",
        "Maven",
        "Node JS Express",
        "AWS Configured",
        "JavaScript",
        "CDC",
        "Analysis Design and Development Testing Implementation",
        "Flume Spark",
        "AWS Glue Lambda",
        "Hadoop Spark",
        "AMAZON EMR",
        "REST",
        "GitHub Performing Unit",
        "SQL Using Chef",
        "MapReduce",
        "Lambda API Gateway Amazon",
        "NoSQL",
        "Spark Hive HDFS HBase",
        "NameNode Data",
        "PaaS Software",
        "EBS",
        "Oracle Database Collaborated",
        "Node"
    ],
    "experience": "Experience in working with AWS services like EC2 S3 RDS IAM CloudFormation Amazon Connect Lex chatbot Lambda Transcribe and Comprehend Experience in AWS Elastic Beanstalk for app deployments and worked on AWS lambda with Amazon kinesis Hands on experience in using Hadoop ecosystem components like Hadoop Hive Pig Sqoop HBase Cassandra Spark Spark Streaming Spark SQL Oozie ZooKeeper Kafka Flume MapReduce and Yarn Responsible for creating Hive tables and working on them using Hive QL Experienced in Working on Big Data Integration and Analytics based on Hadoop Spark and NoSQL databases like HBase and MongoDB Good involvement in creating web applications in Object Oriented Programming concepts like MultiThreading Exception Handling and Collections and also executing Model View Control design utilizing Django Framework Experience in developing Web Services SOAP Restful in Python using XML JSON Experience in working with various version control systems like GIT CVS and SVN Proficient in using editors like Eclipse sublime text Net beans PyCharm PyScripter spyder PyStudio and PyDev Used Python Unit test framework for developing and implementing the unit tests using Test driven approach Good Hands on experience in establishing connections for Java and Python by configuring packages like MySQLPython JDBC Successfully migrated the Django database from SQLite to MySQL to PostgreSQL with complete data integrity Hands on experience in monitoring developing and transforming data using SQL Server Integration Service SSIS and SQL Service Analysis Service SSAS Hands on experience with databases using ORMsDOMs for integrating with Oracle MySQL PostgreSQL Good knowledge in working with Webapplication server Apache Tomcat Tornado Cherrypy Chaussette Rocket Experience in infrastructure as service IaaS Platform as service PaaS Software as a service SaaS end user computing Used Pandas API to put the data as time series and tabular form for east timestamp data retrieval and manipulation and for statistical analysis Work Experience Python Developer Citi Group CA February 2018 to Present Responsibilities Involved in developing webbased application using Python Django JavaScript Express ReactJS Node JS Express AJAX CSS3 and HTML5 Currently working on a cloud base application that developed controls centered around the new search tool and Amazon Connect to ensure that calls are available recording consistently are retained properly in a cloud based application On SWNG application initiate TDD Test Driven Development approach to update Rest API from DRF Django Rest Framework to Rest API Developed custom Amazon Connect UI to provide Service Cloud agents with advanced enduser functionality using Lighting Components Worked on AWS services S3 EC2 and deployment services Lambda and RDS DynamoDB NoSQL Beanstalk SQS and Jenkins CICD Assist in server and network administration in corporate datacenter and Amazon cloud Developed Hadoop integrations for data ingestion data mapping and data processing Involved building Hadoop platforms maximizing business value by combining data science with big data Experience in Installing JenkinsPlugins for GIT Repository Setup SCM Polling for Immediate Build with Maven and Maven Repository and Deployment of apps using custom modules through Puppet as a CICD Process Capable of using AWS utilities such as EMR S3 and cloud watch to run and monitor Hadoop and spark jobs on AWS Designed and developed an entire module called CDC change data capture in python and deployed in AWS GLUE using pySpark library and python Loaded and transformed large sets of structured semistructured and unstructured data using HadoopBig Data concepts Wrote Lambda functions in python for AWSs Lambda Kinesis and Elastic Search which invokes python scripts to perform various transformations and analytics on large data sets in AMAZON EMR clusters Integrated AWSRDS Oracle and Aurora DBs to AWSHive EMR using DynamoDB with direct connect Used Python to write data into JSON files for testing Django Websites Created scripts for data modelling and data import and export Understanding of securecloud configuration Cloud Trail cloudsecurity technologies VPC Security Groups etc and cloudpermission systems IAM Developed POC using Scala deployed on Yarn cluster compared the performance of Spark with Hive and SQL Using Chef deployed and configured Elasticsearch Logstash and Kibana ELK for log analytics full text search application monitoring in integration with AWS Lambda and CloudWatch Build custom transformations using AWS Glue Lambda and Kinesis helped reduce costs in ETL tool onpremise infrastructure Documented the requirements including the available code which should be implemented using Spark Hive HDFS HBase and Elasticsearch Designing and creating HIVE external tables using shared metastore instead of the derby with partitioning dynamic partitioning and buckets Supported development of Web portals completed Database Modelling in PostgreSQL front end support in HTMLCSS jQuery Container management using Docker by writing Docker files and set up the automated build on Docker HUB and installed and configured Kubernetes Experienced in developing a portal to manage and entities in a content management system using Python and Django Golang Infrastructure Teams and Engineering Productivity utilizing Kubernetes Docker influx DB Ansible Spinnaker Worked on analyzing Hadoop stack and different big data analytic tools including Pig Hive HBase database and DynamoDB Used Amazon Elastic Beanstalk with Amazon EC2 instance to deploy Django project into AWS Configured continuous integration with Jenkins on Amazon EC2 Developed Serverside automation using Node JS scripting and connecting different types of SQL and NoSQL stores from Node JS Developed Scala R Python for regular expression regex project in the HadoopHive environment with LinuxWindows for big data resources Used Amazon Web Services AWS for improved efficiency of storage and fast access Used Celery with RabbitMQ MySQL Django and Flask to create a distributed worker framework Used automation Jenkins for continuous integration and continuous delivery CICD on Amazon EC2 Executed MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Designed and developed the framework to consume the web services hosted in AmazonEC2 Python Developer ASURION San Mateo CA October 2016 to December 2017 Responsibilities Developed the notification service by posting the JSON request in AWS API Gateway Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS experienced in querying data using SparkSQL on top of Spark engine for faster data sets processing Using Python included Boto3 to supplement automation provided by Ansible and Terraform for tasks such as encrypting EBS volumes backing AMIs and scheduling Lambda functions for routine AWS tasks Responsible for the global redesign of the Service Console including streamlining the overall support process researching new CTI telephony platforms BCMForce Amazon Connect and Bucher Suter and the introduction of Salesforce Einstein and other AI related technologies Worked extensively with importing metadata into Hive and migrated existing tables and applications to work on Hive and Spark Worked with Hadoop architecture and the daemons of Hadoop including NameNode Data Node Job Tracker Task Tracker and Resource Manager Created an Application was based on serviceoriented architecture and used Python Django JSF Spring Ajax HTML CSS for the frontend Implemented Stable React JS components and Standalone functions to be added to any future pages Launched Kubernetes to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts Worked with Hadoop architecture and the daemons of Hadoop including NameNode Data Node Job Tracker Task Tracker and Resource Manager Built Jenkins jobs to create AWS infrastructure from GitHub repos containing terraform code Wrote with objectoriented Python Flask SQL Beautiful Soup httplib2 Jinja2 HTMLCSS Bootstrap jQuery Linux Sublime Text GIT Worked on integrating Python with Web development tools for developing Web Services in python using XML JSON Worked on migrating MapReduce programs into Spark transformations using Scala Responsible for building scalable distributed data solutions using Hadoop Implemented user interface guidelines and standards throughout the development and maintenance of the website using the HTML CSS JavaScript and JQuery Involved in managing and reviewing Hadoop log files Used React JS in components like JSX creating React components Virtual DOM ReactProps Lifecycle methods working with the React States and Events Analysis the logs data and filter required columns by logstash configuration and send it to elasticsearch Design and developed the test cases for REST API Involved REST API test framework development Worked on serverside applications with Django using Python programming and used python libraries like Beautiful Soup matplotlib SciPy NumPy and Built efficient Nodejs backend for client web application Involved in using Python MongoDB and ReactJS for the design development and deployment of the application Used Elasticsearch Framework for developing web applications using model view control architecture Used Amazon Elastic Beanstalk with Amazon EC2 instance to deploy Django project into AWS Configured continuous integration with Jenkins on Amazon EC2 Automated the existing scripts for performance calculations using NumPy and SQLAlchemy Optimization of heavy load workflows via queues RabbitMQ for enhanced performance and less downtime for stakeholders Involved in working with Webservices backend development using Python CherryPy Django and SQLAlchemy Involved in development of Web Services using and REST for sending and getting data from the external interface in XML and JSON format Integrated AWSRDS Oracle and Aurora DBs to AWSHive EMR using DynamoDB with direct connect Deploying application in Docker Container for custom environment and hosting in Elastic Beanstalk Developed and tested many features for dashboard using Python ROBOT framework Bootstrap CSS and JavaScript Developed data pipeline using Flume Spark and Hive to ingest transform and analyzing data Maintained the Selenium and Python code and resources in source control like CVS SVN over the time for improvements and new features Python Developer Amazon September 2014 to December 2015 Responsibilities Used Python and Django to interface with the jQuery UI and manage the storage and deletion of content Involved in creating Hive tables as per requirement defined with appropriate static and dynamic partitions Worked on migrating MapReduce programs into Spark transformations using Scala Responsible for building scalable distributed data solutions using Hadoop Developed Scala based Spark applications for performing data cleansing data aggregation denormalization and data preparation needed for machine learning and reporting teams to consume Designed and developed data management system using MySQL Built application logic using Python Worked on Python Open stack APIs used Python scripts to update content in the database and manipulate files Designed and developed persistence layers to modify data for application using Django and PostgreSQL Worked on troubleshooting spark application to make them more error tolerant Implemented MVC architecture using Django Servlet and RESTful SOAP web service and SOAPUI Scraped and retrieved web data as JSON using Scrapy presented with Pandas library Developed web applications and RESTful web services and APIs using python Django Tornado and PHP Worked on JavaScript frameworks like Jest Jasmine and Karma and AngularJS test framework Protractor Developed Navigation bar Manu bar drop down list with React widgets and bootstrap Developed and tested many features for dashboard using Ruby on Rails RSpec Bootstrap and JavaScript Develop and executed unit test cases using JUnit and Mockito as mocking framework for mocking data Involved in Regression testing by following AgileScrum Kanban and Waterfall software development Worked in AWS Cloud platform and its features which include EC2 RDS DynamoDB S3 and CloudFormation Worked extensively with hip chat and Jira on UNIX platform for automation of application Software Engineer Accenture October 2013 to August 2014 Responsibilities Responsible for the design and development of different standalone applications based on clients requirements using Python programming C Pro C and Oracle Database Collaborated with a team of instructors and programmers to develop the curriculum and guidelines for workshops to teach the logic of programming Worked with JSON based REST Web services and Created a Git repository and added the project to GitHub Performing Unit testing Integration testing User acceptance testing and Functional testing along with debuggingtroubleshooting issues in complex applications Developed tools using Python Shell scripting XML to automate some of the menial tasks Interfacing with supervisors artists systems administrators and production to ensure production deadlines are met Analyzing and fixing of performance issues critical bugs and application crashes Work with team of developers on python applications for RISK management Creating unit testregression test framework for workingnew code Responsible for debugging and troubleshooting the application Tested all completed work to ensure proper and error free functionality Created Use Case diagrams Class diagrams Involved in entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Generated property list for every application dynamically using python Handling the day to day issues and fine tuning the applications for enhanced performance Worked in development of applications especially in UNIX environment and familiar with all of its commands",
    "extracted_keywords": [
        "Python",
        "Developer",
        "Python",
        "span",
        "lDeveloperspan",
        "Python",
        "Developer",
        "Citi",
        "Group",
        "CA",
        "years",
        "experience",
        "WebApplication",
        "Developer",
        "understanding",
        "technology",
        "trends",
        "expertise",
        "core",
        "technologies",
        "experience",
        "Analysis",
        "Design",
        "Development",
        "Testing",
        "Implementation",
        "production",
        "support",
        "maintenance",
        "Web",
        "Applications",
        "Python",
        "Django",
        "involvement",
        "Python",
        "softwares",
        "tools",
        "libraries",
        "Beautiful",
        "Soup",
        "NumPy",
        "SciPy",
        "PySide",
        "matplotlib",
        "Pickle",
        "Pandas",
        "data",
        "frame",
        "urllib2",
        "MySQL",
        "DB",
        "software",
        "development",
        "process",
        "Support",
        "services",
        "Lambda",
        "API",
        "Gateway",
        "Amazon",
        "Connect",
        "Step",
        "Functions",
        "Django",
        "evolution",
        "SQL",
        "modifications",
        "data",
        "site",
        "production",
        "Expertise",
        "web",
        "stack",
        "applications",
        "analysis",
        "Python",
        "Django",
        "Proficient",
        "Web",
        "User",
        "Interface",
        "UI",
        "HTML5",
        "DHTML",
        "XHTML",
        "Hibernate",
        "CSSCSS3",
        "JavaScript",
        "Nodejs",
        "Backbonejs",
        "D3",
        "jQuery",
        "W3C",
        "Web",
        "Standards",
        "browser",
        "Experience",
        "AWS",
        "services",
        "EC2",
        "S3",
        "RDS",
        "IAM",
        "CloudFormation",
        "Amazon",
        "Connect",
        "Lex",
        "chatbot",
        "Lambda",
        "Transcribe",
        "Experience",
        "AWS",
        "Beanstalk",
        "app",
        "deployments",
        "AWS",
        "lambda",
        "Amazon",
        "kinesis",
        "Hands",
        "experience",
        "Hadoop",
        "ecosystem",
        "components",
        "Hadoop",
        "Hive",
        "Pig",
        "Sqoop",
        "HBase",
        "Cassandra",
        "Spark",
        "Spark",
        "Streaming",
        "Spark",
        "SQL",
        "Oozie",
        "ZooKeeper",
        "Kafka",
        "Flume",
        "MapReduce",
        "Yarn",
        "Responsible",
        "Hive",
        "tables",
        "Hive",
        "QL",
        "Working",
        "Big",
        "Data",
        "Integration",
        "Analytics",
        "Hadoop",
        "Spark",
        "NoSQL",
        "HBase",
        "involvement",
        "web",
        "applications",
        "Object",
        "Programming",
        "concepts",
        "MultiThreading",
        "Exception",
        "Handling",
        "Collections",
        "Model",
        "View",
        "Control",
        "design",
        "Django",
        "Framework",
        "Experience",
        "Web",
        "Services",
        "SOAP",
        "Restful",
        "Python",
        "XML",
        "JSON",
        "Experience",
        "version",
        "control",
        "systems",
        "GIT",
        "CVS",
        "SVN",
        "Proficient",
        "editors",
        "Eclipse",
        "text",
        "beans",
        "PyCharm",
        "PyScripter",
        "spyder",
        "PyStudio",
        "PyDev",
        "Python",
        "Unit",
        "test",
        "framework",
        "unit",
        "tests",
        "Test",
        "approach",
        "Good",
        "Hands",
        "experience",
        "connections",
        "Java",
        "Python",
        "packages",
        "MySQLPython",
        "JDBC",
        "Django",
        "database",
        "SQLite",
        "PostgreSQL",
        "data",
        "integrity",
        "Hands",
        "experience",
        "data",
        "SQL",
        "Server",
        "Integration",
        "Service",
        "SSIS",
        "SQL",
        "Service",
        "Analysis",
        "Service",
        "SSAS",
        "Hands",
        "experience",
        "databases",
        "ORMsDOMs",
        "Oracle",
        "MySQL",
        "PostgreSQL",
        "knowledge",
        "Webapplication",
        "server",
        "Apache",
        "Tomcat",
        "Tornado",
        "Cherrypy",
        "Chaussette",
        "Rocket",
        "Experience",
        "infrastructure",
        "service",
        "IaaS",
        "Platform",
        "service",
        "PaaS",
        "Software",
        "service",
        "SaaS",
        "end",
        "user",
        "Pandas",
        "API",
        "data",
        "time",
        "series",
        "form",
        "east",
        "timestamp",
        "data",
        "retrieval",
        "manipulation",
        "analysis",
        "Work",
        "Experience",
        "Python",
        "Developer",
        "Citi",
        "Group",
        "CA",
        "February",
        "Present",
        "Responsibilities",
        "application",
        "Python",
        "Django",
        "JavaScript",
        "Express",
        "ReactJS",
        "Node",
        "JS",
        "Express",
        "AJAX",
        "CSS3",
        "HTML5",
        "base",
        "application",
        "controls",
        "search",
        "tool",
        "Amazon",
        "Connect",
        "calls",
        "recording",
        "cloud",
        "application",
        "SWNG",
        "application",
        "TDD",
        "Test",
        "Driven",
        "Development",
        "approach",
        "Rest",
        "API",
        "DRF",
        "Django",
        "Rest",
        "Framework",
        "API",
        "custom",
        "Amazon",
        "Connect",
        "UI",
        "Service",
        "Cloud",
        "agents",
        "functionality",
        "Lighting",
        "Components",
        "AWS",
        "services",
        "S3",
        "EC2",
        "deployment",
        "services",
        "Lambda",
        "RDS",
        "DynamoDB",
        "NoSQL",
        "Beanstalk",
        "SQS",
        "Jenkins",
        "CICD",
        "Assist",
        "server",
        "network",
        "administration",
        "datacenter",
        "Amazon",
        "Developed",
        "Hadoop",
        "integrations",
        "data",
        "ingestion",
        "data",
        "mapping",
        "data",
        "processing",
        "building",
        "Hadoop",
        "platforms",
        "business",
        "value",
        "data",
        "science",
        "data",
        "Experience",
        "Installing",
        "JenkinsPlugins",
        "GIT",
        "Repository",
        "Setup",
        "SCM",
        "Polling",
        "Immediate",
        "Build",
        "Maven",
        "Maven",
        "Repository",
        "Deployment",
        "apps",
        "custom",
        "modules",
        "Puppet",
        "CICD",
        "Process",
        "AWS",
        "utilities",
        "EMR",
        "S3",
        "cloud",
        "Hadoop",
        "spark",
        "jobs",
        "AWS",
        "module",
        "CDC",
        "change",
        "data",
        "capture",
        "python",
        "AWS",
        "GLUE",
        "pySpark",
        "library",
        "Loaded",
        "sets",
        "data",
        "HadoopBig",
        "Data",
        "concepts",
        "Wrote",
        "Lambda",
        "functions",
        "python",
        "AWSs",
        "Lambda",
        "Kinesis",
        "Elastic",
        "Search",
        "scripts",
        "transformations",
        "analytics",
        "data",
        "sets",
        "AMAZON",
        "EMR",
        "Integrated",
        "AWSRDS",
        "Oracle",
        "Aurora",
        "DBs",
        "AWSHive",
        "EMR",
        "DynamoDB",
        "connect",
        "Used",
        "Python",
        "data",
        "files",
        "Django",
        "Websites",
        "scripts",
        "data",
        "modelling",
        "data",
        "import",
        "export",
        "Understanding",
        "configuration",
        "Cloud",
        "Trail",
        "cloudsecurity",
        "VPC",
        "Security",
        "Groups",
        "cloudpermission",
        "systems",
        "IAM",
        "Developed",
        "POC",
        "Scala",
        "Yarn",
        "cluster",
        "performance",
        "Spark",
        "Hive",
        "SQL",
        "Chef",
        "Elasticsearch",
        "Logstash",
        "Kibana",
        "ELK",
        "log",
        "analytics",
        "text",
        "search",
        "application",
        "monitoring",
        "integration",
        "AWS",
        "Lambda",
        "CloudWatch",
        "Build",
        "custom",
        "transformations",
        "AWS",
        "Glue",
        "Lambda",
        "Kinesis",
        "costs",
        "ETL",
        "tool",
        "onpremise",
        "infrastructure",
        "requirements",
        "code",
        "Spark",
        "Hive",
        "HDFS",
        "HBase",
        "Elasticsearch",
        "Designing",
        "tables",
        "metastore",
        "derby",
        "partitioning",
        "buckets",
        "development",
        "Web",
        "portals",
        "Database",
        "Modelling",
        "PostgreSQL",
        "end",
        "support",
        "HTMLCSS",
        "jQuery",
        "Container",
        "management",
        "Docker",
        "Docker",
        "files",
        "build",
        "Docker",
        "HUB",
        "Kubernetes",
        "portal",
        "entities",
        "content",
        "management",
        "system",
        "Python",
        "Django",
        "Golang",
        "Infrastructure",
        "Teams",
        "Engineering",
        "Productivity",
        "Kubernetes",
        "Docker",
        "DB",
        "Ansible",
        "Spinnaker",
        "Hadoop",
        "stack",
        "data",
        "tools",
        "Pig",
        "Hive",
        "HBase",
        "database",
        "DynamoDB",
        "Amazon",
        "Elastic",
        "Beanstalk",
        "Amazon",
        "EC2",
        "instance",
        "Django",
        "project",
        "AWS",
        "integration",
        "Jenkins",
        "Amazon",
        "EC2",
        "Developed",
        "Serverside",
        "automation",
        "Node",
        "JS",
        "scripting",
        "types",
        "SQL",
        "NoSQL",
        "stores",
        "Node",
        "JS",
        "Developed",
        "Scala",
        "R",
        "Python",
        "expression",
        "regex",
        "project",
        "environment",
        "LinuxWindows",
        "data",
        "resources",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "efficiency",
        "storage",
        "access",
        "Celery",
        "RabbitMQ",
        "MySQL",
        "Django",
        "Flask",
        "worker",
        "framework",
        "automation",
        "Jenkins",
        "integration",
        "delivery",
        "CICD",
        "Amazon",
        "EC2",
        "MYSQL",
        "database",
        "python",
        "PythonMySQL",
        "connector",
        "MySQL",
        "package",
        "information",
        "framework",
        "web",
        "services",
        "AmazonEC2",
        "Python",
        "Developer",
        "ASURION",
        "San",
        "Mateo",
        "CA",
        "October",
        "December",
        "Responsibilities",
        "notification",
        "service",
        "request",
        "AWS",
        "API",
        "Gateway",
        "response",
        "Lambda",
        "data",
        "DynamoDB",
        "notification",
        "AWS",
        "SNS",
        "data",
        "SparkSQL",
        "top",
        "Spark",
        "engine",
        "data",
        "sets",
        "processing",
        "Python",
        "Boto3",
        "automation",
        "Ansible",
        "Terraform",
        "tasks",
        "EBS",
        "volumes",
        "AMIs",
        "scheduling",
        "Lambda",
        "functions",
        "AWS",
        "tasks",
        "redesign",
        "Service",
        "Console",
        "support",
        "process",
        "CTI",
        "telephony",
        "platforms",
        "BCMForce",
        "Amazon",
        "Connect",
        "Bucher",
        "Suter",
        "introduction",
        "Salesforce",
        "Einstein",
        "AI",
        "technologies",
        "metadata",
        "Hive",
        "tables",
        "applications",
        "Hive",
        "Spark",
        "Hadoop",
        "architecture",
        "daemons",
        "Hadoop",
        "NameNode",
        "Data",
        "Node",
        "Job",
        "Tracker",
        "Task",
        "Tracker",
        "Resource",
        "Manager",
        "Application",
        "architecture",
        "Python",
        "Django",
        "JSF",
        "Spring",
        "Ajax",
        "HTML",
        "CSS",
        "frontend",
        "Stable",
        "React",
        "JS",
        "components",
        "functions",
        "pages",
        "Kubernetes",
        "platform",
        "deployment",
        "scaling",
        "operations",
        "application",
        "containers",
        "clusters",
        "hosts",
        "Hadoop",
        "architecture",
        "daemons",
        "Hadoop",
        "NameNode",
        "Data",
        "Node",
        "Job",
        "Tracker",
        "Task",
        "Tracker",
        "Resource",
        "Manager",
        "Jenkins",
        "jobs",
        "AWS",
        "infrastructure",
        "GitHub",
        "repos",
        "terraform",
        "code",
        "Python",
        "Flask",
        "SQL",
        "Beautiful",
        "Soup",
        "httplib2",
        "Jinja2",
        "HTMLCSS",
        "Bootstrap",
        "jQuery",
        "Linux",
        "Sublime",
        "Text",
        "GIT",
        "Python",
        "Web",
        "development",
        "tools",
        "Web",
        "Services",
        "python",
        "XML",
        "JSON",
        "MapReduce",
        "programs",
        "Spark",
        "transformations",
        "Scala",
        "Responsible",
        "data",
        "solutions",
        "Hadoop",
        "user",
        "interface",
        "guidelines",
        "standards",
        "development",
        "maintenance",
        "website",
        "HTML",
        "CSS",
        "JavaScript",
        "JQuery",
        "Hadoop",
        "log",
        "files",
        "React",
        "JS",
        "components",
        "JSX",
        "React",
        "components",
        "DOM",
        "ReactProps",
        "Lifecycle",
        "methods",
        "React",
        "States",
        "Events",
        "Analysis",
        "logs",
        "data",
        "filter",
        "columns",
        "logstash",
        "configuration",
        "Design",
        "test",
        "cases",
        "REST",
        "API",
        "REST",
        "API",
        "test",
        "framework",
        "development",
        "serverside",
        "applications",
        "Django",
        "Python",
        "programming",
        "python",
        "libraries",
        "Beautiful",
        "Soup",
        "matplotlib",
        "SciPy",
        "NumPy",
        "Nodejs",
        "backend",
        "client",
        "web",
        "application",
        "Python",
        "MongoDB",
        "ReactJS",
        "design",
        "development",
        "deployment",
        "application",
        "Elasticsearch",
        "Framework",
        "web",
        "applications",
        "model",
        "view",
        "control",
        "architecture",
        "Amazon",
        "Elastic",
        "Beanstalk",
        "Amazon",
        "EC2",
        "instance",
        "Django",
        "project",
        "AWS",
        "integration",
        "Jenkins",
        "Amazon",
        "EC2",
        "scripts",
        "performance",
        "calculations",
        "NumPy",
        "SQLAlchemy",
        "Optimization",
        "load",
        "workflows",
        "queues",
        "RabbitMQ",
        "performance",
        "downtime",
        "stakeholders",
        "Webservices",
        "development",
        "Python",
        "CherryPy",
        "Django",
        "SQLAlchemy",
        "development",
        "Web",
        "Services",
        "REST",
        "data",
        "interface",
        "XML",
        "format",
        "Integrated",
        "AWSRDS",
        "Oracle",
        "Aurora",
        "DBs",
        "AWSHive",
        "EMR",
        "DynamoDB",
        "connect",
        "Deploying",
        "application",
        "Docker",
        "Container",
        "custom",
        "environment",
        "Elastic",
        "Beanstalk",
        "Developed",
        "features",
        "dashboard",
        "Python",
        "ROBOT",
        "framework",
        "Bootstrap",
        "CSS",
        "JavaScript",
        "data",
        "pipeline",
        "Flume",
        "Spark",
        "Hive",
        "transform",
        "data",
        "Selenium",
        "Python",
        "code",
        "resources",
        "source",
        "control",
        "CVS",
        "SVN",
        "time",
        "improvements",
        "features",
        "Python",
        "Developer",
        "Amazon",
        "September",
        "December",
        "Responsibilities",
        "Python",
        "Django",
        "jQuery",
        "UI",
        "storage",
        "deletion",
        "content",
        "Hive",
        "tables",
        "requirement",
        "partitions",
        "MapReduce",
        "programs",
        "Spark",
        "transformations",
        "Scala",
        "Responsible",
        "data",
        "solutions",
        "Hadoop",
        "Developed",
        "Scala",
        "Spark",
        "applications",
        "data",
        "cleansing",
        "data",
        "aggregation",
        "denormalization",
        "data",
        "preparation",
        "machine",
        "learning",
        "reporting",
        "teams",
        "data",
        "management",
        "system",
        "MySQL",
        "application",
        "logic",
        "Python",
        "Worked",
        "Python",
        "stack",
        "APIs",
        "Python",
        "scripts",
        "content",
        "database",
        "manipulate",
        "files",
        "persistence",
        "layers",
        "data",
        "application",
        "Django",
        "PostgreSQL",
        "spark",
        "application",
        "error",
        "MVC",
        "architecture",
        "Django",
        "Servlet",
        "SOAP",
        "web",
        "service",
        "SOAPUI",
        "web",
        "data",
        "JSON",
        "Scrapy",
        "Pandas",
        "library",
        "web",
        "applications",
        "web",
        "services",
        "APIs",
        "python",
        "Django",
        "Tornado",
        "PHP",
        "JavaScript",
        "frameworks",
        "Jest",
        "Jasmine",
        "Karma",
        "test",
        "framework",
        "Protractor",
        "Developed",
        "Navigation",
        "bar",
        "Manu",
        "bar",
        "list",
        "React",
        "widgets",
        "bootstrap",
        "features",
        "dashboard",
        "Ruby",
        "Rails",
        "RSpec",
        "Bootstrap",
        "JavaScript",
        "Develop",
        "unit",
        "test",
        "cases",
        "JUnit",
        "Mockito",
        "framework",
        "data",
        "Regression",
        "testing",
        "AgileScrum",
        "Kanban",
        "Waterfall",
        "software",
        "development",
        "AWS",
        "Cloud",
        "platform",
        "features",
        "EC2",
        "RDS",
        "DynamoDB",
        "S3",
        "CloudFormation",
        "hip",
        "chat",
        "Jira",
        "UNIX",
        "platform",
        "automation",
        "application",
        "Software",
        "Engineer",
        "Accenture",
        "October",
        "August",
        "Responsibilities",
        "design",
        "development",
        "applications",
        "clients",
        "requirements",
        "Python",
        "programming",
        "C",
        "Pro",
        "C",
        "Oracle",
        "Database",
        "Collaborated",
        "team",
        "instructors",
        "programmers",
        "curriculum",
        "guidelines",
        "workshops",
        "logic",
        "programming",
        "JSON",
        "REST",
        "Web",
        "services",
        "Git",
        "repository",
        "project",
        "GitHub",
        "Performing",
        "Unit",
        "testing",
        "Integration",
        "testing",
        "User",
        "acceptance",
        "testing",
        "testing",
        "issues",
        "applications",
        "tools",
        "Python",
        "Shell",
        "XML",
        "tasks",
        "supervisors",
        "artists",
        "systems",
        "administrators",
        "production",
        "production",
        "deadlines",
        "fixing",
        "performance",
        "issues",
        "bugs",
        "application",
        "Work",
        "team",
        "developers",
        "applications",
        "RISK",
        "management",
        "unit",
        "testregression",
        "test",
        "framework",
        "code",
        "application",
        "work",
        "error",
        "functionality",
        "Created",
        "Use",
        "Case",
        "diagrams",
        "Class",
        "diagrams",
        "lifecycle",
        "projects",
        "Design",
        "Development",
        "Deployment",
        "Testing",
        "Implementation",
        "property",
        "list",
        "application",
        "python",
        "day",
        "day",
        "issues",
        "applications",
        "performance",
        "development",
        "applications",
        "UNIX",
        "environment",
        "commands"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T22:38:38.772482",
    "resume_data": "Python Developer Python span lDeveloperspan Python Developer Citi Group CA Around 5 years of experience as a WebApplication Developer with deep understanding of technology trends with expertise in core of complex technologies Solid experience in Analysis Design and Development Testing Implementation production support and maintenance of various Web Applications using Python Django Skillful involvement in Python by developing softwares utilizing new tools libraries utilized Beautiful Soup NumPy SciPy PySide matplotlib Pickle Pandas data frame urllib2 MySQL DB to improve software development process Support developeroriented services such as Lambda API Gateway Amazon Connect Step Functions Used Django evolution and manual SQL modifications to retain all the data while site is in production Expertise in developing web based open stack applications for large dataset analysis using Python and Django Proficient in building Web User Interface UI using HTML5 DHTML XHTML AngularJS Hibernate CSSCSS3 and JavaScript Nodejs Backbonejs D3 jQuery that follows W3C Web Standards and are browser compatible Experience in working with AWS services like EC2 S3 RDS IAM CloudFormation Amazon Connect Lex chatbot Lambda Transcribe and Comprehend Experience in AWS Elastic Beanstalk for app deployments and worked on AWS lambda with Amazon kinesis Hands on experience in using Hadoop ecosystem components like Hadoop Hive Pig Sqoop HBase Cassandra Spark Spark Streaming Spark SQL Oozie ZooKeeper Kafka Flume MapReduce and Yarn Responsible for creating Hive tables and working on them using Hive QL Experienced in Working on Big Data Integration and Analytics based on Hadoop Spark and NoSQL databases like HBase and MongoDB Good involvement in creating web applications in Object Oriented Programming concepts like MultiThreading Exception Handling and Collections and also executing Model View Control design utilizing Django Framework Experience in developing Web Services SOAP Restful in Python using XML JSON Experience in working with various version control systems like GIT CVS and SVN Proficient in using editors like Eclipse sublime text Net beans PyCharm PyScripter spyder PyStudio and PyDev Used Python Unit test framework for developing and implementing the unit tests using Test driven approach Good Hands on experience in establishing connections for Java and Python by configuring packages like MySQLPython JDBC Successfully migrated the Django database from SQLite to MySQL to PostgreSQL with complete data integrity Hands on experience in monitoring developing and transforming data using SQL Server Integration Service SSIS and SQL Service Analysis Service SSAS Hands on experience with databases using ORMsDOMs for integrating with Oracle MySQL PostgreSQL Good knowledge in working with Webapplication server Apache Tomcat Tornado Cherrypy Chaussette Rocket Experience in infrastructure as service IaaS Platform as service PaaS Software as a service SaaS end user computing Used Pandas API to put the data as time series and tabular form for east timestamp data retrieval and manipulation and for statistical analysis Work Experience Python Developer Citi Group CA February 2018 to Present Responsibilities Involved in developing webbased application using Python Django JavaScript Express ReactJS Node JS Express AJAX CSS3 and HTML5 Currently working on a cloud base application that developed controls centered around the new search tool and Amazon Connect to ensure that calls are available recording consistently are retained properly in a cloud based application On SWNG application initiate TDD Test Driven Development approach to update Rest API from DRF Django Rest Framework to Rest API Developed custom Amazon Connect UI to provide Service Cloud agents with advanced enduser functionality using Lighting Components Worked on AWS services S3 EC2 and deployment services Lambda and RDS DynamoDB NoSQL Beanstalk SQS and Jenkins CICD Assist in server and network administration in corporate datacenter and Amazon cloud Developed Hadoop integrations for data ingestion data mapping and data processing Involved building Hadoop platforms maximizing business value by combining data science with big data Experience in Installing JenkinsPlugins for GIT Repository Setup SCM Polling for Immediate Build with Maven and Maven Repository and Deployment of apps using custom modules through Puppet as a CICD Process Capable of using AWS utilities such as EMR S3 and cloud watch to run and monitor Hadoop and spark jobs on AWS Designed and developed an entire module called CDC change data capture in python and deployed in AWS GLUE using pySpark library and python Loaded and transformed large sets of structured semistructured and unstructured data using HadoopBig Data concepts Wrote Lambda functions in python for AWSs Lambda Kinesis and Elastic Search which invokes python scripts to perform various transformations and analytics on large data sets in AMAZON EMR clusters Integrated AWSRDS Oracle and Aurora DBs to AWSHive EMR using DynamoDB with direct connect Used Python to write data into JSON files for testing Django Websites Created scripts for data modelling and data import and export Understanding of securecloud configuration Cloud Trail cloudsecurity technologies VPC Security Groups etc and cloudpermission systems IAM Developed POC using Scala deployed on Yarn cluster compared the performance of Spark with Hive and SQL Using Chef deployed and configured Elasticsearch Logstash and Kibana ELK for log analytics full text search application monitoring in integration with AWS Lambda and CloudWatch Build custom transformations using AWS Glue Lambda and Kinesis helped reduce costs in ETL tool onpremise infrastructure Documented the requirements including the available code which should be implemented using Spark Hive HDFS HBase and Elasticsearch Designing and creating HIVE external tables using shared metastore instead of the derby with partitioning dynamic partitioning and buckets Supported development of Web portals completed Database Modelling in PostgreSQL front end support in HTMLCSS jQuery Container management using Docker by writing Docker files and set up the automated build on Docker HUB and installed and configured Kubernetes Experienced in developing a portal to manage and entities in a content management system using Python and Django Golang Infrastructure Teams and Engineering Productivity utilizing Kubernetes Docker influx DB Ansible Spinnaker Worked on analyzing Hadoop stack and different big data analytic tools including Pig Hive HBase database and DynamoDB Used Amazon Elastic Beanstalk with Amazon EC2 instance to deploy Django project into AWS Configured continuous integration with Jenkins on Amazon EC2 Developed Serverside automation using Node JS scripting and connecting different types of SQL and NoSQL stores from Node JS Developed Scala R Python for regular expression regex project in the HadoopHive environment with LinuxWindows for big data resources Used Amazon Web Services AWS for improved efficiency of storage and fast access Used Celery with RabbitMQ MySQL Django and Flask to create a distributed worker framework Used automation Jenkins for continuous integration and continuous delivery CICD on Amazon EC2 Executed MYSQL database queries from python using PythonMySQL connector and MySQL dB package to retrieve information Designed and developed the framework to consume the web services hosted in AmazonEC2 Python Developer ASURION San Mateo CA October 2016 to December 2017 Responsibilities Developed the notification service by posting the JSON request in AWS API Gateway Validating the response in Lambda by getting the data from DynamoDB and sending the notification through AWS SNS experienced in querying data using SparkSQL on top of Spark engine for faster data sets processing Using Python included Boto3 to supplement automation provided by Ansible and Terraform for tasks such as encrypting EBS volumes backing AMIs and scheduling Lambda functions for routine AWS tasks Responsible for the global redesign of the Service Console including streamlining the overall support process researching new CTI telephony platforms BCMForce Amazon Connect and Bucher Suter and the introduction of Salesforce Einstein and other AI related technologies Worked extensively with importing metadata into Hive and migrated existing tables and applications to work on Hive and Spark Worked with Hadoop architecture and the daemons of Hadoop including NameNode Data Node Job Tracker Task Tracker and Resource Manager Created an Application was based on serviceoriented architecture and used Python Django JSF Spring Ajax HTML CSS for the frontend Implemented Stable React JS components and Standalone functions to be added to any future pages Launched Kubernetes to provide a platform for automating deployment scaling and operations of application containers across clusters of hosts Worked with Hadoop architecture and the daemons of Hadoop including NameNode Data Node Job Tracker Task Tracker and Resource Manager Built Jenkins jobs to create AWS infrastructure from GitHub repos containing terraform code Wrote with objectoriented Python Flask SQL Beautiful Soup httplib2 Jinja2 HTMLCSS Bootstrap jQuery Linux Sublime Text GIT Worked on integrating Python with Web development tools for developing Web Services in python using XML JSON Worked on migrating MapReduce programs into Spark transformations using Scala Responsible for building scalable distributed data solutions using Hadoop Implemented user interface guidelines and standards throughout the development and maintenance of the website using the HTML CSS JavaScript and JQuery Involved in managing and reviewing Hadoop log files Used React JS in components like JSX creating React components Virtual DOM ReactProps Lifecycle methods working with the React States and Events Analysis the logs data and filter required columns by logstash configuration and send it to elasticsearch Design and developed the test cases for REST API Involved REST API test framework development Worked on serverside applications with Django using Python programming and used python libraries like Beautiful Soup matplotlib SciPy NumPy and Built efficient Nodejs backend for client web application Involved in using Python MongoDB and ReactJS for the design development and deployment of the application Used Elasticsearch Framework for developing web applications using model view control architecture Used Amazon Elastic Beanstalk with Amazon EC2 instance to deploy Django project into AWS Configured continuous integration with Jenkins on Amazon EC2 Automated the existing scripts for performance calculations using NumPy and SQLAlchemy Optimization of heavy load workflows via queues RabbitMQ for enhanced performance and less downtime for stakeholders Involved in working with Webservices backend development using Python CherryPy Django and SQLAlchemy Involved in development of Web Services using and REST for sending and getting data from the external interface in XML and JSON format Integrated AWSRDS Oracle and Aurora DBs to AWSHive EMR using DynamoDB with direct connect Deploying application in Docker Container for custom environment and hosting in Elastic Beanstalk Developed and tested many features for dashboard using Python ROBOT framework Bootstrap CSS and JavaScript Developed data pipeline using Flume Spark and Hive to ingest transform and analyzing data Maintained the Selenium and Python code and resources in source control like CVS SVN over the time for improvements and new features Python Developer Amazon September 2014 to December 2015 Responsibilities Used Python and Django to interface with the jQuery UI and manage the storage and deletion of content Involved in creating Hive tables as per requirement defined with appropriate static and dynamic partitions Worked on migrating MapReduce programs into Spark transformations using Scala Responsible for building scalable distributed data solutions using Hadoop Developed Scala based Spark applications for performing data cleansing data aggregation denormalization and data preparation needed for machine learning and reporting teams to consume Designed and developed data management system using MySQL Built application logic using Python Worked on Python Open stack APIs used Python scripts to update content in the database and manipulate files Designed and developed persistence layers to modify data for application using Django and PostgreSQL Worked on troubleshooting spark application to make them more error tolerant Implemented MVC architecture using Django Servlet and RESTful SOAP web service and SOAPUI Scraped and retrieved web data as JSON using Scrapy presented with Pandas library Developed web applications and RESTful web services and APIs using python Django Tornado and PHP Worked on JavaScript frameworks like Jest Jasmine and Karma and AngularJS test framework Protractor Developed Navigation bar Manu bar drop down list with React widgets and bootstrap Developed and tested many features for dashboard using Ruby on Rails RSpec Bootstrap and JavaScript Develop and executed unit test cases using JUnit and Mockito as mocking framework for mocking data Involved in Regression testing by following AgileScrum Kanban and Waterfall software development Worked in AWS Cloud platform and its features which include EC2 RDS DynamoDB S3 and CloudFormation Worked extensively with hip chat and Jira on UNIX platform for automation of application Software Engineer Accenture October 2013 to August 2014 Responsibilities Responsible for the design and development of different standalone applications based on clients requirements using Python programming C Pro C and Oracle Database Collaborated with a team of instructors and programmers to develop the curriculum and guidelines for workshops to teach the logic of programming Worked with JSON based REST Web services and Created a Git repository and added the project to GitHub Performing Unit testing Integration testing User acceptance testing and Functional testing along with debuggingtroubleshooting issues in complex applications Developed tools using Python Shell scripting XML to automate some of the menial tasks Interfacing with supervisors artists systems administrators and production to ensure production deadlines are met Analyzing and fixing of performance issues critical bugs and application crashes Work with team of developers on python applications for RISK management Creating unit testregression test framework for workingnew code Responsible for debugging and troubleshooting the application Tested all completed work to ensure proper and error free functionality Created Use Case diagrams Class diagrams Involved in entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Generated property list for every application dynamically using python Handling the day to day issues and fine tuning the applications for enhanced performance Worked in development of applications especially in UNIX environment and familiar with all of its commands",
    "unique_id": "f683494b-1d01-49bf-9af8-98a09e0c3e3c"
}