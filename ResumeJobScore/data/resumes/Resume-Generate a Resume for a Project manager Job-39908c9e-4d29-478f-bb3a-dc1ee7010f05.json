{
    "clean_data": "Data Scientist Python Developer Data Scientist span lPythonspan span lDeveloperspan Data Scientist Python Developer Amus Inc New York NY Over 12 years of experience as Data Scientist Python developer and Data Analyst with technical prowess Worked on projects which involved Deep Learning Machine Learning Algorithms Natural Language Processing statistical modeling Data transformation performed sentiment analytics and handled large datasets 4 years experience with performing Data Analysis with compiling analyzing validating modeling data sets and developing Machine Learning models including neural network models for solving the business problems 3 years experience with Hadoop stack HDFS Map Reduce Pig Hive HBase Strom Apache Spark and Scala 3 years experience on Building and maintaining SQL scripts indexes and complex queries for data analysis extraction provided data expertise for adhoc support and attribute verification Worked with varieties of Relational Databases RDBMS like SQLite MySQL PostgreSQL and NoSQL DBs Performed predictive analytics with Python to predict the defaults for US Mortgage loans and Indian Personal loans Utilized machine learning models like KNN Kmeans Decision trees Nave Bayes Regression XGBoost SVM Random Forest for estimation of parameters to predict stock movement and default on loans Experience in Natural Language Processing including web scraping text wrangling parsing and sentiment analysis with application to predicting the price movement of a stock from the real time news data Performed large scale data analysis and developed statistical models for regressions classification clustering and time series and conducted hypothesis testing with tests like ANOVA ttest ftest Hands on working knowledge of Linux operating system Unix Windows OS AWS and Google cloud platform for machine learning applications to create and manage databases on cloud platform and analyze data sets Worked on Python libraries like Numpy sklearn Matplotlib Pandas Beautifulsoup DataReader Statsmodel Utilized TensorFlow and Keras for implementing deep learning models like LSTM RNN to create chat bot systems Involved in various phases of Software Development Life Cycle SDLC such as requirements gathering modeling analysis design and development with experience in Agile methodologies and SCRUM process Involved in the process of creating Usecase diagrams Activity flow diagrams Class diagrams and Object diagrams in the design phase and developed the Coding module Experienced in creating reports presentations documents dashboards and visualizations using Tableau and RShiny and presented it to senior management for review and decision making Solid knowledge of Finance Risk Data and Business analytics and performed as team leader for numerous projects Managed the credit risk for the bank by developing machine learning model to estimate PD and LGD Strong client facing skills able to interact with high net worth clients and deepen relationship with them Highly Motivated to discover and learn new analytical and software tools to improve the quality of work Ability to work in team environment and managed deliverables within the context of a larger projects Authorized to work in the US for any employer Work Experience Data Scientist Python Developer Amus Inc New York NY June 2018 to Present Responsibilities Scraped and cleaned tax FAQs from multiple sources in Python using Beautifulsoup and inserted into a SQL database Implemented Google Analytics created dashboards analyzed the collected data to understand the user engagement Created interactive dashboards using Tableau to visualize the efficiency of the algorithm and quarterly usage of the product Developed an Alexa skill to integrate the chatbot with Alexa and created lamda function using AWS toolkit to process the json data Implemented Deep Learning LSTM using TensorFlow in python to build a chat bot system Generated word2vec word embeddings for tax publications and IRS tax code using TensorFlow and Python Calculated sentence similarity scores using word2vec embeddings and similarity measures from sklearn to handle semantic and syntactic differences Used different NLP similarity score functions including word2vec ngram tfidf topic modelling to match an input question with our target answers Conducted AB testing for the AMUS Inc webpage and delivered simplified reports to senior management weekly Ensured high quality data collection and maintaining the integrity of the data Designed and developed the UI of the website using HTML AJAX CSS and JavaScript Designed and developed the data management system using MySQL Performed troubleshooting fixed and deployed many Python bug fixes of web application that were a main source of information for both customers Actively involved in Agile Methodologies and SCRUM Process and worked closely with different stakeholders to understand their system needs Environment Python Django Linux Alexa Amazon Web Services AWS NLP TensorFlow Tableau SQL HTML AJAX CSS JavaScript MySQL Data Scientist Machine Learning Python Developer Amethyst Technologies LLC Baltimore MD March 2016 to June 2018 Responsibilities Performed data migration and developed Python Django based web application Postgre SQLDB and integrations with 3rd party email messaging storage services Python Object Oriented Design code for manufacturing quality monitoring logging and debugging code optimization Validated huge data and worked on python backend scripting Automated the developed web applicationportal and developed Python Automation Scripts using Selenium IDE Quantitative analysis and software development using data sets forecasting Economic Capital models and Regulatory Capital models for managing riskbased capital for the bank Analyzed and worked with all aspects of regression models OLS etc and time series analysis Worked with creditrisk models PD LGD EAD in use for retailwholesale credit risk Redesigned market risk model originally implemented in R to use map reduce in Clouderas Hadoop cluster using unsupervised learning principal components analysis Used PROCSQL to fetch tables from Teradata warehouse Merged tables by using PROC SORT Random sampling using PROC SURVEYSELECT Performed logistic regression on each variable and then delete the redundant ones Used APPEND to generate the outcome variable table Checked outliers and missing values using PROC UNIVARIATE and PROC FREQ Macros were employed for data transformation and filling up missing values PROC VARCLUS was used to check the collinearity among explanatory variables Performed logistic regression on newly selected variables Created LIFT probability table and GAIN chart Create shared Object repository Selenium Library Function saved all components functions in Library Functions in Selenium library Developed entire frontend and backend modules using Python on Django Web Framework Used AWS for application deployment and configuration Designed and developed the UI of the website using HTML AJAX CSS and JavaScript Performed debugging and troubleshooting the web applications using Subversion version control tool to coordinate teamdevelopment Created Python scripts to validate based on the keyworddriven testing test cases Developed for fully automated continuous integration system using Python and Bash scripting Environment Python 27 SAS Django 17 CSS HTML JQuery Pandas PostgreSQL GIT AWS AJAX CSS JavaScript Hadoop Python Developer Data Analyst HDFC Bank Hyderabad Telangana December 2013 to March 2016 Responsibilities Performed customer due diligence and determined the credit worthiness of the clients approved accounts and dispensed limits up to 20K in authority and recommended higher limits to Clevel management for approval Gathered loan data designed new credit evaluation policies created statistical data models using Python Excel and SQL which lowered bad debts by 5 for the personal loan segment Collaborated with crossfunctional stakeholders and senior management to design credit check procedures that eliminated 15 of monthly customers at source who did not meet full criteria prior to loan underwriting process Communicated and presented default customers profiles along with reports using Python and Tableau analytical results and strategic implications to senior management for strategic decision making Developed scripts in Python to automate the customer query addressable system using python which decreased the time for solving the query of the customer by 45 Collaborated with other functional teams across the Risk and NonRisk groups to use standard methodologies and ensure a positive customer experience throughout the customer journey Monitored and resolved customer issues via phone email web or chat and managed customer issues from initiation till disbursement of loans which increased customer satisfaction by 15 Provided technical or analytical guidance as needed for issue management project assessments and reporting Environment Python SciPy NumPy Pandas StatsModel Plotly R Tableau MySQL Excel Google Cloud Platform Python Developer Data Analyst ICICI Securities Hyderabad Telangana September 2011 to December 2013 Responsibilities Managed and supervised client portfolio by trading on equity options and futures Developed a web scraper to collect historical financial data of technology giants from Yahoo Finance using DataReader in Python Visualized the moving averages of the stock over the years to obtain the trends and estimate the growth of the companies using Seaborn in Python Performed preliminary risk analysis and implemented methods like Monte Carlo and Bootstrap to estimate the Value of Risk for an asset Analyzed Trade racer website and customer data to identify market product trends and profitable revenue growth opportunities using Python Worked with managers and directors to design solutions and strategies enhancing trade racer platform Facilitated effective communications with equity researchers and senior management and generated trade ideas by devising derivatives strategies which boosted the Customer Satisfaction Index by 24 Leverage information design concepts and principles to create compelling and effective charts tables presentations and other visuals using Python and Excel that convey analytical results clearly and effectively Surpassed 120 of target revenue for 3 consecutive quarters and ranked among the top 10 advisors in the Western Zone in terms of reactivating stopped customers Coached and mentored new trainees and consulted struggling advisors to help them meet monthly target goals Environment Python DataReader Pandas Seaborn Plotly Quandl R Tableau MySQL Excel Yahoo Finance Trade Racer Business Data Analyst Bank of Baroda Mumbai Maharashtra June 2009 to September 2011 Responsibilities Conducted detailed industry analysis research drafted reports and developed analytics insights on SME industry Served as a key strategic partner to uncover underlying business sector needs and information gaps Coordinated with internal and external stakeholders to gather key compounding industry insights and proactively communicated industry news Implemented approaches like Process Capability Analysis and Root Cause Analysis to determine the reasons for problems in food and logistics mining and textiles Maintained traceability among business requirements technical requirements design and testing Assisted to build analytic tools to manage data and streamline data analyses using R and SQL Server Created reporting documentation that identified metrics and data required for display as well as identification of filtering criteria and input Environment Python DataReader Numpy Seaborn Plotly Pandas R Tableau SQL Server Excel Python Developer Riconz Technologies Hyderabad Telangana March 2007 to June 2009 Responsibilities Gathered and analyzed the requirements and converted them into User Requirement Specifications and Functional Requirement Specifications for the designers and developers to understand them as per their perspective Worked on objectoriented programming OOP concepts using Python Django and Linux Developed webbased applications using Python Django XML CSS HTML JavaScript Angular JS and JQuery Experience with JSON based REST Web services and Amazon Web Services AWS Worked on Amazon services like Amazon Cloud EC2 Added support for Amazon AWS and RDS to host staticmedia files and the database into Amazon Cloud Experience in writing Sub Queries Stored Procedures Triggers Cursors and Functions on MySQL and PostgreSQL database Worked in agile and waterfall methodologies with high quality deliverables delivered ontime Experience with continuous integration and automation using Jenkins Experience with Unit testing Test driven Development TDD Load Testing Developed the required XML Schema documents and implemented the framework for parsing XML documents Involved in Unit testing and Integration testing Worked on AJAX framework to transform Datasets and Data tables into HTTPserializable JSON strings Designed Interface using Bootstrap framework Experience with working on multiple environments like development testing production Excellent analytical and problemsolving skills and ability to work on own besides being valuable and contributing team player Environment Python Django REST Web services XML CSS HTTP AJAX AngularJS Bootstrap JSON HTML CSS JavaScript jQuery AWS EC2 Triggers Cursors MySQL and PostgreSQL database Amazon Cloud EC2 Amazon Web Services AWS Education Bachelors Skills Cc C Hadoop Ms project Python Vba Visio Database Database systems Ms access Mysql Postgresql Tableau Data science Hadoop Machine learning Nlp Deep learning Neural networks Linux",
    "entities": [
        "Analyzed Trade",
        "Data Scientist Python",
        "AJAX",
        "Regulatory Capital",
        "HTML AJAX CSS",
        "Building",
        "Python Excel",
        "Keras",
        "TensorFlow",
        "Google",
        "RNN",
        "Hadoop",
        "XML",
        "HDFC Bank Hyderabad",
        "Nlp Deep",
        "Clevel",
        "Maintained",
        "Coached",
        "the Value of Risk",
        "Automated",
        "Baltimore",
        "Amazon",
        "Python",
        "Assisted",
        "Developed",
        "SME",
        "LGD Strong",
        "Neural",
        "Created Python",
        "Utilized",
        "Alexa",
        "Monitored",
        "Present Responsibilities Scraped",
        "Communicated",
        "Linux",
        "Amazon Cloud",
        "Collaborated",
        "Deep Learning Machine Learning Algorithms Natural Language Processing",
        "APPEND",
        "Agile Methodologies",
        "RDS",
        "RShiny",
        "NonRisk",
        "Interface",
        "Data Scientist Python Developer Data Scientist",
        "Process Capability Analysis and Root Cause Analysis",
        "US",
        "Amazon Web Services AWS NLP",
        "IRS",
        "KNN",
        "AWS",
        "Create shared Object repository Selenium Library Function",
        "Coordinated",
        "Coding",
        "Sub Queries Stored Procedures Triggers Cursors and Functions",
        "Python Object Oriented Design",
        "AMUS Inc",
        "Work Experience Data Scientist Python Developer Amus Inc New York",
        "Conducted AB",
        "SQL",
        "Facilitated",
        "Mysql Postgresql Tableau Data",
        "Bootstrap",
        "User Requirement Specifications and Functional Requirement Specifications",
        "NLP",
        "lPythonspan",
        "Data Analysis",
        "Python Django",
        "Economic Capital",
        "Amazon AWS",
        "Seaborn in Python Performed",
        "DataReader",
        "Performed",
        "Selenium",
        "Google Analytics",
        "Amazon Web Services AWS Worked",
        "Data Analyst",
        "SQL Server Created",
        "Clouderas Hadoop",
        "Data",
        "REST",
        "Yahoo Finance",
        "NoSQL",
        "US Mortgage",
        "Tableau",
        "Machine Learning",
        "Software Development Life Cycle",
        "GAIN",
        "Integration",
        "lDeveloperspan Data Scientist Python Developer Amus Inc New York",
        "Amazon Web Services AWS Education",
        "Indian Personal"
    ],
    "experience": "Experience in Natural Language Processing including web scraping text wrangling parsing and sentiment analysis with application to predicting the price movement of a stock from the real time news data Performed large scale data analysis and developed statistical models for regressions classification clustering and time series and conducted hypothesis testing with tests like ANOVA ttest ftest Hands on working knowledge of Linux operating system Unix Windows OS AWS and Google cloud platform for machine learning applications to create and manage databases on cloud platform and analyze data sets Worked on Python libraries like Numpy sklearn Matplotlib Pandas Beautifulsoup DataReader Statsmodel Utilized TensorFlow and Keras for implementing deep learning models like LSTM RNN to create chat bot systems Involved in various phases of Software Development Life Cycle SDLC such as requirements gathering modeling analysis design and development with experience in Agile methodologies and SCRUM process Involved in the process of creating Usecase diagrams Activity flow diagrams Class diagrams and Object diagrams in the design phase and developed the Coding module Experienced in creating reports presentations documents dashboards and visualizations using Tableau and RShiny and presented it to senior management for review and decision making Solid knowledge of Finance Risk Data and Business analytics and performed as team leader for numerous projects Managed the credit risk for the bank by developing machine learning model to estimate PD and LGD Strong client facing skills able to interact with high net worth clients and deepen relationship with them Highly Motivated to discover and learn new analytical and software tools to improve the quality of work Ability to work in team environment and managed deliverables within the context of a larger projects Authorized to work in the US for any employer Work Experience Data Scientist Python Developer Amus Inc New York NY June 2018 to Present Responsibilities Scraped and cleaned tax FAQs from multiple sources in Python using Beautifulsoup and inserted into a SQL database Implemented Google Analytics created dashboards analyzed the collected data to understand the user engagement Created interactive dashboards using Tableau to visualize the efficiency of the algorithm and quarterly usage of the product Developed an Alexa skill to integrate the chatbot with Alexa and created lamda function using AWS toolkit to process the json data Implemented Deep Learning LSTM using TensorFlow in python to build a chat bot system Generated word2vec word embeddings for tax publications and IRS tax code using TensorFlow and Python Calculated sentence similarity scores using word2vec embeddings and similarity measures from sklearn to handle semantic and syntactic differences Used different NLP similarity score functions including word2vec ngram tfidf topic modelling to match an input question with our target answers Conducted AB testing for the AMUS Inc webpage and delivered simplified reports to senior management weekly Ensured high quality data collection and maintaining the integrity of the data Designed and developed the UI of the website using HTML AJAX CSS and JavaScript Designed and developed the data management system using MySQL Performed troubleshooting fixed and deployed many Python bug fixes of web application that were a main source of information for both customers Actively involved in Agile Methodologies and SCRUM Process and worked closely with different stakeholders to understand their system needs Environment Python Django Linux Alexa Amazon Web Services AWS NLP TensorFlow Tableau SQL HTML AJAX CSS JavaScript MySQL Data Scientist Machine Learning Python Developer Amethyst Technologies LLC Baltimore MD March 2016 to June 2018 Responsibilities Performed data migration and developed Python Django based web application Postgre SQLDB and integrations with 3rd party email messaging storage services Python Object Oriented Design code for manufacturing quality monitoring logging and debugging code optimization Validated huge data and worked on python backend scripting Automated the developed web applicationportal and developed Python Automation Scripts using Selenium IDE Quantitative analysis and software development using data sets forecasting Economic Capital models and Regulatory Capital models for managing riskbased capital for the bank Analyzed and worked with all aspects of regression models OLS etc and time series analysis Worked with creditrisk models PD LGD EAD in use for retailwholesale credit risk Redesigned market risk model originally implemented in R to use map reduce in Clouderas Hadoop cluster using unsupervised learning principal components analysis Used PROCSQL to fetch tables from Teradata warehouse Merged tables by using PROC SORT Random sampling using PROC SURVEYSELECT Performed logistic regression on each variable and then delete the redundant ones Used APPEND to generate the outcome variable table Checked outliers and missing values using PROC UNIVARIATE and PROC FREQ Macros were employed for data transformation and filling up missing values PROC VARCLUS was used to check the collinearity among explanatory variables Performed logistic regression on newly selected variables Created LIFT probability table and GAIN chart Create shared Object repository Selenium Library Function saved all components functions in Library Functions in Selenium library Developed entire frontend and backend modules using Python on Django Web Framework Used AWS for application deployment and configuration Designed and developed the UI of the website using HTML AJAX CSS and JavaScript Performed debugging and troubleshooting the web applications using Subversion version control tool to coordinate teamdevelopment Created Python scripts to validate based on the keyworddriven testing test cases Developed for fully automated continuous integration system using Python and Bash scripting Environment Python 27 SAS Django 17 CSS HTML JQuery Pandas PostgreSQL GIT AWS AJAX CSS JavaScript Hadoop Python Developer Data Analyst HDFC Bank Hyderabad Telangana December 2013 to March 2016 Responsibilities Performed customer due diligence and determined the credit worthiness of the clients approved accounts and dispensed limits up to 20 K in authority and recommended higher limits to Clevel management for approval Gathered loan data designed new credit evaluation policies created statistical data models using Python Excel and SQL which lowered bad debts by 5 for the personal loan segment Collaborated with crossfunctional stakeholders and senior management to design credit check procedures that eliminated 15 of monthly customers at source who did not meet full criteria prior to loan underwriting process Communicated and presented default customers profiles along with reports using Python and Tableau analytical results and strategic implications to senior management for strategic decision making Developed scripts in Python to automate the customer query addressable system using python which decreased the time for solving the query of the customer by 45 Collaborated with other functional teams across the Risk and NonRisk groups to use standard methodologies and ensure a positive customer experience throughout the customer journey Monitored and resolved customer issues via phone email web or chat and managed customer issues from initiation till disbursement of loans which increased customer satisfaction by 15 Provided technical or analytical guidance as needed for issue management project assessments and reporting Environment Python SciPy NumPy Pandas StatsModel Plotly R Tableau MySQL Excel Google Cloud Platform Python Developer Data Analyst ICICI Securities Hyderabad Telangana September 2011 to December 2013 Responsibilities Managed and supervised client portfolio by trading on equity options and futures Developed a web scraper to collect historical financial data of technology giants from Yahoo Finance using DataReader in Python Visualized the moving averages of the stock over the years to obtain the trends and estimate the growth of the companies using Seaborn in Python Performed preliminary risk analysis and implemented methods like Monte Carlo and Bootstrap to estimate the Value of Risk for an asset Analyzed Trade racer website and customer data to identify market product trends and profitable revenue growth opportunities using Python Worked with managers and directors to design solutions and strategies enhancing trade racer platform Facilitated effective communications with equity researchers and senior management and generated trade ideas by devising derivatives strategies which boosted the Customer Satisfaction Index by 24 Leverage information design concepts and principles to create compelling and effective charts tables presentations and other visuals using Python and Excel that convey analytical results clearly and effectively Surpassed 120 of target revenue for 3 consecutive quarters and ranked among the top 10 advisors in the Western Zone in terms of reactivating stopped customers Coached and mentored new trainees and consulted struggling advisors to help them meet monthly target goals Environment Python DataReader Pandas Seaborn Plotly Quandl R Tableau MySQL Excel Yahoo Finance Trade Racer Business Data Analyst Bank of Baroda Mumbai Maharashtra June 2009 to September 2011 Responsibilities Conducted detailed industry analysis research drafted reports and developed analytics insights on SME industry Served as a key strategic partner to uncover underlying business sector needs and information gaps Coordinated with internal and external stakeholders to gather key compounding industry insights and proactively communicated industry news Implemented approaches like Process Capability Analysis and Root Cause Analysis to determine the reasons for problems in food and logistics mining and textiles Maintained traceability among business requirements technical requirements design and testing Assisted to build analytic tools to manage data and streamline data analyses using R and SQL Server Created reporting documentation that identified metrics and data required for display as well as identification of filtering criteria and input Environment Python DataReader Numpy Seaborn Plotly Pandas R Tableau SQL Server Excel Python Developer Riconz Technologies Hyderabad Telangana March 2007 to June 2009 Responsibilities Gathered and analyzed the requirements and converted them into User Requirement Specifications and Functional Requirement Specifications for the designers and developers to understand them as per their perspective Worked on objectoriented programming OOP concepts using Python Django and Linux Developed webbased applications using Python Django XML CSS HTML JavaScript Angular JS and JQuery Experience with JSON based REST Web services and Amazon Web Services AWS Worked on Amazon services like Amazon Cloud EC2 Added support for Amazon AWS and RDS to host staticmedia files and the database into Amazon Cloud Experience in writing Sub Queries Stored Procedures Triggers Cursors and Functions on MySQL and PostgreSQL database Worked in agile and waterfall methodologies with high quality deliverables delivered ontime Experience with continuous integration and automation using Jenkins Experience with Unit testing Test driven Development TDD Load Testing Developed the required XML Schema documents and implemented the framework for parsing XML documents Involved in Unit testing and Integration testing Worked on AJAX framework to transform Datasets and Data tables into HTTPserializable JSON strings Designed Interface using Bootstrap framework Experience with working on multiple environments like development testing production Excellent analytical and problemsolving skills and ability to work on own besides being valuable and contributing team player Environment Python Django REST Web services XML CSS HTTP AJAX AngularJS Bootstrap JSON HTML CSS JavaScript jQuery AWS EC2 Triggers Cursors MySQL and PostgreSQL database Amazon Cloud EC2 Amazon Web Services AWS Education Bachelors Skills Cc C Hadoop Ms project Python Vba Visio Database Database systems Ms access Mysql Postgresql Tableau Data science Hadoop Machine learning Nlp Deep learning Neural networks Linux",
    "extracted_keywords": [
        "Data",
        "Scientist",
        "Python",
        "Developer",
        "Data",
        "Scientist",
        "span",
        "lPythonspan",
        "span",
        "lDeveloperspan",
        "Data",
        "Scientist",
        "Python",
        "Developer",
        "Amus",
        "Inc",
        "New",
        "York",
        "NY",
        "years",
        "experience",
        "Data",
        "Scientist",
        "Python",
        "developer",
        "Data",
        "Analyst",
        "prowess",
        "projects",
        "Deep",
        "Learning",
        "Machine",
        "Learning",
        "Algorithms",
        "Natural",
        "Language",
        "Processing",
        "modeling",
        "Data",
        "transformation",
        "sentiment",
        "analytics",
        "datasets",
        "years",
        "experience",
        "Data",
        "Analysis",
        "modeling",
        "data",
        "sets",
        "Machine",
        "Learning",
        "models",
        "network",
        "models",
        "business",
        "problems",
        "years",
        "experience",
        "Hadoop",
        "stack",
        "HDFS",
        "Map",
        "Reduce",
        "Pig",
        "Hive",
        "HBase",
        "Strom",
        "Apache",
        "Spark",
        "Scala",
        "years",
        "experience",
        "Building",
        "SQL",
        "scripts",
        "indexes",
        "queries",
        "data",
        "analysis",
        "extraction",
        "data",
        "expertise",
        "support",
        "verification",
        "varieties",
        "Relational",
        "Databases",
        "RDBMS",
        "MySQL",
        "PostgreSQL",
        "NoSQL",
        "DBs",
        "analytics",
        "Python",
        "defaults",
        "US",
        "Mortgage",
        "loans",
        "loans",
        "machine",
        "learning",
        "models",
        "KNN",
        "Kmeans",
        "Decision",
        "trees",
        "Nave",
        "Bayes",
        "Regression",
        "XGBoost",
        "SVM",
        "Random",
        "Forest",
        "estimation",
        "parameters",
        "stock",
        "movement",
        "default",
        "loans",
        "Experience",
        "Natural",
        "Language",
        "Processing",
        "web",
        "text",
        "parsing",
        "analysis",
        "application",
        "price",
        "movement",
        "stock",
        "time",
        "news",
        "data",
        "scale",
        "data",
        "analysis",
        "models",
        "regressions",
        "classification",
        "clustering",
        "time",
        "series",
        "hypothesis",
        "testing",
        "tests",
        "ANOVA",
        "Hands",
        "knowledge",
        "Linux",
        "operating",
        "system",
        "Unix",
        "Windows",
        "OS",
        "AWS",
        "Google",
        "cloud",
        "platform",
        "machine",
        "learning",
        "applications",
        "databases",
        "cloud",
        "platform",
        "data",
        "sets",
        "Python",
        "libraries",
        "Numpy",
        "Matplotlib",
        "Pandas",
        "Beautifulsoup",
        "DataReader",
        "Statsmodel",
        "Utilized",
        "TensorFlow",
        "Keras",
        "learning",
        "models",
        "LSTM",
        "RNN",
        "chat",
        "bot",
        "systems",
        "phases",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "SDLC",
        "requirements",
        "analysis",
        "design",
        "development",
        "experience",
        "methodologies",
        "SCRUM",
        "process",
        "process",
        "Usecase",
        "diagrams",
        "Activity",
        "flow",
        "diagrams",
        "Class",
        "diagrams",
        "Object",
        "diagrams",
        "design",
        "phase",
        "module",
        "reports",
        "presentations",
        "documents",
        "dashboards",
        "visualizations",
        "Tableau",
        "RShiny",
        "management",
        "review",
        "decision",
        "knowledge",
        "Finance",
        "Risk",
        "Data",
        "Business",
        "analytics",
        "team",
        "leader",
        "projects",
        "credit",
        "risk",
        "bank",
        "machine",
        "model",
        "PD",
        "LGD",
        "Strong",
        "client",
        "facing",
        "skills",
        "clients",
        "relationship",
        "software",
        "tools",
        "quality",
        "work",
        "Ability",
        "team",
        "environment",
        "deliverables",
        "context",
        "projects",
        "US",
        "employer",
        "Work",
        "Experience",
        "Data",
        "Scientist",
        "Python",
        "Developer",
        "Amus",
        "Inc",
        "New",
        "York",
        "NY",
        "June",
        "Present",
        "Responsibilities",
        "tax",
        "FAQs",
        "sources",
        "Python",
        "Beautifulsoup",
        "SQL",
        "database",
        "Google",
        "Analytics",
        "dashboards",
        "data",
        "user",
        "engagement",
        "dashboards",
        "Tableau",
        "efficiency",
        "algorithm",
        "usage",
        "product",
        "Alexa",
        "skill",
        "chatbot",
        "Alexa",
        "function",
        "AWS",
        "toolkit",
        "json",
        "data",
        "Deep",
        "Learning",
        "LSTM",
        "TensorFlow",
        "python",
        "chat",
        "bot",
        "system",
        "word",
        "embeddings",
        "tax",
        "publications",
        "IRS",
        "tax",
        "code",
        "TensorFlow",
        "Python",
        "sentence",
        "similarity",
        "scores",
        "embeddings",
        "similarity",
        "measures",
        "sklearn",
        "differences",
        "NLP",
        "similarity",
        "score",
        "functions",
        "ngram",
        "tfidf",
        "topic",
        "input",
        "question",
        "target",
        "AB",
        "testing",
        "AMUS",
        "Inc",
        "webpage",
        "reports",
        "management",
        "weekly",
        "quality",
        "data",
        "collection",
        "integrity",
        "data",
        "UI",
        "website",
        "HTML",
        "AJAX",
        "CSS",
        "JavaScript",
        "data",
        "management",
        "system",
        "MySQL",
        "Performed",
        "troubleshooting",
        "Python",
        "bug",
        "fixes",
        "web",
        "application",
        "source",
        "information",
        "customers",
        "Agile",
        "Methodologies",
        "SCRUM",
        "Process",
        "stakeholders",
        "system",
        "Environment",
        "Python",
        "Django",
        "Linux",
        "Alexa",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "NLP",
        "TensorFlow",
        "Tableau",
        "SQL",
        "HTML",
        "AJAX",
        "CSS",
        "JavaScript",
        "MySQL",
        "Data",
        "Scientist",
        "Machine",
        "Learning",
        "Python",
        "Developer",
        "Amethyst",
        "Technologies",
        "LLC",
        "Baltimore",
        "MD",
        "March",
        "June",
        "Responsibilities",
        "data",
        "migration",
        "Python",
        "Django",
        "web",
        "application",
        "Postgre",
        "SQLDB",
        "integrations",
        "party",
        "email",
        "storage",
        "services",
        "Python",
        "Object",
        "Oriented",
        "Design",
        "code",
        "quality",
        "monitoring",
        "code",
        "optimization",
        "data",
        "python",
        "scripting",
        "Automated",
        "web",
        "applicationportal",
        "Python",
        "Automation",
        "Scripts",
        "Selenium",
        "IDE",
        "Quantitative",
        "analysis",
        "software",
        "development",
        "data",
        "sets",
        "Economic",
        "Capital",
        "models",
        "Regulatory",
        "Capital",
        "models",
        "capital",
        "bank",
        "aspects",
        "regression",
        "models",
        "OLS",
        "etc",
        "time",
        "series",
        "analysis",
        "creditrisk",
        "models",
        "LGD",
        "EAD",
        "use",
        "retailwholesale",
        "credit",
        "risk",
        "market",
        "risk",
        "model",
        "R",
        "map",
        "reduce",
        "Clouderas",
        "Hadoop",
        "cluster",
        "components",
        "analysis",
        "PROCSQL",
        "tables",
        "Teradata",
        "warehouse",
        "tables",
        "PROC",
        "SORT",
        "Random",
        "sampling",
        "PROC",
        "SURVEYSELECT",
        "regression",
        "variable",
        "ones",
        "APPEND",
        "outcome",
        "variable",
        "table",
        "outliers",
        "values",
        "PROC",
        "UNIVARIATE",
        "PROC",
        "FREQ",
        "Macros",
        "data",
        "transformation",
        "values",
        "PROC",
        "VARCLUS",
        "collinearity",
        "variables",
        "regression",
        "variables",
        "Created",
        "LIFT",
        "probability",
        "table",
        "GAIN",
        "chart",
        "Object",
        "repository",
        "Selenium",
        "Library",
        "Function",
        "components",
        "functions",
        "Library",
        "Functions",
        "Selenium",
        "library",
        "frontend",
        "modules",
        "Python",
        "Django",
        "Web",
        "Framework",
        "AWS",
        "application",
        "deployment",
        "configuration",
        "UI",
        "website",
        "HTML",
        "AJAX",
        "CSS",
        "JavaScript",
        "debugging",
        "web",
        "applications",
        "Subversion",
        "version",
        "control",
        "tool",
        "teamdevelopment",
        "Created",
        "Python",
        "scripts",
        "keyworddriven",
        "testing",
        "test",
        "cases",
        "integration",
        "system",
        "Python",
        "Bash",
        "Environment",
        "Python",
        "SAS",
        "Django",
        "CSS",
        "HTML",
        "JQuery",
        "Pandas",
        "PostgreSQL",
        "GIT",
        "AWS",
        "CSS",
        "JavaScript",
        "Hadoop",
        "Python",
        "Developer",
        "Data",
        "Analyst",
        "HDFC",
        "Bank",
        "Hyderabad",
        "Telangana",
        "December",
        "March",
        "Responsibilities",
        "customer",
        "diligence",
        "credit",
        "worthiness",
        "clients",
        "accounts",
        "limits",
        "K",
        "authority",
        "limits",
        "Clevel",
        "management",
        "approval",
        "Gathered",
        "loan",
        "data",
        "credit",
        "evaluation",
        "policies",
        "data",
        "models",
        "Python",
        "Excel",
        "SQL",
        "debts",
        "loan",
        "segment",
        "stakeholders",
        "management",
        "credit",
        "check",
        "procedures",
        "customers",
        "source",
        "criteria",
        "loan",
        "underwriting",
        "process",
        "Communicated",
        "default",
        "customers",
        "profiles",
        "reports",
        "Python",
        "Tableau",
        "results",
        "implications",
        "management",
        "decision",
        "scripts",
        "Python",
        "customer",
        "query",
        "system",
        "python",
        "time",
        "query",
        "customer",
        "Collaborated",
        "teams",
        "Risk",
        "NonRisk",
        "groups",
        "methodologies",
        "customer",
        "experience",
        "customer",
        "journey",
        "customer",
        "issues",
        "phone",
        "email",
        "web",
        "customer",
        "issues",
        "initiation",
        "disbursement",
        "loans",
        "customer",
        "satisfaction",
        "guidance",
        "issue",
        "management",
        "project",
        "assessments",
        "Environment",
        "Python",
        "SciPy",
        "NumPy",
        "Pandas",
        "StatsModel",
        "Plotly",
        "R",
        "Tableau",
        "MySQL",
        "Excel",
        "Google",
        "Cloud",
        "Platform",
        "Python",
        "Developer",
        "Data",
        "Analyst",
        "ICICI",
        "Securities",
        "Hyderabad",
        "Telangana",
        "September",
        "December",
        "Responsibilities",
        "client",
        "portfolio",
        "equity",
        "options",
        "futures",
        "web",
        "scraper",
        "data",
        "technology",
        "giants",
        "Yahoo",
        "Finance",
        "DataReader",
        "Python",
        "averages",
        "stock",
        "years",
        "trends",
        "growth",
        "companies",
        "Seaborn",
        "Python",
        "Performed",
        "risk",
        "analysis",
        "methods",
        "Monte",
        "Carlo",
        "Bootstrap",
        "Value",
        "Risk",
        "asset",
        "Trade",
        "racer",
        "website",
        "customer",
        "data",
        "market",
        "product",
        "trends",
        "revenue",
        "growth",
        "opportunities",
        "Python",
        "Worked",
        "managers",
        "directors",
        "solutions",
        "strategies",
        "trade",
        "racer",
        "platform",
        "communications",
        "equity",
        "researchers",
        "management",
        "trade",
        "ideas",
        "derivatives",
        "strategies",
        "Customer",
        "Satisfaction",
        "Index",
        "Leverage",
        "information",
        "design",
        "concepts",
        "principles",
        "charts",
        "tables",
        "presentations",
        "visuals",
        "Python",
        "Excel",
        "results",
        "target",
        "revenue",
        "quarters",
        "advisors",
        "Western",
        "Zone",
        "terms",
        "customers",
        "trainees",
        "advisors",
        "target",
        "goals",
        "Environment",
        "Python",
        "DataReader",
        "Pandas",
        "Seaborn",
        "Quandl",
        "R",
        "Tableau",
        "MySQL",
        "Excel",
        "Yahoo",
        "Finance",
        "Trade",
        "Racer",
        "Business",
        "Data",
        "Analyst",
        "Bank",
        "Baroda",
        "Mumbai",
        "Maharashtra",
        "June",
        "September",
        "Responsibilities",
        "industry",
        "analysis",
        "research",
        "reports",
        "analytics",
        "insights",
        "SME",
        "industry",
        "partner",
        "business",
        "sector",
        "needs",
        "information",
        "gaps",
        "stakeholders",
        "compounding",
        "industry",
        "insights",
        "industry",
        "news",
        "approaches",
        "Process",
        "Capability",
        "Analysis",
        "Root",
        "Cause",
        "Analysis",
        "reasons",
        "problems",
        "food",
        "logistics",
        "mining",
        "textiles",
        "traceability",
        "business",
        "requirements",
        "requirements",
        "testing",
        "Assisted",
        "tools",
        "data",
        "data",
        "analyses",
        "R",
        "SQL",
        "Server",
        "Created",
        "reporting",
        "documentation",
        "metrics",
        "data",
        "display",
        "identification",
        "filtering",
        "criteria",
        "input",
        "Environment",
        "Python",
        "DataReader",
        "Numpy",
        "Seaborn",
        "Pandas",
        "R",
        "Tableau",
        "SQL",
        "Server",
        "Excel",
        "Python",
        "Developer",
        "Riconz",
        "Technologies",
        "Hyderabad",
        "Telangana",
        "March",
        "June",
        "Responsibilities",
        "requirements",
        "User",
        "Requirement",
        "Specifications",
        "Functional",
        "Requirement",
        "Specifications",
        "designers",
        "developers",
        "perspective",
        "programming",
        "OOP",
        "concepts",
        "Python",
        "Django",
        "Linux",
        "Developed",
        "applications",
        "Python",
        "Django",
        "XML",
        "CSS",
        "HTML",
        "JavaScript",
        "Angular",
        "JS",
        "JQuery",
        "Experience",
        "JSON",
        "REST",
        "Web",
        "services",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "Amazon",
        "services",
        "Amazon",
        "Cloud",
        "EC2",
        "support",
        "Amazon",
        "AWS",
        "RDS",
        "files",
        "database",
        "Amazon",
        "Cloud",
        "Experience",
        "Sub",
        "Queries",
        "Stored",
        "Procedures",
        "Triggers",
        "Cursors",
        "Functions",
        "MySQL",
        "PostgreSQL",
        "database",
        "methodologies",
        "quality",
        "deliverables",
        "ontime",
        "Experience",
        "integration",
        "automation",
        "Jenkins",
        "Experience",
        "Unit",
        "testing",
        "Test",
        "Development",
        "TDD",
        "Load",
        "Testing",
        "XML",
        "Schema",
        "documents",
        "framework",
        "XML",
        "documents",
        "Unit",
        "testing",
        "Integration",
        "testing",
        "AJAX",
        "framework",
        "Datasets",
        "Data",
        "tables",
        "JSON",
        "strings",
        "Interface",
        "Bootstrap",
        "framework",
        "Experience",
        "environments",
        "development",
        "testing",
        "production",
        "Excellent",
        "skills",
        "ability",
        "team",
        "player",
        "Environment",
        "Python",
        "Django",
        "REST",
        "Web",
        "services",
        "XML",
        "CSS",
        "HTTP",
        "AJAX",
        "Bootstrap",
        "JSON",
        "HTML",
        "CSS",
        "JavaScript",
        "jQuery",
        "AWS",
        "EC2",
        "Triggers",
        "Cursors",
        "MySQL",
        "PostgreSQL",
        "database",
        "Amazon",
        "Cloud",
        "EC2",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "Education",
        "Bachelors",
        "Skills",
        "Cc",
        "C",
        "Hadoop",
        "Ms",
        "project",
        "Python",
        "Vba",
        "Visio",
        "Database",
        "Database",
        "systems",
        "Ms",
        "access",
        "Mysql",
        "Postgresql",
        "Tableau",
        "Data",
        "science",
        "Hadoop",
        "Machine",
        "Nlp",
        "Deep",
        "Neural",
        "networks",
        "Linux"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:45:24.430677",
    "resume_data": "Data Scientist Python Developer Data Scientist span lPythonspan span lDeveloperspan Data Scientist Python Developer Amus Inc New York NY Over 12 years of experience as Data Scientist Python developer and Data Analyst with technical prowess Worked on projects which involved Deep Learning Machine Learning Algorithms Natural Language Processing statistical modeling Data transformation performed sentiment analytics and handled large datasets 4 years experience with performing Data Analysis with compiling analyzing validating modeling data sets and developing Machine Learning models including neural network models for solving the business problems 3 years experience with Hadoop stack HDFS Map Reduce Pig Hive HBase Strom Apache Spark and Scala 3 years experience on Building and maintaining SQL scripts indexes and complex queries for data analysis extraction provided data expertise for adhoc support and attribute verification Worked with varieties of Relational Databases RDBMS like SQLite MySQL PostgreSQL and NoSQL DBs Performed predictive analytics with Python to predict the defaults for US Mortgage loans and Indian Personal loans Utilized machine learning models like KNN Kmeans Decision trees Nave Bayes Regression XGBoost SVM Random Forest for estimation of parameters to predict stock movement and default on loans Experience in Natural Language Processing including web scraping text wrangling parsing and sentiment analysis with application to predicting the price movement of a stock from the real time news data Performed large scale data analysis and developed statistical models for regressions classification clustering and time series and conducted hypothesis testing with tests like ANOVA ttest ftest Hands on working knowledge of Linux operating system Unix Windows OS AWS and Google cloud platform for machine learning applications to create and manage databases on cloud platform and analyze data sets Worked on Python libraries like Numpy sklearn Matplotlib Pandas Beautifulsoup DataReader Statsmodel Utilized TensorFlow and Keras for implementing deep learning models like LSTM RNN to create chat bot systems Involved in various phases of Software Development Life Cycle SDLC such as requirements gathering modeling analysis design and development with experience in Agile methodologies and SCRUM process Involved in the process of creating Usecase diagrams Activity flow diagrams Class diagrams and Object diagrams in the design phase and developed the Coding module Experienced in creating reports presentations documents dashboards and visualizations using Tableau and RShiny and presented it to senior management for review and decision making Solid knowledge of Finance Risk Data and Business analytics and performed as team leader for numerous projects Managed the credit risk for the bank by developing machine learning model to estimate PD and LGD Strong client facing skills able to interact with high net worth clients and deepen relationship with them Highly Motivated to discover and learn new analytical and software tools to improve the quality of work Ability to work in team environment and managed deliverables within the context of a larger projects Authorized to work in the US for any employer Work Experience Data Scientist Python Developer Amus Inc New York NY June 2018 to Present Responsibilities Scraped and cleaned tax FAQs from multiple sources in Python using Beautifulsoup and inserted into a SQL database Implemented Google Analytics created dashboards analyzed the collected data to understand the user engagement Created interactive dashboards using Tableau to visualize the efficiency of the algorithm and quarterly usage of the product Developed an Alexa skill to integrate the chatbot with Alexa and created lamda function using AWS toolkit to process the json data Implemented Deep Learning LSTM using TensorFlow in python to build a chat bot system Generated word2vec word embeddings for tax publications and IRS tax code using TensorFlow and Python Calculated sentence similarity scores using word2vec embeddings and similarity measures from sklearn to handle semantic and syntactic differences Used different NLP similarity score functions including word2vec ngram tfidf topic modelling to match an input question with our target answers Conducted AB testing for the AMUS Inc webpage and delivered simplified reports to senior management weekly Ensured high quality data collection and maintaining the integrity of the data Designed and developed the UI of the website using HTML AJAX CSS and JavaScript Designed and developed the data management system using MySQL Performed troubleshooting fixed and deployed many Python bug fixes of web application that were a main source of information for both customers Actively involved in Agile Methodologies and SCRUM Process and worked closely with different stakeholders to understand their system needs Environment Python Django Linux Alexa Amazon Web Services AWS NLP TensorFlow Tableau SQL HTML AJAX CSS JavaScript MySQL Data Scientist Machine Learning Python Developer Amethyst Technologies LLC Baltimore MD March 2016 to June 2018 Responsibilities Performed data migration and developed Python Django based web application Postgre SQLDB and integrations with 3rd party email messaging storage services Python Object Oriented Design code for manufacturing quality monitoring logging and debugging code optimization Validated huge data and worked on python backend scripting Automated the developed web applicationportal and developed Python Automation Scripts using Selenium IDE Quantitative analysis and software development using data sets forecasting Economic Capital models and Regulatory Capital models for managing riskbased capital for the bank Analyzed and worked with all aspects of regression models OLS etc and time series analysis Worked with creditrisk models PD LGD EAD in use for retailwholesale credit risk Redesigned market risk model originally implemented in R to use map reduce in Clouderas Hadoop cluster using unsupervised learning principal components analysis Used PROCSQL to fetch tables from Teradata warehouse Merged tables by using PROC SORT Random sampling using PROC SURVEYSELECT Performed logistic regression on each variable and then delete the redundant ones Used APPEND to generate the outcome variable table Checked outliers and missing values using PROC UNIVARIATE and PROC FREQ Macros were employed for data transformation and filling up missing values PROC VARCLUS was used to check the collinearity among explanatory variables Performed logistic regression on newly selected variables Created LIFT probability table and GAIN chart Create shared Object repository Selenium Library Function saved all components functions in Library Functions in Selenium library Developed entire frontend and backend modules using Python on Django Web Framework Used AWS for application deployment and configuration Designed and developed the UI of the website using HTML AJAX CSS and JavaScript Performed debugging and troubleshooting the web applications using Subversion version control tool to coordinate teamdevelopment Created Python scripts to validate based on the keyworddriven testing test cases Developed for fully automated continuous integration system using Python and Bash scripting Environment Python 27 SAS Django 17 CSS HTML JQuery Pandas PostgreSQL GIT AWS AJAX CSS JavaScript Hadoop Python Developer Data Analyst HDFC Bank Hyderabad Telangana December 2013 to March 2016 Responsibilities Performed customer due diligence and determined the credit worthiness of the clients approved accounts and dispensed limits up to 20K in authority and recommended higher limits to Clevel management for approval Gathered loan data designed new credit evaluation policies created statistical data models using Python Excel and SQL which lowered bad debts by 5 for the personal loan segment Collaborated with crossfunctional stakeholders and senior management to design credit check procedures that eliminated 15 of monthly customers at source who did not meet full criteria prior to loan underwriting process Communicated and presented default customers profiles along with reports using Python and Tableau analytical results and strategic implications to senior management for strategic decision making Developed scripts in Python to automate the customer query addressable system using python which decreased the time for solving the query of the customer by 45 Collaborated with other functional teams across the Risk and NonRisk groups to use standard methodologies and ensure a positive customer experience throughout the customer journey Monitored and resolved customer issues via phone email web or chat and managed customer issues from initiation till disbursement of loans which increased customer satisfaction by 15 Provided technical or analytical guidance as needed for issue management project assessments and reporting Environment Python SciPy NumPy Pandas StatsModel Plotly R Tableau MySQL Excel Google Cloud Platform Python Developer Data Analyst ICICI Securities Hyderabad Telangana September 2011 to December 2013 Responsibilities Managed and supervised client portfolio by trading on equity options and futures Developed a web scraper to collect historical financial data of technology giants from Yahoo Finance using DataReader in Python Visualized the moving averages of the stock over the years to obtain the trends and estimate the growth of the companies using Seaborn in Python Performed preliminary risk analysis and implemented methods like Monte Carlo and Bootstrap to estimate the Value of Risk for an asset Analyzed Trade racer website and customer data to identify market product trends and profitable revenue growth opportunities using Python Worked with managers and directors to design solutions and strategies enhancing trade racer platform Facilitated effective communications with equity researchers and senior management and generated trade ideas by devising derivatives strategies which boosted the Customer Satisfaction Index by 24 Leverage information design concepts and principles to create compelling and effective charts tables presentations and other visuals using Python and Excel that convey analytical results clearly and effectively Surpassed 120 of target revenue for 3 consecutive quarters and ranked among the top 10 advisors in the Western Zone in terms of reactivating stopped customers Coached and mentored new trainees and consulted struggling advisors to help them meet monthly target goals Environment Python DataReader Pandas Seaborn Plotly Quandl R Tableau MySQL Excel Yahoo Finance Trade Racer Business Data Analyst Bank of Baroda Mumbai Maharashtra June 2009 to September 2011 Responsibilities Conducted detailed industry analysis research drafted reports and developed analytics insights on SME industry Served as a key strategic partner to uncover underlying business sector needs and information gaps Coordinated with internal and external stakeholders to gather key compounding industry insights and proactively communicated industry news Implemented approaches like Process Capability Analysis and Root Cause Analysis to determine the reasons for problems in food and logistics mining and textiles Maintained traceability among business requirements technical requirements design and testing Assisted to build analytic tools to manage data and streamline data analyses using R and SQL Server Created reporting documentation that identified metrics and data required for display as well as identification of filtering criteria and input Environment Python DataReader Numpy Seaborn Plotly Pandas R Tableau SQL Server Excel Python Developer Riconz Technologies Hyderabad Telangana March 2007 to June 2009 Responsibilities Gathered and analyzed the requirements and converted them into User Requirement Specifications and Functional Requirement Specifications for the designers and developers to understand them as per their perspective Worked on objectoriented programming OOP concepts using Python Django and Linux Developed webbased applications using Python Django XML CSS HTML JavaScript Angular JS and JQuery Experience with JSON based REST Web services and Amazon Web Services AWS Worked on Amazon services like Amazon Cloud EC2 Added support for Amazon AWS and RDS to host staticmedia files and the database into Amazon Cloud Experience in writing Sub Queries Stored Procedures Triggers Cursors and Functions on MySQL and PostgreSQL database Worked in agile and waterfall methodologies with high quality deliverables delivered ontime Experience with continuous integration and automation using Jenkins Experience with Unit testing Test driven Development TDD Load Testing Developed the required XML Schema documents and implemented the framework for parsing XML documents Involved in Unit testing and Integration testing Worked on AJAX framework to transform Datasets and Data tables into HTTPserializable JSON strings Designed Interface using Bootstrap framework Experience with working on multiple environments like development testing production Excellent analytical and problemsolving skills and ability to work on own besides being valuable and contributing team player Environment Python Django REST Web services XML CSS HTTP AJAX AngularJS Bootstrap JSON HTML CSS JavaScript jQuery AWS EC2 Triggers Cursors MySQL and PostgreSQL database Amazon Cloud EC2 Amazon Web Services AWS Education Bachelors Skills Cc C Hadoop Ms project Python Vba Visio Database Database systems Ms access Mysql Postgresql Tableau Data science Hadoop Machine learning Nlp Deep learning Neural networks Linux",
    "unique_id": "39908c9e-4d29-478f-bb3a-dc1ee7010f05"
}