{
    "clean_data": "Data Analyst Data Analyst Data Analyst PNC Pennsylvania Over 7 years of experience in IT industry on analytical programming using Python R programming Django Flask Database design and agile methodologies Over 4 years of experience with Statistics Data Analysis Machine Learning using Python and R language Experienced in SQL programming and creation of relational database models Experienced in creating cutting edge data processing algorithms to meet project demands Experience in Data collection Data Extraction Data Cleaning Data Aggregation DataMining Data verification Data analysis Reporting and data warehousing environments Experience in object oriented programming OOP concepts using Python PHP Developed Merge jobs in Python to extract and load data into MySQL database Experience and Technical proficiency in Designing Data Modeling Online Applications Solution Lead for Architecting Data WarehouseBusiness Intelligence Applications Expertise in designing Conceptual Logical and Physical Data Models for various environments and business processes Strong understanding of the System Architecture and the data flow from various systems Used Visio for creating process and data flow diagrams Extensive experience in designing Normalized Data Model by business process by use cases Performed Data mapping between source systems to local systems logical data modeling created class diagrams and ER diagrams and used SQL queries to filter data Expertise in usage of Django Framework for developing web applications Good knowledge in establishing database connections for Python by configuring packages MySQL Python Worked with Developers and DBAs for requirements gathering analysis and testing to implement fixes for identified data and customer issues metrics and project coordination Define project requirements by identifying project milestones phases and elements forming project team establishing project budget Monitor project progress by tracking activity resolving problems publishing progress reports recommending actions Prepare technical reports by collecting analyzing and summarizing information and trends Contribute to team effort by accomplishing related results as needed strategic and business planning within the various departments and programs of the client group Good experience of software development in Python libraries used libraries Beautiful Soup PySpark Numpy Scipy Matplotlib asyncio pythontwitter Pandas data frame network urllib2 MySQL for database connectivity and IDEs sublime text Spyder pycharm pytest Experience in using Design Patterns such as MVC Singleton and frameworks such as DJANGO Experienced in developing Web Services with Python programming language Good knowledge on NoSQL databases like Cassandra MongoDB Worked with Chef to aid with deployment process and migrating in house systems to Amazon Cloud Services Experience in writing Sub Queries Stored Procedures Triggers Cursors and Functions on MySQL and PostgreSQL database Good experience in Shell Scripting SQL Server UNIX and Linux Developed and optimized ETL workflows in both legacy and distributed environments Work Experience Data Analyst PNC Pennsylvania October 2018 to Present Understood and articulated business requirements from user interviews and then convert requirements into technical specifications Setup storage and data analysis tools in Amazon Web Services cloud computing infrastructure Used pandas NumPy seaborn SciPy matplotlib scikitlearn in Python for developing various machine learning algorithms Involved in executing test cases to validate the data from source to target evaluating test results and preparing test summary reports Wrote test cases developed Test scripts using SQL and PLSQL for UAT Identified issues within the data by querying the source data and identifying the data patterns Visually plotted the data using matplotlib and Seaborn after performing analysis with pandas Using pandas DataFrame performed Groupby merging and joining operations like in SQL Read date from different sources like CSV file Excel HTML page and SQL and performed data analysis and written to any data source like CSV file Excel or database Conduct systems design feasibility and cost studies and recommend costeffective cloud solutions such as Amazon Web Services AWS CreatedExtract Transform Load ETL design mapping sheets data reconciliation strategy data archival strategy ETL framework stored procedures and built SQL query objects to detect data loss Performed data testing tested ETL mappings Transformation logic tested stored procedures and tested the XML messages Developed Merge jobs in Python to extract and load data into MySQL database also worked on Python ETL file loading and use of regular expression Worked on data preprocessing and cleaning the data to perform feature engineering and performed data imputation techniques for the missing values in the dataset using Python Used extracted data for analysis and carried out various mathematical operations for calculation purpose using python library NumPy SciPy Data wrangling and scripting in Python database cleanup in SQL advanced model building in R Python and expertise in data visualization Environment Python AWS PostgreSQL ETL R studio ScikitLearn Seaborn Numpy SciPy MySQL Data Analyst CPS Energy San Antonio September 2017 to September 2018 Responsibilities Experience working in project with machine learning big data data visualization R and Python development Unix SQL Performed exploratory data analysis using numPY matplotlib and pandas Expertise in quantitative analysis data mining and the presentation of data to see beyond the numbers and understand trends and insights Experience analyzing data with the help of Python libraries including Pandas NumPy SciPy and Matplotlib Configured AWS Identity and Access Management IAM Groups and Users for improved login authentication Conduct systems design feasibility and cost studies and recommend costeffective cloud solutions such as Amazon Web Services AWS Creating complex SQL queries and scripts to extract and aggregate data to validate the accuracy of the data and Business requirement gathering and translating them into clear and concise specifications and queries Prepared highlevel analysis reports with Excel and Tableau Provides feedback on the quality of Data including identification of billing patterns and outliers Identify and document limitations in data quality that jeopardize the ability of internal and external data analysts and Wrote standard SQL Queries to perform data validation and created excel summary reports Pivot tables and Charts as well as gathered analytical data to develop functional requirements using data modeling and ETL tools Read date from different sources like CSV file Excel HTML page and SQL and performed data analysis and written to any data source like CSV file Excel or database Experience in using the Lambda functions like filter map and reduce with pandas Data Frame and perform various operations Used Pandas API for analyzing time series Creating regression test framework for new code Developed and handled business logic through backend Python code Created templates for page rendering and Django views for the business logic Used DjangoREST framework and integrated new and existing APIs endpoints Utilized PyUnit for unit testing of the application Performed data analysis using goggle APIs and created visualizations such as pie charts waterfall charts and displayed in the web application Extensive knowledge in loading data into charts using python code Using High charts passed data and created interactive JavaScript charts for the web application Extensive knowledge in using python libraries like OS Pickle numPY and sciPY Used Bit bucket for version control and coordinating with the team Environment Python PyQuery HTML5 CSS3Apache Spark Django SQL UNIX Linux Windows OracleNoSQL PostgreSQL and python libraries such as PySpark NumpyAWS Business Analyst OC Tanner UT December 2016 to August 2017 Responsibilities Translate stakeholder requirements such as functional specifications user cases user stories workflow process diagrams data flow and data model diagrams Evaluate risks related to requirements implementation testing processes project communications Engage client to gather software requirements business rules and ensure alignment with development teams Identify and reconcile errors in client data to ensure accurate business requirements Draft and maintain business requirements and align them with functional and technical requirements Facilitate monthly meetings with clients to document requirements and explore potential solutions Monitor project progress by tracking activity resolving problemspublishing progress reports recommending actions Evaluate risks related to requirements implementation testing processes and project communications Identify and reconcile errors in client data to ensure accurate business requirements Draft and maintain business requirements and align them with functional and technical requirements Facilitate monthly meetings with clients to document requirements and explore potential solutions Identified and replicated intricate and inconsistent issues analyzed them prepared root cause analysis RCA reports found the root cause and fixed them after proposing the solution to client Provide input into developing and modifying systems to meet client needs and develop business specifications to support these modifications Liaise between business and technical personnel to ensure a mutual understanding of processes and applications Environment DatabaseSQL ServerLinuxUnixExcelOracleTabealu Python Developer Accenture Minnesota MN Minnesota MN US January 2015 to December 2016 Responsibilities Involved in reviewing and understanding the Business requirements Involved in entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Wrote scripts to Import and Export data to CSV EXCEL formats from different environments using Python Designed the user interactive web pages as the frontend part of the web application using various web technologies like HTML and implemented CSS framework Bootstrap for better appearance and feel Developed remote integration with third party platforms by using RESTful web services Developed web services that make database calls for inserts updates and select queries Developed Unit Integration and Performance Test Cases using Junit Selenium and Rational Function Tester Improved code reuse and performance by making effective use of various design patterns Used Python library Beautiful Soup for webscrappingss Fetched twitter feeds for certain important keyword using pythontwitter library Managed large datasets using Panda data frames and SQL Wrote and executed various MYSQL database queries from python using PythonMySQL connector and MySQL dB package TestDriven Development approach was used and Developed Merge jobs in Python to extract and load data into MySQL database Worked on SQL Server Integration Services SSIS and SQL Lite Developed methods for Create Read Update and Delete CRUD in Active Record Used Django evolution and manual SQL modifications able to modify Django models while retaining all data while site was in production mode Environment Python Celery Django Angular JQuery JavaScript AJAX HTMLXHTML XML MsSQL server TSQL Jasper GIT Reports REST ful Linux Python Developer HSBC Hyderabad Telangana February 2013 to December 2014 Responsibilities Worked with the Stakeholders gathered requirements developed high level design documents Have used Python libraries like NumPy SciPy Pandas for market analysis and done some machine learning using Python Analyzed various logs that are been generated and used various Python libraries to predictforecast next occurrence of event with various Python libraries Used Django framework in developing web applications to implement the model view control architecture MVC Refactored and extended large existing Django Python code base reducing the number of lines in code and duplication significantly Wrote Sub Queries Stored Procedures Triggers Cursors and Functions on MySQL and PostgreSQL database Experience with working on software changes based on the natural call flow with the customer instead of letting the system dictate the call flow Query Optimization through MYSQL server tools for quick response time and using Golang Experience with automation of linear call flows instead of static so the agents have access to an adaptive user interface Designed and Developed DB2 SQL Procedures and UNIX Shell Scripts for Data ImportExport and Conversions Wrote Python scripts to parse JSON documents and load the data in database and also used python scripts to update content in the database and manipulate files Responsible to set up REST API frame work using Django Flask Developed designed managed dashboard control panel for customers and Administrators using Django PostgreSQL API calls Performed some operations visualization on Oracle DB using libraries like MatPlotlib Pandas Environment PythonNumPySciPyPandasMatplotlibPostgreSQLHTMLCSSPySparkBootStrap JavascriptJQuery Database Developer Sitel Hyderabad Telangana June 2011 to February 2013 Designed the user interactive web pages as the frontend part of the web application using various web technologies like HTML JavaScript Angular JS JQuery and implemented CSS framework Bootstrap for better appearance and feel Wrote scripts to Import and Export data to CSV EXCEL formats from different environments using Python Developed web services that make database calls for inserts updates and select queries Fetched twitter feeds for certain important keyword using pythontwitter library Building complex SQL queries for data analysis and data extract Defining problems collecting data establishing facts and drawing valid conclusions Participated in the creation of technical documentation and training materials Determining where data sets should be loaded for application use or reporting Environment PythonHTML XML MsSQL server Excel CSS Education Masters in Business Administration in Business Administration University of the incarnate word Bachelors in Commerce in Commerce Osmania University Skills DATABASE DB2 JDBC MS ACCESS SQL SERVER",
    "entities": [
        "Wrote Sub Queries Stored Procedures Triggers Cursors and Functions",
        "Database Developer Sitel Hyderabad",
        "Identify",
        "UNIX",
        "Building",
        "Design Patterns",
        "Business Administration University",
        "Commerce Osmania University Skills",
        "Conceptual Logical and Physical Data Models",
        "Panda",
        "ER",
        "Design Development and Deployment Testing and Implementation",
        "XML",
        "Import and Export",
        "Telangana",
        "Pennsylvania",
        "SSIS",
        "Python",
        "Liaise",
        "Statistics Data Analysis Machine Learning",
        "Normalized Data Model",
        "Developed",
        "CPS Energy",
        "Draft",
        "RCA",
        "Data Extraction Data Cleaning Data Aggregation DataMining Data",
        "Matplotlib Configured AWS Identity and Access Management IAM Groups",
        "SQL Lite Developed",
        "San Antonio",
        "DataFrame",
        "Developed Unit Integration",
        "MVC Singleton",
        "SQL Queries",
        "Shell Scripting",
        "Present Understood",
        "Seaborn",
        "flow Query Optimization",
        "Amazon Web Services AWS CreatedExtract Transform Load ETL",
        "MVC",
        "TestDriven Development",
        "linear",
        "Engage",
        "CSV",
        "SQL Server Integration Services",
        "JDBC MS ACCESS SQL SERVER",
        "US",
        "Created",
        "Sub Queries Stored Procedures Triggers Cursors and Functions",
        "SQL Wrote",
        "Oracle DB",
        "Performed Data",
        "Business Administration",
        "HTML",
        "PySpark NumpyAWS",
        "the System Architecture",
        "SQL",
        "Prepare",
        "Amazon Web Services",
        "Transformation",
        "Administrators",
        "Data Frame",
        "Amazon Web Services AWS Creating",
        "Contribute",
        "Pandas",
        "ETL",
        "MatPlotlib Pandas",
        "Excel CSS Education Masters",
        "Performed",
        "Python Used",
        "Facilitate",
        "JavaScript",
        "Amazon Cloud Services",
        "Utilized PyUnit",
        "the Business requirements Involved",
        "CSS",
        "Data",
        "NoSQL",
        "Minnesota"
    ],
    "experience": "Experience in Data collection Data Extraction Data Cleaning Data Aggregation DataMining Data verification Data analysis Reporting and data warehousing environments Experience in object oriented programming OOP concepts using Python PHP Developed Merge jobs in Python to extract and load data into MySQL database Experience and Technical proficiency in Designing Data Modeling Online Applications Solution Lead for Architecting Data WarehouseBusiness Intelligence Applications Expertise in designing Conceptual Logical and Physical Data Models for various environments and business processes Strong understanding of the System Architecture and the data flow from various systems Used Visio for creating process and data flow diagrams Extensive experience in designing Normalized Data Model by business process by use cases Performed Data mapping between source systems to local systems logical data modeling created class diagrams and ER diagrams and used SQL queries to filter data Expertise in usage of Django Framework for developing web applications Good knowledge in establishing database connections for Python by configuring packages MySQL Python Worked with Developers and DBAs for requirements gathering analysis and testing to implement fixes for identified data and customer issues metrics and project coordination Define project requirements by identifying project milestones phases and elements forming project team establishing project budget Monitor project progress by tracking activity resolving problems publishing progress reports recommending actions Prepare technical reports by collecting analyzing and summarizing information and trends Contribute to team effort by accomplishing related results as needed strategic and business planning within the various departments and programs of the client group Good experience of software development in Python libraries used libraries Beautiful Soup PySpark Numpy Scipy Matplotlib asyncio pythontwitter Pandas data frame network urllib2 MySQL for database connectivity and IDEs sublime text Spyder pycharm pytest Experience in using Design Patterns such as MVC Singleton and frameworks such as DJANGO Experienced in developing Web Services with Python programming language Good knowledge on NoSQL databases like Cassandra MongoDB Worked with Chef to aid with deployment process and migrating in house systems to Amazon Cloud Services Experience in writing Sub Queries Stored Procedures Triggers Cursors and Functions on MySQL and PostgreSQL database Good experience in Shell Scripting SQL Server UNIX and Linux Developed and optimized ETL workflows in both legacy and distributed environments Work Experience Data Analyst PNC Pennsylvania October 2018 to Present Understood and articulated business requirements from user interviews and then convert requirements into technical specifications Setup storage and data analysis tools in Amazon Web Services cloud computing infrastructure Used pandas NumPy seaborn SciPy matplotlib scikitlearn in Python for developing various machine learning algorithms Involved in executing test cases to validate the data from source to target evaluating test results and preparing test summary reports Wrote test cases developed Test scripts using SQL and PLSQL for UAT Identified issues within the data by querying the source data and identifying the data patterns Visually plotted the data using matplotlib and Seaborn after performing analysis with pandas Using pandas DataFrame performed Groupby merging and joining operations like in SQL Read date from different sources like CSV file Excel HTML page and SQL and performed data analysis and written to any data source like CSV file Excel or database Conduct systems design feasibility and cost studies and recommend costeffective cloud solutions such as Amazon Web Services AWS CreatedExtract Transform Load ETL design mapping sheets data reconciliation strategy data archival strategy ETL framework stored procedures and built SQL query objects to detect data loss Performed data testing tested ETL mappings Transformation logic tested stored procedures and tested the XML messages Developed Merge jobs in Python to extract and load data into MySQL database also worked on Python ETL file loading and use of regular expression Worked on data preprocessing and cleaning the data to perform feature engineering and performed data imputation techniques for the missing values in the dataset using Python Used extracted data for analysis and carried out various mathematical operations for calculation purpose using python library NumPy SciPy Data wrangling and scripting in Python database cleanup in SQL advanced model building in R Python and expertise in data visualization Environment Python AWS PostgreSQL ETL R studio ScikitLearn Seaborn Numpy SciPy MySQL Data Analyst CPS Energy San Antonio September 2017 to September 2018 Responsibilities Experience working in project with machine learning big data data visualization R and Python development Unix SQL Performed exploratory data analysis using numPY matplotlib and pandas Expertise in quantitative analysis data mining and the presentation of data to see beyond the numbers and understand trends and insights Experience analyzing data with the help of Python libraries including Pandas NumPy SciPy and Matplotlib Configured AWS Identity and Access Management IAM Groups and Users for improved login authentication Conduct systems design feasibility and cost studies and recommend costeffective cloud solutions such as Amazon Web Services AWS Creating complex SQL queries and scripts to extract and aggregate data to validate the accuracy of the data and Business requirement gathering and translating them into clear and concise specifications and queries Prepared highlevel analysis reports with Excel and Tableau Provides feedback on the quality of Data including identification of billing patterns and outliers Identify and document limitations in data quality that jeopardize the ability of internal and external data analysts and Wrote standard SQL Queries to perform data validation and created excel summary reports Pivot tables and Charts as well as gathered analytical data to develop functional requirements using data modeling and ETL tools Read date from different sources like CSV file Excel HTML page and SQL and performed data analysis and written to any data source like CSV file Excel or database Experience in using the Lambda functions like filter map and reduce with pandas Data Frame and perform various operations Used Pandas API for analyzing time series Creating regression test framework for new code Developed and handled business logic through backend Python code Created templates for page rendering and Django views for the business logic Used DjangoREST framework and integrated new and existing APIs endpoints Utilized PyUnit for unit testing of the application Performed data analysis using goggle APIs and created visualizations such as pie charts waterfall charts and displayed in the web application Extensive knowledge in loading data into charts using python code Using High charts passed data and created interactive JavaScript charts for the web application Extensive knowledge in using python libraries like OS Pickle numPY and sciPY Used Bit bucket for version control and coordinating with the team Environment Python PyQuery HTML5 CSS3Apache Spark Django SQL UNIX Linux Windows OracleNoSQL PostgreSQL and python libraries such as PySpark NumpyAWS Business Analyst OC Tanner UT December 2016 to August 2017 Responsibilities Translate stakeholder requirements such as functional specifications user cases user stories workflow process diagrams data flow and data model diagrams Evaluate risks related to requirements implementation testing processes project communications Engage client to gather software requirements business rules and ensure alignment with development teams Identify and reconcile errors in client data to ensure accurate business requirements Draft and maintain business requirements and align them with functional and technical requirements Facilitate monthly meetings with clients to document requirements and explore potential solutions Monitor project progress by tracking activity resolving problemspublishing progress reports recommending actions Evaluate risks related to requirements implementation testing processes and project communications Identify and reconcile errors in client data to ensure accurate business requirements Draft and maintain business requirements and align them with functional and technical requirements Facilitate monthly meetings with clients to document requirements and explore potential solutions Identified and replicated intricate and inconsistent issues analyzed them prepared root cause analysis RCA reports found the root cause and fixed them after proposing the solution to client Provide input into developing and modifying systems to meet client needs and develop business specifications to support these modifications Liaise between business and technical personnel to ensure a mutual understanding of processes and applications Environment DatabaseSQL ServerLinuxUnixExcelOracleTabealu Python Developer Accenture Minnesota MN Minnesota MN US January 2015 to December 2016 Responsibilities Involved in reviewing and understanding the Business requirements Involved in entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Wrote scripts to Import and Export data to CSV EXCEL formats from different environments using Python Designed the user interactive web pages as the frontend part of the web application using various web technologies like HTML and implemented CSS framework Bootstrap for better appearance and feel Developed remote integration with third party platforms by using RESTful web services Developed web services that make database calls for inserts updates and select queries Developed Unit Integration and Performance Test Cases using Junit Selenium and Rational Function Tester Improved code reuse and performance by making effective use of various design patterns Used Python library Beautiful Soup for webscrappingss Fetched twitter feeds for certain important keyword using pythontwitter library Managed large datasets using Panda data frames and SQL Wrote and executed various MYSQL database queries from python using PythonMySQL connector and MySQL dB package TestDriven Development approach was used and Developed Merge jobs in Python to extract and load data into MySQL database Worked on SQL Server Integration Services SSIS and SQL Lite Developed methods for Create Read Update and Delete CRUD in Active Record Used Django evolution and manual SQL modifications able to modify Django models while retaining all data while site was in production mode Environment Python Celery Django Angular JQuery JavaScript AJAX HTMLXHTML XML MsSQL server TSQL Jasper GIT Reports REST ful Linux Python Developer HSBC Hyderabad Telangana February 2013 to December 2014 Responsibilities Worked with the Stakeholders gathered requirements developed high level design documents Have used Python libraries like NumPy SciPy Pandas for market analysis and done some machine learning using Python Analyzed various logs that are been generated and used various Python libraries to predictforecast next occurrence of event with various Python libraries Used Django framework in developing web applications to implement the model view control architecture MVC Refactored and extended large existing Django Python code base reducing the number of lines in code and duplication significantly Wrote Sub Queries Stored Procedures Triggers Cursors and Functions on MySQL and PostgreSQL database Experience with working on software changes based on the natural call flow with the customer instead of letting the system dictate the call flow Query Optimization through MYSQL server tools for quick response time and using Golang Experience with automation of linear call flows instead of static so the agents have access to an adaptive user interface Designed and Developed DB2 SQL Procedures and UNIX Shell Scripts for Data ImportExport and Conversions Wrote Python scripts to parse JSON documents and load the data in database and also used python scripts to update content in the database and manipulate files Responsible to set up REST API frame work using Django Flask Developed designed managed dashboard control panel for customers and Administrators using Django PostgreSQL API calls Performed some operations visualization on Oracle DB using libraries like MatPlotlib Pandas Environment PythonNumPySciPyPandasMatplotlibPostgreSQLHTMLCSSPySparkBootStrap JavascriptJQuery Database Developer Sitel Hyderabad Telangana June 2011 to February 2013 Designed the user interactive web pages as the frontend part of the web application using various web technologies like HTML JavaScript Angular JS JQuery and implemented CSS framework Bootstrap for better appearance and feel Wrote scripts to Import and Export data to CSV EXCEL formats from different environments using Python Developed web services that make database calls for inserts updates and select queries Fetched twitter feeds for certain important keyword using pythontwitter library Building complex SQL queries for data analysis and data extract Defining problems collecting data establishing facts and drawing valid conclusions Participated in the creation of technical documentation and training materials Determining where data sets should be loaded for application use or reporting Environment PythonHTML XML MsSQL server Excel CSS Education Masters in Business Administration in Business Administration University of the incarnate word Bachelors in Commerce in Commerce Osmania University Skills DATABASE DB2 JDBC MS ACCESS SQL SERVER",
    "extracted_keywords": [
        "Data",
        "Analyst",
        "Data",
        "Analyst",
        "Data",
        "Analyst",
        "PNC",
        "Pennsylvania",
        "years",
        "experience",
        "IT",
        "industry",
        "programming",
        "Python",
        "R",
        "programming",
        "Django",
        "Flask",
        "Database",
        "design",
        "methodologies",
        "years",
        "experience",
        "Statistics",
        "Data",
        "Analysis",
        "Machine",
        "Learning",
        "Python",
        "R",
        "language",
        "SQL",
        "programming",
        "creation",
        "database",
        "models",
        "edge",
        "data",
        "processing",
        "algorithms",
        "project",
        "demands",
        "Experience",
        "Data",
        "collection",
        "Data",
        "Extraction",
        "Data",
        "Cleaning",
        "Data",
        "Aggregation",
        "DataMining",
        "Data",
        "verification",
        "Data",
        "analysis",
        "Reporting",
        "data",
        "warehousing",
        "environments",
        "Experience",
        "object",
        "programming",
        "OOP",
        "concepts",
        "Python",
        "PHP",
        "Merge",
        "jobs",
        "Python",
        "data",
        "MySQL",
        "database",
        "Experience",
        "proficiency",
        "Designing",
        "Data",
        "Modeling",
        "Online",
        "Applications",
        "Solution",
        "Lead",
        "Data",
        "WarehouseBusiness",
        "Intelligence",
        "Applications",
        "Expertise",
        "Conceptual",
        "Logical",
        "Physical",
        "Data",
        "Models",
        "environments",
        "business",
        "understanding",
        "System",
        "Architecture",
        "data",
        "flow",
        "systems",
        "Visio",
        "process",
        "data",
        "flow",
        "diagrams",
        "experience",
        "Normalized",
        "Data",
        "Model",
        "business",
        "process",
        "use",
        "cases",
        "Performed",
        "Data",
        "mapping",
        "source",
        "systems",
        "systems",
        "data",
        "class",
        "diagrams",
        "ER",
        "diagrams",
        "SQL",
        "queries",
        "data",
        "Expertise",
        "usage",
        "Django",
        "Framework",
        "web",
        "applications",
        "knowledge",
        "database",
        "connections",
        "Python",
        "packages",
        "MySQL",
        "Python",
        "Developers",
        "DBAs",
        "requirements",
        "analysis",
        "testing",
        "fixes",
        "data",
        "customer",
        "metrics",
        "project",
        "coordination",
        "Define",
        "project",
        "requirements",
        "project",
        "milestones",
        "phases",
        "elements",
        "project",
        "team",
        "project",
        "budget",
        "Monitor",
        "project",
        "progress",
        "activity",
        "problems",
        "progress",
        "reports",
        "actions",
        "reports",
        "information",
        "trends",
        "team",
        "effort",
        "results",
        "business",
        "planning",
        "departments",
        "programs",
        "client",
        "group",
        "Good",
        "experience",
        "software",
        "development",
        "Python",
        "libraries",
        "libraries",
        "Beautiful",
        "Soup",
        "PySpark",
        "Numpy",
        "Scipy",
        "Matplotlib",
        "asyncio",
        "pythontwitter",
        "Pandas",
        "data",
        "frame",
        "network",
        "urllib2",
        "MySQL",
        "database",
        "connectivity",
        "IDEs",
        "text",
        "Spyder",
        "Experience",
        "Design",
        "Patterns",
        "MVC",
        "Singleton",
        "frameworks",
        "DJANGO",
        "Web",
        "Services",
        "Python",
        "programming",
        "language",
        "knowledge",
        "NoSQL",
        "databases",
        "Cassandra",
        "MongoDB",
        "Chef",
        "deployment",
        "process",
        "migrating",
        "house",
        "systems",
        "Amazon",
        "Cloud",
        "Services",
        "Experience",
        "Sub",
        "Queries",
        "Stored",
        "Procedures",
        "Triggers",
        "Cursors",
        "Functions",
        "MySQL",
        "PostgreSQL",
        "database",
        "experience",
        "Shell",
        "Scripting",
        "SQL",
        "Server",
        "UNIX",
        "Linux",
        "Developed",
        "ETL",
        "workflows",
        "legacy",
        "environments",
        "Work",
        "Experience",
        "Data",
        "Analyst",
        "PNC",
        "Pennsylvania",
        "October",
        "Present",
        "Understood",
        "business",
        "requirements",
        "user",
        "interviews",
        "requirements",
        "specifications",
        "Setup",
        "storage",
        "data",
        "analysis",
        "tools",
        "Amazon",
        "Web",
        "Services",
        "cloud",
        "infrastructure",
        "pandas",
        "NumPy",
        "SciPy",
        "matplotlib",
        "Python",
        "machine",
        "algorithms",
        "test",
        "cases",
        "data",
        "source",
        "test",
        "results",
        "test",
        "summary",
        "reports",
        "Wrote",
        "test",
        "cases",
        "Test",
        "scripts",
        "SQL",
        "PLSQL",
        "UAT",
        "issues",
        "data",
        "source",
        "data",
        "data",
        "patterns",
        "data",
        "matplotlib",
        "Seaborn",
        "analysis",
        "pandas",
        "pandas",
        "DataFrame",
        "Groupby",
        "operations",
        "SQL",
        "Read",
        "date",
        "sources",
        "CSV",
        "file",
        "Excel",
        "HTML",
        "page",
        "SQL",
        "data",
        "analysis",
        "data",
        "source",
        "CSV",
        "file",
        "Excel",
        "database",
        "Conduct",
        "systems",
        "design",
        "feasibility",
        "studies",
        "cloud",
        "solutions",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "CreatedExtract",
        "Transform",
        "Load",
        "ETL",
        "design",
        "mapping",
        "sheets",
        "data",
        "reconciliation",
        "strategy",
        "data",
        "archival",
        "strategy",
        "ETL",
        "framework",
        "procedures",
        "SQL",
        "query",
        "data",
        "loss",
        "Performed",
        "data",
        "testing",
        "ETL",
        "mappings",
        "Transformation",
        "logic",
        "procedures",
        "XML",
        "messages",
        "Merge",
        "jobs",
        "Python",
        "data",
        "MySQL",
        "database",
        "Python",
        "ETL",
        "file",
        "loading",
        "use",
        "expression",
        "data",
        "data",
        "feature",
        "engineering",
        "data",
        "imputation",
        "techniques",
        "values",
        "dataset",
        "Python",
        "data",
        "analysis",
        "operations",
        "calculation",
        "purpose",
        "library",
        "NumPy",
        "SciPy",
        "Data",
        "scripting",
        "Python",
        "database",
        "cleanup",
        "SQL",
        "model",
        "building",
        "R",
        "Python",
        "expertise",
        "data",
        "visualization",
        "Environment",
        "Python",
        "AWS",
        "PostgreSQL",
        "ETL",
        "R",
        "studio",
        "ScikitLearn",
        "Seaborn",
        "Numpy",
        "SciPy",
        "MySQL",
        "Data",
        "Analyst",
        "CPS",
        "Energy",
        "San",
        "Antonio",
        "September",
        "September",
        "Responsibilities",
        "Experience",
        "project",
        "machine",
        "data",
        "data",
        "visualization",
        "R",
        "Python",
        "development",
        "Unix",
        "SQL",
        "data",
        "analysis",
        "numPY",
        "matplotlib",
        "Expertise",
        "analysis",
        "data",
        "mining",
        "presentation",
        "data",
        "numbers",
        "trends",
        "insights",
        "data",
        "help",
        "Python",
        "libraries",
        "Pandas",
        "NumPy",
        "SciPy",
        "Matplotlib",
        "Configured",
        "AWS",
        "Identity",
        "Access",
        "Management",
        "IAM",
        "Groups",
        "Users",
        "login",
        "authentication",
        "Conduct",
        "systems",
        "design",
        "feasibility",
        "studies",
        "cloud",
        "solutions",
        "Amazon",
        "Web",
        "Services",
        "AWS",
        "SQL",
        "queries",
        "scripts",
        "data",
        "accuracy",
        "data",
        "Business",
        "requirement",
        "gathering",
        "specifications",
        "highlevel",
        "analysis",
        "reports",
        "Excel",
        "Tableau",
        "feedback",
        "quality",
        "Data",
        "identification",
        "billing",
        "patterns",
        "outliers",
        "document",
        "limitations",
        "data",
        "quality",
        "ability",
        "data",
        "analysts",
        "Wrote",
        "SQL",
        "Queries",
        "data",
        "validation",
        "summary",
        "Pivot",
        "tables",
        "Charts",
        "data",
        "requirements",
        "data",
        "modeling",
        "ETL",
        "tools",
        "Read",
        "date",
        "sources",
        "CSV",
        "file",
        "Excel",
        "HTML",
        "page",
        "SQL",
        "data",
        "analysis",
        "data",
        "source",
        "CSV",
        "file",
        "Excel",
        "database",
        "Experience",
        "Lambda",
        "functions",
        "filter",
        "map",
        "pandas",
        "Data",
        "Frame",
        "operations",
        "Pandas",
        "API",
        "time",
        "series",
        "regression",
        "test",
        "framework",
        "code",
        "business",
        "logic",
        "Python",
        "code",
        "templates",
        "page",
        "Django",
        "business",
        "logic",
        "DjangoREST",
        "framework",
        "APIs",
        "endpoints",
        "PyUnit",
        "unit",
        "testing",
        "application",
        "data",
        "analysis",
        "goggle",
        "APIs",
        "visualizations",
        "pie",
        "charts",
        "waterfall",
        "charts",
        "web",
        "application",
        "knowledge",
        "loading",
        "data",
        "charts",
        "code",
        "charts",
        "data",
        "JavaScript",
        "charts",
        "web",
        "application",
        "knowledge",
        "python",
        "libraries",
        "OS",
        "Pickle",
        "numPY",
        "sciPY",
        "Bit",
        "bucket",
        "version",
        "control",
        "team",
        "Environment",
        "Python",
        "PyQuery",
        "HTML5",
        "CSS3Apache",
        "Spark",
        "Django",
        "SQL",
        "UNIX",
        "Linux",
        "Windows",
        "OracleNoSQL",
        "PostgreSQL",
        "python",
        "libraries",
        "PySpark",
        "Business",
        "Analyst",
        "OC",
        "Tanner",
        "UT",
        "December",
        "August",
        "Responsibilities",
        "stakeholder",
        "requirements",
        "specifications",
        "user",
        "cases",
        "user",
        "stories",
        "workflow",
        "process",
        "diagrams",
        "data",
        "flow",
        "data",
        "model",
        "diagrams",
        "risks",
        "requirements",
        "implementation",
        "testing",
        "processes",
        "project",
        "communications",
        "Engage",
        "client",
        "software",
        "requirements",
        "business",
        "rules",
        "alignment",
        "development",
        "teams",
        "errors",
        "client",
        "data",
        "business",
        "requirements",
        "business",
        "requirements",
        "requirements",
        "meetings",
        "clients",
        "document",
        "requirements",
        "solutions",
        "Monitor",
        "project",
        "progress",
        "activity",
        "progress",
        "reports",
        "actions",
        "risks",
        "requirements",
        "implementation",
        "testing",
        "processes",
        "project",
        "communications",
        "errors",
        "client",
        "data",
        "business",
        "requirements",
        "business",
        "requirements",
        "requirements",
        "meetings",
        "clients",
        "document",
        "requirements",
        "solutions",
        "issues",
        "root",
        "analysis",
        "RCA",
        "reports",
        "root",
        "cause",
        "solution",
        "client",
        "Provide",
        "input",
        "systems",
        "client",
        "needs",
        "business",
        "specifications",
        "modifications",
        "Liaise",
        "business",
        "personnel",
        "understanding",
        "processes",
        "applications",
        "Environment",
        "DatabaseSQL",
        "Python",
        "Developer",
        "Accenture",
        "Minnesota",
        "MN",
        "Minnesota",
        "MN",
        "US",
        "January",
        "December",
        "Responsibilities",
        "Business",
        "requirements",
        "lifecycle",
        "projects",
        "Design",
        "Development",
        "Deployment",
        "Testing",
        "Implementation",
        "support",
        "scripts",
        "Import",
        "Export",
        "data",
        "CSV",
        "EXCEL",
        "formats",
        "environments",
        "Python",
        "user",
        "web",
        "pages",
        "part",
        "web",
        "application",
        "web",
        "technologies",
        "HTML",
        "CSS",
        "framework",
        "Bootstrap",
        "appearance",
        "integration",
        "party",
        "platforms",
        "web",
        "services",
        "web",
        "services",
        "database",
        "calls",
        "inserts",
        "updates",
        "Developed",
        "Unit",
        "Integration",
        "Performance",
        "Test",
        "Cases",
        "Junit",
        "Selenium",
        "Rational",
        "Function",
        "Tester",
        "code",
        "reuse",
        "performance",
        "use",
        "design",
        "patterns",
        "Python",
        "library",
        "Beautiful",
        "Soup",
        "webscrappingss",
        "twitter",
        "keyword",
        "pythontwitter",
        "library",
        "datasets",
        "Panda",
        "data",
        "frames",
        "SQL",
        "Wrote",
        "MYSQL",
        "database",
        "python",
        "PythonMySQL",
        "connector",
        "MySQL",
        "package",
        "TestDriven",
        "Development",
        "approach",
        "Merge",
        "jobs",
        "Python",
        "data",
        "MySQL",
        "database",
        "SQL",
        "Server",
        "Integration",
        "Services",
        "SSIS",
        "SQL",
        "Lite",
        "methods",
        "Create",
        "Read",
        "Update",
        "Delete",
        "CRUD",
        "Active",
        "Record",
        "Django",
        "evolution",
        "SQL",
        "modifications",
        "Django",
        "models",
        "data",
        "site",
        "production",
        "mode",
        "Environment",
        "Python",
        "Celery",
        "Django",
        "Angular",
        "JQuery",
        "JavaScript",
        "AJAX",
        "HTMLXHTML",
        "XML",
        "MsSQL",
        "server",
        "TSQL",
        "Jasper",
        "GIT",
        "Reports",
        "REST",
        "Linux",
        "Python",
        "Developer",
        "HSBC",
        "Hyderabad",
        "Telangana",
        "February",
        "December",
        "Responsibilities",
        "Stakeholders",
        "requirements",
        "level",
        "design",
        "documents",
        "Python",
        "libraries",
        "NumPy",
        "SciPy",
        "Pandas",
        "market",
        "analysis",
        "machine",
        "Python",
        "logs",
        "Python",
        "libraries",
        "occurrence",
        "event",
        "Python",
        "libraries",
        "Django",
        "framework",
        "web",
        "applications",
        "model",
        "view",
        "control",
        "architecture",
        "MVC",
        "Refactored",
        "Django",
        "Python",
        "code",
        "base",
        "number",
        "lines",
        "code",
        "duplication",
        "Wrote",
        "Sub",
        "Queries",
        "Stored",
        "Procedures",
        "Triggers",
        "Cursors",
        "Functions",
        "MySQL",
        "PostgreSQL",
        "database",
        "Experience",
        "software",
        "changes",
        "call",
        "flow",
        "customer",
        "system",
        "call",
        "flow",
        "Query",
        "Optimization",
        "MYSQL",
        "server",
        "tools",
        "response",
        "time",
        "Golang",
        "Experience",
        "automation",
        "call",
        "static",
        "agents",
        "access",
        "user",
        "interface",
        "Developed",
        "DB2",
        "SQL",
        "Procedures",
        "UNIX",
        "Shell",
        "Scripts",
        "Data",
        "ImportExport",
        "Conversions",
        "Wrote",
        "Python",
        "scripts",
        "documents",
        "data",
        "database",
        "scripts",
        "content",
        "database",
        "manipulate",
        "files",
        "REST",
        "API",
        "frame",
        "work",
        "Django",
        "Flask",
        "Developed",
        "dashboard",
        "control",
        "panel",
        "customers",
        "Administrators",
        "Django",
        "PostgreSQL",
        "API",
        "operations",
        "visualization",
        "Oracle",
        "DB",
        "libraries",
        "MatPlotlib",
        "Pandas",
        "Environment",
        "PythonNumPySciPyPandasMatplotlibPostgreSQLHTMLCSSPySparkBootStrap",
        "Database",
        "Developer",
        "Sitel",
        "Hyderabad",
        "Telangana",
        "June",
        "February",
        "user",
        "web",
        "pages",
        "part",
        "web",
        "application",
        "web",
        "technologies",
        "HTML",
        "JavaScript",
        "Angular",
        "JS",
        "JQuery",
        "CSS",
        "framework",
        "Bootstrap",
        "appearance",
        "Wrote",
        "scripts",
        "Import",
        "Export",
        "data",
        "CSV",
        "EXCEL",
        "formats",
        "environments",
        "Python",
        "Developed",
        "web",
        "services",
        "database",
        "calls",
        "inserts",
        "updates",
        "queries",
        "twitter",
        "keyword",
        "pythontwitter",
        "library",
        "Building",
        "SQL",
        "data",
        "analysis",
        "data",
        "problems",
        "data",
        "facts",
        "conclusions",
        "creation",
        "documentation",
        "training",
        "materials",
        "data",
        "sets",
        "application",
        "use",
        "Environment",
        "PythonHTML",
        "XML",
        "MsSQL",
        "server",
        "Excel",
        "CSS",
        "Education",
        "Masters",
        "Business",
        "Administration",
        "Business",
        "Administration",
        "University",
        "word",
        "Bachelors",
        "Commerce",
        "Commerce",
        "Osmania",
        "University",
        "Skills",
        "DATABASE",
        "DB2",
        "JDBC",
        "MS",
        "ACCESS",
        "SQL",
        "SERVER"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T23:11:22.621213",
    "resume_data": "Data Analyst Data Analyst Data Analyst PNC Pennsylvania Over 7 years of experience in IT industry on analytical programming using Python R programming Django Flask Database design and agile methodologies Over 4 years of experience with Statistics Data Analysis Machine Learning using Python and R language Experienced in SQL programming and creation of relational database models Experienced in creating cutting edge data processing algorithms to meet project demands Experience in Data collection Data Extraction Data Cleaning Data Aggregation DataMining Data verification Data analysis Reporting and data warehousing environments Experience in object oriented programming OOP concepts using Python PHP Developed Merge jobs in Python to extract and load data into MySQL database Experience and Technical proficiency in Designing Data Modeling Online Applications Solution Lead for Architecting Data WarehouseBusiness Intelligence Applications Expertise in designing Conceptual Logical and Physical Data Models for various environments and business processes Strong understanding of the System Architecture and the data flow from various systems Used Visio for creating process and data flow diagrams Extensive experience in designing Normalized Data Model by business process by use cases Performed Data mapping between source systems to local systems logical data modeling created class diagrams and ER diagrams and used SQL queries to filter data Expertise in usage of Django Framework for developing web applications Good knowledge in establishing database connections for Python by configuring packages MySQL Python Worked with Developers and DBAs for requirements gathering analysis and testing to implement fixes for identified data and customer issues metrics and project coordination Define project requirements by identifying project milestones phases and elements forming project team establishing project budget Monitor project progress by tracking activity resolving problems publishing progress reports recommending actions Prepare technical reports by collecting analyzing and summarizing information and trends Contribute to team effort by accomplishing related results as needed strategic and business planning within the various departments and programs of the client group Good experience of software development in Python libraries used libraries Beautiful Soup PySpark Numpy Scipy Matplotlib asyncio pythontwitter Pandas data frame network urllib2 MySQL for database connectivity and IDEs sublime text Spyder pycharm pytest Experience in using Design Patterns such as MVC Singleton and frameworks such as DJANGO Experienced in developing Web Services with Python programming language Good knowledge on NoSQL databases like Cassandra MongoDB Worked with Chef to aid with deployment process and migrating in house systems to Amazon Cloud Services Experience in writing Sub Queries Stored Procedures Triggers Cursors and Functions on MySQL and PostgreSQL database Good experience in Shell Scripting SQL Server UNIX and Linux Developed and optimized ETL workflows in both legacy and distributed environments Work Experience Data Analyst PNC Pennsylvania October 2018 to Present Understood and articulated business requirements from user interviews and then convert requirements into technical specifications Setup storage and data analysis tools in Amazon Web Services cloud computing infrastructure Used pandas NumPy seaborn SciPy matplotlib scikitlearn in Python for developing various machine learning algorithms Involved in executing test cases to validate the data from source to target evaluating test results and preparing test summary reports Wrote test cases developed Test scripts using SQL and PLSQL for UAT Identified issues within the data by querying the source data and identifying the data patterns Visually plotted the data using matplotlib and Seaborn after performing analysis with pandas Using pandas DataFrame performed Groupby merging and joining operations like in SQL Read date from different sources like CSV file Excel HTML page and SQL and performed data analysis and written to any data source like CSV file Excel or database Conduct systems design feasibility and cost studies and recommend costeffective cloud solutions such as Amazon Web Services AWS CreatedExtract Transform Load ETL design mapping sheets data reconciliation strategy data archival strategy ETL framework stored procedures and built SQL query objects to detect data loss Performed data testing tested ETL mappings Transformation logic tested stored procedures and tested the XML messages Developed Merge jobs in Python to extract and load data into MySQL database also worked on Python ETL file loading and use of regular expression Worked on data preprocessing and cleaning the data to perform feature engineering and performed data imputation techniques for the missing values in the dataset using Python Used extracted data for analysis and carried out various mathematical operations for calculation purpose using python library NumPy SciPy Data wrangling and scripting in Python database cleanup in SQL advanced model building in R Python and expertise in data visualization Environment Python AWS PostgreSQL ETL R studio ScikitLearn Seaborn Numpy SciPy MySQL Data Analyst CPS Energy San Antonio September 2017 to September 2018 Responsibilities Experience working in project with machine learning big data data visualization R and Python development Unix SQL Performed exploratory data analysis using numPY matplotlib and pandas Expertise in quantitative analysis data mining and the presentation of data to see beyond the numbers and understand trends and insights Experience analyzing data with the help of Python libraries including Pandas NumPy SciPy and Matplotlib Configured AWS Identity and Access Management IAM Groups and Users for improved login authentication Conduct systems design feasibility and cost studies and recommend costeffective cloud solutions such as Amazon Web Services AWS Creating complex SQL queries and scripts to extract and aggregate data to validate the accuracy of the data and Business requirement gathering and translating them into clear and concise specifications and queries Prepared highlevel analysis reports with Excel and Tableau Provides feedback on the quality of Data including identification of billing patterns and outliers Identify and document limitations in data quality that jeopardize the ability of internal and external data analysts and Wrote standard SQL Queries to perform data validation and created excel summary reports Pivot tables and Charts as well as gathered analytical data to develop functional requirements using data modeling and ETL tools Read date from different sources like CSV file Excel HTML page and SQL and performed data analysis and written to any data source like CSV file Excel or database Experience in using the Lambda functions like filter map and reduce with pandas Data Frame and perform various operations Used Pandas API for analyzing time series Creating regression test framework for new code Developed and handled business logic through backend Python code Created templates for page rendering and Django views for the business logic Used DjangoREST framework and integrated new and existing APIs endpoints Utilized PyUnit for unit testing of the application Performed data analysis using goggle APIs and created visualizations such as pie charts waterfall charts and displayed in the web application Extensive knowledge in loading data into charts using python code Using High charts passed data and created interactive JavaScript charts for the web application Extensive knowledge in using python libraries like OS Pickle numPY and sciPY Used Bit bucket for version control and coordinating with the team Environment Python PyQuery HTML5 CSS3Apache Spark Django SQL UNIX Linux Windows OracleNoSQL PostgreSQL and python libraries such as PySpark NumpyAWS Business Analyst OC Tanner UT December 2016 to August 2017 Responsibilities Translate stakeholder requirements such as functional specifications user cases user stories workflow process diagrams data flow and data model diagrams Evaluate risks related to requirements implementation testing processes project communications Engage client to gather software requirements business rules and ensure alignment with development teams Identify and reconcile errors in client data to ensure accurate business requirements Draft and maintain business requirements and align them with functional and technical requirements Facilitate monthly meetings with clients to document requirements and explore potential solutions Monitor project progress by tracking activity resolving problemspublishing progress reports recommending actions Evaluate risks related to requirements implementation testing processes and project communications Identify and reconcile errors in client data to ensure accurate business requirements Draft and maintain business requirements and align them with functional and technical requirements Facilitate monthly meetings with clients to document requirements and explore potential solutions Identified and replicated intricate and inconsistent issues analyzed them prepared root cause analysis RCA reports found the root cause and fixed them after proposing the solution to client Provide input into developing and modifying systems to meet client needs and develop business specifications to support these modifications Liaise between business and technical personnel to ensure a mutual understanding of processes and applications Environment DatabaseSQL ServerLinuxUnixExcelOracleTabealu Python Developer Accenture Minnesota MN Minnesota MN US January 2015 to December 2016 Responsibilities Involved in reviewing and understanding the Business requirements Involved in entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Wrote scripts to Import and Export data to CSV EXCEL formats from different environments using Python Designed the user interactive web pages as the frontend part of the web application using various web technologies like HTML and implemented CSS framework Bootstrap for better appearance and feel Developed remote integration with third party platforms by using RESTful web services Developed web services that make database calls for inserts updates and select queries Developed Unit Integration and Performance Test Cases using Junit Selenium and Rational Function Tester Improved code reuse and performance by making effective use of various design patterns Used Python library Beautiful Soup for webscrappingss Fetched twitter feeds for certain important keyword using pythontwitter library Managed large datasets using Panda data frames and SQL Wrote and executed various MYSQL database queries from python using PythonMySQL connector and MySQL dB package TestDriven Development approach was used and Developed Merge jobs in Python to extract and load data into MySQL database Worked on SQL Server Integration Services SSIS and SQL Lite Developed methods for Create Read Update and Delete CRUD in Active Record Used Django evolution and manual SQL modifications able to modify Django models while retaining all data while site was in production mode Environment Python Celery Django Angular JQuery JavaScript AJAX HTMLXHTML XML MsSQL server TSQL Jasper GIT Reports REST ful Linux Python Developer HSBC Hyderabad Telangana February 2013 to December 2014 Responsibilities Worked with the Stakeholders gathered requirements developed high level design documents Have used Python libraries like NumPy SciPy Pandas for market analysis and done some machine learning using Python Analyzed various logs that are been generated and used various Python libraries to predictforecast next occurrence of event with various Python libraries Used Django framework in developing web applications to implement the model view control architecture MVC Refactored and extended large existing Django Python code base reducing the number of lines in code and duplication significantly Wrote Sub Queries Stored Procedures Triggers Cursors and Functions on MySQL and PostgreSQL database Experience with working on software changes based on the natural call flow with the customer instead of letting the system dictate the call flow Query Optimization through MYSQL server tools for quick response time and using Golang Experience with automation of linear call flows instead of static so the agents have access to an adaptive user interface Designed and Developed DB2 SQL Procedures and UNIX Shell Scripts for Data ImportExport and Conversions Wrote Python scripts to parse JSON documents and load the data in database and also used python scripts to update content in the database and manipulate files Responsible to set up REST API frame work using Django Flask Developed designed managed dashboard control panel for customers and Administrators using Django PostgreSQL API calls Performed some operations visualization on Oracle DB using libraries like MatPlotlib Pandas Environment PythonNumPySciPyPandasMatplotlibPostgreSQLHTMLCSSPySparkBootStrap JavascriptJQuery Database Developer Sitel Hyderabad Telangana June 2011 to February 2013 Designed the user interactive web pages as the frontend part of the web application using various web technologies like HTML JavaScript Angular JS JQuery and implemented CSS framework Bootstrap for better appearance and feel Wrote scripts to Import and Export data to CSV EXCEL formats from different environments using Python Developed web services that make database calls for inserts updates and select queries Fetched twitter feeds for certain important keyword using pythontwitter library Building complex SQL queries for data analysis and data extract Defining problems collecting data establishing facts and drawing valid conclusions Participated in the creation of technical documentation and training materials Determining where data sets should be loaded for application use or reporting Environment PythonHTML XML MsSQL server Excel CSS Education Masters in Business Administration in Business Administration University of the incarnate word Bachelors in Commerce in Commerce Osmania University Skills DATABASE DB2 JDBC MS ACCESS SQL SERVER",
    "unique_id": "ce7642fe-1717-4b11-814f-ddbf55f9ac3a"
}