{
    "clean_data": "Python Developer span lPythonspan span lDeveloperspan Python Developer InfosysApple iTunes Sunnyvale CA Engineering professional with 8 years of experience in Software development MasteringLeading in the development of applicationstools using Python for 6 years Experience with Web Development Web Services Python and the Djangoflask framework Proficient in Front end development experience using HTML XML CSS JQuery and JavaScript AngularJS Mastering Web Application Development using html JavaScript Expertise in ObjectOriented design and coding Good knowledge of various Design Patterns and UML Experience in developing webbased applications using Python 2X Django 1XFlask Experienced in using flask components like needs permission Principal for providing user permissions at granular level Proficient in SQL databases MS SQL MySQL Oracle and NoSQL databases like MongoDB Pymongo SQL and PLSQL programming developing complex code units database triggers and using the latest features to optimize performance Bulk Binds Materialized views Inline views Global Temporary Tables Experience in building frameworks and automating complex workflows using Python for Test Automation Experienced in writing SQL Queries Stored procedures functions packages tables views triggers Experience in working with Python ORM Libraries including Django ORM SQL Alchemy Good experience in working with Web services like Amazon EC2 AWS and Amazon s3 Handson experience in UNIX and LINUX Kernels Hands on experience in SVN Git JIRA and Bugzilla Good knowledge of web services with protocols SOAP REST Good knowledge of server Apache Tomcat Web logic Experienced in various types of testing such as Unit testing Integration testing User acceptance testing Functional testing Experience in writing test plans test cases test specifications and test coverage Good Experience in error and exceptional handling Proven ability to implement Continuous Integration and Continuous Deployment processes Having experienced in Agile Methodologies Scrum stories and sprints experience in a Python based environment along with data analytics data wrangling and Excel data extracts Performed numerous server migrations on both Linux and Windows servers Migrations include moving all clients and their data configuration settings testing and verifying Extensive knowledge on automated batch programs by UNIX shell Scripts file validations file downloads workflow executions Can handle writing technical and functional documents defined by the business requirements Outstanding communication analysis and outoftheboxcreative problem solving Experience in working with different operating systems Windows UNIX Linux and OS X Have flexibility and ability to learn and use new technologies and also to work in team environment as wells as independently to get things done Authorized to work in the US for any employer Work Experience Python Developer InfosysApple iTunes Sunnyvale CA January 2017 to Present Intelligent Data Analytics and AlertsiDAA Project Description The ETL Framework was used to do extensive auditing of data based on statistical analysis Auditing is done on data and gives a graphical and tabular view for the data The tabular structure is send to the user through email The various features for the tool is to provide Data Check Variance Check difference between data on the same period Recon Checkdifference between data between two clusters Various Quality scores are assigned daily and the dashboard loads the latest scores for the latest runs with the trend of last 14 days 2 weeks The various quality measures we track are Completeness Consistency Uniqueness Validity Accuracy Timeliness Responsibilities Responsible for gathering requirements system analysis design development testing and deployment Developed and enhanced ETL framework which checks DQMs on different databases and gets the counts validates the data between multiple environmentsClusters Designed and developed alerting system to framework users when ever the DQM runs the email alert contains DQM details and if it fails an incident is raised and ticket is created for the application teams Framework has multiple modules like LoadEdit DQM Executer ExportImport data from OracleHiveTeradataVerticaDruid LoadEdit is a command line API exposed to application teams for on boarding Excel templatethe DQMs into the Oracle DB Used Anaconda Python numpy pandas for reading the data from the input template Excel and loading the data into Oracle DB Executer module is an command line API which is envoked through Autosys with necessary params and this module uses the params for pulling the DQM metadata from Oracle Wrote Success Criteria logic for DQMs with 0 dimensions and Multiple Measures and also for Multiple dimensions and multiple measure Wrote custom python scripts for migrating the data from Hive to Oracle and vice versa which is envoked through a shell script using Autosys job scheduler and is schedule to run every day Wrote a python alerting custom code which works as a package and sends an alerting email with the DQM deails and for PASS FAIL NOT_EVAL and  cases Environment Anaconda Python numpy pandas Oracle cx_oracle Hadoop Teradata Vertica vertica_ pythonDruid Pycharm GIT Jenkins Python Developer WiproApple Sunnyvale CA August 2017 to December 2017 Project Description Particles formerly known as ProtoDB is an effort to track data population and coverage at a granular Protopath level across multiple releases and plan for future releases It is also an attempt to document at a granular level which specific subsets of existing data are consumed by services Historical and future Protopath data population statistics can be leveraged for a variety of use cases Responsibilities Responsible for gathering requirements system analysis design development testing and deployment Wrote Python scripts which periodically ingests data into Postgres and serves as the backend to a web server Worked on Jenkins creating jobs executing jobs in different environment creating triggers and configuring jobs Load and transform large data sets of structured semi structured and unstructured data using HadoopBig Data concepts Developed spark jobs using pyspark in test environment for faster data processing Working on Swaggerenabled REST API to serve as entrypoint for web UI and integrate with other applications Worked on Nodejs Protopath parser project to come up with all possible combinations of Protopath by analyzing the input for predicting the combination of incorrect inputs Working on designing and implementing a web application using PythonDjango for displaying the Maps data for every release and also providing a scope for generating a diff between the data for every release Working on Gradle utility to automate the build and deployment process Environment Python 27 Django Postgres Hadoop Pycharm Docker GIT Jenkins Gradle Python Developer WalmartLabs Bentonville AR April 2016 to July 2017 Responsibilities Worked on multiple projects like Taxonomy Feed Gate Way which deals with the product classification and providing a platform for sellers suppliers and MP sellers for updating the product and inventory in com Understand the business process variants and created the process flow for automating the adhoc request Developed and supported Taxonomy API RestAPI using Python and Flask Cerberus MongoDB Wrote python wrapper for Flask and EVE frame work for generating desired results of Taxonomy API Created client and server actions and added permissions for admins and nonadmin users by restricting individuals for a particular data set by using flask principal permissions and needs Developed an API that asynchronously distributes task using RabbitMQ and Celery Porting of data import jobs from cron jobs to distributed tasks leading to a speedup Efficiently performed all backend tasks from OPS up to the REST API interfacePortal frontend single handedly Deployed async jobs monitoring system using celery flower Wrote unittests and did code reviews Worked with search business and search team to implement dynamic rule updates to search using elasticsearch Created mapreduce job using python for creating sync between PTC configs and PTCs to remove unwanted attributes for products in com Used basic Hive queries for processing large sets of data used for analyzing the 1P 2P and 3P products and also for analyzing data from MP Sellers Sellers and Suppliers Developed Spark code using python for faster processing of data given by market place sellers for generating best specification and description of products Worked closely with the search team Machine learning for the title optimization of products by processing the product information given by the sellers Title Specifications Description etc Wrote Python normalizations scripts to find duplicate data in different environments Good Knowledge on MongoDB Workspaces Snapshots and patching documents in Snapshots Wrote scripts to integrate APIs with 3rd party applications Wrote scripts to Import and Export data to CSV EXCEL formats from different environments using Python and made a Celery action using REST API call Performed Did data validation and data cleaning process and data manipulation with pandas and numpy used for data visualization by reporting teams to genereate ranking for content provided by sellers Did data analysis miss value imputation with statistical methodologies using pandas numpy Worked under AgileScrum environment and handled production rollouts and issues Developed new and enhanced search features such as SYNONYM CANONICAL and ABBREVIATION for optimizing search results and relevancy JSONelasticsearchKibana Extensively used XLSX reader and writer modules to read write and analyze data and project the results as per the client request Used GIT and JENKINS for continuous integration and deployment Was a part of Holiday readiness support team starting from Thanksgiving to Christmas Environment Python 27 Flask Eve Celery Mongodb Hive Hadoop Event Postman Pycharm JIRA JSON Docker GIT Jenkins Linux Python Developer CVS Caremark Phoenix AZ June 2015 to March 2016 Responsibilities Design develop test deploy and maintain the website Developed entire frontend and backend modules using Python on Django Web Framework Designed and developed the UI of the website using HTML AJAX CSS and JavaScript Implemented SQL Alchemy which is a python library for complete access over SQL Designed and developed data management system using MySQL and wrote several queries to extractstore data Rewrite existing Java application in Python module to deliver certain format of data Wrote Python scripts to parse XML documents and load the data in database Generated property list for every application dynamically using Python Wrote Automation test cases using Selenium WebDriver using Python API Responsible for search engine optimization to improve the visibility of the website Used Apache htaccess to provide authentication system for DjangoMySQL sites Handled all the client side validation using JavaScript Performed testing using Djangos Test Module Added support for Amazon AWS S3 and RDS to host staticmedia files and the database into Amazon Cloud Developed MapReduce jobs in python data cleaning and data processing Involved in AJAX driven application by invoking web servicesAPI and parsing the JSON response Involved in writing application level code to interact with APIs Web Services using JSON Deployed the project into Heroku using Django and GIT version control system Designed and Developed Restful webservices for both consumer and producer using Django Swagger Gunicorn Creating unit testregression test framework for workingnew code Using version control tool to coordinate teamdevelopment Responsible for debugging and troubleshooting the web application Environment Python 27 Django 18 Swagger Hadoop MySQL XML HTML XHTML CSS AJAX JSON JavaScript Apache Web Server MYSQL and Linux Python Developer ABC Insurance Bloomington IL January 2014 to May 2015 Responsibilities Responsible for gathering requirements system analysis design development testing and deployment Worked on Frontend UI using HTML5 CSS3 JavaScript Bootstrap and Jquery for event handling popup dialogs menus and skinning Developed tools using Python Shell scripting XML to automate some of the menial tasks Involved in building database Model APIs and Views utilizing PythonDjango in order to build an interactive web based solution Used Python to place data into JSON for Django Webapp Used Python scripts to update content in the database and manipulate files Used Beautiful Soup for selecting particular DOM elements when parsing HTML Used Apache MongoDB NoSQL in AWS Linux instance to store and analyze data Restructuring data for faster distributed queries to aid caching Made Django web based apps for Insurance premium calculations Implemented jobs in Python to extract and load data into MySQL database Created servermonitoring daemon with Psutil supported by Django app for analytics which I created Also researched big data solutions with MongoDB database Deployed the project into Heroku using GIT version control system Involved in writing application level code to interact with Rest APIs Web Services using JSON Wrote validation scripts in SQL to validate data loading Identified several hidden bugs caused by complicated multithreading issues such as race conditions caused by asynchronous events and resolved them Interfacing with supervisors artists systems administrators and production to ensure production deadlines are met Environment Python 27 Django JSON REST HTML XHTML CSS AJAX JavaScript Apache Web Server Heroku SOAP Git MongoDB UNIX Python Developer US Cellular Chicago IL November 2013 to November 2014 Responsibilities Involved in understanding the current business process defining scope of the project along with position statement Reengineered various modules for implementing changes and creating efficient system Developed dynamic web pages using python Django Frameworks Used Python and Django creating for XML processing data exchange and business logic implementation Used python scripts to update content in the database and manipulate files Resolved issues and improvised the process to ensure a stable and accurate solution Generated Python Django Forms to record data of online users Python OO Design code for manufacturing quality monitoring logging and debugging code optimization Writing Unit Functional and Integration test cases for Cloud Computing applications on AWS using Python with boto library Held meetings with client and worked all alone for entire internal project with limited help from the client Worked on writing and as well as read data from csv and excel file formats Provided technical and business knowledge to clients Connected Flex from Backend Controller using different API services Working with the architect developers on business and technical issues helping in designing the system and testers to ensure all requirements are correctly translated Managed requirements and tasks using JIRA Data mapping logical data modeling created class diagrams and ER diagrams and used SQL queries to filter data within the Oracle database Environment Python Django Java MySQL XML HTML XHTML CSS AJAX JSON JavaScript Apache Web Server MYSQL and Linux JAVA Python Developer HILTI Hyderabad Telangana May 2010 to September 2013 India Responsibilities Developed Python based API RESTful Web Service to track sales and perform sales analysis using Flask SQLAlchemy and PostgreSQL Developed and designed an API RESTful Web Service for the companys website Developed and designed email marketing campaigns using HTML and CSS Maintained customers relationship management databases MySQL PostgreSQL Developed server based web traffic statistical analysis tool using Flask Pandas Implemented and tested many features for dashboard using Flask CSS and JavaScript Managed companies virtual servers at Amazon EC2 S3 Designed and developed UseCase Diagrams Class Diagrams and Object Diagrams using UML Rational Rose for OOAOOD techniques Designed and developed components using JavaJ2EE Created UI using HTML CSS and JavaScripts Created Servlets and Beans to implement Business Logic Used SAXDOM Parser for parsing the data to Oracle Database Designed and created backend data access modules using PLSQL stored procedures and Oracle 9i Created database access layer using JDBC and PLSQL stored procedures Designed object model data model tables constraints necessary stored procedures functions triggers and packages for Oracle Database Worked on Socket communication layers and multithreading on Linux Worked on SNMP interfaces Environment Python Flask SQLAlchemy PostgreSQL SQL J2EE HTML CSS JDBC Servlets SNMP JavaScript Oracle Apache Web Server and Linux Education Masters Skills Apache 6 years database 6 years HTML 6 years Linux 7 years Python 8 years C Flask Java Javascript Django Additional Information Technical Skills Languages Python Java C SQL Shell Scripting Web Technologies HTMLDHTML JavaScript AngularJS XML Development Tools IDEs Pycharm Eclipse Sublimetext Atom Komodo WebApplication Servers Nginx Apache WebSphere WebLogic Gunicorn Python Framework Django Flask Web2py Bottle Database SQL SERVER MySQL Oracle Sqlite3 MongoDB Cloud Computing Amazon EC2S3 Heroku Google App Engine Bug Tracking Tools Jira Bugzilla Platforms Windows UNIX LINUXMac Version Control SVN GIT CVS TFS Methodologies Agile Methodology Scum",
    "entities": [
        "Rest APIs Web Services",
        "Oracle Wrote Success Criteria",
        "HTML AJAX CSS",
        "Oracle 9i Created",
        "UseCase Diagrams Class Diagrams and Object Diagrams",
        "UNIX",
        "Writing Unit Functional and Integration",
        "Interfacing",
        "Principal",
        "Python for Test Automation Experienced",
        "Mastering Web Application Development",
        "DQM",
        "Heroku",
        "Oracle cx_oracle Hadoop Teradata Vertica",
        "ER",
        "3P",
        "Linux Education Masters Skills",
        "JavaScript Implemented SQL Alchemy",
        "Import and Export",
        "XML",
        "Telangana",
        "SQL Designed",
        "Multiple Measures",
        "vertica",
        "Project Description",
        "IL",
        "Shell",
        "csv",
        "Web Development Web Services Python",
        "LoadEdit DQM Executer ExportImport",
        "Working on Swaggerenabled REST API",
        "Amazon",
        "Oracle DB Executer",
        "Python",
        "Amazon AWS S3",
        "Developed",
        "Reengineered",
        "WebSphere WebLogic Gunicorn Python Framework Django Flask",
        "UML",
        "Protopath",
        "Oracle Database Worked",
        "JSON for Django Webapp Used Python",
        "Linux",
        "HadoopBig Data",
        "API RESTful Web Service",
        "Present Intelligent Data Analytics",
        "Flask",
        "ObjectOriented",
        "Nodejs Protopath",
        "SYNONYM CANONICAL",
        "DOM",
        "RDS",
        "Efficiently",
        "2P",
        "Celery",
        "Views",
        "Autosys",
        "PythonDjango",
        "GIT",
        "Various Quality",
        "JavaJ2EE Created UI",
        "CSV",
        "JIRA Data",
        "HTML CSS",
        "API",
        "US",
        "The ETL Framework",
        "UML Rational Rose",
        "Snapshots Wrote",
        "AWS",
        "Framework",
        "Oracle",
        "Pycharm GIT Jenkins Python",
        "Windows UNIX Linux",
        "Postgres",
        "JENKINS",
        "Sunnyvale",
        "HTML",
        "Taxonomy API Created",
        "Responsibilities Responsible",
        "Linux Python Developer ABC Insurance",
        "Python ORM Libraries",
        "SQL",
        "Flask CSS",
        "lPythonspan",
        "Chicago",
        "Auditing",
        "HTML XML CSS JQuery",
        "Hive",
        "Handson",
        "Continuous Deployment",
        "ETL",
        "Working on Gradle",
        "Python API Responsible",
        "JavaScripts Created Servlets",
        "Performed",
        "Version Control SVN",
        "Front",
        "Continuous Integration",
        "Pymongo",
        "Selenium WebDriver",
        "SQL Queries Stored",
        "Oracle Database Designed",
        "JavaScript Oracle",
        "CSS Maintained",
        "NoSQL",
        "Developed Restful",
        "Djangos Test Module Added",
        "Responsibilities Design"
    ],
    "experience": "Experience with Web Development Web Services Python and the Djangoflask framework Proficient in Front end development experience using HTML XML CSS JQuery and JavaScript AngularJS Mastering Web Application Development using html JavaScript Expertise in ObjectOriented design and coding Good knowledge of various Design Patterns and UML Experience in developing webbased applications using Python 2X Django 1XFlask Experienced in using flask components like needs permission Principal for providing user permissions at granular level Proficient in SQL databases MS SQL MySQL Oracle and NoSQL databases like MongoDB Pymongo SQL and PLSQL programming developing complex code units database triggers and using the latest features to optimize performance Bulk Binds Materialized views Inline views Global Temporary Tables Experience in building frameworks and automating complex workflows using Python for Test Automation Experienced in writing SQL Queries Stored procedures functions packages tables views triggers Experience in working with Python ORM Libraries including Django ORM SQL Alchemy Good experience in working with Web services like Amazon EC2 AWS and Amazon s3 Handson experience in UNIX and LINUX Kernels Hands on experience in SVN Git JIRA and Bugzilla Good knowledge of web services with protocols SOAP REST Good knowledge of server Apache Tomcat Web logic Experienced in various types of testing such as Unit testing Integration testing User acceptance testing Functional testing Experience in writing test plans test cases test specifications and test coverage Good Experience in error and exceptional handling Proven ability to implement Continuous Integration and Continuous Deployment processes Having experienced in Agile Methodologies Scrum stories and sprints experience in a Python based environment along with data analytics data wrangling and Excel data extracts Performed numerous server migrations on both Linux and Windows servers Migrations include moving all clients and their data configuration settings testing and verifying Extensive knowledge on automated batch programs by UNIX shell Scripts file validations file downloads workflow executions Can handle writing technical and functional documents defined by the business requirements Outstanding communication analysis and outoftheboxcreative problem solving Experience in working with different operating systems Windows UNIX Linux and OS X Have flexibility and ability to learn and use new technologies and also to work in team environment as wells as independently to get things done Authorized to work in the US for any employer Work Experience Python Developer InfosysApple iTunes Sunnyvale CA January 2017 to Present Intelligent Data Analytics and AlertsiDAA Project Description The ETL Framework was used to do extensive auditing of data based on statistical analysis Auditing is done on data and gives a graphical and tabular view for the data The tabular structure is send to the user through email The various features for the tool is to provide Data Check Variance Check difference between data on the same period Recon Checkdifference between data between two clusters Various Quality scores are assigned daily and the dashboard loads the latest scores for the latest runs with the trend of last 14 days 2 weeks The various quality measures we track are Completeness Consistency Uniqueness Validity Accuracy Timeliness Responsibilities Responsible for gathering requirements system analysis design development testing and deployment Developed and enhanced ETL framework which checks DQMs on different databases and gets the counts validates the data between multiple environmentsClusters Designed and developed alerting system to framework users when ever the DQM runs the email alert contains DQM details and if it fails an incident is raised and ticket is created for the application teams Framework has multiple modules like LoadEdit DQM Executer ExportImport data from OracleHiveTeradataVerticaDruid LoadEdit is a command line API exposed to application teams for on boarding Excel templatethe DQMs into the Oracle DB Used Anaconda Python numpy pandas for reading the data from the input template Excel and loading the data into Oracle DB Executer module is an command line API which is envoked through Autosys with necessary params and this module uses the params for pulling the DQM metadata from Oracle Wrote Success Criteria logic for DQMs with 0 dimensions and Multiple Measures and also for Multiple dimensions and multiple measure Wrote custom python scripts for migrating the data from Hive to Oracle and vice versa which is envoked through a shell script using Autosys job scheduler and is schedule to run every day Wrote a python alerting custom code which works as a package and sends an alerting email with the DQM deails and for PASS FAIL NOT_EVAL and   cases Environment Anaconda Python numpy pandas Oracle cx_oracle Hadoop Teradata Vertica vertica _ pythonDruid Pycharm GIT Jenkins Python Developer WiproApple Sunnyvale CA August 2017 to December 2017 Project Description Particles formerly known as ProtoDB is an effort to track data population and coverage at a granular Protopath level across multiple releases and plan for future releases It is also an attempt to document at a granular level which specific subsets of existing data are consumed by services Historical and future Protopath data population statistics can be leveraged for a variety of use cases Responsibilities Responsible for gathering requirements system analysis design development testing and deployment Wrote Python scripts which periodically ingests data into Postgres and serves as the backend to a web server Worked on Jenkins creating jobs executing jobs in different environment creating triggers and configuring jobs Load and transform large data sets of structured semi structured and unstructured data using HadoopBig Data concepts Developed spark jobs using pyspark in test environment for faster data processing Working on Swaggerenabled REST API to serve as entrypoint for web UI and integrate with other applications Worked on Nodejs Protopath parser project to come up with all possible combinations of Protopath by analyzing the input for predicting the combination of incorrect inputs Working on designing and implementing a web application using PythonDjango for displaying the Maps data for every release and also providing a scope for generating a diff between the data for every release Working on Gradle utility to automate the build and deployment process Environment Python 27 Django Postgres Hadoop Pycharm Docker GIT Jenkins Gradle Python Developer WalmartLabs Bentonville AR April 2016 to July 2017 Responsibilities Worked on multiple projects like Taxonomy Feed Gate Way which deals with the product classification and providing a platform for sellers suppliers and MP sellers for updating the product and inventory in com Understand the business process variants and created the process flow for automating the adhoc request Developed and supported Taxonomy API RestAPI using Python and Flask Cerberus MongoDB Wrote python wrapper for Flask and EVE frame work for generating desired results of Taxonomy API Created client and server actions and added permissions for admins and nonadmin users by restricting individuals for a particular data set by using flask principal permissions and needs Developed an API that asynchronously distributes task using RabbitMQ and Celery Porting of data import jobs from cron jobs to distributed tasks leading to a speedup Efficiently performed all backend tasks from OPS up to the REST API interfacePortal frontend single handedly Deployed async jobs monitoring system using celery flower Wrote unittests and did code reviews Worked with search business and search team to implement dynamic rule updates to search using elasticsearch Created mapreduce job using python for creating sync between PTC configs and PTCs to remove unwanted attributes for products in com Used basic Hive queries for processing large sets of data used for analyzing the 1P 2P and 3P products and also for analyzing data from MP Sellers Sellers and Suppliers Developed Spark code using python for faster processing of data given by market place sellers for generating best specification and description of products Worked closely with the search team Machine learning for the title optimization of products by processing the product information given by the sellers Title Specifications Description etc Wrote Python normalizations scripts to find duplicate data in different environments Good Knowledge on MongoDB Workspaces Snapshots and patching documents in Snapshots Wrote scripts to integrate APIs with 3rd party applications Wrote scripts to Import and Export data to CSV EXCEL formats from different environments using Python and made a Celery action using REST API call Performed Did data validation and data cleaning process and data manipulation with pandas and numpy used for data visualization by reporting teams to genereate ranking for content provided by sellers Did data analysis miss value imputation with statistical methodologies using pandas numpy Worked under AgileScrum environment and handled production rollouts and issues Developed new and enhanced search features such as SYNONYM CANONICAL and ABBREVIATION for optimizing search results and relevancy JSONelasticsearchKibana Extensively used XLSX reader and writer modules to read write and analyze data and project the results as per the client request Used GIT and JENKINS for continuous integration and deployment Was a part of Holiday readiness support team starting from Thanksgiving to Christmas Environment Python 27 Flask Eve Celery Mongodb Hive Hadoop Event Postman Pycharm JIRA JSON Docker GIT Jenkins Linux Python Developer CVS Caremark Phoenix AZ June 2015 to March 2016 Responsibilities Design develop test deploy and maintain the website Developed entire frontend and backend modules using Python on Django Web Framework Designed and developed the UI of the website using HTML AJAX CSS and JavaScript Implemented SQL Alchemy which is a python library for complete access over SQL Designed and developed data management system using MySQL and wrote several queries to extractstore data Rewrite existing Java application in Python module to deliver certain format of data Wrote Python scripts to parse XML documents and load the data in database Generated property list for every application dynamically using Python Wrote Automation test cases using Selenium WebDriver using Python API Responsible for search engine optimization to improve the visibility of the website Used Apache htaccess to provide authentication system for DjangoMySQL sites Handled all the client side validation using JavaScript Performed testing using Djangos Test Module Added support for Amazon AWS S3 and RDS to host staticmedia files and the database into Amazon Cloud Developed MapReduce jobs in python data cleaning and data processing Involved in AJAX driven application by invoking web servicesAPI and parsing the JSON response Involved in writing application level code to interact with APIs Web Services using JSON Deployed the project into Heroku using Django and GIT version control system Designed and Developed Restful webservices for both consumer and producer using Django Swagger Gunicorn Creating unit testregression test framework for workingnew code Using version control tool to coordinate teamdevelopment Responsible for debugging and troubleshooting the web application Environment Python 27 Django 18 Swagger Hadoop MySQL XML HTML XHTML CSS AJAX JSON JavaScript Apache Web Server MYSQL and Linux Python Developer ABC Insurance Bloomington IL January 2014 to May 2015 Responsibilities Responsible for gathering requirements system analysis design development testing and deployment Worked on Frontend UI using HTML5 CSS3 JavaScript Bootstrap and Jquery for event handling popup dialogs menus and skinning Developed tools using Python Shell scripting XML to automate some of the menial tasks Involved in building database Model APIs and Views utilizing PythonDjango in order to build an interactive web based solution Used Python to place data into JSON for Django Webapp Used Python scripts to update content in the database and manipulate files Used Beautiful Soup for selecting particular DOM elements when parsing HTML Used Apache MongoDB NoSQL in AWS Linux instance to store and analyze data Restructuring data for faster distributed queries to aid caching Made Django web based apps for Insurance premium calculations Implemented jobs in Python to extract and load data into MySQL database Created servermonitoring daemon with Psutil supported by Django app for analytics which I created Also researched big data solutions with MongoDB database Deployed the project into Heroku using GIT version control system Involved in writing application level code to interact with Rest APIs Web Services using JSON Wrote validation scripts in SQL to validate data loading Identified several hidden bugs caused by complicated multithreading issues such as race conditions caused by asynchronous events and resolved them Interfacing with supervisors artists systems administrators and production to ensure production deadlines are met Environment Python 27 Django JSON REST HTML XHTML CSS AJAX JavaScript Apache Web Server Heroku SOAP Git MongoDB UNIX Python Developer US Cellular Chicago IL November 2013 to November 2014 Responsibilities Involved in understanding the current business process defining scope of the project along with position statement Reengineered various modules for implementing changes and creating efficient system Developed dynamic web pages using python Django Frameworks Used Python and Django creating for XML processing data exchange and business logic implementation Used python scripts to update content in the database and manipulate files Resolved issues and improvised the process to ensure a stable and accurate solution Generated Python Django Forms to record data of online users Python OO Design code for manufacturing quality monitoring logging and debugging code optimization Writing Unit Functional and Integration test cases for Cloud Computing applications on AWS using Python with boto library Held meetings with client and worked all alone for entire internal project with limited help from the client Worked on writing and as well as read data from csv and excel file formats Provided technical and business knowledge to clients Connected Flex from Backend Controller using different API services Working with the architect developers on business and technical issues helping in designing the system and testers to ensure all requirements are correctly translated Managed requirements and tasks using JIRA Data mapping logical data modeling created class diagrams and ER diagrams and used SQL queries to filter data within the Oracle database Environment Python Django Java MySQL XML HTML XHTML CSS AJAX JSON JavaScript Apache Web Server MYSQL and Linux JAVA Python Developer HILTI Hyderabad Telangana May 2010 to September 2013 India Responsibilities Developed Python based API RESTful Web Service to track sales and perform sales analysis using Flask SQLAlchemy and PostgreSQL Developed and designed an API RESTful Web Service for the companys website Developed and designed email marketing campaigns using HTML and CSS Maintained customers relationship management databases MySQL PostgreSQL Developed server based web traffic statistical analysis tool using Flask Pandas Implemented and tested many features for dashboard using Flask CSS and JavaScript Managed companies virtual servers at Amazon EC2 S3 Designed and developed UseCase Diagrams Class Diagrams and Object Diagrams using UML Rational Rose for OOAOOD techniques Designed and developed components using JavaJ2EE Created UI using HTML CSS and JavaScripts Created Servlets and Beans to implement Business Logic Used SAXDOM Parser for parsing the data to Oracle Database Designed and created backend data access modules using PLSQL stored procedures and Oracle 9i Created database access layer using JDBC and PLSQL stored procedures Designed object model data model tables constraints necessary stored procedures functions triggers and packages for Oracle Database Worked on Socket communication layers and multithreading on Linux Worked on SNMP interfaces Environment Python Flask SQLAlchemy PostgreSQL SQL J2EE HTML CSS JDBC Servlets SNMP JavaScript Oracle Apache Web Server and Linux Education Masters Skills Apache 6 years database 6 years HTML 6 years Linux 7 years Python 8 years C Flask Java Javascript Django Additional Information Technical Skills Languages Python Java C SQL Shell Scripting Web Technologies HTMLDHTML JavaScript AngularJS XML Development Tools IDEs Pycharm Eclipse Sublimetext Atom Komodo WebApplication Servers Nginx Apache WebSphere WebLogic Gunicorn Python Framework Django Flask Web2py Bottle Database SQL SERVER MySQL Oracle Sqlite3 MongoDB Cloud Computing Amazon EC2S3 Heroku Google App Engine Bug Tracking Tools Jira Bugzilla Platforms Windows UNIX LINUXMac Version Control SVN GIT CVS TFS Methodologies Agile Methodology Scum",
    "extracted_keywords": [
        "Python",
        "Developer",
        "lPythonspan",
        "span",
        "lDeveloperspan",
        "Python",
        "Developer",
        "InfosysApple",
        "iTunes",
        "Sunnyvale",
        "CA",
        "Engineering",
        "years",
        "experience",
        "Software",
        "development",
        "MasteringLeading",
        "development",
        "applicationstools",
        "Python",
        "years",
        "Experience",
        "Web",
        "Development",
        "Web",
        "Services",
        "Python",
        "Djangoflask",
        "framework",
        "Proficient",
        "Front",
        "end",
        "development",
        "experience",
        "HTML",
        "XML",
        "CSS",
        "JQuery",
        "JavaScript",
        "AngularJS",
        "Mastering",
        "Web",
        "Application",
        "Development",
        "html",
        "JavaScript",
        "Expertise",
        "ObjectOriented",
        "design",
        "knowledge",
        "Design",
        "Patterns",
        "UML",
        "Experience",
        "applications",
        "Python",
        "2X",
        "Django",
        "1XFlask",
        "flask",
        "components",
        "needs",
        "permission",
        "Principal",
        "user",
        "permissions",
        "level",
        "Proficient",
        "SQL",
        "MS",
        "SQL",
        "MySQL",
        "Oracle",
        "NoSQL",
        "MongoDB",
        "Pymongo",
        "SQL",
        "PLSQL",
        "programming",
        "code",
        "units",
        "database",
        "triggers",
        "features",
        "performance",
        "Bulk",
        "Binds",
        "views",
        "Inline",
        "Global",
        "Temporary",
        "Tables",
        "Experience",
        "frameworks",
        "workflows",
        "Python",
        "Test",
        "Automation",
        "SQL",
        "Queries",
        "procedures",
        "functions",
        "packages",
        "tables",
        "views",
        "Experience",
        "Python",
        "ORM",
        "Libraries",
        "Django",
        "ORM",
        "SQL",
        "Alchemy",
        "Good",
        "experience",
        "Web",
        "services",
        "Amazon",
        "EC2",
        "AWS",
        "Amazon",
        "s3",
        "Handson",
        "experience",
        "UNIX",
        "LINUX",
        "Kernels",
        "Hands",
        "experience",
        "SVN",
        "Git",
        "JIRA",
        "Bugzilla",
        "knowledge",
        "web",
        "services",
        "protocols",
        "SOAP",
        "REST",
        "knowledge",
        "server",
        "Apache",
        "Tomcat",
        "Web",
        "logic",
        "types",
        "testing",
        "Unit",
        "testing",
        "Integration",
        "testing",
        "User",
        "acceptance",
        "testing",
        "Experience",
        "test",
        "plans",
        "test",
        "cases",
        "specifications",
        "test",
        "coverage",
        "Good",
        "Experience",
        "error",
        "ability",
        "Continuous",
        "Integration",
        "Continuous",
        "Deployment",
        "processes",
        "Agile",
        "Methodologies",
        "Scrum",
        "stories",
        "sprints",
        "experience",
        "Python",
        "environment",
        "data",
        "analytics",
        "data",
        "Excel",
        "data",
        "server",
        "migrations",
        "Linux",
        "Windows",
        "servers",
        "Migrations",
        "clients",
        "data",
        "configuration",
        "settings",
        "knowledge",
        "batch",
        "programs",
        "UNIX",
        "shell",
        "Scripts",
        "file",
        "validations",
        "file",
        "downloads",
        "executions",
        "documents",
        "business",
        "requirements",
        "communication",
        "analysis",
        "problem",
        "Experience",
        "operating",
        "systems",
        "Windows",
        "UNIX",
        "Linux",
        "OS",
        "X",
        "flexibility",
        "ability",
        "technologies",
        "team",
        "environment",
        "wells",
        "things",
        "US",
        "employer",
        "Work",
        "Experience",
        "Python",
        "Developer",
        "InfosysApple",
        "iTunes",
        "Sunnyvale",
        "CA",
        "January",
        "Present",
        "Intelligent",
        "Data",
        "Analytics",
        "Project",
        "Description",
        "ETL",
        "Framework",
        "auditing",
        "data",
        "analysis",
        "Auditing",
        "data",
        "view",
        "data",
        "structure",
        "user",
        "email",
        "features",
        "tool",
        "Data",
        "Check",
        "Variance",
        "Check",
        "difference",
        "data",
        "period",
        "Recon",
        "Checkdifference",
        "data",
        "clusters",
        "Various",
        "Quality",
        "scores",
        "dashboard",
        "scores",
        "runs",
        "trend",
        "days",
        "weeks",
        "quality",
        "measures",
        "Completeness",
        "Consistency",
        "Uniqueness",
        "Validity",
        "Accuracy",
        "Timeliness",
        "Responsibilities",
        "requirements",
        "system",
        "analysis",
        "design",
        "development",
        "testing",
        "deployment",
        "Developed",
        "ETL",
        "framework",
        "DQMs",
        "databases",
        "counts",
        "data",
        "environmentsClusters",
        "system",
        "users",
        "DQM",
        "email",
        "alert",
        "DQM",
        "details",
        "incident",
        "ticket",
        "application",
        "teams",
        "Framework",
        "modules",
        "LoadEdit",
        "DQM",
        "Executer",
        "ExportImport",
        "data",
        "LoadEdit",
        "command",
        "line",
        "API",
        "application",
        "teams",
        "boarding",
        "Excel",
        "templatethe",
        "DQMs",
        "Oracle",
        "DB",
        "Anaconda",
        "Python",
        "numpy",
        "data",
        "input",
        "template",
        "Excel",
        "data",
        "Oracle",
        "DB",
        "Executer",
        "module",
        "command",
        "line",
        "API",
        "Autosys",
        "params",
        "module",
        "params",
        "DQM",
        "metadata",
        "Oracle",
        "Wrote",
        "Success",
        "Criteria",
        "logic",
        "DQMs",
        "dimensions",
        "Multiple",
        "Measures",
        "dimensions",
        "measure",
        "Wrote",
        "custom",
        "python",
        "scripts",
        "data",
        "Hive",
        "Oracle",
        "vice",
        "versa",
        "shell",
        "script",
        "Autosys",
        "job",
        "scheduler",
        "schedule",
        "day",
        "python",
        "custom",
        "code",
        "package",
        "email",
        "DQM",
        "deails",
        "PASS",
        "FAIL",
        "NOT_EVAL",
        "cases",
        "Environment",
        "Anaconda",
        "Python",
        "numpy",
        "Oracle",
        "cx_oracle",
        "Hadoop",
        "Teradata",
        "Vertica",
        "vertica",
        "_",
        "pythonDruid",
        "Pycharm",
        "GIT",
        "Jenkins",
        "Python",
        "Developer",
        "WiproApple",
        "Sunnyvale",
        "CA",
        "August",
        "December",
        "Project",
        "Description",
        "Particles",
        "ProtoDB",
        "effort",
        "data",
        "population",
        "coverage",
        "Protopath",
        "level",
        "releases",
        "plan",
        "releases",
        "attempt",
        "level",
        "subsets",
        "data",
        "services",
        "Historical",
        "Protopath",
        "data",
        "population",
        "statistics",
        "variety",
        "use",
        "cases",
        "Responsibilities",
        "requirements",
        "system",
        "analysis",
        "design",
        "development",
        "testing",
        "deployment",
        "Wrote",
        "Python",
        "scripts",
        "data",
        "Postgres",
        "backend",
        "web",
        "server",
        "Jenkins",
        "jobs",
        "jobs",
        "environment",
        "triggers",
        "jobs",
        "Load",
        "data",
        "sets",
        "data",
        "HadoopBig",
        "Data",
        "concepts",
        "spark",
        "jobs",
        "pyspark",
        "test",
        "environment",
        "data",
        "Working",
        "Swaggerenabled",
        "REST",
        "API",
        "entrypoint",
        "web",
        "UI",
        "applications",
        "Nodejs",
        "Protopath",
        "parser",
        "project",
        "combinations",
        "Protopath",
        "input",
        "combination",
        "inputs",
        "Working",
        "web",
        "application",
        "PythonDjango",
        "Maps",
        "data",
        "release",
        "scope",
        "diff",
        "data",
        "release",
        "Gradle",
        "utility",
        "build",
        "deployment",
        "process",
        "Environment",
        "Python",
        "Django",
        "Postgres",
        "Hadoop",
        "Pycharm",
        "Docker",
        "GIT",
        "Jenkins",
        "Gradle",
        "Python",
        "Developer",
        "WalmartLabs",
        "Bentonville",
        "AR",
        "April",
        "July",
        "Responsibilities",
        "projects",
        "Taxonomy",
        "Feed",
        "Gate",
        "Way",
        "product",
        "classification",
        "platform",
        "sellers",
        "suppliers",
        "MP",
        "sellers",
        "product",
        "inventory",
        "com",
        "business",
        "process",
        "variants",
        "process",
        "flow",
        "request",
        "Taxonomy",
        "API",
        "RestAPI",
        "Python",
        "Flask",
        "Cerberus",
        "Wrote",
        "python",
        "wrapper",
        "Flask",
        "EVE",
        "frame",
        "work",
        "results",
        "Taxonomy",
        "API",
        "client",
        "server",
        "actions",
        "permissions",
        "admins",
        "nonadmin",
        "users",
        "individuals",
        "data",
        "flask",
        "permissions",
        "API",
        "task",
        "RabbitMQ",
        "Celery",
        "Porting",
        "data",
        "import",
        "jobs",
        "cron",
        "jobs",
        "tasks",
        "speedup",
        "tasks",
        "OPS",
        "REST",
        "API",
        "interfacePortal",
        "async",
        "jobs",
        "system",
        "celery",
        "flower",
        "Wrote",
        "unittests",
        "code",
        "reviews",
        "search",
        "business",
        "search",
        "team",
        "rule",
        "updates",
        "elasticsearch",
        "Created",
        "mapreduce",
        "job",
        "python",
        "sync",
        "configs",
        "PTCs",
        "attributes",
        "products",
        "com",
        "Hive",
        "queries",
        "sets",
        "data",
        "1P",
        "2P",
        "3P",
        "products",
        "data",
        "MP",
        "Sellers",
        "Sellers",
        "Suppliers",
        "Spark",
        "code",
        "python",
        "processing",
        "data",
        "market",
        "place",
        "sellers",
        "specification",
        "description",
        "products",
        "search",
        "team",
        "Machine",
        "title",
        "optimization",
        "products",
        "product",
        "information",
        "sellers",
        "Title",
        "Specifications",
        "Description",
        "Wrote",
        "Python",
        "normalizations",
        "data",
        "environments",
        "Good",
        "Knowledge",
        "Workspaces",
        "Snapshots",
        "documents",
        "Snapshots",
        "scripts",
        "APIs",
        "party",
        "applications",
        "scripts",
        "Import",
        "Export",
        "data",
        "CSV",
        "EXCEL",
        "formats",
        "environments",
        "Python",
        "Celery",
        "action",
        "REST",
        "API",
        "call",
        "Performed",
        "data",
        "validation",
        "data",
        "cleaning",
        "process",
        "data",
        "manipulation",
        "pandas",
        "numpy",
        "data",
        "visualization",
        "teams",
        "content",
        "sellers",
        "data",
        "analysis",
        "value",
        "imputation",
        "methodologies",
        "pandas",
        "numpy",
        "Worked",
        "AgileScrum",
        "environment",
        "production",
        "rollouts",
        "issues",
        "search",
        "features",
        "SYNONYM",
        "CANONICAL",
        "ABBREVIATION",
        "search",
        "results",
        "relevancy",
        "JSONelasticsearchKibana",
        "XLSX",
        "reader",
        "writer",
        "modules",
        "data",
        "results",
        "client",
        "request",
        "GIT",
        "JENKINS",
        "integration",
        "deployment",
        "part",
        "Holiday",
        "readiness",
        "support",
        "team",
        "Thanksgiving",
        "Christmas",
        "Environment",
        "Python",
        "Flask",
        "Eve",
        "Celery",
        "Mongodb",
        "Hive",
        "Hadoop",
        "Event",
        "Postman",
        "Pycharm",
        "JIRA",
        "JSON",
        "Docker",
        "GIT",
        "Jenkins",
        "Linux",
        "Python",
        "Developer",
        "CVS",
        "Caremark",
        "Phoenix",
        "AZ",
        "June",
        "March",
        "Responsibilities",
        "Design",
        "test",
        "deploy",
        "website",
        "frontend",
        "modules",
        "Python",
        "Django",
        "Web",
        "Framework",
        "UI",
        "website",
        "HTML",
        "AJAX",
        "CSS",
        "JavaScript",
        "SQL",
        "Alchemy",
        "library",
        "access",
        "SQL",
        "data",
        "management",
        "system",
        "MySQL",
        "queries",
        "data",
        "Rewrite",
        "Java",
        "application",
        "Python",
        "module",
        "format",
        "data",
        "Wrote",
        "Python",
        "scripts",
        "XML",
        "documents",
        "data",
        "database",
        "property",
        "list",
        "application",
        "Python",
        "Wrote",
        "Automation",
        "test",
        "cases",
        "Selenium",
        "WebDriver",
        "API",
        "search",
        "engine",
        "optimization",
        "visibility",
        "website",
        "Apache",
        "htaccess",
        "authentication",
        "system",
        "DjangoMySQL",
        "sites",
        "client",
        "side",
        "validation",
        "JavaScript",
        "Performed",
        "testing",
        "Djangos",
        "Test",
        "Module",
        "support",
        "Amazon",
        "AWS",
        "S3",
        "RDS",
        "files",
        "database",
        "Amazon",
        "Cloud",
        "MapReduce",
        "jobs",
        "python",
        "data",
        "cleaning",
        "data",
        "processing",
        "AJAX",
        "application",
        "web",
        "servicesAPI",
        "response",
        "application",
        "level",
        "code",
        "APIs",
        "Web",
        "Services",
        "JSON",
        "project",
        "Heroku",
        "Django",
        "GIT",
        "version",
        "control",
        "system",
        "webservices",
        "consumer",
        "producer",
        "Django",
        "Swagger",
        "Gunicorn",
        "Creating",
        "unit",
        "testregression",
        "test",
        "framework",
        "code",
        "version",
        "control",
        "tool",
        "teamdevelopment",
        "web",
        "application",
        "Environment",
        "Python",
        "Django",
        "Swagger",
        "Hadoop",
        "MySQL",
        "XML",
        "HTML",
        "XHTML",
        "CSS",
        "AJAX",
        "JSON",
        "JavaScript",
        "Apache",
        "Web",
        "Server",
        "MYSQL",
        "Linux",
        "Python",
        "Developer",
        "ABC",
        "Insurance",
        "Bloomington",
        "IL",
        "January",
        "May",
        "Responsibilities",
        "requirements",
        "system",
        "analysis",
        "design",
        "development",
        "testing",
        "deployment",
        "Frontend",
        "UI",
        "HTML5",
        "CSS3",
        "JavaScript",
        "Bootstrap",
        "Jquery",
        "event",
        "popup",
        "dialogs",
        "menus",
        "tools",
        "Python",
        "Shell",
        "XML",
        "tasks",
        "database",
        "Model",
        "APIs",
        "Views",
        "PythonDjango",
        "order",
        "web",
        "solution",
        "Python",
        "data",
        "JSON",
        "Django",
        "Webapp",
        "Python",
        "scripts",
        "content",
        "database",
        "manipulate",
        "files",
        "Beautiful",
        "Soup",
        "DOM",
        "elements",
        "HTML",
        "Apache",
        "NoSQL",
        "AWS",
        "Linux",
        "instance",
        "data",
        "data",
        "queries",
        "aid",
        "Made",
        "Django",
        "web",
        "apps",
        "Insurance",
        "premium",
        "calculations",
        "jobs",
        "Python",
        "data",
        "MySQL",
        "database",
        "daemon",
        "Psutil",
        "Django",
        "app",
        "analytics",
        "data",
        "solutions",
        "MongoDB",
        "database",
        "project",
        "Heroku",
        "GIT",
        "version",
        "control",
        "system",
        "application",
        "level",
        "code",
        "Rest",
        "APIs",
        "Web",
        "Services",
        "JSON",
        "Wrote",
        "validation",
        "scripts",
        "SQL",
        "data",
        "loading",
        "bugs",
        "issues",
        "race",
        "conditions",
        "events",
        "supervisors",
        "artists",
        "systems",
        "administrators",
        "production",
        "production",
        "deadlines",
        "Environment",
        "Python",
        "Django",
        "JSON",
        "REST",
        "HTML",
        "XHTML",
        "CSS",
        "AJAX",
        "JavaScript",
        "Apache",
        "Web",
        "Server",
        "Heroku",
        "SOAP",
        "Git",
        "UNIX",
        "Python",
        "Developer",
        "US",
        "Cellular",
        "Chicago",
        "IL",
        "November",
        "November",
        "Responsibilities",
        "business",
        "process",
        "scope",
        "project",
        "position",
        "statement",
        "modules",
        "changes",
        "system",
        "web",
        "pages",
        "python",
        "Django",
        "Frameworks",
        "Python",
        "Django",
        "XML",
        "processing",
        "data",
        "exchange",
        "business",
        "logic",
        "implementation",
        "python",
        "scripts",
        "content",
        "database",
        "manipulate",
        "files",
        "issues",
        "process",
        "solution",
        "Python",
        "Django",
        "Forms",
        "data",
        "users",
        "Python",
        "OO",
        "Design",
        "code",
        "quality",
        "monitoring",
        "code",
        "optimization",
        "Writing",
        "Unit",
        "Functional",
        "Integration",
        "test",
        "cases",
        "Cloud",
        "Computing",
        "applications",
        "AWS",
        "Python",
        "boto",
        "library",
        "meetings",
        "client",
        "project",
        "help",
        "client",
        "writing",
        "data",
        "csv",
        "file",
        "formats",
        "business",
        "knowledge",
        "clients",
        "Flex",
        "Backend",
        "Controller",
        "API",
        "services",
        "architect",
        "developers",
        "business",
        "issues",
        "system",
        "testers",
        "requirements",
        "requirements",
        "tasks",
        "JIRA",
        "Data",
        "mapping",
        "data",
        "class",
        "diagrams",
        "ER",
        "diagrams",
        "SQL",
        "queries",
        "data",
        "Oracle",
        "database",
        "Environment",
        "Python",
        "Django",
        "Java",
        "MySQL",
        "XML",
        "HTML",
        "XHTML",
        "CSS",
        "AJAX",
        "JSON",
        "JavaScript",
        "Apache",
        "Web",
        "Server",
        "MYSQL",
        "Linux",
        "Python",
        "Developer",
        "HILTI",
        "Hyderabad",
        "Telangana",
        "May",
        "September",
        "India",
        "Responsibilities",
        "Python",
        "API",
        "RESTful",
        "Web",
        "Service",
        "sales",
        "sales",
        "analysis",
        "Flask",
        "SQLAlchemy",
        "PostgreSQL",
        "API",
        "RESTful",
        "Web",
        "Service",
        "companys",
        "website",
        "email",
        "marketing",
        "campaigns",
        "HTML",
        "CSS",
        "customers",
        "relationship",
        "management",
        "MySQL",
        "PostgreSQL",
        "server",
        "web",
        "traffic",
        "analysis",
        "tool",
        "Flask",
        "Pandas",
        "features",
        "dashboard",
        "Flask",
        "CSS",
        "JavaScript",
        "Managed",
        "companies",
        "servers",
        "Amazon",
        "EC2",
        "S3",
        "UseCase",
        "Diagrams",
        "Class",
        "Diagrams",
        "Object",
        "Diagrams",
        "UML",
        "Rational",
        "Rose",
        "techniques",
        "components",
        "JavaJ2EE",
        "UI",
        "HTML",
        "CSS",
        "JavaScripts",
        "Created",
        "Servlets",
        "Beans",
        "Business",
        "Logic",
        "SAXDOM",
        "Parser",
        "data",
        "Oracle",
        "Database",
        "data",
        "access",
        "modules",
        "procedures",
        "Oracle",
        "9i",
        "database",
        "access",
        "layer",
        "JDBC",
        "procedures",
        "object",
        "model",
        "data",
        "model",
        "tables",
        "constraints",
        "procedures",
        "functions",
        "triggers",
        "packages",
        "Oracle",
        "Database",
        "Socket",
        "communication",
        "layers",
        "Linux",
        "Worked",
        "SNMP",
        "interfaces",
        "Environment",
        "Python",
        "Flask",
        "SQLAlchemy",
        "PostgreSQL",
        "SQL",
        "J2EE",
        "HTML",
        "CSS",
        "JDBC",
        "Servlets",
        "SNMP",
        "JavaScript",
        "Oracle",
        "Apache",
        "Web",
        "Server",
        "Linux",
        "Education",
        "Masters",
        "Skills",
        "Apache",
        "years",
        "database",
        "years",
        "HTML",
        "years",
        "Linux",
        "years",
        "Python",
        "years",
        "C",
        "Flask",
        "Java",
        "Javascript",
        "Django",
        "Additional",
        "Information",
        "Technical",
        "Skills",
        "Languages",
        "Python",
        "Java",
        "C",
        "SQL",
        "Shell",
        "Scripting",
        "Web",
        "Technologies",
        "HTMLDHTML",
        "JavaScript",
        "XML",
        "Development",
        "Tools",
        "IDEs",
        "Pycharm",
        "Eclipse",
        "Sublimetext",
        "Atom",
        "Komodo",
        "WebApplication",
        "Servers",
        "Nginx",
        "Apache",
        "WebSphere",
        "WebLogic",
        "Gunicorn",
        "Python",
        "Framework",
        "Django",
        "Flask",
        "Web2py",
        "Bottle",
        "Database",
        "SQL",
        "SERVER",
        "MySQL",
        "Oracle",
        "Sqlite3",
        "Cloud",
        "Computing",
        "Amazon",
        "EC2S3",
        "Heroku",
        "Google",
        "App",
        "Engine",
        "Bug",
        "Tracking",
        "Tools",
        "Jira",
        "Bugzilla",
        "Platforms",
        "UNIX",
        "LINUXMac",
        "Version",
        "Control",
        "SVN",
        "GIT",
        "CVS",
        "TFS",
        "Methodologies",
        "Agile",
        "Methodology",
        "Scum"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T21:51:06.249498",
    "resume_data": "Python Developer span lPythonspan span lDeveloperspan Python Developer InfosysApple iTunes Sunnyvale CA Engineering professional with 8 years of experience in Software development MasteringLeading in the development of applicationstools using Python for 6 years Experience with Web Development Web Services Python and the Djangoflask framework Proficient in Front end development experience using HTML XML CSS JQuery and JavaScript AngularJS Mastering Web Application Development using html JavaScript Expertise in ObjectOriented design and coding Good knowledge of various Design Patterns and UML Experience in developing webbased applications using Python 2X Django 1XFlask Experienced in using flask components like needs permission Principal for providing user permissions at granular level Proficient in SQL databases MS SQL MySQL Oracle and NoSQL databases like MongoDB Pymongo SQL and PLSQL programming developing complex code units database triggers and using the latest features to optimize performance Bulk Binds Materialized views Inline views Global Temporary Tables Experience in building frameworks and automating complex workflows using Python for Test Automation Experienced in writing SQL Queries Stored procedures functions packages tables views triggers Experience in working with Python ORM Libraries including Django ORM SQL Alchemy Good experience in working with Web services like Amazon EC2 AWS and Amazon s3 Handson experience in UNIX and LINUX Kernels Hands on experience in SVN Git JIRA and Bugzilla Good knowledge of web services with protocols SOAP REST Good knowledge of server Apache Tomcat Web logic Experienced in various types of testing such as Unit testing Integration testing User acceptance testing Functional testing Experience in writing test plans test cases test specifications and test coverage Good Experience in error and exceptional handling Proven ability to implement Continuous Integration and Continuous Deployment processes Having experienced in Agile Methodologies Scrum stories and sprints experience in a Python based environment along with data analytics data wrangling and Excel data extracts Performed numerous server migrations on both Linux and Windows servers Migrations include moving all clients and their data configuration settings testing and verifying Extensive knowledge on automated batch programs by UNIX shell Scripts file validations file downloads workflow executions Can handle writing technical and functional documents defined by the business requirements Outstanding communication analysis and outoftheboxcreative problem solving Experience in working with different operating systems Windows UNIX Linux and OS X Have flexibility and ability to learn and use new technologies and also to work in team environment as wells as independently to get things done Authorized to work in the US for any employer Work Experience Python Developer InfosysApple iTunes Sunnyvale CA January 2017 to Present Intelligent Data Analytics and AlertsiDAA Project Description The ETL Framework was used to do extensive auditing of data based on statistical analysis Auditing is done on data and gives a graphical and tabular view for the data The tabular structure is send to the user through email The various features for the tool is to provide Data Check Variance Check difference between data on the same period Recon Checkdifference between data between two clusters Various Quality scores are assigned daily and the dashboard loads the latest scores for the latest runs with the trend of last 14 days 2 weeks The various quality measures we track are Completeness Consistency Uniqueness Validity Accuracy Timeliness Responsibilities Responsible for gathering requirements system analysis design development testing and deployment Developed and enhanced ETL framework which checks DQMs on different databases and gets the counts validates the data between multiple environmentsClusters Designed and developed alerting system to framework users when ever the DQM runs the email alert contains DQM details and if it fails an incident is raised and ticket is created for the application teams Framework has multiple modules like LoadEdit DQM Executer ExportImport data from OracleHiveTeradataVerticaDruid LoadEdit is a command line API exposed to application teams for on boarding Excel templatethe DQMs into the Oracle DB Used Anaconda Python numpy pandas for reading the data from the input template Excel and loading the data into Oracle DB Executer module is an command line API which is envoked through Autosys with necessary params and this module uses the params for pulling the DQM metadata from Oracle Wrote Success Criteria logic for DQMs with 0 dimensions and Multiple Measures and also for Multiple dimensions and multiple measure Wrote custom python scripts for migrating the data from Hive to Oracle and vice versa which is envoked through a shell script using Autosys job scheduler and is schedule to run every day Wrote a python alerting custom code which works as a package and sends an alerting email with the DQM deails and for PASS FAIL NOT_EVAL and EXCEPTION_RAISED cases Environment Anaconda Python numpy pandas Oracle cx_oracle Hadoop Teradata Vertica vertica_ pythonDruid Pycharm GIT Jenkins Python Developer WiproApple Sunnyvale CA August 2017 to December 2017 Project Description Particles formerly known as ProtoDB is an effort to track data population and coverage at a granular Protopath level across multiple releases and plan for future releases It is also an attempt to document at a granular level which specific subsets of existing data are consumed by services Historical and future Protopath data population statistics can be leveraged for a variety of use cases Responsibilities Responsible for gathering requirements system analysis design development testing and deployment Wrote Python scripts which periodically ingests data into Postgres and serves as the backend to a web server Worked on Jenkins creating jobs executing jobs in different environment creating triggers and configuring jobs Load and transform large data sets of structured semi structured and unstructured data using HadoopBig Data concepts Developed spark jobs using pyspark in test environment for faster data processing Working on Swaggerenabled REST API to serve as entrypoint for web UI and integrate with other applications Worked on Nodejs Protopath parser project to come up with all possible combinations of Protopath by analyzing the input for predicting the combination of incorrect inputs Working on designing and implementing a web application using PythonDjango for displaying the Maps data for every release and also providing a scope for generating a diff between the data for every release Working on Gradle utility to automate the build and deployment process Environment Python 27 Django Postgres Hadoop Pycharm Docker GIT Jenkins Gradle Python Developer WalmartLabs Bentonville AR April 2016 to July 2017 Responsibilities Worked on multiple projects like Taxonomy Feed Gate Way which deals with the product classification and providing a platform for sellers suppliers and MP sellers for updating the product and inventory in com Understand the business process variants and created the process flow for automating the adhoc request Developed and supported Taxonomy API RestAPI using Python and Flask Cerberus MongoDB Wrote python wrapper for Flask and EVE frame work for generating desired results of Taxonomy API Created client and server actions and added permissions for admins and nonadmin users by restricting individuals for a particular data set by using flask principal permissions and needs Developed an API that asynchronously distributes task using RabbitMQ and Celery Porting of data import jobs from cron jobs to distributed tasks leading to a speedup Efficiently performed all backend tasks from OPS up to the REST API interfacePortal frontend single handedly Deployed async jobs monitoring system using celery flower Wrote unittests and did code reviews Worked with search business and search team to implement dynamic rule updates to search using elasticsearch Created mapreduce job using python for creating sync between PTC configs and PTCs to remove unwanted attributes for products in com Used basic Hive queries for processing large sets of data used for analyzing the 1P 2P and 3P products and also for analyzing data from MP Sellers Sellers and Suppliers Developed Spark code using python for faster processing of data given by market place sellers for generating best specification and description of products Worked closely with the search team Machine learning for the title optimization of products by processing the product information given by the sellers Title Specifications Description etc Wrote Python normalizations scripts to find duplicate data in different environments Good Knowledge on MongoDB Workspaces Snapshots and patching documents in Snapshots Wrote scripts to integrate APIs with 3rd party applications Wrote scripts to Import and Export data to CSV EXCEL formats from different environments using Python and made a Celery action using REST API call Performed Did data validation and data cleaning process and data manipulation with pandas and numpy used for data visualization by reporting teams to genereate ranking for content provided by sellers Did data analysis miss value imputation with statistical methodologies using pandas numpy Worked under AgileScrum environment and handled production rollouts and issues Developed new and enhanced search features such as SYNONYM CANONICAL and ABBREVIATION for optimizing search results and relevancy JSONelasticsearchKibana Extensively used XLSX reader and writer modules to read write and analyze data and project the results as per the client request Used GIT and JENKINS for continuous integration and deployment Was a part of Holiday readiness support team starting from Thanksgiving to Christmas Environment Python 27 Flask Eve Celery Mongodb Hive Hadoop Event Postman Pycharm JIRA JSON Docker GIT Jenkins Linux Python Developer CVS Caremark Phoenix AZ June 2015 to March 2016 Responsibilities Design develop test deploy and maintain the website Developed entire frontend and backend modules using Python on Django Web Framework Designed and developed the UI of the website using HTML AJAX CSS and JavaScript Implemented SQL Alchemy which is a python library for complete access over SQL Designed and developed data management system using MySQL and wrote several queries to extractstore data Rewrite existing Java application in Python module to deliver certain format of data Wrote Python scripts to parse XML documents and load the data in database Generated property list for every application dynamically using Python Wrote Automation test cases using Selenium WebDriver using Python API Responsible for search engine optimization to improve the visibility of the website Used Apache htaccess to provide authentication system for DjangoMySQL sites Handled all the client side validation using JavaScript Performed testing using Djangos Test Module Added support for Amazon AWS S3 and RDS to host staticmedia files and the database into Amazon Cloud Developed MapReduce jobs in python data cleaning and data processing Involved in AJAX driven application by invoking web servicesAPI and parsing the JSON response Involved in writing application level code to interact with APIs Web Services using JSON Deployed the project into Heroku using Django and GIT version control system Designed and Developed Restful webservices for both consumer and producer using Django Swagger Gunicorn Creating unit testregression test framework for workingnew code Using version control tool to coordinate teamdevelopment Responsible for debugging and troubleshooting the web application Environment Python 27 Django 18 Swagger Hadoop MySQL XML HTML XHTML CSS AJAX JSON JavaScript Apache Web Server MYSQL and Linux Python Developer ABC Insurance Bloomington IL January 2014 to May 2015 Responsibilities Responsible for gathering requirements system analysis design development testing and deployment Worked on Frontend UI using HTML5 CSS3 JavaScript Bootstrap and Jquery for event handling popup dialogs menus and skinning Developed tools using Python Shell scripting XML to automate some of the menial tasks Involved in building database Model APIs and Views utilizing PythonDjango in order to build an interactive web based solution Used Python to place data into JSON for Django Webapp Used Python scripts to update content in the database and manipulate files Used Beautiful Soup for selecting particular DOM elements when parsing HTML Used Apache MongoDB NoSQL in AWS Linux instance to store and analyze data Restructuring data for faster distributed queries to aid caching Made Django web based apps for Insurance premium calculations Implemented jobs in Python to extract and load data into MySQL database Created servermonitoring daemon with Psutil supported by Django app for analytics which I created Also researched big data solutions with MongoDB database Deployed the project into Heroku using GIT version control system Involved in writing application level code to interact with Rest APIs Web Services using JSON Wrote validation scripts in SQL to validate data loading Identified several hidden bugs caused by complicated multithreading issues such as race conditions caused by asynchronous events and resolved them Interfacing with supervisors artists systems administrators and production to ensure production deadlines are met Environment Python 27 Django JSON REST HTML XHTML CSS AJAX JavaScript Apache Web Server Heroku SOAP Git MongoDB UNIX Python Developer US Cellular Chicago IL November 2013 to November 2014 Responsibilities Involved in understanding the current business process defining scope of the project along with position statement Reengineered various modules for implementing changes and creating efficient system Developed dynamic web pages using python Django Frameworks Used Python and Django creating for XML processing data exchange and business logic implementation Used python scripts to update content in the database and manipulate files Resolved issues and improvised the process to ensure a stable and accurate solution Generated Python Django Forms to record data of online users Python OO Design code for manufacturing quality monitoring logging and debugging code optimization Writing Unit Functional and Integration test cases for Cloud Computing applications on AWS using Python with boto library Held meetings with client and worked all alone for entire internal project with limited help from the client Worked on writing and as well as read data from csv and excel file formats Provided technical and business knowledge to clients Connected Flex from Backend Controller using different API services Working with the architect developers on business and technical issues helping in designing the system and testers to ensure all requirements are correctly translated Managed requirements and tasks using JIRA Data mapping logical data modeling created class diagrams and ER diagrams and used SQL queries to filter data within the Oracle database Environment Python Django Java MySQL XML HTML XHTML CSS AJAX JSON JavaScript Apache Web Server MYSQL and Linux JAVA Python Developer HILTI Hyderabad Telangana May 2010 to September 2013 India Responsibilities Developed Python based API RESTful Web Service to track sales and perform sales analysis using Flask SQLAlchemy and PostgreSQL Developed and designed an API RESTful Web Service for the companys website Developed and designed email marketing campaigns using HTML and CSS Maintained customers relationship management databases MySQL PostgreSQL Developed server based web traffic statistical analysis tool using Flask Pandas Implemented and tested many features for dashboard using Flask CSS and JavaScript Managed companies virtual servers at Amazon EC2 S3 Designed and developed UseCase Diagrams Class Diagrams and Object Diagrams using UML Rational Rose for OOAOOD techniques Designed and developed components using JavaJ2EE Created UI using HTML CSS and JavaScripts Created Servlets and Beans to implement Business Logic Used SAXDOM Parser for parsing the data to Oracle Database Designed and created backend data access modules using PLSQL stored procedures and Oracle 9i Created database access layer using JDBC and PLSQL stored procedures Designed object model data model tables constraints necessary stored procedures functions triggers and packages for Oracle Database Worked on Socket communication layers and multithreading on Linux Worked on SNMP interfaces Environment Python Flask SQLAlchemy PostgreSQL SQL J2EE HTML CSS JDBC Servlets SNMP JavaScript Oracle Apache Web Server and Linux Education Masters Skills Apache 6 years database 6 years HTML 6 years Linux 7 years Python 8 years C Flask Java Javascript Django Additional Information Technical Skills Languages Python Java C SQL Shell Scripting Web Technologies HTMLDHTML JavaScript AngularJS XML Development Tools IDEs Pycharm Eclipse Sublimetext Atom Komodo WebApplication Servers Nginx Apache WebSphere WebLogic Gunicorn Python Framework Django Flask Web2py Bottle Database SQL SERVER MySQL Oracle Sqlite3 MongoDB Cloud Computing Amazon EC2S3 Heroku Google App Engine Bug Tracking Tools Jira Bugzilla Platforms Windows UNIX LINUXMac Version Control SVN GIT CVS TFS Methodologies Agile Methodology Scum",
    "unique_id": "b77f52c6-bf87-48bc-9016-d871d577f1d8"
}