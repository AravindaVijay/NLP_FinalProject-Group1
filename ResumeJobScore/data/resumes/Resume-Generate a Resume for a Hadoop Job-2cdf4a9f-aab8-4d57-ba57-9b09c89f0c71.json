{
    "clean_data": "Areas of expertise Big Data Ecosystems Hadoop HDFS MapReduce Hive Pig Sqoop HBase Oozie Spark Pyspark HUE and having knowledge on cassandra Programming Languages Python Core Java and have an idea on Scala Databases Oracle 10g MySQL Sqlserver NoSQL HBase Cassandra Tools Eclipse Toad FTP Tectia Putty Autosys Anaconda Jupyter notebool and Devops RTC RLM Scripting Languages JSP Platforms Windows UnixEducation Details M Tech IT DBS B Tech CSE SRM University Software Engineer Software Engineer Larsen and Toubro Skill Details Company Details company Larsen and Toubro description Worked as a Software Engineer in Technosoft Corporation Chennai from Aug 2015 to sep 2016 company Current Project description Duration September 2016 to Till date Vendor Citi bank Description Citibank s Citi Anti Money Laundering AML Transaction Monitoring TM program is a future state solution and a rules based system for transaction monitoring of ICG Markets business Roles and Responesbilities Building and providing domain knowledge for Anti Money Laundering among team members The layered architecture has Data Warehouse and Workspace layers which are used by Business Analysts Actively involved in designing of star schema model involving various Dimensions and Fact tables Designed SCD2 for maintaining history of the DIM data Developing Hive Queries for mapping data between different layers of architecture and it s usage in Oozie Workflows Integration with Data Quality and Reconciliation Module Regression and Integration testing of solution for any issues in integration with other modules and effectively testing the data flow from layer to layer Transaction monitoring system development to generate Alerts for the suspicious and fraudulent transactions based on requirements provide by BAs Developing spark Jobs for various business rules Learning Machine Learning which will be used further in the project for developing an effective model for Fraud detection for Anti Money Laundering system Scheduling Jobs using Autosys tool Deployment and Code Management using RTC and RLM Release Lifecycle Management Hadoop Developer Current Project PRTS RAN Environment Hadoop 2 x HDFS Yarn Hive Sqoop HBase Tez Tableau Sqlserver Teradata Cluster Size 96 Node Cluster Distribution Horton works HDP2 3 company Alcatel lucent description 1X and Ruckus Wireless Description The scope of this project is to maintain and store the operational and parameters data collected from the multiple vendors networks by the mediation team into the OMS data store and make it available for RF engineers to boost the network performance Responsibilities Working with Hadoop Distributed File System Involved in importing data from MySQL to HDFS using SQOOP Involved in creating Hive tables loading with data and writing hive queries which will run on top of Tez execution Engine Involved in Preparing Test cases Document Involved in Integrating Hive and HBase to store the operational data Monitoring the Jobs through Oozie company Current Project description Anti Money laundering Environment Hadoop 2 x HDFS Yarn Hive Oozie Spark Unix Autosys Python RTC RLM ETL Framwe work Cluster Size 56 Node Cluster Distribution Cloudera 5 9 14",
    "entities": [
        "RLM Release Lifecycle Management Hadoop Developer Current Project PRTS RAN Environment Hadoop",
        "Learning Machine Learning",
        "Responsibilities Working with Hadoop Distributed File System Involved",
        "Alcatel",
        "Toubro",
        "Technosoft Corporation Chennai",
        "Responesbilities Building",
        "Current Project",
        "Toubro Skill Details Company Details",
        "OMS",
        "Data Quality and Reconciliation Module Regression and Integration",
        "RLM",
        "Business Analysts Actively",
        "Data Warehouse and Workspace",
        "Autosys tool Deployment and Code Management",
        "ICG Markets",
        "Dimensions and Fact",
        "Transaction",
        "Alerts",
        "Oozie Workflows Integration",
        "Devops RTC RLM Scripting Languages JSP Platforms",
        "RTC",
        "Big Data Ecosystems Hadoop HDFS MapReduce Hive Pig Sqoop",
        "Roles",
        "Ruckus Wireless Description",
        "HBase",
        "DIM"
    ],
    "experience": "",
    "extracted_keywords": [
        "Areas",
        "expertise",
        "Big",
        "Data",
        "Ecosystems",
        "Hadoop",
        "HDFS",
        "MapReduce",
        "Hive",
        "Pig",
        "Sqoop",
        "HBase",
        "Oozie",
        "Spark",
        "Pyspark",
        "HUE",
        "knowledge",
        "cassandra",
        "Programming",
        "Languages",
        "Python",
        "Core",
        "Java",
        "idea",
        "Scala",
        "Databases",
        "Oracle",
        "g",
        "MySQL",
        "Sqlserver",
        "NoSQL",
        "HBase",
        "Cassandra",
        "Tools",
        "Eclipse",
        "Toad",
        "FTP",
        "Tectia",
        "Putty",
        "Autosys",
        "Anaconda",
        "Jupyter",
        "Devops",
        "RTC",
        "RLM",
        "Scripting",
        "Languages",
        "JSP",
        "Platforms",
        "Windows",
        "UnixEducation",
        "Details",
        "M",
        "Tech",
        "IT",
        "DBS",
        "B",
        "Tech",
        "CSE",
        "SRM",
        "University",
        "Software",
        "Engineer",
        "Software",
        "Engineer",
        "Larsen",
        "Toubro",
        "Skill",
        "Details",
        "Company",
        "Details",
        "company",
        "Larsen",
        "Toubro",
        "description",
        "Software",
        "Engineer",
        "Technosoft",
        "Corporation",
        "Chennai",
        "Aug",
        "sep",
        "company",
        "Current",
        "Project",
        "description",
        "Duration",
        "September",
        "date",
        "Vendor",
        "Citi",
        "bank",
        "Description",
        "Citibank",
        "Citi",
        "Anti",
        "Money",
        "Laundering",
        "AML",
        "Transaction",
        "Monitoring",
        "TM",
        "program",
        "state",
        "solution",
        "rules",
        "system",
        "transaction",
        "monitoring",
        "ICG",
        "Markets",
        "business",
        "Roles",
        "Responesbilities",
        "Building",
        "domain",
        "knowledge",
        "Anti",
        "Money",
        "Laundering",
        "team",
        "members",
        "architecture",
        "Data",
        "Warehouse",
        "Workspace",
        "layers",
        "Business",
        "Analysts",
        "designing",
        "star",
        "schema",
        "model",
        "Dimensions",
        "Fact",
        "tables",
        "SCD2",
        "history",
        "DIM",
        "data",
        "Hive",
        "Queries",
        "mapping",
        "data",
        "layers",
        "architecture",
        "usage",
        "Oozie",
        "Workflows",
        "Integration",
        "Data",
        "Quality",
        "Reconciliation",
        "Module",
        "Regression",
        "Integration",
        "testing",
        "solution",
        "issues",
        "integration",
        "modules",
        "data",
        "flow",
        "layer",
        "layer",
        "Transaction",
        "monitoring",
        "system",
        "development",
        "Alerts",
        "transactions",
        "requirements",
        "BAs",
        "spark",
        "Jobs",
        "business",
        "rules",
        "Learning",
        "Machine",
        "Learning",
        "project",
        "model",
        "Fraud",
        "detection",
        "Anti",
        "Money",
        "Laundering",
        "system",
        "Scheduling",
        "Jobs",
        "Autosys",
        "tool",
        "Deployment",
        "Code",
        "Management",
        "RTC",
        "RLM",
        "Release",
        "Lifecycle",
        "Management",
        "Hadoop",
        "Developer",
        "Current",
        "Project",
        "PRTS",
        "RAN",
        "Environment",
        "Hadoop",
        "2",
        "HDFS",
        "Yarn",
        "Hive",
        "Sqoop",
        "HBase",
        "Tez",
        "Tableau",
        "Sqlserver",
        "Teradata",
        "Cluster",
        "Size",
        "Node",
        "Cluster",
        "Distribution",
        "Horton",
        "HDP2",
        "company",
        "Alcatel",
        "lucent",
        "description",
        "1X",
        "Ruckus",
        "Wireless",
        "Description",
        "scope",
        "project",
        "parameters",
        "data",
        "vendors",
        "networks",
        "mediation",
        "team",
        "OMS",
        "data",
        "store",
        "RF",
        "engineers",
        "network",
        "performance",
        "Responsibilities",
        "Hadoop",
        "Distributed",
        "File",
        "System",
        "data",
        "MySQL",
        "HDFS",
        "SQOOP",
        "Hive",
        "tables",
        "data",
        "hive",
        "queries",
        "top",
        "Tez",
        "execution",
        "Engine",
        "Preparing",
        "Test",
        "cases",
        "Document",
        "Integrating",
        "Hive",
        "HBase",
        "data",
        "Jobs",
        "Oozie",
        "company",
        "Current",
        "Project",
        "description",
        "Anti",
        "Money",
        "laundering",
        "Environment",
        "Hadoop",
        "2",
        "HDFS",
        "Yarn",
        "Hive",
        "Oozie",
        "Spark",
        "Unix",
        "Autosys",
        "Python",
        "RTC",
        "RLM",
        "ETL",
        "Framwe",
        "work",
        "Cluster",
        "Size",
        "Node",
        "Cluster",
        "Distribution",
        "Cloudera"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:01:34.462649",
    "resume_data": "Areas of expertise Big Data Ecosystems Hadoop HDFS MapReduce Hive Pig Sqoop HBase Oozie Spark Pyspark HUE and having knowledge on cassandra Programming Languages Python Core Java and have an idea on Scala Databases Oracle 10g MySQL Sqlserver NoSQL HBase Cassandra Tools Eclipse Toad FTP Tectia Putty Autosys Anaconda Jupyter notebool and Devops RTC RLM Scripting Languages JSP Platforms Windows UnixEducation Details M Tech IT DBS B Tech CSE SRM University Software Engineer Software Engineer Larsen and Toubro Skill Details Company Details company Larsen and Toubro description Worked as a Software Engineer in Technosoft Corporation Chennai from Aug 2015 to sep 2016 company Current Project description Duration September 2016 to Till date Vendor Citi bank Description Citibank s Citi Anti Money Laundering AML Transaction Monitoring TM program is a future state solution and a rules based system for transaction monitoring of ICG Markets business Roles and Responesbilities Building and providing domain knowledge for Anti Money Laundering among team members The layered architecture has Data Warehouse and Workspace layers which are used by Business Analysts Actively involved in designing of star schema model involving various Dimensions and Fact tables Designed SCD2 for maintaining history of the DIM data Developing Hive Queries for mapping data between different layers of architecture and it s usage in Oozie Workflows Integration with Data Quality and Reconciliation Module Regression and Integration testing of solution for any issues in integration with other modules and effectively testing the data flow from layer to layer Transaction monitoring system development to generate Alerts for the suspicious and fraudulent transactions based on requirements provide by BAs Developing spark Jobs for various business rules Learning Machine Learning which will be used further in the project for developing an effective model for Fraud detection for Anti Money Laundering system Scheduling Jobs using Autosys tool Deployment and Code Management using RTC and RLM Release Lifecycle Management Hadoop Developer Current Project PRTS RAN Environment Hadoop 2 x HDFS Yarn Hive Sqoop HBase Tez Tableau Sqlserver Teradata Cluster Size 96 Node Cluster Distribution Horton works HDP2 3 company Alcatel lucent description 1X and Ruckus Wireless Description The scope of this project is to maintain and store the operational and parameters data collected from the multiple vendors networks by the mediation team into the OMS data store and make it available for RF engineers to boost the network performance Responsibilities Working with Hadoop Distributed File System Involved in importing data from MySQL to HDFS using SQOOP Involved in creating Hive tables loading with data and writing hive queries which will run on top of Tez execution Engine Involved in Preparing Test cases Document Involved in Integrating Hive and HBase to store the operational data Monitoring the Jobs through Oozie company Current Project description Anti Money laundering Environment Hadoop 2 x HDFS Yarn Hive Oozie Spark Unix Autosys Python RTC RLM ETL Framwe work Cluster Size 56 Node Cluster Distribution Cloudera 5 9 14",
    "unique_id": "2cdf4a9f-aab8-4d57-ba57-9b09c89f0c71"
}