{
    "clean_data": "Cloud Engineer Cloud Engineer Cloud Engineer ALTA GDIT Brandywine MD Over 4 years experience planning designing implementing and maintaining system applications in AWS Cloud in Linux and Windows environments and overall 15 years IT related experience Experience working in Agile Scrum Software Development Life Cycle with respect to delivering Operations Functional and Technical Specifications Resource Planning Development Testing and Maintenance Experience in migrating and implementation of multiple applications from on premise to cloud using AWS services like SMS Server Migration Service DMS Database Migration Service SCT Schema Conversion Tool CloudFormation Cloudwatch Cloudtrail S3 Route53 Glacier EC2 RDS SQS SNS and VPC Build and configure a virtual data center in the Amazon Web Services cloud to support Enterprise Data Warehouse hosting including Virtual Private Cloud VPC Public and Private Subnets Security Groups Route Tables Elastic Load Balancer Experience with Amazon Kinesis to Stream Analyze and Process realtime Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket Experience with Amazon Athena to Analyze Web Data Stored in S3 Bucket Experience in Big Data Processing with Apache Hadoop Apache Spark and Amazon Elastic MapReduce EMR using HDFS and EMRFS to directly access files stored in S3 Bucket with Cluster Nodes Configured EMR Transient and Persistent Clusters depending on the workload and scenario of the application Experience with Apache Hadoop frame works like Hive Presto Hue Pig and Ganglia to Process and Analyze datasets from various data sources and applications Migrated on premise Data Warehouse Application into Amazon Redshift and implemented the Leader Node and Compute Nodes for processing the information Implemented Amazon QuickSight and TIBCO Spotfire Analytics to generate various reports Configuration of Continuous Integration CI Continuous Delivery and Deployment CD using Github Jenkins for automation Experience in deployment of JavaJ2EE applications on WebLogic and WebSphere application servers Good experience in creating and editing Shell Bash Python Scripts for automation Excellent communication analytical and problem solving skills with ability to work within a team environment and independently Cloud Computing AWS EC2 EBS RDS S3 Glacier Apache Hadoop Apache Spark EMR Hive Presto Pig Hue Ganglia Apache Spark Redshift SQS SNS SES CloudFormation VPC IAM Route53 DynamoDB Lambda CloudWatch Cloudtrail CICD CodeDeploy and CodePipeline Ansible Jenkins Docker Github AWS Glue AWS Athena RDBMS Oracle 12c11g10g9i SQL PLSQL MySQL5657 MS SQL Server 2014 2012 2008 MS SSIS SSAS SSRS SAP ECC SAP HANA Authorized to work in the US for any employer Work Experience Cloud Engineer ALTA GDIT Herndon VA November 2018 to Present Managing Cloud Infrastructure and Shared Services for various customers applications running on Amazon EC2 Instances for Linux Windows environments Responsible for launching Amazon EC2 Cloud Instances and Configuring Instances with respect to specific Applications in various Availability Zones using CloudFormation Worked with project team members in the development of approval criteria and request for designing change management process of various applications running in hybrid environments Installed applications on AWS EC2 instances and configured storage on S3 buckets with security options for access and the IAM role based polices Build VPCs Virtual Private Cloud and launching EC2 instances with Security Groups AutoScaling Load Balancers and other like S3 Glacier RDS SQS SNS and SES in defined public and private connections Implemented Big Data Processing with Apache Hadoop Apache Spark and Amazon Elastic MapReduce EMR using HDFS and EMFS to directly access files stored in S3 Bucket for Cluster Nodes Configured Transient and Persistent Clusters depending on the workload and scenario of the application Implemented Apache Hadoop frame works like Hive Hue Pig and Ganglia to Process and Analyze datasets from various data sources and applications Implemented Amazon Kinesis to Stream Analyze and Process realtime Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket Implemented Amazon Athena to Analyze Web Data Stored in S3 Bucket Responsible for creating monitors alarms and notifications for EC2 hosts using Cloud Watch Migrating on promise application into AWS cloud and also configured a Hybrid environment for certain applications Involved in 24X7support rotation for all the Production Im pl Test and Development environments Environment AWS EC2 S3 Glacier SMS RDS SQS SNS CloudFormation VPC Apache Hadoop Apache Spark Java Scala EMR Hive Presto Pig Hue Ganglia CloudWatch Kinesis Lambda QuickSight Athena Redshift DynamoDB Oracle 12c LinuxWindows Python RDMS MySQL MS SQL Server 2012 AWS Cloud Systems Engineer Glocoms Inc Chicago IL November 2014 to October 2018 Responsible for launching Amazon EC2 Cloud Instances using Amazon Web Services and Configuring Instances with respect to specific Applications Availability Zones and Regions Worked with project team members in the development of approval criteria and request for designing change management process of various applications running in hybrid environments Installed applications on AWS EC2 instances and configured the storage on S3 buckets Responsible for S3 buckets creation policies and the IAM role based polices Build servers using AWS importing volumes launching EC2 RDS creating security groups autoscaling load balancers ELBs in the defined virtual private connection AWS Glue for ETL and Data Analytics Responsible for creating monitors alarms and notifications for EC2 hosts using Cloud Watch Involved in the migration and implementation of multiple applications from on premise to cloud using AWS services like SMS DBMS CloudFormation S3 Route53 Glacier EC2 RDS SQS SNS Redshift Lambda CloudFormation Cloudwatch Cloudtrail and VPC Build servers using AWS and launching EC2 RDS creating security groups autoscaling load balancers ELBs in the defined virtual private connection Implemented Big Data Processing with Apache Hadoop Apache Spark and Amazon Elastic MapReduce EMR using HDFS and EMRFS to directly access files stored in S3 Bucket for Cluster Nodes Configured Transient and Persistent Clusters depending on the workload and scenario of the application Implemented Apache Hadoop frame works like Hive Hue Pig and Ganglia to Process and Analyze datasets from various data sources and applications Implemented Amazon Kinesis to Stream Analyze and Process realtime Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket Implemented Amazon Athena to Analyze Web Data Stored in S3 Bucket by Elastic Load Balancer Configuration of Continuous Integration CI and Continuous Delivery CD using CodePipeline and CodeDeploy for automation Involved in 24X7support rotation for all the Production Test and Development environments Responsible for the Installation Configuration and Maintenance of Oracle 12c11g10g Single Instances and RAC databases for High Availability and Disaster Recovery Performed patching upgrade and migration of multiple development test and production databases from 10g11g to 12c and migration to different platforms Performed backup and recovery strategy using Recovery Manager RMAN physical backup and Data Pump ImportExport logical backup respectively Created User accounts Roles and granting required access Permissions and Privileges to the users Implemented SQL PLSQL and TSQL queries packages functions stored procedures triggers tables views materialized views indexes Involved in 24X7support rotation for all the Production Test and Development databases Performed Performance Tuning using SQLTRACE EXPLAIN PLAN TKPROF STATSPACK AWR and ADDM Developed various Bash Shell Scripts for automation Environment AWS EC2 S3 Glacier SMS RDS SQS SNS SES CloudFormation VPC Apache Spark Apache Hadoop EMR Hive Pig Hue Ganglia CloudWatch Kinesis Lambda QuickSight Athena Redshift DynamoDB Oracle 12c LinuxWindows Java Scala Python MySQL MS SQL Server 2012 Database Administrator Glocoms Inc Chicago IL August 2011 to October 2014 Responsible for Installation Configuration and Maintenance of Oracle 12c11g Single Instances RAC and Standby databases DataGuard for High Availability and Disaster Recovery Planned designed and implemented a robust backup and recovery strategy using Recovery Manager RMAN physical backup and Data Pump ImportExport logical backup respectively I periodically used production backups to refreshclone the lower environments Created User accounts Roles and granting required access Permissions and Privileges to the users Implemented SQL PLSQL and TSQL queries packages functions stored procedures triggers tables views materialized views indexes Performed SQL PLSQL Performance Tuning using various tools like EXPLAIN PLAN SQLTRACE TKPROF and AUTOTRACE Heavily utilized Oracle Enterprise Manager OEM for monitoring job scheduling performance tuning and other routine DBA activities Provided 24X7 supports for all the Production Quality Test Development databases Performed the Installation Configuration and Migration of various Schema Objects Patches and Database Upgrade from 10g to 11g and 11g to 12c Developed various UNIX Power Shell Scripts for automation Installed configured and maintained MySQL both cluster and nonclustered configurations Experienced in configuring troubleshooting managing and maintaining MySQL Servers with third party tools like percona toolkit ptquery digest ptonline schema change etc Maintained Optimized tuned MySQL Error log Log maintenance and troubleshooting queries Experienced in handling MySQL Security establishing MySQL Replication and MySQL Clustering between two or more MySQL Database servers Performed MySQL full incremental Backups logical and physical and recovery strategies making use of master binary log Implemented database backups for both MyISAM and InnoDB storage engines in production Recovered database using crash version and rollforward recovery methods Maintained database security by GrantingRevoking usersrole v 55 56 authorizations and privileges Implemented MySQL Enterprise Monitor MySQL Replication Monitor and MySQL Query Analyzer for improving query performance and capacity planning Installation and Administration of MS SQL Server 14 databases in high availability environments including Clustering AlwaysOn Mirroring Log Shipping and Replication Implemented the Extract Transform and Load ETL process for developing high performance Business Intelligence Reports using OBIEE MS SSIS and SSRS tools from various Data Sources Strong knowledge of BI solution with Star Schema Snow Flake Schema Dimension and Fact table Configure OBIEE and SQL Reporting Services SSRS for Developing Drill Tabular Reports Matrix Reports and Drill Down Reports Developed user guide documentation and training materials for various database environments and SOX compliance Environment Oracle 12c 11g RAC OBIEE MySQL 5556 MS SSIS SSAS SSRS HPUX REDHAT LINUX Windows ASM OEM Grid ControlCloud RMAN SQLLoader Database Administrator Oracle SAP Partner K2 AG Zurich CH March 2010 to February 2011 Provided Production support for database on 11g 10g and 9i versions with standalone and RAC environment Developed various UNIX Power Shell Scripts for automation Performed full incremental backup using RMAN and implemented recovery strategies Performed Database performance tuning using Tuning Advisor AWR ADDM SQL ANALYZER and Explain Plan also using command line in generating reports needed Heavily utilized TOAD DBArtisan and OEM for various administrations reporting job scheduling and performance optimization tasks Implementing Switchovers in Data Guard environments for schedule and Rolling Upgrades Used Data Pump for logical backups and schema migrations Scheduled and used RMAN backups for refreshes using DPITR Interfaced regularly with developers to help optimize their queries and database support Performed capacity planning Extracting Transforming and Loading ETL data using SQLLoader and External Tables Migrated databases from Sun Solaris HPUX to IBM AIX and Windows to Linux Performing core database administrative tasks like user creation password resets unlocking accounts creating profiles roles migrating objects and backups etc Environment Oracle 11g 10g 9i HPUX SUN SOLARIS IBM AIX OEM Grid Control RMAN SQLLoader ASM Data Guard SAP Basis Administrator Ecolab GmbH Dsseldorf DE August 2007 to August 2008 Responsible for SAP Client Administration User Authorization concept Client copy Transport Management System performance tuning Database maintenance includes Online Backup Archive Log Backup Upgrade and SAP DBA BRTools Environment SAP R3 Enterprise 47 Oracle 9i and 10g windows 2000 Solaris SAP Consultant Accenture GmbH Frankfurt DE July 2005 to May 2007 Performed a broad range of SAPrelated consulting services for the following client companies Givaudan Schweiz AG October 2006 to April 2007 Bombardier Transportation UK June 2006 to September 2006 Messer Group DE November 2005 to May 2006 TMobile GmbH August 2005 to October 2005 Education Master of Science in Data Analytics in Data Analytics University of Maryland University College 2020 Master of Science in Technical Management in Technical Management University of Applied Sciences Emden 2001 Skills DATA MODEL PLSQL SQL AIX LINUX SHELL SCRIPTING SUN UX POWER BI CC C JAVASCRIPT JSON PERL PHP PYTHON SCRIPTING XML BASH SCALA Docker Devops",
    "entities": [
        "Bombardier Transportation",
        "Cluster Nodes Configured",
        "Permissions and Privileges",
        "Data Guard",
        "Virtual Private Cloud VPC Public and Private Subnets Security Groups Route Tables Elastic Load Balancer",
        "BI",
        "HDFS",
        "UNIX",
        "UK",
        "SQLLoader and External Tables Migrated",
        "Implemented Big Data Processing with Apache Hadoop",
        "IBM",
        "EMRFS",
        "Givaudan Schweiz AG",
        "Implemented SQL PLSQL",
        "Maintained Optimized",
        "Loading ETL",
        "WebLogic",
        "Maintained",
        "Performed Database",
        "MySQL Database",
        "Amazon Elastic MapReduce EMR",
        "JavaJ2EE",
        "Amazon",
        "Database Upgrade",
        "WebSphere",
        "DBArtisan",
        "Skills DATA",
        "SQL Reporting Services",
        "Developed",
        "RDMS",
        "Amazon Redshift",
        "CodePipeline",
        "Heavily",
        "Amazon Kinesis",
        "Oracle 9i",
        "Present Managing Cloud Infrastructure and Shared Services",
        "Explain Plan",
        "Processed",
        "Linux",
        "GrantingRevoking",
        "AG Zurich",
        "Database Administrator Glocoms Inc Chicago",
        "Amazon Athena",
        "RDS",
        "Roles",
        "Installation and Administration of MS",
        "Configuration of Continuous Integration",
        "Data Sources Strong",
        "Analyze Web Data Stored",
        "Windows to",
        "SQL AIX",
        "Test and Development",
        "US",
        "Online Backup Archive Log Backup Upgrade",
        "Performed SQL PLSQL Performance Tuning",
        "SMS Server Migration Service",
        "IAM",
        "Created User",
        "AWS",
        "SAP DBA BRTools Environment",
        "UX POWER BI CC C",
        "Single Instances RAC",
        "Implemented MySQL Enterprise Monitor MySQL Replication Monitor",
        "SSRS",
        "Amazon Web Services",
        "EMFS",
        "Operations Functional and Technical Specifications Resource Planning Development Testing and Maintenance Experience",
        "Security Groups AutoScaling Load Balancers",
        "Lambda CloudWatch Cloudtrail CICD CodeDeploy",
        "Amazon Kinesis Firehose",
        "Sun Solaris",
        "Single Instances",
        "ETL",
        "RAC",
        "CloudFormation Worked",
        "Apache Hadoop",
        "Build",
        "Performed",
        "Messer Group",
        "Bash Shell Scripts",
        "Rolling Upgrades Used Data Pump",
        "SAPrelated",
        "Data Analytics University of Maryland University College",
        "Implemented Apache Hadoop",
        "Data Analytics Responsible",
        "Science in Technical Management in Technical Management University of Applied Sciences Emden 2001",
        "CodeDeploy",
        "Implemented Amazon Kinesis",
        "Big Data Processing with Apache Hadoop",
        "DMS Database Migration Service",
        "QuickSight",
        "SOX",
        "Data Warehouse Application",
        "SES",
        "RMAN",
        "TIBCO Spotfire Analytics",
        "Athena",
        "SQLTRACE",
        "OBIEE MS",
        "SCALA Docker Devops",
        "Implementing Switchovers"
    ],
    "experience": "Experience working in Agile Scrum Software Development Life Cycle with respect to delivering Operations Functional and Technical Specifications Resource Planning Development Testing and Maintenance Experience in migrating and implementation of multiple applications from on premise to cloud using AWS services like SMS Server Migration Service DMS Database Migration Service SCT Schema Conversion Tool CloudFormation Cloudwatch Cloudtrail S3 Route53 Glacier EC2 RDS SQS SNS and VPC Build and configure a virtual data center in the Amazon Web Services cloud to support Enterprise Data Warehouse hosting including Virtual Private Cloud VPC Public and Private Subnets Security Groups Route Tables Elastic Load Balancer Experience with Amazon Kinesis to Stream Analyze and Process realtime Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket Experience with Amazon Athena to Analyze Web Data Stored in S3 Bucket Experience in Big Data Processing with Apache Hadoop Apache Spark and Amazon Elastic MapReduce EMR using HDFS and EMRFS to directly access files stored in S3 Bucket with Cluster Nodes Configured EMR Transient and Persistent Clusters depending on the workload and scenario of the application Experience with Apache Hadoop frame works like Hive Presto Hue Pig and Ganglia to Process and Analyze datasets from various data sources and applications Migrated on premise Data Warehouse Application into Amazon Redshift and implemented the Leader Node and Compute Nodes for processing the information Implemented Amazon QuickSight and TIBCO Spotfire Analytics to generate various reports Configuration of Continuous Integration CI Continuous Delivery and Deployment CD using Github Jenkins for automation Experience in deployment of JavaJ2EE applications on WebLogic and WebSphere application servers Good experience in creating and editing Shell Bash Python Scripts for automation Excellent communication analytical and problem solving skills with ability to work within a team environment and independently Cloud Computing AWS EC2 EBS RDS S3 Glacier Apache Hadoop Apache Spark EMR Hive Presto Pig Hue Ganglia Apache Spark Redshift SQS SNS SES CloudFormation VPC IAM Route53 DynamoDB Lambda CloudWatch Cloudtrail CICD CodeDeploy and CodePipeline Ansible Jenkins Docker Github AWS Glue AWS Athena RDBMS Oracle 12c11g10g9i SQL PLSQL MySQL5657 MS SQL Server 2014 2012 2008 MS SSIS SSAS SSRS SAP ECC SAP HANA Authorized to work in the US for any employer Work Experience Cloud Engineer ALTA GDIT Herndon VA November 2018 to Present Managing Cloud Infrastructure and Shared Services for various customers applications running on Amazon EC2 Instances for Linux Windows environments Responsible for launching Amazon EC2 Cloud Instances and Configuring Instances with respect to specific Applications in various Availability Zones using CloudFormation Worked with project team members in the development of approval criteria and request for designing change management process of various applications running in hybrid environments Installed applications on AWS EC2 instances and configured storage on S3 buckets with security options for access and the IAM role based polices Build VPCs Virtual Private Cloud and launching EC2 instances with Security Groups AutoScaling Load Balancers and other like S3 Glacier RDS SQS SNS and SES in defined public and private connections Implemented Big Data Processing with Apache Hadoop Apache Spark and Amazon Elastic MapReduce EMR using HDFS and EMFS to directly access files stored in S3 Bucket for Cluster Nodes Configured Transient and Persistent Clusters depending on the workload and scenario of the application Implemented Apache Hadoop frame works like Hive Hue Pig and Ganglia to Process and Analyze datasets from various data sources and applications Implemented Amazon Kinesis to Stream Analyze and Process realtime Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket Implemented Amazon Athena to Analyze Web Data Stored in S3 Bucket Responsible for creating monitors alarms and notifications for EC2 hosts using Cloud Watch Migrating on promise application into AWS cloud and also configured a Hybrid environment for certain applications Involved in 24X7support rotation for all the Production I m pl Test and Development environments Environment AWS EC2 S3 Glacier SMS RDS SQS SNS CloudFormation VPC Apache Hadoop Apache Spark Java Scala EMR Hive Presto Pig Hue Ganglia CloudWatch Kinesis Lambda QuickSight Athena Redshift DynamoDB Oracle 12c LinuxWindows Python RDMS MySQL MS SQL Server 2012 AWS Cloud Systems Engineer Glocoms Inc Chicago IL November 2014 to October 2018 Responsible for launching Amazon EC2 Cloud Instances using Amazon Web Services and Configuring Instances with respect to specific Applications Availability Zones and Regions Worked with project team members in the development of approval criteria and request for designing change management process of various applications running in hybrid environments Installed applications on AWS EC2 instances and configured the storage on S3 buckets Responsible for S3 buckets creation policies and the IAM role based polices Build servers using AWS importing volumes launching EC2 RDS creating security groups autoscaling load balancers ELBs in the defined virtual private connection AWS Glue for ETL and Data Analytics Responsible for creating monitors alarms and notifications for EC2 hosts using Cloud Watch Involved in the migration and implementation of multiple applications from on premise to cloud using AWS services like SMS DBMS CloudFormation S3 Route53 Glacier EC2 RDS SQS SNS Redshift Lambda CloudFormation Cloudwatch Cloudtrail and VPC Build servers using AWS and launching EC2 RDS creating security groups autoscaling load balancers ELBs in the defined virtual private connection Implemented Big Data Processing with Apache Hadoop Apache Spark and Amazon Elastic MapReduce EMR using HDFS and EMRFS to directly access files stored in S3 Bucket for Cluster Nodes Configured Transient and Persistent Clusters depending on the workload and scenario of the application Implemented Apache Hadoop frame works like Hive Hue Pig and Ganglia to Process and Analyze datasets from various data sources and applications Implemented Amazon Kinesis to Stream Analyze and Process realtime Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket Implemented Amazon Athena to Analyze Web Data Stored in S3 Bucket by Elastic Load Balancer Configuration of Continuous Integration CI and Continuous Delivery CD using CodePipeline and CodeDeploy for automation Involved in 24X7support rotation for all the Production Test and Development environments Responsible for the Installation Configuration and Maintenance of Oracle 12c11g10 g Single Instances and RAC databases for High Availability and Disaster Recovery Performed patching upgrade and migration of multiple development test and production databases from 10g11 g to 12c and migration to different platforms Performed backup and recovery strategy using Recovery Manager RMAN physical backup and Data Pump ImportExport logical backup respectively Created User accounts Roles and granting required access Permissions and Privileges to the users Implemented SQL PLSQL and TSQL queries packages functions stored procedures triggers tables views materialized views indexes Involved in 24X7support rotation for all the Production Test and Development databases Performed Performance Tuning using SQLTRACE EXPLAIN PLAN TKPROF STATSPACK AWR and ADDM Developed various Bash Shell Scripts for automation Environment AWS EC2 S3 Glacier SMS RDS SQS SNS SES CloudFormation VPC Apache Spark Apache Hadoop EMR Hive Pig Hue Ganglia CloudWatch Kinesis Lambda QuickSight Athena Redshift DynamoDB Oracle 12c LinuxWindows Java Scala Python MySQL MS SQL Server 2012 Database Administrator Glocoms Inc Chicago IL August 2011 to October 2014 Responsible for Installation Configuration and Maintenance of Oracle 12c11 g Single Instances RAC and Standby databases DataGuard for High Availability and Disaster Recovery Planned designed and implemented a robust backup and recovery strategy using Recovery Manager RMAN physical backup and Data Pump ImportExport logical backup respectively I periodically used production backups to refreshclone the lower environments Created User accounts Roles and granting required access Permissions and Privileges to the users Implemented SQL PLSQL and TSQL queries packages functions stored procedures triggers tables views materialized views indexes Performed SQL PLSQL Performance Tuning using various tools like EXPLAIN PLAN SQLTRACE TKPROF and AUTOTRACE Heavily utilized Oracle Enterprise Manager OEM for monitoring job scheduling performance tuning and other routine DBA activities Provided 24X7 supports for all the Production Quality Test Development databases Performed the Installation Configuration and Migration of various Schema Objects Patches and Database Upgrade from 10 g to 11 g and 11 g to 12c Developed various UNIX Power Shell Scripts for automation Installed configured and maintained MySQL both cluster and nonclustered configurations Experienced in configuring troubleshooting managing and maintaining MySQL Servers with third party tools like percona toolkit ptquery digest ptonline schema change etc Maintained Optimized tuned MySQL Error log Log maintenance and troubleshooting queries Experienced in handling MySQL Security establishing MySQL Replication and MySQL Clustering between two or more MySQL Database servers Performed MySQL full incremental Backups logical and physical and recovery strategies making use of master binary log Implemented database backups for both MyISAM and InnoDB storage engines in production Recovered database using crash version and rollforward recovery methods Maintained database security by GrantingRevoking usersrole v 55 56 authorizations and privileges Implemented MySQL Enterprise Monitor MySQL Replication Monitor and MySQL Query Analyzer for improving query performance and capacity planning Installation and Administration of MS SQL Server 14 databases in high availability environments including Clustering AlwaysOn Mirroring Log Shipping and Replication Implemented the Extract Transform and Load ETL process for developing high performance Business Intelligence Reports using OBIEE MS SSIS and SSRS tools from various Data Sources Strong knowledge of BI solution with Star Schema Snow Flake Schema Dimension and Fact table Configure OBIEE and SQL Reporting Services SSRS for Developing Drill Tabular Reports Matrix Reports and Drill Down Reports Developed user guide documentation and training materials for various database environments and SOX compliance Environment Oracle 12c 11 g RAC OBIEE MySQL 5556 MS SSIS SSAS SSRS HPUX REDHAT LINUX Windows ASM OEM Grid ControlCloud RMAN SQLLoader Database Administrator Oracle SAP Partner K2 AG Zurich CH March 2010 to February 2011 Provided Production support for database on 11 g 10 g and 9i versions with standalone and RAC environment Developed various UNIX Power Shell Scripts for automation Performed full incremental backup using RMAN and implemented recovery strategies Performed Database performance tuning using Tuning Advisor AWR ADDM SQL ANALYZER and Explain Plan also using command line in generating reports needed Heavily utilized TOAD DBArtisan and OEM for various administrations reporting job scheduling and performance optimization tasks Implementing Switchovers in Data Guard environments for schedule and Rolling Upgrades Used Data Pump for logical backups and schema migrations Scheduled and used RMAN backups for refreshes using DPITR Interfaced regularly with developers to help optimize their queries and database support Performed capacity planning Extracting Transforming and Loading ETL data using SQLLoader and External Tables Migrated databases from Sun Solaris HPUX to IBM AIX and Windows to Linux Performing core database administrative tasks like user creation password resets unlocking accounts creating profiles roles migrating objects and backups etc Environment Oracle 11 g 10 g 9i HPUX SUN SOLARIS IBM AIX OEM Grid Control RMAN SQLLoader ASM Data Guard SAP Basis Administrator Ecolab GmbH Dsseldorf DE August 2007 to August 2008 Responsible for SAP Client Administration User Authorization concept Client copy Transport Management System performance tuning Database maintenance includes Online Backup Archive Log Backup Upgrade and SAP DBA BRTools Environment SAP R3 Enterprise 47 Oracle 9i and 10 g windows 2000 Solaris SAP Consultant Accenture GmbH Frankfurt DE July 2005 to May 2007 Performed a broad range of SAPrelated consulting services for the following client companies Givaudan Schweiz AG October 2006 to April 2007 Bombardier Transportation UK June 2006 to September 2006 Messer Group DE November 2005 to May 2006 TMobile GmbH August 2005 to October 2005 Education Master of Science in Data Analytics in Data Analytics University of Maryland University College 2020 Master of Science in Technical Management in Technical Management University of Applied Sciences Emden 2001 Skills DATA MODEL PLSQL SQL AIX LINUX SHELL SCRIPTING SUN UX POWER BI CC C JAVASCRIPT JSON PERL PHP PYTHON SCRIPTING XML BASH SCALA Docker Devops",
    "extracted_keywords": [
        "Cloud",
        "Engineer",
        "Cloud",
        "Engineer",
        "Cloud",
        "Engineer",
        "ALTA",
        "GDIT",
        "Brandywine",
        "MD",
        "years",
        "experience",
        "system",
        "applications",
        "AWS",
        "Cloud",
        "Linux",
        "Windows",
        "environments",
        "years",
        "IT",
        "experience",
        "Experience",
        "Agile",
        "Scrum",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "respect",
        "Operations",
        "Functional",
        "Technical",
        "Specifications",
        "Resource",
        "Planning",
        "Development",
        "Testing",
        "Maintenance",
        "Experience",
        "migrating",
        "implementation",
        "applications",
        "premise",
        "AWS",
        "services",
        "SMS",
        "Server",
        "Migration",
        "Service",
        "DMS",
        "Database",
        "Migration",
        "Service",
        "SCT",
        "Schema",
        "Conversion",
        "Tool",
        "CloudFormation",
        "Cloudwatch",
        "Cloudtrail",
        "S3",
        "Route53",
        "Glacier",
        "EC2",
        "RDS",
        "SQS",
        "SNS",
        "VPC",
        "Build",
        "data",
        "center",
        "Amazon",
        "Web",
        "Services",
        "cloud",
        "Enterprise",
        "Data",
        "Warehouse",
        "Virtual",
        "Cloud",
        "VPC",
        "Public",
        "Private",
        "Subnets",
        "Security",
        "Groups",
        "Route",
        "Tables",
        "Elastic",
        "Load",
        "Balancer",
        "Experience",
        "Amazon",
        "Kinesis",
        "Stream",
        "Analyze",
        "Process",
        "Logs",
        "Apache",
        "application",
        "server",
        "Amazon",
        "Kinesis",
        "Firehose",
        "Processed",
        "Log",
        "Files",
        "Amazon",
        "S3",
        "Bucket",
        "Experience",
        "Amazon",
        "Athena",
        "Web",
        "Data",
        "S3",
        "Bucket",
        "Experience",
        "Big",
        "Data",
        "Processing",
        "Apache",
        "Hadoop",
        "Apache",
        "Spark",
        "Amazon",
        "Elastic",
        "MapReduce",
        "EMR",
        "HDFS",
        "EMRFS",
        "files",
        "S3",
        "Bucket",
        "Cluster",
        "Nodes",
        "Configured",
        "EMR",
        "Transient",
        "Persistent",
        "Clusters",
        "workload",
        "scenario",
        "application",
        "Experience",
        "Apache",
        "Hadoop",
        "frame",
        "Hive",
        "Presto",
        "Hue",
        "Pig",
        "Ganglia",
        "Process",
        "Analyze",
        "datasets",
        "data",
        "sources",
        "applications",
        "premise",
        "Data",
        "Warehouse",
        "Application",
        "Amazon",
        "Redshift",
        "Leader",
        "Node",
        "Compute",
        "Nodes",
        "information",
        "Amazon",
        "QuickSight",
        "TIBCO",
        "Spotfire",
        "Analytics",
        "reports",
        "Configuration",
        "Continuous",
        "Integration",
        "CI",
        "Continuous",
        "Delivery",
        "Deployment",
        "CD",
        "Github",
        "Jenkins",
        "automation",
        "Experience",
        "deployment",
        "JavaJ2EE",
        "applications",
        "WebLogic",
        "WebSphere",
        "application",
        "experience",
        "Shell",
        "Bash",
        "Python",
        "Scripts",
        "automation",
        "communication",
        "problem",
        "skills",
        "ability",
        "team",
        "environment",
        "Cloud",
        "Computing",
        "AWS",
        "EC2",
        "EBS",
        "RDS",
        "S3",
        "Glacier",
        "Apache",
        "Hadoop",
        "Apache",
        "Spark",
        "EMR",
        "Hive",
        "Presto",
        "Pig",
        "Hue",
        "Ganglia",
        "Apache",
        "Spark",
        "Redshift",
        "SQS",
        "SNS",
        "SES",
        "CloudFormation",
        "VPC",
        "IAM",
        "Route53",
        "Lambda",
        "CloudWatch",
        "Cloudtrail",
        "CICD",
        "CodeDeploy",
        "CodePipeline",
        "Ansible",
        "Jenkins",
        "Docker",
        "Github",
        "AWS",
        "Athena",
        "RDBMS",
        "Oracle",
        "SQL",
        "PLSQL",
        "MySQL5657",
        "MS",
        "SQL",
        "Server",
        "MS",
        "SSIS",
        "SSAS",
        "SSRS",
        "SAP",
        "ECC",
        "SAP",
        "Authorized",
        "US",
        "employer",
        "Work",
        "Experience",
        "Cloud",
        "Engineer",
        "ALTA",
        "GDIT",
        "Herndon",
        "VA",
        "November",
        "Present",
        "Managing",
        "Cloud",
        "Infrastructure",
        "Shared",
        "Services",
        "customers",
        "applications",
        "Amazon",
        "EC2",
        "Instances",
        "Linux",
        "Windows",
        "Amazon",
        "EC2",
        "Cloud",
        "Instances",
        "Configuring",
        "Instances",
        "respect",
        "Applications",
        "Availability",
        "Zones",
        "CloudFormation",
        "Worked",
        "project",
        "team",
        "members",
        "development",
        "approval",
        "criteria",
        "request",
        "change",
        "management",
        "process",
        "applications",
        "environments",
        "applications",
        "AWS",
        "EC2",
        "instances",
        "storage",
        "S3",
        "buckets",
        "security",
        "options",
        "access",
        "IAM",
        "role",
        "polices",
        "Build",
        "VPCs",
        "Virtual",
        "Cloud",
        "EC2",
        "instances",
        "Security",
        "Groups",
        "AutoScaling",
        "Load",
        "Balancers",
        "S3",
        "Glacier",
        "RDS",
        "SQS",
        "SNS",
        "SES",
        "connections",
        "Big",
        "Data",
        "Processing",
        "Apache",
        "Hadoop",
        "Apache",
        "Spark",
        "Amazon",
        "Elastic",
        "MapReduce",
        "EMR",
        "HDFS",
        "EMFS",
        "files",
        "S3",
        "Bucket",
        "Cluster",
        "Nodes",
        "Configured",
        "Transient",
        "Persistent",
        "Clusters",
        "workload",
        "scenario",
        "application",
        "Apache",
        "Hadoop",
        "frame",
        "Hive",
        "Hue",
        "Pig",
        "Ganglia",
        "Process",
        "Analyze",
        "datasets",
        "data",
        "sources",
        "applications",
        "Amazon",
        "Kinesis",
        "Stream",
        "Analyze",
        "Process",
        "Logs",
        "Apache",
        "application",
        "server",
        "Amazon",
        "Kinesis",
        "Firehose",
        "Processed",
        "Log",
        "Files",
        "Amazon",
        "S3",
        "Bucket",
        "Amazon",
        "Athena",
        "Web",
        "Data",
        "S3",
        "Bucket",
        "Responsible",
        "monitors",
        "alarms",
        "notifications",
        "EC2",
        "hosts",
        "Cloud",
        "Watch",
        "Migrating",
        "promise",
        "application",
        "AWS",
        "cloud",
        "Hybrid",
        "environment",
        "applications",
        "rotation",
        "Production",
        "Test",
        "Development",
        "Environment",
        "AWS",
        "EC2",
        "S3",
        "Glacier",
        "SMS",
        "RDS",
        "SQS",
        "SNS",
        "CloudFormation",
        "VPC",
        "Apache",
        "Hadoop",
        "Apache",
        "Spark",
        "Java",
        "Scala",
        "EMR",
        "Hive",
        "Presto",
        "Pig",
        "Hue",
        "Ganglia",
        "CloudWatch",
        "Kinesis",
        "Lambda",
        "QuickSight",
        "Athena",
        "Redshift",
        "DynamoDB",
        "Oracle",
        "LinuxWindows",
        "Python",
        "RDMS",
        "MySQL",
        "MS",
        "SQL",
        "Server",
        "AWS",
        "Cloud",
        "Systems",
        "Engineer",
        "Glocoms",
        "Inc",
        "Chicago",
        "IL",
        "November",
        "October",
        "Amazon",
        "EC2",
        "Cloud",
        "Instances",
        "Amazon",
        "Web",
        "Services",
        "Configuring",
        "Instances",
        "respect",
        "Applications",
        "Availability",
        "Zones",
        "Regions",
        "project",
        "team",
        "members",
        "development",
        "approval",
        "criteria",
        "request",
        "change",
        "management",
        "process",
        "applications",
        "environments",
        "applications",
        "AWS",
        "EC2",
        "instances",
        "storage",
        "S3",
        "buckets",
        "S3",
        "buckets",
        "creation",
        "policies",
        "IAM",
        "role",
        "polices",
        "Build",
        "servers",
        "AWS",
        "volumes",
        "EC2",
        "RDS",
        "security",
        "groups",
        "load",
        "balancers",
        "ELBs",
        "connection",
        "AWS",
        "Glue",
        "ETL",
        "Data",
        "Analytics",
        "Responsible",
        "monitors",
        "alarms",
        "notifications",
        "EC2",
        "hosts",
        "Cloud",
        "Watch",
        "migration",
        "implementation",
        "applications",
        "premise",
        "AWS",
        "services",
        "SMS",
        "DBMS",
        "CloudFormation",
        "S3",
        "Route53",
        "Glacier",
        "EC2",
        "RDS",
        "SQS",
        "SNS",
        "Redshift",
        "Lambda",
        "CloudFormation",
        "Cloudwatch",
        "Cloudtrail",
        "VPC",
        "Build",
        "servers",
        "AWS",
        "EC2",
        "RDS",
        "security",
        "groups",
        "load",
        "balancers",
        "ELBs",
        "connection",
        "Big",
        "Data",
        "Processing",
        "Apache",
        "Hadoop",
        "Apache",
        "Spark",
        "Amazon",
        "Elastic",
        "MapReduce",
        "EMR",
        "HDFS",
        "EMRFS",
        "files",
        "S3",
        "Bucket",
        "Cluster",
        "Nodes",
        "Configured",
        "Transient",
        "Persistent",
        "Clusters",
        "workload",
        "scenario",
        "application",
        "Apache",
        "Hadoop",
        "frame",
        "Hive",
        "Hue",
        "Pig",
        "Ganglia",
        "Process",
        "Analyze",
        "datasets",
        "data",
        "sources",
        "applications",
        "Amazon",
        "Kinesis",
        "Stream",
        "Analyze",
        "Process",
        "Logs",
        "Apache",
        "application",
        "server",
        "Amazon",
        "Kinesis",
        "Firehose",
        "Processed",
        "Log",
        "Files",
        "Amazon",
        "S3",
        "Bucket",
        "Amazon",
        "Athena",
        "Web",
        "Data",
        "S3",
        "Bucket",
        "Elastic",
        "Load",
        "Balancer",
        "Configuration",
        "Continuous",
        "Integration",
        "CI",
        "Continuous",
        "Delivery",
        "CD",
        "CodePipeline",
        "CodeDeploy",
        "automation",
        "rotation",
        "Production",
        "Test",
        "Development",
        "environments",
        "Installation",
        "Configuration",
        "Maintenance",
        "Oracle",
        "g",
        "Single",
        "Instances",
        "RAC",
        "databases",
        "Availability",
        "Disaster",
        "Recovery",
        "upgrade",
        "migration",
        "development",
        "test",
        "production",
        "databases",
        "g",
        "12c",
        "migration",
        "platforms",
        "backup",
        "recovery",
        "strategy",
        "Recovery",
        "Manager",
        "RMAN",
        "backup",
        "Data",
        "Pump",
        "ImportExport",
        "backup",
        "User",
        "Roles",
        "access",
        "Permissions",
        "Privileges",
        "users",
        "SQL",
        "PLSQL",
        "TSQL",
        "queries",
        "packages",
        "functions",
        "procedures",
        "tables",
        "views",
        "views",
        "indexes",
        "rotation",
        "Production",
        "Test",
        "Development",
        "Performed",
        "Performance",
        "Tuning",
        "SQLTRACE",
        "EXPLAIN",
        "PLAN",
        "TKPROF",
        "STATSPACK",
        "AWR",
        "ADDM",
        "Bash",
        "Shell",
        "Scripts",
        "automation",
        "Environment",
        "AWS",
        "EC2",
        "S3",
        "Glacier",
        "SMS",
        "RDS",
        "SQS",
        "SNS",
        "SES",
        "CloudFormation",
        "VPC",
        "Apache",
        "Spark",
        "Apache",
        "Hadoop",
        "EMR",
        "Hive",
        "Pig",
        "Hue",
        "Ganglia",
        "CloudWatch",
        "Kinesis",
        "Lambda",
        "QuickSight",
        "Athena",
        "Redshift",
        "DynamoDB",
        "Oracle",
        "12c",
        "LinuxWindows",
        "Java",
        "Scala",
        "Python",
        "MySQL",
        "MS",
        "SQL",
        "Server",
        "Database",
        "Administrator",
        "Glocoms",
        "Inc",
        "Chicago",
        "IL",
        "August",
        "October",
        "Responsible",
        "Installation",
        "Configuration",
        "Maintenance",
        "Oracle",
        "g",
        "Single",
        "Instances",
        "RAC",
        "Standby",
        "DataGuard",
        "High",
        "Availability",
        "Disaster",
        "Recovery",
        "Planned",
        "backup",
        "recovery",
        "strategy",
        "Recovery",
        "Manager",
        "RMAN",
        "backup",
        "Data",
        "Pump",
        "ImportExport",
        "backup",
        "production",
        "backups",
        "environments",
        "User",
        "Roles",
        "access",
        "Permissions",
        "Privileges",
        "users",
        "SQL",
        "PLSQL",
        "TSQL",
        "queries",
        "packages",
        "functions",
        "procedures",
        "tables",
        "views",
        "views",
        "indexes",
        "SQL",
        "PLSQL",
        "Performance",
        "Tuning",
        "tools",
        "EXPLAIN",
        "PLAN",
        "SQLTRACE",
        "TKPROF",
        "AUTOTRACE",
        "Oracle",
        "Enterprise",
        "Manager",
        "OEM",
        "job",
        "scheduling",
        "performance",
        "tuning",
        "DBA",
        "activities",
        "Production",
        "Quality",
        "Test",
        "Development",
        "Installation",
        "Configuration",
        "Migration",
        "Schema",
        "Objects",
        "Patches",
        "Database",
        "Upgrade",
        "g",
        "g",
        "g",
        "UNIX",
        "Power",
        "Shell",
        "Scripts",
        "automation",
        "Installed",
        "MySQL",
        "cluster",
        "configurations",
        "MySQL",
        "Servers",
        "party",
        "tools",
        "percona",
        "toolkit",
        "ptquery",
        "digest",
        "ptonline",
        "schema",
        "MySQL",
        "Error",
        "log",
        "Log",
        "maintenance",
        "troubleshooting",
        "queries",
        "MySQL",
        "Security",
        "MySQL",
        "Replication",
        "MySQL",
        "Clustering",
        "MySQL",
        "Database",
        "Performed",
        "MySQL",
        "Backups",
        "recovery",
        "strategies",
        "use",
        "master",
        "log",
        "database",
        "backups",
        "MyISAM",
        "InnoDB",
        "storage",
        "engines",
        "production",
        "database",
        "crash",
        "version",
        "recovery",
        "methods",
        "database",
        "security",
        "GrantingRevoking",
        "usersrole",
        "authorizations",
        "privileges",
        "MySQL",
        "Enterprise",
        "Monitor",
        "MySQL",
        "Replication",
        "Monitor",
        "MySQL",
        "Query",
        "Analyzer",
        "query",
        "performance",
        "capacity",
        "Installation",
        "Administration",
        "MS",
        "SQL",
        "Server",
        "databases",
        "availability",
        "environments",
        "AlwaysOn",
        "Mirroring",
        "Log",
        "Shipping",
        "Replication",
        "Extract",
        "Transform",
        "Load",
        "ETL",
        "process",
        "performance",
        "Business",
        "Intelligence",
        "Reports",
        "OBIEE",
        "MS",
        "SSIS",
        "SSRS",
        "tools",
        "Data",
        "Sources",
        "knowledge",
        "BI",
        "solution",
        "Star",
        "Schema",
        "Snow",
        "Flake",
        "Schema",
        "Dimension",
        "Fact",
        "table",
        "Configure",
        "OBIEE",
        "SQL",
        "Reporting",
        "Services",
        "SSRS",
        "Developing",
        "Drill",
        "Tabular",
        "Reports",
        "Matrix",
        "Reports",
        "Drill",
        "Down",
        "Reports",
        "user",
        "guide",
        "documentation",
        "training",
        "materials",
        "database",
        "environments",
        "SOX",
        "compliance",
        "Environment",
        "Oracle",
        "g",
        "RAC",
        "OBIEE",
        "MySQL",
        "MS",
        "SSIS",
        "SSAS",
        "SSRS",
        "HPUX",
        "REDHAT",
        "LINUX",
        "ASM",
        "OEM",
        "Grid",
        "ControlCloud",
        "RMAN",
        "SQLLoader",
        "Database",
        "Administrator",
        "Oracle",
        "SAP",
        "Partner",
        "K2",
        "AG",
        "Zurich",
        "CH",
        "March",
        "February",
        "Production",
        "support",
        "database",
        "g",
        "g",
        "9i",
        "versions",
        "RAC",
        "environment",
        "UNIX",
        "Power",
        "Shell",
        "Scripts",
        "automation",
        "backup",
        "RMAN",
        "recovery",
        "strategies",
        "Performed",
        "Database",
        "performance",
        "Tuning",
        "Advisor",
        "AWR",
        "ADDM",
        "SQL",
        "ANALYZER",
        "Explain",
        "Plan",
        "command",
        "line",
        "generating",
        "reports",
        "TOAD",
        "DBArtisan",
        "OEM",
        "administrations",
        "job",
        "scheduling",
        "performance",
        "optimization",
        "tasks",
        "Switchovers",
        "Data",
        "Guard",
        "schedule",
        "Rolling",
        "Upgrades",
        "Used",
        "Data",
        "Pump",
        "backups",
        "schema",
        "migrations",
        "RMAN",
        "backups",
        "refreshes",
        "DPITR",
        "developers",
        "queries",
        "database",
        "capacity",
        "planning",
        "Transforming",
        "Loading",
        "ETL",
        "data",
        "SQLLoader",
        "External",
        "Tables",
        "databases",
        "Sun",
        "Solaris",
        "HPUX",
        "IBM",
        "AIX",
        "Windows",
        "Linux",
        "core",
        "database",
        "tasks",
        "user",
        "creation",
        "password",
        "accounts",
        "profiles",
        "roles",
        "migrating",
        "objects",
        "backups",
        "Environment",
        "Oracle",
        "g",
        "g",
        "9i",
        "HPUX",
        "SUN",
        "SOLARIS",
        "IBM",
        "AIX",
        "OEM",
        "Grid",
        "Control",
        "RMAN",
        "SQLLoader",
        "ASM",
        "Data",
        "Guard",
        "SAP",
        "Basis",
        "Administrator",
        "Ecolab",
        "GmbH",
        "Dsseldorf",
        "DE",
        "August",
        "August",
        "SAP",
        "Client",
        "Administration",
        "User",
        "Authorization",
        "concept",
        "Client",
        "copy",
        "Transport",
        "Management",
        "System",
        "performance",
        "Database",
        "maintenance",
        "Online",
        "Backup",
        "Archive",
        "Log",
        "Backup",
        "Upgrade",
        "SAP",
        "DBA",
        "BRTools",
        "Environment",
        "SAP",
        "R3",
        "Enterprise",
        "Oracle",
        "9i",
        "g",
        "Solaris",
        "SAP",
        "Consultant",
        "Accenture",
        "GmbH",
        "Frankfurt",
        "DE",
        "July",
        "May",
        "range",
        "consulting",
        "services",
        "client",
        "companies",
        "Givaudan",
        "Schweiz",
        "AG",
        "October",
        "April",
        "Bombardier",
        "Transportation",
        "UK",
        "June",
        "September",
        "Messer",
        "Group",
        "DE",
        "November",
        "May",
        "TMobile",
        "GmbH",
        "August",
        "October",
        "Education",
        "Master",
        "Science",
        "Data",
        "Analytics",
        "Data",
        "Analytics",
        "University",
        "Maryland",
        "University",
        "College",
        "Master",
        "Science",
        "Technical",
        "Management",
        "Technical",
        "Management",
        "University",
        "Applied",
        "Sciences",
        "Emden",
        "Skills",
        "DATA",
        "MODEL",
        "PLSQL",
        "SQL",
        "AIX",
        "LINUX",
        "SHELL",
        "SCRIPTING",
        "SUN",
        "UX",
        "POWER",
        "BI",
        "CC",
        "C",
        "JAVASCRIPT",
        "JSON",
        "PERL",
        "PHP",
        "PYTHON",
        "SCRIPTING",
        "XML",
        "BASH",
        "SCALA",
        "Docker",
        "Devops"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:28:16.493471",
    "resume_data": "Cloud Engineer Cloud Engineer Cloud Engineer ALTA GDIT Brandywine MD Over 4 years experience planning designing implementing and maintaining system applications in AWS Cloud in Linux and Windows environments and overall 15 years IT related experience Experience working in Agile Scrum Software Development Life Cycle with respect to delivering Operations Functional and Technical Specifications Resource Planning Development Testing and Maintenance Experience in migrating and implementation of multiple applications from on premise to cloud using AWS services like SMS Server Migration Service DMS Database Migration Service SCT Schema Conversion Tool CloudFormation Cloudwatch Cloudtrail S3 Route53 Glacier EC2 RDS SQS SNS and VPC Build and configure a virtual data center in the Amazon Web Services cloud to support Enterprise Data Warehouse hosting including Virtual Private Cloud VPC Public and Private Subnets Security Groups Route Tables Elastic Load Balancer Experience with Amazon Kinesis to Stream Analyze and Process realtime Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket Experience with Amazon Athena to Analyze Web Data Stored in S3 Bucket Experience in Big Data Processing with Apache Hadoop Apache Spark and Amazon Elastic MapReduce EMR using HDFS and EMRFS to directly access files stored in S3 Bucket with Cluster Nodes Configured EMR Transient and Persistent Clusters depending on the workload and scenario of the application Experience with Apache Hadoop frame works like Hive Presto Hue Pig and Ganglia to Process and Analyze datasets from various data sources and applications Migrated on premise Data Warehouse Application into Amazon Redshift and implemented the Leader Node and Compute Nodes for processing the information Implemented Amazon QuickSight and TIBCO Spotfire Analytics to generate various reports Configuration of Continuous Integration CI Continuous Delivery and Deployment CD using Github Jenkins for automation Experience in deployment of JavaJ2EE applications on WebLogic and WebSphere application servers Good experience in creating and editing Shell Bash Python Scripts for automation Excellent communication analytical and problem solving skills with ability to work within a team environment and independently Cloud Computing AWS EC2 EBS RDS S3 Glacier Apache Hadoop Apache Spark EMR Hive Presto Pig Hue Ganglia Apache Spark Redshift SQS SNS SES CloudFormation VPC IAM Route53 DynamoDB Lambda CloudWatch Cloudtrail CICD CodeDeploy and CodePipeline Ansible Jenkins Docker Github AWS Glue AWS Athena RDBMS Oracle 12c11g10g9i SQL PLSQL MySQL5657 MS SQL Server 2014 2012 2008 MS SSIS SSAS SSRS SAP ECC SAP HANA Authorized to work in the US for any employer Work Experience Cloud Engineer ALTA GDIT Herndon VA November 2018 to Present Managing Cloud Infrastructure and Shared Services for various customers applications running on Amazon EC2 Instances for Linux Windows environments Responsible for launching Amazon EC2 Cloud Instances and Configuring Instances with respect to specific Applications in various Availability Zones using CloudFormation Worked with project team members in the development of approval criteria and request for designing change management process of various applications running in hybrid environments Installed applications on AWS EC2 instances and configured storage on S3 buckets with security options for access and the IAM role based polices Build VPCs Virtual Private Cloud and launching EC2 instances with Security Groups AutoScaling Load Balancers and other like S3 Glacier RDS SQS SNS and SES in defined public and private connections Implemented Big Data Processing with Apache Hadoop Apache Spark and Amazon Elastic MapReduce EMR using HDFS and EMFS to directly access files stored in S3 Bucket for Cluster Nodes Configured Transient and Persistent Clusters depending on the workload and scenario of the application Implemented Apache Hadoop frame works like Hive Hue Pig and Ganglia to Process and Analyze datasets from various data sources and applications Implemented Amazon Kinesis to Stream Analyze and Process realtime Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket Implemented Amazon Athena to Analyze Web Data Stored in S3 Bucket Responsible for creating monitors alarms and notifications for EC2 hosts using Cloud Watch Migrating on promise application into AWS cloud and also configured a Hybrid environment for certain applications Involved in 24X7support rotation for all the Production Im pl Test and Development environments Environment AWS EC2 S3 Glacier SMS RDS SQS SNS CloudFormation VPC Apache Hadoop Apache Spark Java Scala EMR Hive Presto Pig Hue Ganglia CloudWatch Kinesis Lambda QuickSight Athena Redshift DynamoDB Oracle 12c LinuxWindows Python RDMS MySQL MS SQL Server 2012 AWS Cloud Systems Engineer Glocoms Inc Chicago IL November 2014 to October 2018 Responsible for launching Amazon EC2 Cloud Instances using Amazon Web Services and Configuring Instances with respect to specific Applications Availability Zones and Regions Worked with project team members in the development of approval criteria and request for designing change management process of various applications running in hybrid environments Installed applications on AWS EC2 instances and configured the storage on S3 buckets Responsible for S3 buckets creation policies and the IAM role based polices Build servers using AWS importing volumes launching EC2 RDS creating security groups autoscaling load balancers ELBs in the defined virtual private connection AWS Glue for ETL and Data Analytics Responsible for creating monitors alarms and notifications for EC2 hosts using Cloud Watch Involved in the migration and implementation of multiple applications from on premise to cloud using AWS services like SMS DBMS CloudFormation S3 Route53 Glacier EC2 RDS SQS SNS Redshift Lambda CloudFormation Cloudwatch Cloudtrail and VPC Build servers using AWS and launching EC2 RDS creating security groups autoscaling load balancers ELBs in the defined virtual private connection Implemented Big Data Processing with Apache Hadoop Apache Spark and Amazon Elastic MapReduce EMR using HDFS and EMRFS to directly access files stored in S3 Bucket for Cluster Nodes Configured Transient and Persistent Clusters depending on the workload and scenario of the application Implemented Apache Hadoop frame works like Hive Hue Pig and Ganglia to Process and Analyze datasets from various data sources and applications Implemented Amazon Kinesis to Stream Analyze and Process realtime Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket Implemented Amazon Athena to Analyze Web Data Stored in S3 Bucket by Elastic Load Balancer Configuration of Continuous Integration CI and Continuous Delivery CD using CodePipeline and CodeDeploy for automation Involved in 24X7support rotation for all the Production Test and Development environments Responsible for the Installation Configuration and Maintenance of Oracle 12c11g10g Single Instances and RAC databases for High Availability and Disaster Recovery Performed patching upgrade and migration of multiple development test and production databases from 10g11g to 12c and migration to different platforms Performed backup and recovery strategy using Recovery Manager RMAN physical backup and Data Pump ImportExport logical backup respectively Created User accounts Roles and granting required access Permissions and Privileges to the users Implemented SQL PLSQL and TSQL queries packages functions stored procedures triggers tables views materialized views indexes Involved in 24X7support rotation for all the Production Test and Development databases Performed Performance Tuning using SQLTRACE EXPLAIN PLAN TKPROF STATSPACK AWR and ADDM Developed various Bash Shell Scripts for automation Environment AWS EC2 S3 Glacier SMS RDS SQS SNS SES CloudFormation VPC Apache Spark Apache Hadoop EMR Hive Pig Hue Ganglia CloudWatch Kinesis Lambda QuickSight Athena Redshift DynamoDB Oracle 12c LinuxWindows Java Scala Python MySQL MS SQL Server 2012 Database Administrator Glocoms Inc Chicago IL August 2011 to October 2014 Responsible for Installation Configuration and Maintenance of Oracle 12c11g Single Instances RAC and Standby databases DataGuard for High Availability and Disaster Recovery Planned designed and implemented a robust backup and recovery strategy using Recovery Manager RMAN physical backup and Data Pump ImportExport logical backup respectively I periodically used production backups to refreshclone the lower environments Created User accounts Roles and granting required access Permissions and Privileges to the users Implemented SQL PLSQL and TSQL queries packages functions stored procedures triggers tables views materialized views indexes Performed SQL PLSQL Performance Tuning using various tools like EXPLAIN PLAN SQLTRACE TKPROF and AUTOTRACE Heavily utilized Oracle Enterprise Manager OEM for monitoring job scheduling performance tuning and other routine DBA activities Provided 24X7 supports for all the Production Quality Test Development databases Performed the Installation Configuration and Migration of various Schema Objects Patches and Database Upgrade from 10g to 11g and 11g to 12c Developed various UNIX Power Shell Scripts for automation Installed configured and maintained MySQL both cluster and nonclustered configurations Experienced in configuring troubleshooting managing and maintaining MySQL Servers with third party tools like percona toolkit ptquery digest ptonline schema change etc Maintained Optimized tuned MySQL Error log Log maintenance and troubleshooting queries Experienced in handling MySQL Security establishing MySQL Replication and MySQL Clustering between two or more MySQL Database servers Performed MySQL full incremental Backups logical and physical and recovery strategies making use of master binary log Implemented database backups for both MyISAM and InnoDB storage engines in production Recovered database using crash version and rollforward recovery methods Maintained database security by GrantingRevoking usersrole v 55 56 authorizations and privileges Implemented MySQL Enterprise Monitor MySQL Replication Monitor and MySQL Query Analyzer for improving query performance and capacity planning Installation and Administration of MS SQL Server 200820122014 databases in high availability environments including Clustering AlwaysOn Mirroring Log Shipping and Replication Implemented the Extract Transform and Load ETL process for developing high performance Business Intelligence Reports using OBIEE MS SSIS and SSRS tools from various Data Sources Strong knowledge of BI solution with Star Schema Snow Flake Schema Dimension and Fact table Configure OBIEE and SQL Reporting Services SSRS for Developing Drill Tabular Reports Matrix Reports and Drill Down Reports Developed user guide documentation and training materials for various database environments and SOX compliance Environment Oracle 12c 11g RAC OBIEE MySQL 5556 MS SSIS SSAS SSRS HPUX REDHAT LINUX Windows ASM OEM Grid ControlCloud RMAN SQLLoader Database Administrator Oracle SAP Partner K2 AG Zurich CH March 2010 to February 2011 Provided Production support for database on 11g 10g and 9i versions with standalone and RAC environment Developed various UNIX Power Shell Scripts for automation Performed full incremental backup using RMAN and implemented recovery strategies Performed Database performance tuning using Tuning Advisor AWR ADDM SQL ANALYZER and Explain Plan also using command line in generating reports needed Heavily utilized TOAD DBArtisan and OEM for various administrations reporting job scheduling and performance optimization tasks Implementing Switchovers in Data Guard environments for schedule and Rolling Upgrades Used Data Pump for logical backups and schema migrations Scheduled and used RMAN backups for refreshes using DPITR Interfaced regularly with developers to help optimize their queries and database support Performed capacity planning Extracting Transforming and Loading ETL data using SQLLoader and External Tables Migrated databases from Sun Solaris HPUX to IBM AIX and Windows to Linux Performing core database administrative tasks like user creation password resets unlocking accounts creating profiles roles migrating objects and backups etc Environment Oracle 11g 10g 9i HPUX SUN SOLARIS IBM AIX OEM Grid Control RMAN SQLLoader ASM Data Guard SAP Basis Administrator Ecolab GmbH Dsseldorf DE August 2007 to August 2008 Responsible for SAP Client Administration User Authorization concept Client copy Transport Management System performance tuning Database maintenance includes Online Backup Archive Log Backup Upgrade and SAP DBA BRTools Environment SAP R3 Enterprise 47 Oracle 9i and 10g windows 2000 Solaris SAP Consultant Accenture GmbH Frankfurt DE July 2005 to May 2007 Performed a broad range of SAPrelated consulting services for the following client companies Givaudan Schweiz AG October 2006 to April 2007 Bombardier Transportation UK June 2006 to September 2006 Messer Group DE November 2005 to May 2006 TMobile GmbH August 2005 to October 2005 Education Master of Science in Data Analytics in Data Analytics University of Maryland University College 2020 Master of Science in Technical Management in Technical Management University of Applied Sciences Emden 2001 Skills DATA MODEL PLSQL SQL AIX LINUX SHELL SCRIPTING SUN UX POWER BI CC C JAVASCRIPT JSON PERL PHP PYTHON SCRIPTING XML BASH SCALA Docker Devops",
    "unique_id": "9c902f35-f81b-4e68-ba53-8dc95f511698"
}