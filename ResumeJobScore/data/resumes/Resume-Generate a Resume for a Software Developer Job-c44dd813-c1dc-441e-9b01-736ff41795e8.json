{
    "clean_data": "Job Seeker Germantown MD Work Experience NETE Solutions Bethesda MD March 2018 to May 2019 Assisted in designing development and architecture of Hadoop and HBase systems Coordinated with technical teams for installation of Hadoop and third related applications on systems Formulated procedures for planning and execution of system upgrades for all existing Hadoop clusters Supported technical team members for automation installation and configuration tasks Suggested improvement processes for all process automation scripts and tasks Provided technical assistance for configuration administration and monitoring of Hadoop clusters Conducted detailed analysis of system and application architecture components as per functional requirements Participated in evaluation and selection of new technologies to support system efficiency Assisted in creation of ETL processes for transformation of data sources from existing RDBMS systems Designed and developed scalable and custom Hadoop solutions as per dynamic data needs Coordinated with technical team for production deployment of software applications for maintenance Provided operational support services relating to Hadoop infrastructure and application installation Supported technical team members in management and review of Hadoop log files and data backups Participated in development and execution of system and disaster recovery processes Formulated procedures for installation of Hadoop patches updates and version upgrades Automated processes for troubleshooting resolution and tuning of Hadoop clusters HadoopCouchbase Administrator Marriott International Corporation Gaithersburg MD May 2017 to January 2018 Managed several Hadoop and Couchbase clusters in development and production environments across data centers at Iron Mountain Phoenix Arizona Ashburn VA and Frederick Md Developed Map Reduce programs for generation of reports supporting Business Intelligence Business intelligence support via import export of column data into HDFSHive Partitioned Tables Hadoop via Sqoop Built and configured log data loading into HDFS using Flume Performed Importing and exporting data into HDFS and Hive using Sqoop Managed cluster coordination services through Zoo Keeper Provisioning installing configuring monitoring and maintaining HDFS Supported codedesign analysis strategy development and project planning Created software design documents for modification of current OLTP NED system for refactoring of several Oracle databases objects to support functionality modifications Performed in depth analysis of legacy system residing as a submodule to the NED system Built Hadoop clusters on HDP 22 and HDP 23 Designed and implemented 3 node Couchbase clusters across data centers Worked with engineering software developers to investigate problems and make changes to the Hadoop environment and associated applications Performance tuning on Hadoop Couchbase and Oracle 122 RAC Expertise in recommending hardware configuration for Hadoop cluster Installing Upgrading and Managing Hadoop Cluster on Hortonworks Trouble shooting many cloud related issues such as Data Node down Network failure and data block missing Major Upgrade from HDP 22 to HDP 23 Managing and reviewing Hadoop and HBase log files Built and configured log data loading into HDFS using Flume Performed Importing and exporting data into HDFS and Hive using Sqoop Managed cluster coordination services through Zoo Keeper Provisioning installing configuring monitoring and maintaining HDFS Yarn HBase Flume Sqoop Oozie Pig and Hive Practiced recovering from node failures and troubleshooting common Hadoop cluster issues Scripting Hadoop package installation and configuration to support fullyautomated deployments Supporting Hadoop developers and assisting in optimization of map reduce jobs Pig Latin scripts Hive Scripts and HBase ingest required Performed HDFS cluster support and maintenance tasks like Adding and Removing Nodes without any effect to running jobs and data Oversaw the design construction and implementation of an Oracle 12201 Real Application Cluster RAC This project included the construction of a Proof of Concept 2 node cluster two 2 node clusters in development and test and a production 2 node cluster Big Data Engineer Database Manager Carey International Frederick MD November 2007 to October 2016 Developed Map reduce program to extract and transform the data sets and resultant dataset were loaded to Cassandra and vice versa using kafka 20x Used Spark API 14x over Cloudera Hadoop YARN 252 to perform analytics on data in Hive Exploring with the Spark 14x improving the performance and optimization of the existing algorithms in Hadoop 252 using Spark Context SparkSQL Data Frames Implemented Batch processing of data sources using Apache Spark 14x Developed analytical components using Spark 14x Scala 210x and Spark Stream Imported data from different sources like HDFSHbase 09427 to Spark RDD Developed Spark scripts by using Scala Shell commands as per the requirement Developed numerous MapReduce jobs in Scala 210x for Data Cleansing and Analyzing Data in Impala 210 Loaded and extracted the data using Sqoop 146 from Oracle 12101 into HDFS Senior Manager Database developer in charge of monitoring database activity conducted by several contracting companies responsible for maintaining existing database systems and implementing new systems Oversee a vast field of players including Accenture Atos Atlas Starwood IBM Linux and Oracle to evaluate database design daytoday activity and various other tasks associated with database systems Databases under my supervision included SQLServer Couchbase 45 DB2 LUW 105 MySQL 57 Oracle 12201 Oversaw the design construction and implementation of an Oracle 12201 Real Application Cluster RAC This project included the construction of a Proof of Concept 2 node cluster two 2 node clusters in development and test and a production 2 node cluster Upgraded 30 Oracle Databases from 11204 to 12102 Designed and implemented Disaster Recovery Site using Oracle Data Guard Designed developed and implemented Korn shell Perl programs to provide real time monitoring of resource intensive SQL alert log scanning and database logon attempts Created security profiles for users developed and maintained procedures and processes to provide proactive database security Utilized AWR reports for review of SQL plans Coded SQL PLSQL Perl programs for study of optimizer plan baselines and general database performance Monitored optimized and allocated physical and virtual storage for database systems via NetApp SAN implemented NetApp block level snapshot backups Supported 50person offshore development team during migration of applications from Web Based to Mobile Based platform Developed database architectures coding standards and quality assurance policies and procedures Designed and implemented RMAN backup at master and disaster recovery sites Assisted in developing the Support Services allocation model in the Hyperion Profitability and Cost Management tool Paragon Computer Professionals Database Manager Developer Consumer Data Industry Association January 2004 to November 2007 Upgraded 920 databases to 1020 on Solaris 9 Solaris 10 Designed and implemented Data Guard for disaster recovery and developed Disaster Recovery Plan Developed Operations and Database Users Manuals and BackupRecovery Guides covering all aspects of database maintenance and usage Provided longterm strategic goals for OLTP and Data Warehouse consisting of several terabytes of data and the online processing of 30 million transactions per month Unisys February 2004 to December 2004 Supported classified Security and Risk Assessment System at TSA client site in Pentagon City Provide 247 support for multiple InternetIntranet RAC enabled 9i databases supporting 11i9ias applications for the Transportation Safety Administration TSA Developed RMAN backup and recovery programs Evaluated database performance via Statspack and implemented changes as needed Maintained multiple Apache Web Servers in complex multinetwork environment Provided general database design implementation and administration to assure highest reliability and availability of IT services for all enterprise databases Education Associate Degree in Applied Science in Computer Information Systems Northern Virginia Community College Alexandria VA 1988 Computer Science Boston University Boston MA",
    "entities": [
        "Cloudera Hadoop",
        "Assisted",
        "Spark Context",
        "LUW",
        "Conducted",
        "ETL",
        "Hadoop Couchbase",
        "Oracle 12101",
        "Data Node",
        "Data Warehouse",
        "Database Users Manuals",
        "Sqoop",
        "Pentagon City",
        "BackupRecovery Guides",
        "the Transportation Safety Administration",
        "Computer Science Boston University",
        "TSA",
        "Performed",
        "Data Guard",
        "Bethesda",
        "HDFS",
        "Impala",
        "NetApp SAN",
        "Consumer Data Industry Association",
        "Boston MA",
        "Built Hadoop",
        "Business Intelligence Business",
        "Oracle",
        "Coordinated",
        "Coded",
        "Spark RDD Developed Spark",
        "Monitored",
        "Hive Exploring",
        "InternetIntranet RAC",
        "Hive",
        "NED",
        "the Hyperion Profitability and Cost Management",
        "Applied Science in Computer Information Systems Northern Virginia Community College",
        "HDFSHive Partitioned Tables Hadoop",
        "Support Services",
        "node",
        "SQL",
        "Hadoop",
        "OLTP",
        "Supporting Hadoop",
        "Oversee",
        "Worked",
        "MapReduce",
        "Marriott International Corporation Gaithersburg",
        "MD",
        "node Couchbase",
        "Performed HDFS",
        "Arizona",
        "Scripting Hadoop",
        "NetApp",
        "Iron Mountain Phoenix",
        "Maintained",
        "HDP",
        "HBase",
        "Formulated",
        "Spark Stream Imported",
        "Apache Spark",
        "Oracle Databases",
        "Suggested",
        "Couchbase",
        "Spark",
        "Oracle Data Guard Designed"
    ],
    "experience": "Experience NETE Solutions Bethesda MD March 2018 to May 2019 Assisted in designing development and architecture of Hadoop and HBase systems Coordinated with technical teams for installation of Hadoop and third related applications on systems Formulated procedures for planning and execution of system upgrades for all existing Hadoop clusters Supported technical team members for automation installation and configuration tasks Suggested improvement processes for all process automation scripts and tasks Provided technical assistance for configuration administration and monitoring of Hadoop clusters Conducted detailed analysis of system and application architecture components as per functional requirements Participated in evaluation and selection of new technologies to support system efficiency Assisted in creation of ETL processes for transformation of data sources from existing RDBMS systems Designed and developed scalable and custom Hadoop solutions as per dynamic data needs Coordinated with technical team for production deployment of software applications for maintenance Provided operational support services relating to Hadoop infrastructure and application installation Supported technical team members in management and review of Hadoop log files and data backups Participated in development and execution of system and disaster recovery processes Formulated procedures for installation of Hadoop patches updates and version upgrades Automated processes for troubleshooting resolution and tuning of Hadoop clusters HadoopCouchbase Administrator Marriott International Corporation Gaithersburg MD May 2017 to January 2018 Managed several Hadoop and Couchbase clusters in development and production environments across data centers at Iron Mountain Phoenix Arizona Ashburn VA and Frederick Md Developed Map Reduce programs for generation of reports supporting Business Intelligence Business intelligence support via import export of column data into HDFSHive Partitioned Tables Hadoop via Sqoop Built and configured log data loading into HDFS using Flume Performed Importing and exporting data into HDFS and Hive using Sqoop Managed cluster coordination services through Zoo Keeper Provisioning installing configuring monitoring and maintaining HDFS Supported codedesign analysis strategy development and project planning Created software design documents for modification of current OLTP NED system for refactoring of several Oracle databases objects to support functionality modifications Performed in depth analysis of legacy system residing as a submodule to the NED system Built Hadoop clusters on HDP 22 and HDP 23 Designed and implemented 3 node Couchbase clusters across data centers Worked with engineering software developers to investigate problems and make changes to the Hadoop environment and associated applications Performance tuning on Hadoop Couchbase and Oracle 122 RAC Expertise in recommending hardware configuration for Hadoop cluster Installing Upgrading and Managing Hadoop Cluster on Hortonworks Trouble shooting many cloud related issues such as Data Node down Network failure and data block missing Major Upgrade from HDP 22 to HDP 23 Managing and reviewing Hadoop and HBase log files Built and configured log data loading into HDFS using Flume Performed Importing and exporting data into HDFS and Hive using Sqoop Managed cluster coordination services through Zoo Keeper Provisioning installing configuring monitoring and maintaining HDFS Yarn HBase Flume Sqoop Oozie Pig and Hive Practiced recovering from node failures and troubleshooting common Hadoop cluster issues Scripting Hadoop package installation and configuration to support fullyautomated deployments Supporting Hadoop developers and assisting in optimization of map reduce jobs Pig Latin scripts Hive Scripts and HBase ingest required Performed HDFS cluster support and maintenance tasks like Adding and Removing Nodes without any effect to running jobs and data Oversaw the design construction and implementation of an Oracle 12201 Real Application Cluster RAC This project included the construction of a Proof of Concept 2 node cluster two 2 node clusters in development and test and a production 2 node cluster Big Data Engineer Database Manager Carey International Frederick MD November 2007 to October 2016 Developed Map reduce program to extract and transform the data sets and resultant dataset were loaded to Cassandra and vice versa using kafka 20x Used Spark API 14x over Cloudera Hadoop YARN 252 to perform analytics on data in Hive Exploring with the Spark 14x improving the performance and optimization of the existing algorithms in Hadoop 252 using Spark Context SparkSQL Data Frames Implemented Batch processing of data sources using Apache Spark 14x Developed analytical components using Spark 14x Scala 210x and Spark Stream Imported data from different sources like HDFSHbase 09427 to Spark RDD Developed Spark scripts by using Scala Shell commands as per the requirement Developed numerous MapReduce jobs in Scala 210x for Data Cleansing and Analyzing Data in Impala 210 Loaded and extracted the data using Sqoop 146 from Oracle 12101 into HDFS Senior Manager Database developer in charge of monitoring database activity conducted by several contracting companies responsible for maintaining existing database systems and implementing new systems Oversee a vast field of players including Accenture Atos Atlas Starwood IBM Linux and Oracle to evaluate database design daytoday activity and various other tasks associated with database systems Databases under my supervision included SQLServer Couchbase 45 DB2 LUW 105 MySQL 57 Oracle 12201 Oversaw the design construction and implementation of an Oracle 12201 Real Application Cluster RAC This project included the construction of a Proof of Concept 2 node cluster two 2 node clusters in development and test and a production 2 node cluster Upgraded 30 Oracle Databases from 11204 to 12102 Designed and implemented Disaster Recovery Site using Oracle Data Guard Designed developed and implemented Korn shell Perl programs to provide real time monitoring of resource intensive SQL alert log scanning and database logon attempts Created security profiles for users developed and maintained procedures and processes to provide proactive database security Utilized AWR reports for review of SQL plans Coded SQL PLSQL Perl programs for study of optimizer plan baselines and general database performance Monitored optimized and allocated physical and virtual storage for database systems via NetApp SAN implemented NetApp block level snapshot backups Supported 50person offshore development team during migration of applications from Web Based to Mobile Based platform Developed database architectures coding standards and quality assurance policies and procedures Designed and implemented RMAN backup at master and disaster recovery sites Assisted in developing the Support Services allocation model in the Hyperion Profitability and Cost Management tool Paragon Computer Professionals Database Manager Developer Consumer Data Industry Association January 2004 to November 2007 Upgraded 920 databases to 1020 on Solaris 9 Solaris 10 Designed and implemented Data Guard for disaster recovery and developed Disaster Recovery Plan Developed Operations and Database Users Manuals and BackupRecovery Guides covering all aspects of database maintenance and usage Provided longterm strategic goals for OLTP and Data Warehouse consisting of several terabytes of data and the online processing of 30 million transactions per month Unisys February 2004 to December 2004 Supported classified Security and Risk Assessment System at TSA client site in Pentagon City Provide 247 support for multiple InternetIntranet RAC enabled 9i databases supporting 11i9ias applications for the Transportation Safety Administration TSA Developed RMAN backup and recovery programs Evaluated database performance via Statspack and implemented changes as needed Maintained multiple Apache Web Servers in complex multinetwork environment Provided general database design implementation and administration to assure highest reliability and availability of IT services for all enterprise databases Education Associate Degree in Applied Science in Computer Information Systems Northern Virginia Community College Alexandria VA 1988 Computer Science Boston University Boston MA",
    "extracted_keywords": [
        "Job",
        "Seeker",
        "Germantown",
        "MD",
        "Work",
        "Experience",
        "NETE",
        "Solutions",
        "Bethesda",
        "MD",
        "March",
        "May",
        "development",
        "architecture",
        "Hadoop",
        "HBase",
        "systems",
        "teams",
        "installation",
        "Hadoop",
        "applications",
        "systems",
        "procedures",
        "planning",
        "execution",
        "system",
        "upgrades",
        "Hadoop",
        "clusters",
        "team",
        "members",
        "automation",
        "installation",
        "configuration",
        "tasks",
        "improvement",
        "processes",
        "process",
        "automation",
        "scripts",
        "tasks",
        "assistance",
        "configuration",
        "administration",
        "monitoring",
        "Hadoop",
        "clusters",
        "analysis",
        "system",
        "application",
        "architecture",
        "components",
        "requirements",
        "evaluation",
        "selection",
        "technologies",
        "system",
        "efficiency",
        "creation",
        "ETL",
        "processes",
        "transformation",
        "data",
        "sources",
        "RDBMS",
        "systems",
        "custom",
        "Hadoop",
        "solutions",
        "data",
        "team",
        "production",
        "deployment",
        "software",
        "applications",
        "maintenance",
        "support",
        "services",
        "Hadoop",
        "infrastructure",
        "application",
        "installation",
        "team",
        "members",
        "management",
        "review",
        "Hadoop",
        "log",
        "files",
        "data",
        "backups",
        "development",
        "execution",
        "system",
        "disaster",
        "recovery",
        "procedures",
        "installation",
        "Hadoop",
        "updates",
        "version",
        "upgrades",
        "Automated",
        "processes",
        "resolution",
        "tuning",
        "Hadoop",
        "clusters",
        "HadoopCouchbase",
        "Administrator",
        "Marriott",
        "International",
        "Corporation",
        "Gaithersburg",
        "MD",
        "May",
        "January",
        "Hadoop",
        "Couchbase",
        "clusters",
        "development",
        "production",
        "environments",
        "data",
        "centers",
        "Iron",
        "Mountain",
        "Phoenix",
        "Arizona",
        "Ashburn",
        "VA",
        "Frederick",
        "Md",
        "Developed",
        "Map",
        "programs",
        "generation",
        "reports",
        "Business",
        "Intelligence",
        "Business",
        "intelligence",
        "support",
        "import",
        "export",
        "column",
        "data",
        "Partitioned",
        "Tables",
        "Hadoop",
        "Sqoop",
        "Built",
        "log",
        "data",
        "HDFS",
        "Flume",
        "Performed",
        "Importing",
        "data",
        "HDFS",
        "Hive",
        "Sqoop",
        "Managed",
        "cluster",
        "coordination",
        "services",
        "Zoo",
        "Keeper",
        "Provisioning",
        "configuring",
        "monitoring",
        "HDFS",
        "codedesign",
        "analysis",
        "strategy",
        "development",
        "project",
        "software",
        "design",
        "documents",
        "modification",
        "OLTP",
        "NED",
        "system",
        "refactoring",
        "Oracle",
        "databases",
        "functionality",
        "modifications",
        "depth",
        "analysis",
        "legacy",
        "system",
        "submodule",
        "NED",
        "system",
        "Hadoop",
        "clusters",
        "HDP",
        "HDP",
        "node",
        "Couchbase",
        "clusters",
        "data",
        "centers",
        "engineering",
        "software",
        "developers",
        "problems",
        "changes",
        "Hadoop",
        "environment",
        "applications",
        "Performance",
        "Hadoop",
        "Couchbase",
        "Oracle",
        "RAC",
        "Expertise",
        "hardware",
        "configuration",
        "Hadoop",
        "cluster",
        "Installing",
        "Upgrading",
        "Managing",
        "Hadoop",
        "Cluster",
        "Hortonworks",
        "Trouble",
        "issues",
        "Data",
        "Node",
        "Network",
        "failure",
        "data",
        "block",
        "Major",
        "Upgrade",
        "HDP",
        "HDP",
        "Managing",
        "Hadoop",
        "HBase",
        "files",
        "log",
        "data",
        "HDFS",
        "Flume",
        "Performed",
        "Importing",
        "data",
        "HDFS",
        "Hive",
        "Sqoop",
        "Managed",
        "cluster",
        "coordination",
        "services",
        "Zoo",
        "Keeper",
        "Provisioning",
        "configuring",
        "monitoring",
        "HDFS",
        "Yarn",
        "HBase",
        "Flume",
        "Sqoop",
        "Oozie",
        "Pig",
        "Hive",
        "Practiced",
        "failures",
        "Hadoop",
        "cluster",
        "issues",
        "Scripting",
        "Hadoop",
        "package",
        "installation",
        "configuration",
        "deployments",
        "Hadoop",
        "developers",
        "optimization",
        "map",
        "jobs",
        "Pig",
        "Latin",
        "Hive",
        "Scripts",
        "HBase",
        "ingest",
        "Performed",
        "HDFS",
        "cluster",
        "support",
        "maintenance",
        "tasks",
        "Removing",
        "Nodes",
        "effect",
        "jobs",
        "data",
        "Oversaw",
        "design",
        "construction",
        "implementation",
        "Oracle",
        "Real",
        "Application",
        "Cluster",
        "RAC",
        "project",
        "construction",
        "Proof",
        "Concept",
        "node",
        "cluster",
        "node",
        "clusters",
        "development",
        "test",
        "production",
        "node",
        "cluster",
        "Big",
        "Data",
        "Engineer",
        "Database",
        "Manager",
        "Carey",
        "International",
        "Frederick",
        "MD",
        "November",
        "October",
        "Developed",
        "Map",
        "program",
        "data",
        "sets",
        "dataset",
        "Cassandra",
        "20x",
        "Spark",
        "API",
        "14x",
        "Cloudera",
        "Hadoop",
        "YARN",
        "analytics",
        "data",
        "Hive",
        "Exploring",
        "Spark",
        "14x",
        "performance",
        "optimization",
        "algorithms",
        "Hadoop",
        "Spark",
        "Context",
        "SparkSQL",
        "Data",
        "Frames",
        "Batch",
        "processing",
        "data",
        "sources",
        "Apache",
        "Spark",
        "components",
        "Spark",
        "14x",
        "Scala",
        "210x",
        "Spark",
        "Stream",
        "data",
        "sources",
        "HDFSHbase",
        "Spark",
        "Spark",
        "scripts",
        "Scala",
        "Shell",
        "requirement",
        "MapReduce",
        "jobs",
        "Scala",
        "210x",
        "Data",
        "Cleansing",
        "Analyzing",
        "Data",
        "Impala",
        "Loaded",
        "data",
        "Sqoop",
        "Oracle",
        "HDFS",
        "Senior",
        "Manager",
        "Database",
        "developer",
        "charge",
        "database",
        "activity",
        "contracting",
        "companies",
        "database",
        "systems",
        "systems",
        "field",
        "players",
        "Accenture",
        "Atos",
        "Atlas",
        "Starwood",
        "IBM",
        "Linux",
        "Oracle",
        "database",
        "design",
        "daytoday",
        "activity",
        "tasks",
        "database",
        "systems",
        "Databases",
        "supervision",
        "SQLServer",
        "Couchbase",
        "DB2",
        "LUW",
        "MySQL",
        "Oracle",
        "Oversaw",
        "design",
        "construction",
        "implementation",
        "Oracle",
        "Real",
        "Application",
        "Cluster",
        "RAC",
        "project",
        "construction",
        "Proof",
        "Concept",
        "node",
        "cluster",
        "node",
        "clusters",
        "development",
        "test",
        "production",
        "node",
        "cluster",
        "Oracle",
        "Databases",
        "Disaster",
        "Recovery",
        "Site",
        "Oracle",
        "Data",
        "Guard",
        "Korn",
        "shell",
        "Perl",
        "programs",
        "time",
        "monitoring",
        "resource",
        "SQL",
        "alert",
        "log",
        "scanning",
        "database",
        "logon",
        "security",
        "profiles",
        "users",
        "procedures",
        "processes",
        "database",
        "security",
        "AWR",
        "reports",
        "review",
        "SQL",
        "SQL",
        "PLSQL",
        "Perl",
        "programs",
        "study",
        "optimizer",
        "plan",
        "baselines",
        "database",
        "performance",
        "storage",
        "database",
        "systems",
        "NetApp",
        "SAN",
        "block",
        "level",
        "snapshot",
        "backups",
        "development",
        "team",
        "migration",
        "applications",
        "Web",
        "Mobile",
        "Based",
        "platform",
        "database",
        "standards",
        "quality",
        "assurance",
        "policies",
        "procedures",
        "RMAN",
        "backup",
        "master",
        "disaster",
        "recovery",
        "sites",
        "Support",
        "Services",
        "allocation",
        "model",
        "Hyperion",
        "Profitability",
        "Cost",
        "Management",
        "tool",
        "Paragon",
        "Computer",
        "Professionals",
        "Database",
        "Manager",
        "Developer",
        "Consumer",
        "Data",
        "Industry",
        "Association",
        "January",
        "November",
        "databases",
        "Solaris",
        "Solaris",
        "Data",
        "Guard",
        "disaster",
        "recovery",
        "Disaster",
        "Recovery",
        "Plan",
        "Developed",
        "Operations",
        "Database",
        "Users",
        "Manuals",
        "BackupRecovery",
        "Guides",
        "aspects",
        "database",
        "maintenance",
        "usage",
        "goals",
        "OLTP",
        "Data",
        "Warehouse",
        "terabytes",
        "data",
        "processing",
        "transactions",
        "month",
        "Unisys",
        "February",
        "December",
        "Security",
        "Risk",
        "Assessment",
        "System",
        "TSA",
        "client",
        "site",
        "Pentagon",
        "City",
        "support",
        "InternetIntranet",
        "RAC",
        "9i",
        "databases",
        "11i9ias",
        "applications",
        "Transportation",
        "Safety",
        "Administration",
        "TSA",
        "Developed",
        "RMAN",
        "backup",
        "recovery",
        "programs",
        "database",
        "performance",
        "Statspack",
        "changes",
        "Apache",
        "Web",
        "Servers",
        "multinetwork",
        "environment",
        "database",
        "design",
        "implementation",
        "administration",
        "reliability",
        "availability",
        "IT",
        "services",
        "enterprise",
        "Education",
        "Associate",
        "Degree",
        "Applied",
        "Science",
        "Computer",
        "Information",
        "Systems",
        "Northern",
        "Virginia",
        "Community",
        "College",
        "Alexandria",
        "VA",
        "Computer",
        "Science",
        "Boston",
        "University",
        "Boston",
        "MA"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T22:16:35.462428",
    "resume_data": "Job Seeker Germantown MD Work Experience NETE Solutions Bethesda MD March 2018 to May 2019 Assisted in designing development and architecture of Hadoop and HBase systems Coordinated with technical teams for installation of Hadoop and third related applications on systems Formulated procedures for planning and execution of system upgrades for all existing Hadoop clusters Supported technical team members for automation installation and configuration tasks Suggested improvement processes for all process automation scripts and tasks Provided technical assistance for configuration administration and monitoring of Hadoop clusters Conducted detailed analysis of system and application architecture components as per functional requirements Participated in evaluation and selection of new technologies to support system efficiency Assisted in creation of ETL processes for transformation of data sources from existing RDBMS systems Designed and developed scalable and custom Hadoop solutions as per dynamic data needs Coordinated with technical team for production deployment of software applications for maintenance Provided operational support services relating to Hadoop infrastructure and application installation Supported technical team members in management and review of Hadoop log files and data backups Participated in development and execution of system and disaster recovery processes Formulated procedures for installation of Hadoop patches updates and version upgrades Automated processes for troubleshooting resolution and tuning of Hadoop clusters HadoopCouchbase Administrator Marriott International Corporation Gaithersburg MD May 2017 to January 2018 Managed several Hadoop and Couchbase clusters in development and production environments across data centers at Iron Mountain Phoenix Arizona Ashburn VA and Frederick Md Developed Map Reduce programs for generation of reports supporting Business Intelligence Business intelligence support via import export of column data into HDFSHive Partitioned Tables Hadoop via Sqoop Built and configured log data loading into HDFS using Flume Performed Importing and exporting data into HDFS and Hive using Sqoop Managed cluster coordination services through Zoo Keeper Provisioning installing configuring monitoring and maintaining HDFS Supported codedesign analysis strategy development and project planning Created software design documents for modification of current OLTP NED system for refactoring of several Oracle databases objects to support functionality modifications Performed in depth analysis of legacy system residing as a submodule to the NED system Built Hadoop clusters on HDP 22 and HDP 23 Designed and implemented 3 node Couchbase clusters across data centers Worked with engineering software developers to investigate problems and make changes to the Hadoop environment and associated applications Performance tuning on Hadoop Couchbase and Oracle 122 RAC Expertise in recommending hardware configuration for Hadoop cluster Installing Upgrading and Managing Hadoop Cluster on Hortonworks Trouble shooting many cloud related issues such as Data Node down Network failure and data block missing Major Upgrade from HDP 22 to HDP 23 Managing and reviewing Hadoop and HBase log files Built and configured log data loading into HDFS using Flume Performed Importing and exporting data into HDFS and Hive using Sqoop Managed cluster coordination services through Zoo Keeper Provisioning installing configuring monitoring and maintaining HDFS Yarn HBase Flume Sqoop Oozie Pig and Hive Practiced recovering from node failures and troubleshooting common Hadoop cluster issues Scripting Hadoop package installation and configuration to support fullyautomated deployments Supporting Hadoop developers and assisting in optimization of map reduce jobs Pig Latin scripts Hive Scripts and HBase ingest required Performed HDFS cluster support and maintenance tasks like Adding and Removing Nodes without any effect to running jobs and data Oversaw the design construction and implementation of an Oracle 12201 Real Application Cluster RAC This project included the construction of a Proof of Concept 2 node cluster two 2 node clusters in development and test and a production 2 node cluster Big Data Engineer Database Manager Carey International Frederick MD November 2007 to October 2016 Developed Map reduce program to extract and transform the data sets and resultant dataset were loaded to Cassandra and vice versa using kafka 20x Used Spark API 14x over Cloudera Hadoop YARN 252 to perform analytics on data in Hive Exploring with the Spark 14x improving the performance and optimization of the existing algorithms in Hadoop 252 using Spark Context SparkSQL Data Frames Implemented Batch processing of data sources using Apache Spark 14x Developed analytical components using Spark 14x Scala 210x and Spark Stream Imported data from different sources like HDFSHbase 09427 to Spark RDD Developed Spark scripts by using Scala Shell commands as per the requirement Developed numerous MapReduce jobs in Scala 210x for Data Cleansing and Analyzing Data in Impala 210 Loaded and extracted the data using Sqoop 146 from Oracle 12101 into HDFS Senior Manager Database developer in charge of monitoring database activity conducted by several contracting companies responsible for maintaining existing database systems and implementing new systems Oversee a vast field of players including Accenture Atos Atlas Starwood IBM Linux and Oracle to evaluate database design daytoday activity and various other tasks associated with database systems Databases under my supervision included SQLServer Couchbase 45 DB2 LUW 105 MySQL 57 Oracle 12201 Oversaw the design construction and implementation of an Oracle 12201 Real Application Cluster RAC This project included the construction of a Proof of Concept 2 node cluster two 2 node clusters in development and test and a production 2 node cluster Upgraded 30 Oracle Databases from 11204 to 12102 Designed and implemented Disaster Recovery Site using Oracle Data Guard Designed developed and implemented Korn shell Perl programs to provide real time monitoring of resource intensive SQL alert log scanning and database logon attempts Created security profiles for users developed and maintained procedures and processes to provide proactive database security Utilized AWR reports for review of SQL plans Coded SQL PLSQL Perl programs for study of optimizer plan baselines and general database performance Monitored optimized and allocated physical and virtual storage for database systems via NetApp SAN implemented NetApp block level snapshot backups Supported 50person offshore development team during migration of applications from Web Based to Mobile Based platform Developed database architectures coding standards and quality assurance policies and procedures Designed and implemented RMAN backup at master and disaster recovery sites Assisted in developing the Support Services allocation model in the Hyperion Profitability and Cost Management tool Paragon Computer Professionals Database Manager Developer Consumer Data Industry Association January 2004 to November 2007 Upgraded 920 databases to 1020 on Solaris 9 Solaris 10 Designed and implemented Data Guard for disaster recovery and developed Disaster Recovery Plan Developed Operations and Database Users Manuals and BackupRecovery Guides covering all aspects of database maintenance and usage Provided longterm strategic goals for OLTP and Data Warehouse consisting of several terabytes of data and the online processing of 30 million transactions per month Unisys February 2004 to December 2004 Supported classified Security and Risk Assessment System at TSA client site in Pentagon City Provide 247 support for multiple InternetIntranet RAC enabled 9i databases supporting 11i9ias applications for the Transportation Safety Administration TSA Developed RMAN backup and recovery programs Evaluated database performance via Statspack and implemented changes as needed Maintained multiple Apache Web Servers in complex multinetwork environment Provided general database design implementation and administration to assure highest reliability and availability of IT services for all enterprise databases Education Associate Degree in Applied Science in Computer Information Systems Northern Virginia Community College Alexandria VA 1988 Computer Science Boston University Boston MA",
    "unique_id": "c44dd813-c1dc-441e-9b01-736ff41795e8"
}