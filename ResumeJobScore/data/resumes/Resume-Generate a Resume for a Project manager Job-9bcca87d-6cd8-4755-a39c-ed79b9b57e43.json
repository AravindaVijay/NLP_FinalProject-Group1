{
    "clean_data": "Certified HDP Hadoop Administrator Certified HDP Hadoop Administrator Certified HDP Hadoop Administrator Lorven Technologies Oak Brook IL Certified and ProminentHadoop Lead with vast experience in managing designing executing implementing and administering industrial gradeHadoop solutions for a competitive edge Authorized to work in the US for any employer Work Experience Certified HDP Hadoop Administrator Lorven Technologies July 2015 to Present Cluster planning and engineering of POC and Production Clusters Strong experience on Hadoop distributions Hortonworks Cloudera Administer troubleshoot and debug cluster problems on RHELUbuntu Troubleshoot and debugs cluster problems on RHEL based Linux infrastructure Kerberos AdministratorKerberize cluster and ensure sound domain name torealm mapping Periodically Check HDFS health Configure YARN Capacity Scheduler based on infrastructure needsYARN tuning Perform upgrades patches and fixes using effective rollout method Ensure HDFS is Balanced and performing optimally at all times CommissionDecommission Hadoop cluster nodes Review namenode WebUI for information concerning Datanode volume failures Backup existing Hadoop databases such as oozie hive metastore HDFS Metadata backup etc Active DirectoryLDAPS integration and management Purge older log files Build cluster according to workload patterncluster type Configure Cluster services for High Availability Ensure volume and hdfs encryptionData at rest encryption Experienced in AWS configuration optimization for Hadoop Backup Procedures and Disaster Recovery ACLs and audits to meet compliance specifications using Ranger Open tickets and troubleshoot cluster problems with support Experienced in AWS Storage methodologies Expertise in cloudbreak setupconfiguration and blueprint creation Engineer data pipeline management using Falcon Definingexecuting feeds processes data pipelines jobs mirroring between production and testing cluster using Falcon ETL offload using Atlas Securing hadoop services Webhdfshiveyarn using Knox for REST API calls Trains and leads teams in understanding and implementing hadoop solutions in organization Monitor clusterorganization servers for intrusionsdetection log file reviews and threats using SIEM solution Alien vault Documents and reports findings to compliance and audit teams Perform Active directorywindows server administration Run Lead Big Data Platform GAD GROUP TECHNOLOGY INC Chicago IL March 2013 to June 2015 Manage onshore and offshore Hadoop teams consisting of Developers Architects Data Engineers and Administrators Report to stakeholders on biweekly basis on the overall health of the Enterprise Big Data platform Oversee Synchrony core 5 Hadoop environments significantly ingesting large datasets sourced from realtime feeds variety user interactions with mobile apps and internal transactions Single point of contact for all platform operations Run issues from immediate response coordination escalation root cause analysis and resolution Ensuring SLAs for availability performance security maintenance upgrades installation and user administration across all Data Lake environments Administer and maintain PivotalHortonworks Hadoop Greenplum and GemFire clusters across all environments Installationconfiguration of the Hadoop ecosystem tools and continuous enhancement and expansion of the enterprise data lake Collaborate with development teams to assist in code promotion across environments and deployments in production including CMDB CI creation and updates Proactively monitor cluster health and perform performance tuning activities Perform capacity planning and expansion activities working across Infrastructure and other enterprise service teams Perform cluster maintenance with patchingupgradesmigration user provisioning automation of routine tasks reprocessing of failed jobs configure and maintain security policies Ensure the Enterprise Data Lake initiative is continually providing unprecedented customer 360 capabilities and associated services at all time Big Data Analyst KengyCo Startup Evanston June 2010 to February 2013 Worked with most Hadoop distributions Hortonworks Developed data governance process and controls and ensured compliance with enterprise data architecture principles and standards for the various systems and components Analyzing profiling data for quality and reconciling data issues Build test and deploy Hadoop solutions using most Hadoop ecosystem components Administer Hadoop cluster monitor performance with Ganglia Design robust Hadoop solutions for complex business problems Utilize new and latest Open Source tools for addressing business challenges Work with multiple customer teams and support teams to execute Hadoop engagements Integrated Hadoop into traditional ETL accelerating the extraction transformation and loading of massive structured and unstructured data Python developer HealthScape Advisors LLC Chicago IL March 2009 to May 2010 Build commandline app with Restful API layers that cater for end users who are mostly kids Pull data out of HTML and XML file with ScrapyBeautiful soup Interacting with webapp using Flask Performed Data analysis using Python Pandas Processing Data records and returning computed results using Mongo DB Aggregation framework Parse aggregated data into Apache Solr and graph database Orient DB IT Analyst Programmer Synchrony Financial Chicago IL January 2007 to February 2009 Worked both independently and in a teamoriented collaborative environment Worked with Microsoft SQL server Documented and provided status of project and technical information related to the applicationsoftware supported  NET Supported remote users at their home office hotel or customer site utilizing remote tools and troubleshooting over phone using VPN Knowledge of DSLCable Modem Routers Windows Server 2012 and 2008 CISCO Switches and Routers and VOIP ie Cisco Call Manager Skills Hadoop 7 years HADOOP 7 years ECOSYSTEM 2 years SECURITY 2 years SQL 2 years Additional Information Technical Skills Operating Systems RHELUbuntu Hadoop Ecosystem HadoopHDFS technology NFS Hive Pig Sqoop HBase Map Reduce Ranger Ranger Kms zeppelin Cloudbreak Atlas hUE Yarn oozie falcon atlas knox zookeeper HAWQ Flume SPARK Zeppelin Distributions HortonWorks data platformHDP Cloudera CDH distribution Pivotal Big Data Suite Data Logistics Solution Apache Nifi Datacentric Encryption Security Solution Protegrity Security kerberos knox Ranger LDAPSLDAP Active Directory Pivotal Big Data Suite GemFire Greenplum HDB Cluster ProvisionAuto Scaling CloudbreakClouderaDirector Cluster Monitoring Ambari Cloudera Manager InfrastructureConfiguration Management SaltStack platform NoSQL Data store Mongodb Hbase RDBMS MS SQL 2012 2008r2 MySQL Postgres CloudData Center Solution EC2 EMR S3AWS EMCDell Search Solr Programming Languages PLSQL Python Java Methodologies Agile",
    "entities": [
        "Infrastructure",
        "ETL",
        "Restful API",
        "Falcon",
        "US",
        "Purge",
        "Hortonworks Cloudera Administer",
        "Perform",
        "ScrapyBeautiful",
        "HortonWorks",
        "InfrastructureConfiguration Management SaltStack",
        "Build",
        "PivotalHortonworks Hadoop Greenplum",
        "falcon",
        "HDP Hadoop Administrator",
        "Active DirectoryLDAPS",
        "Cisco",
        "AWS",
        "Additional Information Technical Skills Operating Systems RHELUbuntu Hadoop Ecosystem HadoopHDFS",
        "Skills Hadoop",
        "Microsoft",
        "Configure Cluster",
        "Periodically Check",
        "Data Lake",
        "Ranger Open",
        "Present Cluster",
        "Engineer",
        "CommissionDecommission Hadoop",
        "the Enterprise Big Data",
        "VOIP",
        "HealthScape Advisors",
        "GemFire",
        "HTML",
        "Perform Active",
        "Review",
        "Ranger LDAPSLDAP Active Directory Pivotal Big Data",
        "Linux",
        "Parse",
        "Falcon Definingexecuting",
        "NoSQL Data",
        "Hadoop",
        "XML",
        "GAD GROUP TECHNOLOGY INC Chicago",
        "HDP Hadoop",
        "apps",
        "Python Pandas Processing Data",
        "Atlas Securing",
        "Flask Performed Data",
        "Hortonworks Developed",
        "Administer Hadoop",
        "Chicago",
        "Hadoop Backup Procedures",
        "Mongo DB Aggregation",
        "NET Supported",
        "Developers Architects Data Engineers and Administrators Report",
        "Integrated Hadoop",
        "Ganglia Design"
    ],
    "experience": "Experience Certified HDP Hadoop Administrator Lorven Technologies July 2015 to Present Cluster planning and engineering of POC and Production Clusters Strong experience on Hadoop distributions Hortonworks Cloudera Administer troubleshoot and debug cluster problems on RHELUbuntu Troubleshoot and debugs cluster problems on RHEL based Linux infrastructure Kerberos AdministratorKerberize cluster and ensure sound domain name torealm mapping Periodically Check HDFS health Configure YARN Capacity Scheduler based on infrastructure needsYARN tuning Perform upgrades patches and fixes using effective rollout method Ensure HDFS is Balanced and performing optimally at all times CommissionDecommission Hadoop cluster nodes Review namenode WebUI for information concerning Datanode volume failures Backup existing Hadoop databases such as oozie hive metastore HDFS Metadata backup etc Active DirectoryLDAPS integration and management Purge older log files Build cluster according to workload patterncluster type Configure Cluster services for High Availability Ensure volume and hdfs encryptionData at rest encryption Experienced in AWS configuration optimization for Hadoop Backup Procedures and Disaster Recovery ACLs and audits to meet compliance specifications using Ranger Open tickets and troubleshoot cluster problems with support Experienced in AWS Storage methodologies Expertise in cloudbreak setupconfiguration and blueprint creation Engineer data pipeline management using Falcon Definingexecuting feeds processes data pipelines jobs mirroring between production and testing cluster using Falcon ETL offload using Atlas Securing hadoop services Webhdfshiveyarn using Knox for REST API calls Trains and leads teams in understanding and implementing hadoop solutions in organization Monitor clusterorganization servers for intrusionsdetection log file reviews and threats using SIEM solution Alien vault Documents and reports findings to compliance and audit teams Perform Active directorywindows server administration Run Lead Big Data Platform GAD GROUP TECHNOLOGY INC Chicago IL March 2013 to June 2015 Manage onshore and offshore Hadoop teams consisting of Developers Architects Data Engineers and Administrators Report to stakeholders on biweekly basis on the overall health of the Enterprise Big Data platform Oversee Synchrony core 5 Hadoop environments significantly ingesting large datasets sourced from realtime feeds variety user interactions with mobile apps and internal transactions Single point of contact for all platform operations Run issues from immediate response coordination escalation root cause analysis and resolution Ensuring SLAs for availability performance security maintenance upgrades installation and user administration across all Data Lake environments Administer and maintain PivotalHortonworks Hadoop Greenplum and GemFire clusters across all environments Installationconfiguration of the Hadoop ecosystem tools and continuous enhancement and expansion of the enterprise data lake Collaborate with development teams to assist in code promotion across environments and deployments in production including CMDB CI creation and updates Proactively monitor cluster health and perform performance tuning activities Perform capacity planning and expansion activities working across Infrastructure and other enterprise service teams Perform cluster maintenance with patchingupgradesmigration user provisioning automation of routine tasks reprocessing of failed jobs configure and maintain security policies Ensure the Enterprise Data Lake initiative is continually providing unprecedented customer 360 capabilities and associated services at all time Big Data Analyst KengyCo Startup Evanston June 2010 to February 2013 Worked with most Hadoop distributions Hortonworks Developed data governance process and controls and ensured compliance with enterprise data architecture principles and standards for the various systems and components Analyzing profiling data for quality and reconciling data issues Build test and deploy Hadoop solutions using most Hadoop ecosystem components Administer Hadoop cluster monitor performance with Ganglia Design robust Hadoop solutions for complex business problems Utilize new and latest Open Source tools for addressing business challenges Work with multiple customer teams and support teams to execute Hadoop engagements Integrated Hadoop into traditional ETL accelerating the extraction transformation and loading of massive structured and unstructured data Python developer HealthScape Advisors LLC Chicago IL March 2009 to May 2010 Build commandline app with Restful API layers that cater for end users who are mostly kids Pull data out of HTML and XML file with ScrapyBeautiful soup Interacting with webapp using Flask Performed Data analysis using Python Pandas Processing Data records and returning computed results using Mongo DB Aggregation framework Parse aggregated data into Apache Solr and graph database Orient DB IT Analyst Programmer Synchrony Financial Chicago IL January 2007 to February 2009 Worked both independently and in a teamoriented collaborative environment Worked with Microsoft SQL server Documented and provided status of project and technical information related to the applicationsoftware supported   NET Supported remote users at their home office hotel or customer site utilizing remote tools and troubleshooting over phone using VPN Knowledge of DSLCable Modem Routers Windows Server 2012 and 2008 CISCO Switches and Routers and VOIP ie Cisco Call Manager Skills Hadoop 7 years HADOOP 7 years ECOSYSTEM 2 years SECURITY 2 years SQL 2 years Additional Information Technical Skills Operating Systems RHELUbuntu Hadoop Ecosystem HadoopHDFS technology NFS Hive Pig Sqoop HBase Map Reduce Ranger Ranger Kms zeppelin Cloudbreak Atlas hUE Yarn oozie falcon atlas knox zookeeper HAWQ Flume SPARK Zeppelin Distributions HortonWorks data platformHDP Cloudera CDH distribution Pivotal Big Data Suite Data Logistics Solution Apache Nifi Datacentric Encryption Security Solution Protegrity Security kerberos knox Ranger LDAPSLDAP Active Directory Pivotal Big Data Suite GemFire Greenplum HDB Cluster ProvisionAuto Scaling CloudbreakClouderaDirector Cluster Monitoring Ambari Cloudera Manager InfrastructureConfiguration Management SaltStack platform NoSQL Data store Mongodb Hbase RDBMS MS SQL 2012 2008r2 MySQL Postgres CloudData Center Solution EC2 EMR S3AWS EMCDell Search Solr Programming Languages PLSQL Python Java Methodologies Agile",
    "extracted_keywords": [
        "HDP",
        "Hadoop",
        "Administrator",
        "HDP",
        "Hadoop",
        "Administrator",
        "HDP",
        "Hadoop",
        "Administrator",
        "Lorven",
        "Technologies",
        "Oak",
        "Brook",
        "IL",
        "Certified",
        "ProminentHadoop",
        "Lead",
        "experience",
        "gradeHadoop",
        "solutions",
        "edge",
        "US",
        "employer",
        "Work",
        "Experience",
        "HDP",
        "Hadoop",
        "Administrator",
        "Lorven",
        "Technologies",
        "July",
        "Present",
        "Cluster",
        "planning",
        "engineering",
        "POC",
        "Production",
        "Clusters",
        "Strong",
        "experience",
        "Hadoop",
        "distributions",
        "Hortonworks",
        "Cloudera",
        "Administer",
        "troubleshoot",
        "cluster",
        "problems",
        "RHELUbuntu",
        "Troubleshoot",
        "debugs",
        "cluster",
        "problems",
        "RHEL",
        "Linux",
        "infrastructure",
        "Kerberos",
        "AdministratorKerberize",
        "cluster",
        "domain",
        "name",
        "torealm",
        "mapping",
        "HDFS",
        "health",
        "Configure",
        "YARN",
        "Capacity",
        "Scheduler",
        "infrastructure",
        "Perform",
        "upgrades",
        "patches",
        "fixes",
        "rollout",
        "method",
        "Ensure",
        "HDFS",
        "times",
        "CommissionDecommission",
        "Hadoop",
        "cluster",
        "nodes",
        "Review",
        "WebUI",
        "information",
        "Datanode",
        "volume",
        "Backup",
        "Hadoop",
        "databases",
        "oozie",
        "hive",
        "metastore",
        "HDFS",
        "Metadata",
        "backup",
        "DirectoryLDAPS",
        "integration",
        "management",
        "Purge",
        "log",
        "Build",
        "cluster",
        "workload",
        "patterncluster",
        "type",
        "Configure",
        "Cluster",
        "services",
        "High",
        "Availability",
        "Ensure",
        "volume",
        "hdfs",
        "encryptionData",
        "rest",
        "encryption",
        "AWS",
        "configuration",
        "optimization",
        "Hadoop",
        "Backup",
        "Procedures",
        "Disaster",
        "Recovery",
        "ACLs",
        "audits",
        "compliance",
        "specifications",
        "Ranger",
        "Open",
        "tickets",
        "troubleshoot",
        "cluster",
        "problems",
        "support",
        "AWS",
        "Storage",
        "methodologies",
        "Expertise",
        "cloudbreak",
        "setupconfiguration",
        "blueprint",
        "creation",
        "Engineer",
        "data",
        "pipeline",
        "management",
        "Falcon",
        "Definingexecuting",
        "feeds",
        "data",
        "pipelines",
        "jobs",
        "production",
        "testing",
        "cluster",
        "Falcon",
        "ETL",
        "offload",
        "Atlas",
        "Securing",
        "hadoop",
        "services",
        "Webhdfshiveyarn",
        "Knox",
        "REST",
        "API",
        "Trains",
        "teams",
        "understanding",
        "hadoop",
        "solutions",
        "organization",
        "Monitor",
        "clusterorganization",
        "servers",
        "intrusionsdetection",
        "log",
        "file",
        "reviews",
        "threats",
        "SIEM",
        "solution",
        "Alien",
        "vault",
        "Documents",
        "findings",
        "audit",
        "teams",
        "directorywindows",
        "server",
        "administration",
        "Run",
        "Lead",
        "Big",
        "Data",
        "Platform",
        "GAD",
        "GROUP",
        "TECHNOLOGY",
        "INC",
        "Chicago",
        "IL",
        "March",
        "June",
        "Manage",
        "Hadoop",
        "teams",
        "Developers",
        "Architects",
        "Data",
        "Engineers",
        "Administrators",
        "Report",
        "stakeholders",
        "basis",
        "health",
        "Enterprise",
        "Big",
        "Data",
        "platform",
        "Oversee",
        "Synchrony",
        "core",
        "Hadoop",
        "environments",
        "datasets",
        "feeds",
        "variety",
        "user",
        "interactions",
        "apps",
        "transactions",
        "point",
        "contact",
        "platform",
        "operations",
        "Run",
        "issues",
        "response",
        "coordination",
        "escalation",
        "root",
        "analysis",
        "resolution",
        "Ensuring",
        "SLAs",
        "availability",
        "performance",
        "security",
        "maintenance",
        "upgrades",
        "installation",
        "user",
        "administration",
        "Data",
        "Lake",
        "PivotalHortonworks",
        "Hadoop",
        "Greenplum",
        "GemFire",
        "clusters",
        "environments",
        "Installationconfiguration",
        "Hadoop",
        "ecosystem",
        "tools",
        "enhancement",
        "expansion",
        "enterprise",
        "data",
        "lake",
        "Collaborate",
        "development",
        "teams",
        "code",
        "promotion",
        "environments",
        "deployments",
        "production",
        "CMDB",
        "CI",
        "creation",
        "updates",
        "cluster",
        "health",
        "performance",
        "tuning",
        "activities",
        "capacity",
        "planning",
        "expansion",
        "activities",
        "Infrastructure",
        "enterprise",
        "service",
        "teams",
        "cluster",
        "maintenance",
        "patchingupgradesmigration",
        "user",
        "automation",
        "tasks",
        "jobs",
        "security",
        "policies",
        "Enterprise",
        "Data",
        "Lake",
        "initiative",
        "customer",
        "capabilities",
        "services",
        "time",
        "Big",
        "Data",
        "Analyst",
        "KengyCo",
        "Startup",
        "Evanston",
        "June",
        "February",
        "Hadoop",
        "distributions",
        "Hortonworks",
        "data",
        "governance",
        "process",
        "controls",
        "compliance",
        "enterprise",
        "data",
        "architecture",
        "principles",
        "standards",
        "systems",
        "components",
        "profiling",
        "data",
        "quality",
        "reconciling",
        "data",
        "issues",
        "test",
        "Hadoop",
        "solutions",
        "Hadoop",
        "ecosystem",
        "components",
        "Administer",
        "Hadoop",
        "cluster",
        "monitor",
        "performance",
        "Ganglia",
        "Design",
        "Hadoop",
        "solutions",
        "business",
        "problems",
        "Utilize",
        "Open",
        "Source",
        "tools",
        "business",
        "challenges",
        "customer",
        "teams",
        "support",
        "teams",
        "Hadoop",
        "engagements",
        "Integrated",
        "Hadoop",
        "ETL",
        "extraction",
        "transformation",
        "loading",
        "data",
        "Python",
        "developer",
        "HealthScape",
        "Advisors",
        "LLC",
        "Chicago",
        "IL",
        "March",
        "May",
        "Build",
        "commandline",
        "app",
        "API",
        "layers",
        "end",
        "users",
        "kids",
        "data",
        "HTML",
        "XML",
        "file",
        "ScrapyBeautiful",
        "soup",
        "webapp",
        "Flask",
        "Performed",
        "Data",
        "analysis",
        "Python",
        "Pandas",
        "Processing",
        "Data",
        "records",
        "results",
        "Mongo",
        "DB",
        "Aggregation",
        "framework",
        "Parse",
        "data",
        "Apache",
        "Solr",
        "graph",
        "database",
        "Orient",
        "DB",
        "IT",
        "Analyst",
        "Programmer",
        "Synchrony",
        "Financial",
        "Chicago",
        "IL",
        "January",
        "February",
        "collaborative",
        "environment",
        "Microsoft",
        "SQL",
        "server",
        "status",
        "project",
        "information",
        "applicationsoftware",
        "NET",
        "users",
        "home",
        "office",
        "hotel",
        "customer",
        "site",
        "tools",
        "troubleshooting",
        "phone",
        "VPN",
        "Knowledge",
        "DSLCable",
        "Modem",
        "Routers",
        "Windows",
        "Server",
        "CISCO",
        "Switches",
        "Routers",
        "VOIP",
        "Cisco",
        "Call",
        "Manager",
        "Skills",
        "Hadoop",
        "years",
        "HADOOP",
        "years",
        "ECOSYSTEM",
        "years",
        "SECURITY",
        "years",
        "SQL",
        "years",
        "Additional",
        "Information",
        "Technical",
        "Skills",
        "Operating",
        "Systems",
        "RHELUbuntu",
        "Hadoop",
        "Ecosystem",
        "HadoopHDFS",
        "technology",
        "NFS",
        "Hive",
        "Pig",
        "Sqoop",
        "HBase",
        "Map",
        "Reduce",
        "Ranger",
        "Ranger",
        "Kms",
        "zeppelin",
        "Cloudbreak",
        "Atlas",
        "hUE",
        "Yarn",
        "oozie",
        "falcon",
        "atlas",
        "knox",
        "zookeeper",
        "HAWQ",
        "Flume",
        "SPARK",
        "Zeppelin",
        "Distributions",
        "HortonWorks",
        "data",
        "Cloudera",
        "CDH",
        "distribution",
        "Big",
        "Data",
        "Suite",
        "Data",
        "Logistics",
        "Solution",
        "Apache",
        "Nifi",
        "Datacentric",
        "Encryption",
        "Security",
        "Solution",
        "Protegrity",
        "Security",
        "knox",
        "Ranger",
        "LDAPSLDAP",
        "Active",
        "Directory",
        "Big",
        "Data",
        "Suite",
        "GemFire",
        "Greenplum",
        "HDB",
        "Cluster",
        "ProvisionAuto",
        "Scaling",
        "CloudbreakClouderaDirector",
        "Cluster",
        "Monitoring",
        "Ambari",
        "Cloudera",
        "Manager",
        "InfrastructureConfiguration",
        "Management",
        "SaltStack",
        "platform",
        "NoSQL",
        "Data",
        "store",
        "Mongodb",
        "Hbase",
        "MS",
        "SQL",
        "2008r2",
        "MySQL",
        "Postgres",
        "CloudData",
        "Center",
        "Solution",
        "EC2",
        "EMR",
        "S3AWS",
        "EMCDell",
        "Search",
        "Solr",
        "Programming",
        "Languages",
        "PLSQL",
        "Python",
        "Java",
        "Methodologies",
        "Agile"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:48:03.517244",
    "resume_data": "Certified HDP Hadoop Administrator Certified HDP Hadoop Administrator Certified HDP Hadoop Administrator Lorven Technologies Oak Brook IL Certified and ProminentHadoop Lead with vast experience in managing designing executing implementing and administering industrial gradeHadoop solutions for a competitive edge Authorized to work in the US for any employer Work Experience Certified HDP Hadoop Administrator Lorven Technologies July 2015 to Present Cluster planning and engineering of POC and Production Clusters Strong experience on Hadoop distributions Hortonworks Cloudera Administer troubleshoot and debug cluster problems on RHELUbuntu Troubleshoot and debugs cluster problems on RHEL based Linux infrastructure Kerberos AdministratorKerberize cluster and ensure sound domain name torealm mapping Periodically Check HDFS health Configure YARN Capacity Scheduler based on infrastructure needsYARN tuning Perform upgrades patches and fixes using effective rollout method Ensure HDFS is Balanced and performing optimally at all times CommissionDecommission Hadoop cluster nodes Review namenode WebUI for information concerning Datanode volume failures Backup existing Hadoop databases such as oozie hive metastore HDFS Metadata backup etc Active DirectoryLDAPS integration and management Purge older log files Build cluster according to workload patterncluster type Configure Cluster services for High Availability Ensure volume and hdfs encryptionData at rest encryption Experienced in AWS configuration optimization for Hadoop Backup Procedures and Disaster Recovery ACLs and audits to meet compliance specifications using Ranger Open tickets and troubleshoot cluster problems with support Experienced in AWS Storage methodologies Expertise in cloudbreak setupconfiguration and blueprint creation Engineer data pipeline management using Falcon Definingexecuting feeds processes data pipelines jobs mirroring between production and testing cluster using Falcon ETL offload using Atlas Securing hadoop services Webhdfshiveyarn using Knox for REST API calls Trains and leads teams in understanding and implementing hadoop solutions in organization Monitor clusterorganization servers for intrusionsdetection log file reviews and threats using SIEM solution Alien vault Documents and reports findings to compliance and audit teams Perform Active directorywindows server administration Run Lead Big Data Platform GAD GROUP TECHNOLOGY INC Chicago IL March 2013 to June 2015 Manage onshore and offshore Hadoop teams consisting of Developers Architects Data Engineers and Administrators Report to stakeholders on biweekly basis on the overall health of the Enterprise Big Data platform Oversee Synchrony core 5 Hadoop environments significantly ingesting large datasets sourced from realtime feeds variety user interactions with mobile apps and internal transactions Single point of contact for all platform operations Run issues from immediate response coordination escalation root cause analysis and resolution Ensuring SLAs for availability performance security maintenance upgrades installation and user administration across all Data Lake environments Administer and maintain PivotalHortonworks Hadoop Greenplum and GemFire clusters across all environments Installationconfiguration of the Hadoop ecosystem tools and continuous enhancement and expansion of the enterprise data lake Collaborate with development teams to assist in code promotion across environments and deployments in production including CMDB CI creation and updates Proactively monitor cluster health and perform performance tuning activities Perform capacity planning and expansion activities working across Infrastructure and other enterprise service teams Perform cluster maintenance with patchingupgradesmigration user provisioning automation of routine tasks reprocessing of failed jobs configure and maintain security policies Ensure the Enterprise Data Lake initiative is continually providing unprecedented customer 360 capabilities and associated services at all time Big Data Analyst KengyCo Startup Evanston June 2010 to February 2013 Worked with most Hadoop distributions Hortonworks Developed data governance process and controls and ensured compliance with enterprise data architecture principles and standards for the various systems and components Analyzing profiling data for quality and reconciling data issues Build test and deploy Hadoop solutions using most Hadoop ecosystem components Administer Hadoop cluster monitor performance with Ganglia Design robust Hadoop solutions for complex business problems Utilize new and latest Open Source tools for addressing business challenges Work with multiple customer teams and support teams to execute Hadoop engagements Integrated Hadoop into traditional ETL accelerating the extraction transformation and loading of massive structured and unstructured data Python developer HealthScape Advisors LLC Chicago IL March 2009 to May 2010 Build commandline app with Restful API layers that cater for end users who are mostly kids Pull data out of HTML and XML file with ScrapyBeautiful soup Interacting with webapp using Flask Performed Data analysis using Python Pandas Processing Data records and returning computed results using Mongo DB Aggregation framework Parse aggregated data into Apache Solr and graph database Orient DB IT Analyst Programmer Synchrony Financial Chicago IL January 2007 to February 2009 Worked both independently and in a teamoriented collaborative environment Worked with Microsoft SQL server Documented and provided status of project and technical information related to the applicationsoftware supported Web2Py NET Supported remote users at their home office hotel or customer site utilizing remote tools and troubleshooting over phone using VPN Knowledge of DSLCable Modem Routers Windows Server 2012 and 2008 CISCO Switches and Routers and VOIP ie Cisco Call Manager Skills Hadoop 7 years HADOOP 7 years ECOSYSTEM 2 years SECURITY 2 years SQL 2 years Additional Information Technical Skills Operating Systems RHELUbuntu Hadoop Ecosystem HadoopHDFS technology NFS Hive Pig Sqoop HBase Map Reduce Ranger Ranger Kms zeppelin Cloudbreak Atlas hUE Yarn oozie falcon atlas knox zookeeper HAWQ Flume SPARK Zeppelin Distributions HortonWorks data platformHDP Cloudera CDH distribution Pivotal Big Data Suite Data Logistics Solution Apache Nifi Datacentric Encryption Security Solution Protegrity Security kerberos knox Ranger LDAPSLDAP Active Directory Pivotal Big Data Suite GemFire Greenplum HDB Cluster ProvisionAuto Scaling CloudbreakClouderaDirector Cluster Monitoring Ambari Cloudera Manager InfrastructureConfiguration Management SaltStack platform NoSQL Data store Mongodb Hbase RDBMS MS SQL 2012 2008r2 MySQL Postgres CloudData Center Solution EC2 EMR S3AWS EMCDell Search Solr Programming Languages PLSQL Python Java Methodologies Agile",
    "unique_id": "9bcca87d-6cd8-4755-a39c-ed79b9b57e43"
}