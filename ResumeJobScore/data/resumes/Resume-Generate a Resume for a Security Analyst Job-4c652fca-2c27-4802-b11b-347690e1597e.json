{
    "clean_data": "Principal System AnalystSr Developer Principal System AnalystSr span lDeveloperspan Python Developer Durham NC Principal DeveloperAnalyst with twelve 12 years of experience in application development interpreting and analyzing large sets of data along with knowledge in cloud computing distributed systems and database programming for credit cards banking financial and retail industries Proven skills in developing server side Python code that is reliable and efficient Extensive data analysis experience on large sets of data using Python machine learning Algorithms Big Data tools and data science methodologies Strong background in Cloud computing solutions cloud computing strategy systems design implementation and management with ability to provision operate and manage distributed application systems on the cloud platform Comprehensive experience working with various database sources such as Oracle SQLite and SQL Server and proficiency in database component development including Constraints Indexes Views Triggers Cursors and Packages using SQL Developer Expert knowledge in designing technical architecture solutions that span multiple platforms and include integration and authentication for systems Proficient in software development and overall automation including SDLC Agile Scrum and DevOps Proven technical background with LinuxUnix and Windows servers file transfer job scheduling and report generation using shell scripting and Perl Proficient in creating and maintaining technical and business documents Ability to adapt to changing technologies ability to learn and assess needs by quickly assimilating new interface or production software Significant experience working with clients stakeholders and business owners in performing requirements analysis providing guidance in implementation of applications Authorized to work in the US for any employer Work Experience Principal System AnalystSr Developer Fidelity Investments Durham NC February 2018 to Present Global HRIS Payroll Platform Modernization The Global HRISPayroll platform modernization project replaces Fidelitys HR and payroll technology systems globally with Workday as a modern cloud based human capital management payroll and financial management system The scope of this project is to rally and guide the teams to meet its Cloud migration goals The scope also includes acceleration of process automation and modernization of development and deployment operationsprocesses Developed disk space usage predictor tool using machine learning Algorithms including Linear Regression Logistic Regression ElasticNet kNN with Python and MongoDB to keep the disk space in control and avoid failure of critical payroll jobs in the cloud environment Designed and developed an automatic change request approval solution using Python packages including Pandas Numpy scikitlearn and SciPy The business and technology teams use it extensively to make decisions on rollouts and mitigate any business risks Incorporated data solution to collect clean transform compare and identify inconsistencies in payroll data that is migrated to cloud from a distributed environment This is a validation solution to facilitate seamless migration of data to Cloud architecture Actively collaborated with IT Architecture Infrastructure and business teams to deploy various applications in Cloud Managed production releases with the help of integration and migration tools such as GIT Stash IBM Clearcase Jenkins and UDeploy Designed deployed automated maintained and managed cloud based production systems to ensure the availability performance scalability and security of production systems Collaborated and implemented the IAM technologies best practices on identity access management and authentication mechanisms for the Cloud servers Reevaluated the existing stack and infrastructure to maintain optimal performance availability and security Environment Redhat Linux Python Machine Learning algorithms Anaconda Go Unix Shell scripting Oracle PLSQL SQLite Jenkins Chef GIT Stash AWS Python Developer Fidelity Investments Durham NC August 2016 to August 2018 Hackathon Project Participated in NC Hackathon and developed Big Pay application using Big Data and data science tools The project develops selfservice reporting and analytics functionality which was used for executiveaudit reporting Performed the below activities as a data analyst for the project Imported structured and unstructured data from relational databases and file systems into Big Data environment using Hive Impala Pig scripts and Python libraries Performed data cleansing of the migrated data in the new environment using Python scripts Organized data in appropriate data sets to use for reporting purposes Generated payroll reports using data visualization tools using Tableau and Matplotlib Created workflows using Oozie for automated data processing Environment Python Hue v311 Hadoop Tableau Oracle Pig Sqoop Oozie Hive Impala Matplotlib Principal System AnalystSr Developer Fidelity Investments Durham NC September 2015 to February 2017 Global HRPayroll Infrastructure Management HR Payroll Infrastructure Management manages all servers that host internal payroll applications for Fidelity Investments The project performs routine system updates to install new elements and continuous monitoring of server performance This team collaborates with other teams to implement processes and procedures to stay with the corporate standards The scope of this project includes relevant data collection and reporting of performance metrics for audit purposes Developed user auditing tools for monitoring the appropriate access of service accounts in multiple servers using Python Linux and shell scripting to enhance the security of Linux servers in a distributed environment Optimized and enhanced payroll data consolidation and comparison process that reduced the total processing time from four hours to three minutes Designed solutions for complex performance andor reliability problems in the distributed system application Automated regular infrastructure activities such as server patching application recycle and storage maintenance using Pythonshell scripts Migrated server applications from physical data center to cloud environment Collected analyzed and interpreted server data and built personalized reports on server readiness and performance Worked closely with the application team to prototype architect plan estimate and implement solutions for the release management Environment Redhat Linux Python Windows 2016 shell scripting Git Stash JIRA Udeploy Jenkins IBM Clearcase Cloud computing Principal System AnalystSr Developer Fidelity Investments Durham NC March 2014 to September 2015 Global HRISPayroll Upgrade Global Payroll Upgrade consolidated the three disparate payroll systems used by Fidelity Investments into a single instance on vendor supported products The primary goal of this upgrade was to migrate from a mainframe based back end to a Linux distributed environment The scope of the project involves gathering requirements designing developing and implementing code and data migration solutions for the distributed system environment Designed and developed reusable customizable Python and UnixLinux shell scripts to reproduce the functionality of the existing system in the new environment Automated data comparison process between multiple environments to ensure the proper migration to the distributed environment Created solutions to complex performance and reliability problems in the distributed system applications Developed data cleaning tool using Python based packages for weekly and biweekly payroll processing Generated adhoc reports using SQL and Python programs for business review and validation Reviewed and analyzed overall architecture of systems and translating architecture into resilient technical solutions Developed source codes and resolved any issues while ensuring the code changes end up in change items CIs and deploying CIs to their target environments Developed and maintained program development strategies using Agile development processes Resolved software or process defects discovered throughout the prelaunch postlaunch and quality review processes Managed production releases with the help of integration and migration tools such as GITStash IBM Clearcase Jenkins and UDeploy Designed analyzed and implemented file transfer solutions based on different server requirements Mentored and assisted other developers in code development performed peer reviews and provided feedback for improvements Assisted in developing and implemented scheduler based solutions using  Migrated developed codes to IBM Clearcase to maintain the effective code management Environment Redhat Linux Python Oracle PLSQL Perl UNIX shell scripting Control M SFTP Oracle IBM Clearcase Microfocus COBOL SharePoint 2012 Programmer Analyst Chicago Mercantile Exchange Chicago IL October 2013 to March 2014 CME Direct Management CME Direct provides online trading and free electronic access to CME futures and OTC markets through a single easyto use free application This project is to automate the process of upgrading the components involved with CME Direct It also involves creating an audit system for the components to be upgraded Environment Redhat Linux Perl UNIX shell scripting Python Oracle IBM Connect Direct NDM Autosys  SQL Server IBM Clearcase IT AnalystTechnical Lead CITI Group Elk Grove Village IL May 2010 to October 2013 Mail360 Customer Statement and Letter Processing Mail Management System tracks every mail piece throughout all production steps to comply with USPS requirements for multipurpose piece level identification piece level tracking and reporting without adding additional identifiers to the pieces Mail 360 project involves implementing intelligent mail barcode in the statementsletters sent to the customer Environment UNIX shell scripts Python Streamweaver Mail360 Autosys IBM Connect Direct NDM Oracle HP QC UNIX commands MailStream Plus SQL Server Windows 2008 server SSH Tectia WCC Sr Software Engineer Toys R Us Chennai Tamil Nadu August 2006 to May 2010 India Merchandising Applications US Maintenance The Merchandising Applications Domestic US Support Maintenance project is a production support and maintenance project for the entire suite of domestic applications used by Toys R Us It involved providing maintenance and support for various modules in the Merchandise applications by resolving tickets bug fixes and enhancements The sales information is used to plan budget and track company performance Essentially all planning happens through the RPAS Retek planning tool The supporting IT jobs and feeds are responsible for feeding the Retek proprietary planning database and retrieving processed information back to database stores on several boxes The scope of the project to develop and maintain Linux based distributed environment to perform the above activities Environment UNIX shell scripts SFTP FTP PERL ACUMATE AUTOSYS Remedy RPAS Oracle DB2 FTP AWK and SED TOAD Education Bachelor of Engineering in Instrumentation and Control Anna University Chennai Tamil Nadu Additional Information SKILLS Application Development Data Skills Python shell scripting PERL Go PLSQL Machine Learning Docker Visualization using Tableau and Matplotlib Advanced analytics using Python packages such as Pandas Numpy Scikitlearn and SciPy Big Data Technologies Hadoop Hive Impala Sqoop Oozie Pig Cloud Computing AWS GCP Chef Operating Systems UnixLinux Windows Ubuntu Databases Oracle SQLite SQL Server Tools Anaconda GIT Stash Jenkins UDeploy Clearcase CyberArk",
    "entities": [
        "GIT",
        "Global HRISPayroll Upgrade Global Payroll Upgrade",
        "FTP",
        "Python",
        "SQL Server",
        "USPS",
        "Fidelitys",
        "Oracle PLSQL SQLite Jenkins Chef",
        "Generated",
        "Assisted",
        "CME Direct Management CME Direct",
        "Letter Processing Mail Management System",
        "Go PLSQL Machine Learning Docker Visualization",
        "Oracle SQLite",
        "Developed",
        "US",
        "India",
        "IAM",
        "Principal System AnalystSr",
        "Performed",
        "Pythonshell",
        "SED TOAD Education Bachelor of Engineering",
        "Autosys IBM Connect Direct NDM Oracle HP QC UNIX",
        "Impala",
        "Created",
        "LinuxUnix",
        "Windows",
        "Customer Statement",
        "Principal System AnalystSr Developer Principal System AnalystSr",
        "RPAS Retek",
        "Control Anna University",
        "Cloud",
        "IBM",
        "Organized",
        "GITStash IBM",
        "Global HRPayroll Infrastructure Management HR Payroll Infrastructure Management",
        "Linux",
        "CME",
        "Perl Proficient",
        "IBM Clearcase",
        "SQL",
        "Collaborated",
        "Cloud Managed",
        "Linear Regression Logistic Regression",
        "Python Oracle IBM Connect Direct NDM Autosys",
        "Programmer",
        "Mentored",
        "Constraints Indexes Views Triggers Cursors",
        "Pandas Numpy Scikitlearn",
        "Tableau",
        "Shell",
        "Fidelity Investments",
        "Chicago",
        "CME Direct",
        "Automated",
        "SSH",
        "MailStream",
        "Matplotlib Created",
        "Chicago Mercantile Exchange",
        "Anaconda",
        "Big Data",
        "Instrumentation",
        "SciPy Big Data Technologies Hadoop Hive",
        "UnixLinux",
        "Agile",
        "Control M SFTP"
    ],
    "experience": "Experience Principal System AnalystSr Developer Fidelity Investments Durham NC February 2018 to Present Global HRIS Payroll Platform Modernization The Global HRISPayroll platform modernization project replaces Fidelitys HR and payroll technology systems globally with Workday as a modern cloud based human capital management payroll and financial management system The scope of this project is to rally and guide the teams to meet its Cloud migration goals The scope also includes acceleration of process automation and modernization of development and deployment operationsprocesses Developed disk space usage predictor tool using machine learning Algorithms including Linear Regression Logistic Regression ElasticNet kNN with Python and MongoDB to keep the disk space in control and avoid failure of critical payroll jobs in the cloud environment Designed and developed an automatic change request approval solution using Python packages including Pandas Numpy scikitlearn and SciPy The business and technology teams use it extensively to make decisions on rollouts and mitigate any business risks Incorporated data solution to collect clean transform compare and identify inconsistencies in payroll data that is migrated to cloud from a distributed environment This is a validation solution to facilitate seamless migration of data to Cloud architecture Actively collaborated with IT Architecture Infrastructure and business teams to deploy various applications in Cloud Managed production releases with the help of integration and migration tools such as GIT Stash IBM Clearcase Jenkins and UDeploy Designed deployed automated maintained and managed cloud based production systems to ensure the availability performance scalability and security of production systems Collaborated and implemented the IAM technologies best practices on identity access management and authentication mechanisms for the Cloud servers Reevaluated the existing stack and infrastructure to maintain optimal performance availability and security Environment Redhat Linux Python Machine Learning algorithms Anaconda Go Unix Shell scripting Oracle PLSQL SQLite Jenkins Chef GIT Stash AWS Python Developer Fidelity Investments Durham NC August 2016 to August 2018 Hackathon Project Participated in NC Hackathon and developed Big Pay application using Big Data and data science tools The project develops selfservice reporting and analytics functionality which was used for executiveaudit reporting Performed the below activities as a data analyst for the project Imported structured and unstructured data from relational databases and file systems into Big Data environment using Hive Impala Pig scripts and Python libraries Performed data cleansing of the migrated data in the new environment using Python scripts Organized data in appropriate data sets to use for reporting purposes Generated payroll reports using data visualization tools using Tableau and Matplotlib Created workflows using Oozie for automated data processing Environment Python Hue v311 Hadoop Tableau Oracle Pig Sqoop Oozie Hive Impala Matplotlib Principal System AnalystSr Developer Fidelity Investments Durham NC September 2015 to February 2017 Global HRPayroll Infrastructure Management HR Payroll Infrastructure Management manages all servers that host internal payroll applications for Fidelity Investments The project performs routine system updates to install new elements and continuous monitoring of server performance This team collaborates with other teams to implement processes and procedures to stay with the corporate standards The scope of this project includes relevant data collection and reporting of performance metrics for audit purposes Developed user auditing tools for monitoring the appropriate access of service accounts in multiple servers using Python Linux and shell scripting to enhance the security of Linux servers in a distributed environment Optimized and enhanced payroll data consolidation and comparison process that reduced the total processing time from four hours to three minutes Designed solutions for complex performance andor reliability problems in the distributed system application Automated regular infrastructure activities such as server patching application recycle and storage maintenance using Pythonshell scripts Migrated server applications from physical data center to cloud environment Collected analyzed and interpreted server data and built personalized reports on server readiness and performance Worked closely with the application team to prototype architect plan estimate and implement solutions for the release management Environment Redhat Linux Python Windows 2016 shell scripting Git Stash JIRA Udeploy Jenkins IBM Clearcase Cloud computing Principal System AnalystSr Developer Fidelity Investments Durham NC March 2014 to September 2015 Global HRISPayroll Upgrade Global Payroll Upgrade consolidated the three disparate payroll systems used by Fidelity Investments into a single instance on vendor supported products The primary goal of this upgrade was to migrate from a mainframe based back end to a Linux distributed environment The scope of the project involves gathering requirements designing developing and implementing code and data migration solutions for the distributed system environment Designed and developed reusable customizable Python and UnixLinux shell scripts to reproduce the functionality of the existing system in the new environment Automated data comparison process between multiple environments to ensure the proper migration to the distributed environment Created solutions to complex performance and reliability problems in the distributed system applications Developed data cleaning tool using Python based packages for weekly and biweekly payroll processing Generated adhoc reports using SQL and Python programs for business review and validation Reviewed and analyzed overall architecture of systems and translating architecture into resilient technical solutions Developed source codes and resolved any issues while ensuring the code changes end up in change items CIs and deploying CIs to their target environments Developed and maintained program development strategies using Agile development processes Resolved software or process defects discovered throughout the prelaunch postlaunch and quality review processes Managed production releases with the help of integration and migration tools such as GITStash IBM Clearcase Jenkins and UDeploy Designed analyzed and implemented file transfer solutions based on different server requirements Mentored and assisted other developers in code development performed peer reviews and provided feedback for improvements Assisted in developing and implemented scheduler based solutions using   Migrated developed codes to IBM Clearcase to maintain the effective code management Environment Redhat Linux Python Oracle PLSQL Perl UNIX shell scripting Control M SFTP Oracle IBM Clearcase Microfocus COBOL SharePoint 2012 Programmer Analyst Chicago Mercantile Exchange Chicago IL October 2013 to March 2014 CME Direct Management CME Direct provides online trading and free electronic access to CME futures and OTC markets through a single easyto use free application This project is to automate the process of upgrading the components involved with CME Direct It also involves creating an audit system for the components to be upgraded Environment Redhat Linux Perl UNIX shell scripting Python Oracle IBM Connect Direct NDM Autosys   SQL Server IBM Clearcase IT AnalystTechnical Lead CITI Group Elk Grove Village IL May 2010 to October 2013 Mail360 Customer Statement and Letter Processing Mail Management System tracks every mail piece throughout all production steps to comply with USPS requirements for multipurpose piece level identification piece level tracking and reporting without adding additional identifiers to the pieces Mail 360 project involves implementing intelligent mail barcode in the statementsletters sent to the customer Environment UNIX shell scripts Python Streamweaver Mail360 Autosys IBM Connect Direct NDM Oracle HP QC UNIX commands MailStream Plus SQL Server Windows 2008 server SSH Tectia WCC Sr Software Engineer Toys R Us Chennai Tamil Nadu August 2006 to May 2010 India Merchandising Applications US Maintenance The Merchandising Applications Domestic US Support Maintenance project is a production support and maintenance project for the entire suite of domestic applications used by Toys R Us It involved providing maintenance and support for various modules in the Merchandise applications by resolving tickets bug fixes and enhancements The sales information is used to plan budget and track company performance Essentially all planning happens through the RPAS Retek planning tool The supporting IT jobs and feeds are responsible for feeding the Retek proprietary planning database and retrieving processed information back to database stores on several boxes The scope of the project to develop and maintain Linux based distributed environment to perform the above activities Environment UNIX shell scripts SFTP FTP PERL ACUMATE AUTOSYS Remedy RPAS Oracle DB2 FTP AWK and SED TOAD Education Bachelor of Engineering in Instrumentation and Control Anna University Chennai Tamil Nadu Additional Information SKILLS Application Development Data Skills Python shell scripting PERL Go PLSQL Machine Learning Docker Visualization using Tableau and Matplotlib Advanced analytics using Python packages such as Pandas Numpy Scikitlearn and SciPy Big Data Technologies Hadoop Hive Impala Sqoop Oozie Pig Cloud Computing AWS GCP Chef Operating Systems UnixLinux Windows Ubuntu Databases Oracle SQLite SQL Server Tools Anaconda GIT Stash Jenkins UDeploy Clearcase CyberArk",
    "extracted_keywords": [
        "Principal",
        "System",
        "AnalystSr",
        "Developer",
        "Principal",
        "System",
        "AnalystSr",
        "span",
        "lDeveloperspan",
        "Python",
        "Developer",
        "Durham",
        "NC",
        "Principal",
        "DeveloperAnalyst",
        "years",
        "experience",
        "application",
        "development",
        "interpreting",
        "sets",
        "data",
        "knowledge",
        "cloud",
        "computing",
        "systems",
        "database",
        "programming",
        "credit",
        "cards",
        "industries",
        "skills",
        "server",
        "side",
        "Python",
        "code",
        "data",
        "analysis",
        "experience",
        "sets",
        "data",
        "Python",
        "machine",
        "Algorithms",
        "Big",
        "Data",
        "tools",
        "data",
        "science",
        "methodologies",
        "background",
        "Cloud",
        "solutions",
        "cloud",
        "strategy",
        "systems",
        "design",
        "implementation",
        "management",
        "ability",
        "provision",
        "application",
        "systems",
        "cloud",
        "platform",
        "Comprehensive",
        "experience",
        "database",
        "sources",
        "Oracle",
        "SQLite",
        "SQL",
        "Server",
        "proficiency",
        "database",
        "component",
        "development",
        "Constraints",
        "Indexes",
        "Views",
        "Triggers",
        "Cursors",
        "Packages",
        "SQL",
        "Developer",
        "Expert",
        "knowledge",
        "architecture",
        "solutions",
        "platforms",
        "integration",
        "authentication",
        "systems",
        "Proficient",
        "software",
        "development",
        "automation",
        "SDLC",
        "Agile",
        "Scrum",
        "DevOps",
        "Proven",
        "background",
        "LinuxUnix",
        "Windows",
        "servers",
        "file",
        "transfer",
        "job",
        "scheduling",
        "report",
        "generation",
        "shell",
        "scripting",
        "Perl",
        "Proficient",
        "business",
        "documents",
        "Ability",
        "technologies",
        "ability",
        "needs",
        "interface",
        "production",
        "software",
        "experience",
        "clients",
        "stakeholders",
        "business",
        "owners",
        "requirements",
        "analysis",
        "guidance",
        "implementation",
        "applications",
        "US",
        "employer",
        "Work",
        "Experience",
        "Principal",
        "System",
        "AnalystSr",
        "Developer",
        "Fidelity",
        "Investments",
        "Durham",
        "NC",
        "February",
        "Present",
        "Global",
        "HRIS",
        "Payroll",
        "Platform",
        "Modernization",
        "Global",
        "HRISPayroll",
        "platform",
        "modernization",
        "project",
        "Fidelitys",
        "HR",
        "payroll",
        "technology",
        "systems",
        "Workday",
        "cloud",
        "capital",
        "management",
        "payroll",
        "management",
        "system",
        "scope",
        "project",
        "teams",
        "Cloud",
        "migration",
        "goals",
        "scope",
        "acceleration",
        "process",
        "automation",
        "modernization",
        "development",
        "deployment",
        "disk",
        "space",
        "usage",
        "predictor",
        "tool",
        "machine",
        "learning",
        "Algorithms",
        "Linear",
        "Regression",
        "Logistic",
        "Regression",
        "ElasticNet",
        "Python",
        "disk",
        "space",
        "control",
        "failure",
        "payroll",
        "jobs",
        "cloud",
        "environment",
        "change",
        "request",
        "approval",
        "solution",
        "Python",
        "packages",
        "Pandas",
        "Numpy",
        "scikitlearn",
        "SciPy",
        "business",
        "technology",
        "teams",
        "decisions",
        "rollouts",
        "business",
        "data",
        "solution",
        "transform",
        "inconsistencies",
        "payroll",
        "data",
        "cloud",
        "environment",
        "validation",
        "solution",
        "migration",
        "data",
        "Cloud",
        "architecture",
        "IT",
        "Architecture",
        "Infrastructure",
        "business",
        "teams",
        "applications",
        "Cloud",
        "production",
        "releases",
        "help",
        "integration",
        "migration",
        "tools",
        "GIT",
        "Stash",
        "IBM",
        "Clearcase",
        "Jenkins",
        "UDeploy",
        "Designed",
        "cloud",
        "production",
        "systems",
        "availability",
        "performance",
        "scalability",
        "security",
        "production",
        "systems",
        "IAM",
        "technologies",
        "practices",
        "identity",
        "access",
        "management",
        "authentication",
        "mechanisms",
        "Cloud",
        "servers",
        "stack",
        "infrastructure",
        "performance",
        "availability",
        "security",
        "Environment",
        "Redhat",
        "Linux",
        "Python",
        "Machine",
        "Learning",
        "Anaconda",
        "Unix",
        "Shell",
        "Oracle",
        "PLSQL",
        "SQLite",
        "Jenkins",
        "Chef",
        "GIT",
        "Stash",
        "Python",
        "Developer",
        "Fidelity",
        "Investments",
        "Durham",
        "NC",
        "August",
        "August",
        "Hackathon",
        "Project",
        "NC",
        "Hackathon",
        "Pay",
        "application",
        "Big",
        "Data",
        "data",
        "science",
        "tools",
        "project",
        "selfservice",
        "reporting",
        "analytics",
        "functionality",
        "executiveaudit",
        "Performed",
        "activities",
        "data",
        "analyst",
        "project",
        "data",
        "databases",
        "file",
        "systems",
        "Big",
        "Data",
        "environment",
        "Hive",
        "Impala",
        "Pig",
        "scripts",
        "Python",
        "data",
        "cleansing",
        "data",
        "environment",
        "Python",
        "scripts",
        "data",
        "data",
        "sets",
        "purposes",
        "payroll",
        "reports",
        "data",
        "visualization",
        "tools",
        "Tableau",
        "Matplotlib",
        "Created",
        "workflows",
        "Oozie",
        "data",
        "Environment",
        "Python",
        "Hue",
        "v311",
        "Hadoop",
        "Tableau",
        "Oracle",
        "Pig",
        "Sqoop",
        "Oozie",
        "Hive",
        "Impala",
        "Matplotlib",
        "Principal",
        "System",
        "AnalystSr",
        "Developer",
        "Fidelity",
        "Investments",
        "Durham",
        "NC",
        "September",
        "February",
        "Global",
        "HRPayroll",
        "Infrastructure",
        "Management",
        "HR",
        "Payroll",
        "Infrastructure",
        "Management",
        "servers",
        "host",
        "payroll",
        "applications",
        "Fidelity",
        "Investments",
        "project",
        "system",
        "updates",
        "elements",
        "monitoring",
        "server",
        "performance",
        "team",
        "teams",
        "processes",
        "procedures",
        "standards",
        "scope",
        "project",
        "data",
        "collection",
        "reporting",
        "performance",
        "metrics",
        "audit",
        "purposes",
        "user",
        "auditing",
        "tools",
        "access",
        "service",
        "accounts",
        "servers",
        "Python",
        "Linux",
        "scripting",
        "security",
        "Linux",
        "servers",
        "environment",
        "payroll",
        "data",
        "consolidation",
        "comparison",
        "process",
        "processing",
        "time",
        "hours",
        "minutes",
        "solutions",
        "performance",
        "reliability",
        "problems",
        "system",
        "application",
        "infrastructure",
        "activities",
        "server",
        "application",
        "recycle",
        "storage",
        "maintenance",
        "Pythonshell",
        "scripts",
        "server",
        "applications",
        "data",
        "center",
        "cloud",
        "environment",
        "Collected",
        "server",
        "data",
        "reports",
        "server",
        "readiness",
        "performance",
        "application",
        "team",
        "architect",
        "plan",
        "solutions",
        "release",
        "management",
        "Environment",
        "Redhat",
        "Linux",
        "Python",
        "shell",
        "Git",
        "Stash",
        "JIRA",
        "Udeploy",
        "Jenkins",
        "IBM",
        "Clearcase",
        "Cloud",
        "Principal",
        "System",
        "AnalystSr",
        "Developer",
        "Fidelity",
        "Investments",
        "Durham",
        "NC",
        "March",
        "September",
        "Global",
        "HRISPayroll",
        "Upgrade",
        "Global",
        "Payroll",
        "Upgrade",
        "payroll",
        "systems",
        "Fidelity",
        "Investments",
        "instance",
        "vendor",
        "products",
        "goal",
        "upgrade",
        "mainframe",
        "end",
        "Linux",
        "environment",
        "scope",
        "project",
        "gathering",
        "requirements",
        "code",
        "data",
        "migration",
        "solutions",
        "system",
        "environment",
        "Python",
        "UnixLinux",
        "shell",
        "scripts",
        "functionality",
        "system",
        "environment",
        "Automated",
        "data",
        "comparison",
        "process",
        "environments",
        "migration",
        "environment",
        "solutions",
        "performance",
        "reliability",
        "problems",
        "system",
        "applications",
        "data",
        "cleaning",
        "tool",
        "Python",
        "packages",
        "payroll",
        "processing",
        "reports",
        "SQL",
        "Python",
        "programs",
        "business",
        "review",
        "validation",
        "architecture",
        "systems",
        "architecture",
        "solutions",
        "source",
        "codes",
        "issues",
        "code",
        "changes",
        "change",
        "items",
        "CIs",
        "CIs",
        "target",
        "environments",
        "program",
        "development",
        "strategies",
        "development",
        "processes",
        "software",
        "process",
        "defects",
        "prelaunch",
        "postlaunch",
        "quality",
        "review",
        "production",
        "releases",
        "help",
        "integration",
        "migration",
        "tools",
        "GITStash",
        "IBM",
        "Clearcase",
        "Jenkins",
        "UDeploy",
        "Designed",
        "file",
        "transfer",
        "solutions",
        "server",
        "requirements",
        "Mentored",
        "developers",
        "code",
        "development",
        "peer",
        "reviews",
        "feedback",
        "improvements",
        "scheduler",
        "solutions",
        "codes",
        "IBM",
        "Clearcase",
        "code",
        "management",
        "Environment",
        "Redhat",
        "Linux",
        "Python",
        "Oracle",
        "PLSQL",
        "Perl",
        "UNIX",
        "shell",
        "Control",
        "M",
        "SFTP",
        "Oracle",
        "IBM",
        "Clearcase",
        "Microfocus",
        "COBOL",
        "SharePoint",
        "Programmer",
        "Analyst",
        "Chicago",
        "Mercantile",
        "Exchange",
        "Chicago",
        "IL",
        "October",
        "March",
        "CME",
        "Direct",
        "Management",
        "CME",
        "Direct",
        "trading",
        "access",
        "CME",
        "futures",
        "OTC",
        "markets",
        "application",
        "project",
        "process",
        "components",
        "CME",
        "Direct",
        "audit",
        "system",
        "components",
        "Environment",
        "Redhat",
        "Linux",
        "Perl",
        "UNIX",
        "shell",
        "Python",
        "Oracle",
        "IBM",
        "Direct",
        "NDM",
        "Autosys",
        "SQL",
        "Server",
        "IBM",
        "Clearcase",
        "IT",
        "AnalystTechnical",
        "Lead",
        "CITI",
        "Group",
        "Elk",
        "Grove",
        "Village",
        "IL",
        "May",
        "October",
        "Mail360",
        "Customer",
        "Statement",
        "Letter",
        "Processing",
        "Mail",
        "Management",
        "System",
        "mail",
        "piece",
        "production",
        "steps",
        "USPS",
        "requirements",
        "piece",
        "level",
        "identification",
        "piece",
        "level",
        "tracking",
        "identifiers",
        "pieces",
        "Mail",
        "project",
        "mail",
        "barcode",
        "statementsletters",
        "customer",
        "Environment",
        "UNIX",
        "shell",
        "Python",
        "Streamweaver",
        "Mail360",
        "Autosys",
        "IBM",
        "Direct",
        "NDM",
        "Oracle",
        "HP",
        "QC",
        "UNIX",
        "MailStream",
        "SQL",
        "Server",
        "Windows",
        "server",
        "SSH",
        "Tectia",
        "WCC",
        "Sr",
        "Software",
        "Engineer",
        "Toys",
        "Us",
        "Chennai",
        "Tamil",
        "Nadu",
        "August",
        "May",
        "India",
        "Merchandising",
        "Applications",
        "US",
        "Maintenance",
        "Merchandising",
        "Applications",
        "Domestic",
        "US",
        "Support",
        "Maintenance",
        "project",
        "production",
        "support",
        "maintenance",
        "project",
        "suite",
        "applications",
        "Toys",
        "R",
        "Us",
        "maintenance",
        "support",
        "modules",
        "Merchandise",
        "applications",
        "tickets",
        "bug",
        "fixes",
        "sales",
        "information",
        "budget",
        "track",
        "company",
        "performance",
        "planning",
        "RPAS",
        "Retek",
        "planning",
        "tool",
        "IT",
        "jobs",
        "feeds",
        "Retek",
        "planning",
        "database",
        "information",
        "database",
        "stores",
        "boxes",
        "scope",
        "project",
        "Linux",
        "environment",
        "activities",
        "Environment",
        "UNIX",
        "shell",
        "scripts",
        "SFTP",
        "FTP",
        "ACUMATE",
        "AUTOSYS",
        "Remedy",
        "RPAS",
        "Oracle",
        "DB2",
        "FTP",
        "AWK",
        "SED",
        "TOAD",
        "Education",
        "Bachelor",
        "Engineering",
        "Instrumentation",
        "Control",
        "Anna",
        "University",
        "Chennai",
        "Tamil",
        "Nadu",
        "Additional",
        "Information",
        "SKILLS",
        "Application",
        "Development",
        "Data",
        "Skills",
        "Python",
        "shell",
        "scripting",
        "PERL",
        "PLSQL",
        "Machine",
        "Learning",
        "Docker",
        "Visualization",
        "Tableau",
        "Matplotlib",
        "Advanced",
        "analytics",
        "Python",
        "packages",
        "Pandas",
        "Numpy",
        "Scikitlearn",
        "SciPy",
        "Big",
        "Data",
        "Technologies",
        "Hadoop",
        "Hive",
        "Impala",
        "Sqoop",
        "Oozie",
        "Pig",
        "Cloud",
        "Computing",
        "AWS",
        "GCP",
        "Chef",
        "Operating",
        "Systems",
        "UnixLinux",
        "Windows",
        "Ubuntu",
        "Oracle",
        "SQLite",
        "SQL",
        "Server",
        "Tools",
        "Anaconda",
        "GIT",
        "Stash",
        "Jenkins",
        "UDeploy",
        "Clearcase",
        "CyberArk"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T21:28:25.481149",
    "resume_data": "Principal System AnalystSr Developer Principal System AnalystSr span lDeveloperspan Python Developer Durham NC Principal DeveloperAnalyst with twelve 12 years of experience in application development interpreting and analyzing large sets of data along with knowledge in cloud computing distributed systems and database programming for credit cards banking financial and retail industries Proven skills in developing server side Python code that is reliable and efficient Extensive data analysis experience on large sets of data using Python machine learning Algorithms Big Data tools and data science methodologies Strong background in Cloud computing solutions cloud computing strategy systems design implementation and management with ability to provision operate and manage distributed application systems on the cloud platform Comprehensive experience working with various database sources such as Oracle SQLite and SQL Server and proficiency in database component development including Constraints Indexes Views Triggers Cursors and Packages using SQL Developer Expert knowledge in designing technical architecture solutions that span multiple platforms and include integration and authentication for systems Proficient in software development and overall automation including SDLC Agile Scrum and DevOps Proven technical background with LinuxUnix and Windows servers file transfer job scheduling and report generation using shell scripting and Perl Proficient in creating and maintaining technical and business documents Ability to adapt to changing technologies ability to learn and assess needs by quickly assimilating new interface or production software Significant experience working with clients stakeholders and business owners in performing requirements analysis providing guidance in implementation of applications Authorized to work in the US for any employer Work Experience Principal System AnalystSr Developer Fidelity Investments Durham NC February 2018 to Present Global HRIS Payroll Platform Modernization The Global HRISPayroll platform modernization project replaces Fidelitys HR and payroll technology systems globally with Workday as a modern cloud based human capital management payroll and financial management system The scope of this project is to rally and guide the teams to meet its Cloud migration goals The scope also includes acceleration of process automation and modernization of development and deployment operationsprocesses Developed disk space usage predictor tool using machine learning Algorithms including Linear Regression Logistic Regression ElasticNet kNN with Python and MongoDB to keep the disk space in control and avoid failure of critical payroll jobs in the cloud environment Designed and developed an automatic change request approval solution using Python packages including Pandas Numpy scikitlearn and SciPy The business and technology teams use it extensively to make decisions on rollouts and mitigate any business risks Incorporated data solution to collect clean transform compare and identify inconsistencies in payroll data that is migrated to cloud from a distributed environment This is a validation solution to facilitate seamless migration of data to Cloud architecture Actively collaborated with IT Architecture Infrastructure and business teams to deploy various applications in Cloud Managed production releases with the help of integration and migration tools such as GIT Stash IBM Clearcase Jenkins and UDeploy Designed deployed automated maintained and managed cloud based production systems to ensure the availability performance scalability and security of production systems Collaborated and implemented the IAM technologies best practices on identity access management and authentication mechanisms for the Cloud servers Reevaluated the existing stack and infrastructure to maintain optimal performance availability and security Environment Redhat Linux Python Machine Learning algorithms Anaconda Go Unix Shell scripting Oracle PLSQL SQLite Jenkins Chef GIT Stash AWS Python Developer Fidelity Investments Durham NC August 2016 to August 2018 Hackathon Project Participated in NC Hackathon and developed Big Pay application using Big Data and data science tools The project develops selfservice reporting and analytics functionality which was used for executiveaudit reporting Performed the below activities as a data analyst for the project Imported structured and unstructured data from relational databases and file systems into Big Data environment using Hive Impala Pig scripts and Python libraries Performed data cleansing of the migrated data in the new environment using Python scripts Organized data in appropriate data sets to use for reporting purposes Generated payroll reports using data visualization tools using Tableau and Matplotlib Created workflows using Oozie for automated data processing Environment Python Hue v311 Hadoop Tableau Oracle Pig Sqoop Oozie Hive Impala Matplotlib Principal System AnalystSr Developer Fidelity Investments Durham NC September 2015 to February 2017 Global HRPayroll Infrastructure Management HR Payroll Infrastructure Management manages all servers that host internal payroll applications for Fidelity Investments The project performs routine system updates to install new elements and continuous monitoring of server performance This team collaborates with other teams to implement processes and procedures to stay with the corporate standards The scope of this project includes relevant data collection and reporting of performance metrics for audit purposes Developed user auditing tools for monitoring the appropriate access of service accounts in multiple servers using Python Linux and shell scripting to enhance the security of Linux servers in a distributed environment Optimized and enhanced payroll data consolidation and comparison process that reduced the total processing time from four hours to three minutes Designed solutions for complex performance andor reliability problems in the distributed system application Automated regular infrastructure activities such as server patching application recycle and storage maintenance using Pythonshell scripts Migrated server applications from physical data center to cloud environment Collected analyzed and interpreted server data and built personalized reports on server readiness and performance Worked closely with the application team to prototype architect plan estimate and implement solutions for the release management Environment Redhat Linux Python Windows 2016 shell scripting Git Stash JIRA Udeploy Jenkins IBM Clearcase Cloud computing Principal System AnalystSr Developer Fidelity Investments Durham NC March 2014 to September 2015 Global HRISPayroll Upgrade Global Payroll Upgrade consolidated the three disparate payroll systems used by Fidelity Investments into a single instance on vendor supported products The primary goal of this upgrade was to migrate from a mainframe based back end to a Linux distributed environment The scope of the project involves gathering requirements designing developing and implementing code and data migration solutions for the distributed system environment Designed and developed reusable customizable Python and UnixLinux shell scripts to reproduce the functionality of the existing system in the new environment Automated data comparison process between multiple environments to ensure the proper migration to the distributed environment Created solutions to complex performance and reliability problems in the distributed system applications Developed data cleaning tool using Python based packages for weekly and biweekly payroll processing Generated adhoc reports using SQL and Python programs for business review and validation Reviewed and analyzed overall architecture of systems and translating architecture into resilient technical solutions Developed source codes and resolved any issues while ensuring the code changes end up in change items CIs and deploying CIs to their target environments Developed and maintained program development strategies using Agile development processes Resolved software or process defects discovered throughout the prelaunch postlaunch and quality review processes Managed production releases with the help of integration and migration tools such as GITStash IBM Clearcase Jenkins and UDeploy Designed analyzed and implemented file transfer solutions based on different server requirements Mentored and assisted other developers in code development performed peer reviews and provided feedback for improvements Assisted in developing and implemented scheduler based solutions using ControlM Migrated developed codes to IBM Clearcase to maintain the effective code management Environment Redhat Linux Python Oracle PLSQL Perl UNIX shell scripting Control M SFTP Oracle IBM Clearcase Microfocus COBOL SharePoint 2012 Programmer Analyst Chicago Mercantile Exchange Chicago IL October 2013 to March 2014 CME Direct Management CME Direct provides online trading and free electronic access to CME futures and OTC markets through a single easyto use free application This project is to automate the process of upgrading the components involved with CME Direct It also involves creating an audit system for the components to be upgraded Environment Redhat Linux Perl UNIX shell scripting Python Oracle IBM Connect Direct NDM Autosys ControlM SQL Server IBM Clearcase IT AnalystTechnical Lead CITI Group Elk Grove Village IL May 2010 to October 2013 Mail360 Customer Statement and Letter Processing Mail Management System tracks every mail piece throughout all production steps to comply with USPS requirements for multipurpose piece level identification piece level tracking and reporting without adding additional identifiers to the pieces Mail 360 project involves implementing intelligent mail barcode in the statementsletters sent to the customer Environment UNIX shell scripts Python Streamweaver Mail360 Autosys IBM Connect Direct NDM Oracle HP QC UNIX commands MailStream Plus SQL Server Windows 2008 server SSH Tectia WCC Sr Software Engineer Toys R Us Chennai Tamil Nadu August 2006 to May 2010 India Merchandising Applications US Maintenance The Merchandising Applications Domestic US Support Maintenance project is a production support and maintenance project for the entire suite of domestic applications used by Toys R Us It involved providing maintenance and support for various modules in the Merchandise applications by resolving tickets bug fixes and enhancements The sales information is used to plan budget and track company performance Essentially all planning happens through the RPAS Retek planning tool The supporting IT jobs and feeds are responsible for feeding the Retek proprietary planning database and retrieving processed information back to database stores on several boxes The scope of the project to develop and maintain Linux based distributed environment to perform the above activities Environment UNIX shell scripts SFTP FTP PERL ACUMATE AUTOSYS Remedy RPAS Oracle DB2 FTP AWK and SED TOAD Education Bachelor of Engineering in Instrumentation and Control Anna University Chennai Tamil Nadu Additional Information SKILLS Application Development Data Skills Python shell scripting PERL Go PLSQL Machine Learning Docker Visualization using Tableau and Matplotlib Advanced analytics using Python packages such as Pandas Numpy Scikitlearn and SciPy Big Data Technologies Hadoop Hive Impala Sqoop Oozie Pig Cloud Computing AWS GCP Chef Operating Systems UnixLinux Windows Ubuntu Databases Oracle SQLite SQL Server Tools Anaconda GIT Stash Jenkins UDeploy Clearcase CyberArk",
    "unique_id": "4c652fca-2c27-4802-b11b-347690e1597e"
}