{
    "clean_data": "Principal Software Engineer IT Principal span lSoftwarespan Engineer IT Principal Software Engineer IT DELL More than 8 years of extensive experience in Data Migration and Integrating it with CRM applications such as Salesforce and Siebel platforms using Cloud and ETL technologies such as DELL Boomi Informatica MSBI Jaspersoft and DataStage Expertise in Business and Data Analysis and requirement understanding development and data modeling across IT Industries such as Product development Services Health Insurance and Marketing Industries Well experienced in end to end ETL Development deployments deployment object creation labelling versioning Production validation Data Validation and Data Migration Extensive experience in developing the DELL Boomi Process to Migrate the data across various source systems to cloud CRM systems Using various Connectors such as FTP Database Salesforce Disk and Mail with respective Connection Operators Experienced in working with various shapes such as Map Set Properties Program Command Process Call Data Process Cache Branch Route Decision Business Rules Flow Control and notify to enhance the data flow process as per business requirements Well experienced in error handling methodologies using TryCatch and exception shapes Also worked on dynamic document process properties to get the run time parameters to process the datasets in larger volumes Experience in Creating new EnvironmentsAtoms and Deploying the processes to various AtomEnvironments Scheduling the processes Working knowledge on different data sources such as OLEDB Excel XML Flat Files PDF DB2 SQL Server X12 Experience in writing Oracle SQL Server MYSQL PLSQL queries query performance tuning and database mirroring Expertise in creatingmodifying Tables Views Stored Procedures Functions and indepth knowledge in query optimization performance tuning Knowledge of OLAP MultiDimensional Data Modeling Designing star snowflake schemas Data Marts Data Mining Data quality Analysis Data Integration Slowly Changing Dimensions SCD and creating job flow diagrams Working experience in Informatica B2B data exchange and B2B transformation Studio Informatica IDQ MDM Informatica ILM Implementation Informatica version upgradation and Data archivals Experience in SQL Server 00 OLAP database development including KPIs Data mining working with changing dimensions Experience in BI tools includes Cognos10 framework Manager and reports designer SSRS and Business Objects BOXIR2 Tableau Experience in ETL tools validation across MSBI IBM DataStage Jasper and Informatica Extensively worked on Waterfall AgileScrum methodologies Well experienced on all phases of Software Development Life Cycle SDLC of Data warehousing including functional requirements gathering from the business users requirement analysis specification writing design creation of mapping documents development testing and PostProduction Support Conductparticipate in IterationSprint planning Story point estimation and work on assigning the User stories for development and implementation Work Experience Principal Software Engineer IT DELL Round Rock TX July 2018 to Present Environment Salesforce Lightning DELL Boomi Integration Oracle SQL Developer Siebel CRM Salesforce Analytics Data Loader Salesforce Classic JavaScript Groovy Informatica 961 UNIX Putty Team Foundation ServerTFS Responsibilities Analyze and identify the Gaps in requirements coordinate with business users and convert the business requirements into technical specifications Track all the requirements using TFS and work with other interlock teams for continuous development Analyze the data migration requirements and design the data flow model with ER model DesignDevelop the DB system to store the data in accordance with business requirements Create necessary Tables stored procedures triggers and PLSQL Packages to extract and store the data for downstreamupstream systems with initial and incremental load Develop new processes to move the data from existing application to new CRM application using DELL Boomi cloud integration Write custom scripts using JavaScriptGroovy to fetch the process parameters inside the map for Data transformation Expertise in using environment extensions cross reference connections parameters to deploy the processes in to different molecules as required Implement the process as per DELL Boomi Coding standards using Maps Set Properties DecisionBusiness rules shapes Branch and Routing as required and tune the performance analyzing the flow control threads to balance the server load during real time executions Perform Unit testing to validate the development in accordance with functional requirements Build the process and deploy it to respective atomsenvironments for SIT UAT and Production environments in each phase Support data migration requests across other streams to provide continuity in interlock testing ondemand Prepare release instructions DBA procedures backout plan and post production validation steps during Production Implementation Work on Major Incident Management to resolve any issues based on severity Software Developer Indotronix International Corporation Poughkeepsie NY May 2018 to July 2018 Environment DELL Boomi Integration Informatica 951 102 UNIX Putty WINSCP SQL Developer Informatica B2B Data Transformation Studio TIDAL Scheduler ClearQuest Responsibilities Defines the scope and objectives and prepares technical functional requirements listing with impacted objects for reference Migrates the code from Informatica 95 to Informatica 102 validates the data in both the systems Creates Tidal jobs and deploys the code from DEV to QA and continues to provide support until post production Perform Gap analysis and reviews the implementation plan with the scrum team to ensure the transition is up to date as per the schedule Performs Code checkins in the SVN and reviews the test results maintains technical development environment Mentors others and may lead multiple or small to medium sized projects Facilitates group sessions to elicit complex information on requirements clarification design sessions code reviews and troubleshooting issues Technology Analyst Infosys Ltd Chennai Tamil Nadu November 2012 to August 2016 Environment DELL Boomi Integration Informatica 951 961 SSIS 2008 Cognos 10 TOAD DB2 UNIX Putty WINSCP SQL Developer Informatica B2B Data Transformation Studio TFS SharePoint Responsibilities Proactively interact and collaborate with stakeholdersArchitects to analyze business needs and create the Business Requirements Document and System requirement specifications for Data Migration and ETL Development Involved in implementation of HIPAA EDI Transactions in building EDIs 270 271 276 277 470 835 837 and 834 Performed GAP Analysis for HIPAA 4010 and 5010 transactions and Used EDI tools to verify mapping to X12 format Preparing technical specifications document ETL Mapping document and Metadata management for ETL load and extract processes Installation Configuration and Administration of Informatica Power Center on ClientServer Environment Worked on Informatica Power Center tools Designer Repository Manager Workflow Manager and Workflow Monitor Developed the ETLs to fetch the data from different source system and integrate Development of new ETLs for EDI gateway 5010 implementation to process HIPAA X12 files from various trading partners Transform X12 files through Data transformation studio and parse the data through Informatica transformations to process EDI data and load it into downstream systems Loading Data to the Interface tables from multiple data sources such as SQL server Text files and Excel Spreadsheets using SQL Loader Informatica and ODBC connections Createmodify the database tables stored procedures to accommodate new customer data as part of metadata management Developed ETL workflows to migrate existing trading partner set up in legacy mainframe system to B2B Data Exchange Repository Has worked on Informatica 91 to 95 upgrade handling multiple realtime and batch transactions code migration inclusive of environment and data testing throughout Designed and developed an approach to handle event creation with two layers of sequence numbers so that both the custom transformations and Informatica transformations can coexist in version 95 Creating necessary repositories to handle the metadata in the ETL process Designing the target warehouse using Star Schema Creating mappings to load data from various sources using different transformations like Source Qualifier Expression Lookup Aggregator Update Strategy Joiner Normalizer Filter and Router transformations Union transformations etc Simplified the data flow by using a Router transformation to check multiple conditions at the same time Creating sessions sequential and concurrent batches for proper execution of mappings using workflow manager Implemented ILM with a threetier architecture to store and manage transactional data This results in storing data segregated by retention period such as short medium and long term Providing technical guidance to the team and work on solution design Prepare Coding standards perform code reviews design review unit testing reviews for each environment Migrated data from Legacy DB2 environment to SQL Server 2005 with SQL Server Integrated Services SSIS Created ETL process using SSIS to transfer data from heterogeneous data sources Created logging for ETL load at package level and task level to log number of records processed by each package and each task in a package using SSIS Responsible for Deploying Scheduling Jobs Alerting and Maintaining SSIS packages Code Migrations to Main Development folders SIT and UAE repository Software Engineer Ascent Staffing Solutions Pvt Ltd Bengaluru Karnataka December 2010 to November 2012 Environment Informatica 8x MSBI Data Stage Net IIS SQL Server 08 Oracle TOAD DB2 UNIX WINSCP TFS 2010 SharePoint Responsibilities Convert business requirements into technical specifications create design and mapping documents with data modelling and database design Creating Sprints assigning enhancements bugs and user stories to the sprints seasons and work on implementation along with the team Involved and Coordinated Sprint meeting sprint review and Sprint Retrospective meeting Conducted the FRS and URS reviews and walkthroughs with designers developers and stakeholders Also conducted feasibility and adaptability study Develop ETLs to fetch the data from various data sources such as DB2 Mainframes excel OLEDB and load into various target systems Created multiple complex mappings using aggregators expressions joiners ranking filters and Lookup transformations Involved in tuning the mappings sessions and source qualifier queries Worked with different caches such as Index cache Data cache Lookup cache Static Dynamic and Persistent and join cache while creating the Mappings Worked on migrating the legacy aviation data from SQL Server 2000 to 2008 through new ETLs with no impact on application Created a new mappingworkflow to validate the daily counts and weekly counts for incremental load and full load jobs to notify the business users for application data validations Worked on multiple adhoc requests to create SSIS ETL creating Config files multiple data flow tasks and data transformations such as Derived Column Conditional Split Merge Joins and SCDs Worked on Code migration from DEV TEST UAT and PROD preparing technical and process documentation for each change object deployment Worked on developing UNIX scripts to move the files from Production to archival locations as part of production server management Worked on creating new Database Tables Indexes Stored Procedures Triggers and Cursors Worked on IIS Internet Information Services deployments as part of application changes during sprint releases Handle Team Foundation Server TFS 2010 for code checkin branchinglabelling the application code and ETL jobs and test cases test results Software Engineer XLCareUnited Health Group Bengaluru Karnataka December 2009 to December 2010 Environment SQL Server 20002005 DTS 2000 SSIS 2005 Oracle SSRS FTP VSS Responsibilities Designed and implemented new SSIS jobs for all the data load processes from various vendors to load the data into target data bases while retiring from DTS system and upgrading to SSIS 2005 Worked on SQL query performance tuning Stored procedures converting cursors into SPs and creating SSIS config files Designing Database creating tables Indexes etc as part of legacy system retirement from SQL 2000 to 2005 Analyzing the data files from Trizetto SFTP for Coordination of Benefits Member Enrollment Institutional and Professional Claims Paper claims Pharmacy data etc to develop the ETL coding templates and to design target database Work on Unit testing data validation of new SSIS jobs wrt legacy DTS jobs to ensure data accuracy in the new system Execute and monitor Replication system as part of Data warehouse refresh process and notify the DBAs in case of job failure Work on adhoc requests to pull the Pharmacy claims and member benefits data extracting from reporting database Skills Data modeling Database Db2 Ms access Sql server Mysql Oracle Plsql Sql Datastage Etl Informatica Mdm Sharepoint Ssrs Team foundation server Siebel Tableau Crm Groovy Additional Information TECHNICAL SKILLS ETLBI Tools DELL Boomi Informatica 102 Informatica PowerCenter 9x8x IDQ Informatica MDM SSIS 20052008 and DataStage Cognos10 Framework Manager and Report Studio SSRS and Business Objects Tableau CRM Salesforce Siebel Scripting JavaScript Groovy 15 Groovy 24 Operating System Windows UNIX Data Modeling Tools Erwin 40 ER Studio Database Oracle 9i10g11g MSSQL Server  DB2 MYSQL MS Access 702000 SQL Server DTSSSISSSRS Tools PLSQL Developer TOAD SSMS MS Office Suite MS Visio TFSTeam Foundation Server SharePoint SVN sub versioning HPALM Clear Quest",
    "entities": [
        "Oracle SQL Server",
        "TryCatch",
        "Business Objects BOXIR2 Tableau",
        "Informatica",
        "X12",
        "Informatica Power Center",
        "SQL Server Integrated Services",
        "Data Marts Data Mining Data",
        "BI",
        "UNIX",
        "Data Validation",
        "Router",
        "Perform Unit",
        "Working",
        "Tableau Crm Groovy Additional Information TECHNICAL SKILLS ETLBI",
        "Maps Set Properties DecisionBusiness",
        "ILM",
        "IBM",
        "Code Migrations",
        "metadata",
        "Facilitates",
        "TFS",
        "ER",
        "Product development Services Health Insurance and Marketing Industries",
        "Software Development Life Cycle SDLC",
        "IterationSprint",
        "DTS",
        "MDM SSIS 20052008",
        "TX",
        "Data Migration and ETL Development Involved",
        "SSIS",
        "Map Set Properties Program Command",
        "SQL Server",
        "Technology Analyst Infosys Ltd",
        "Lookup",
        "SSIS Responsible for Deploying Scheduling Jobs Alerting and Maintaining SSIS",
        "DesignDevelop",
        "Involved",
        "Main Development",
        "Migrate",
        "Tables Views Stored Procedures Functions",
        "Develop",
        "DELL",
        "Oracle TOAD DB2",
        "Enrollment Institutional and Professional Claims Paper",
        "Connection Operators Experienced",
        "UNIX WINSCP TFS",
        "Putty Team Foundation",
        "DBA",
        "Interface",
        "Informatica B2B Data Transformation Studio",
        "SIT",
        "Informatica B2B Data Transformation Studio TFS SharePoint Responsibilities",
        "QA",
        "PDF",
        "Conducted the FRS",
        "Created",
        "Software Developer Indotronix International Corporation Poughkeepsie",
        "Developed ETL",
        "Sprint Retrospective",
        "DataStage Cognos10 Framework",
        "AtomEnvironments Scheduling",
        "Sql",
        "Prepare Coding",
        "Software Engineer Ascent Staffing Solutions Pvt Ltd",
        "IDQ",
        "SQL Loader Informatica",
        "ODBC",
        "SSRS",
        "SQL",
        "Prepare",
        "DELL Boomi",
        "Execute",
        "SSIS Created ETL",
        "HPALM Clear Quest",
        "Mainframes",
        "Metadata",
        "FTP Database Salesforce Disk and Mail",
        "Studio Database Oracle",
        "URS",
        "Principal Software Engineer",
        "Routing",
        "SharePoint Responsibilities Convert",
        "the Business Requirements Document and System",
        "Present Environment Salesforce Lightning",
        "ETL",
        "Skills Data",
        "Business Objects Tableau CRM Salesforce",
        "Build",
        "Installation Configuration and Administration of Informatica Power Center on ClientServer Environment Worked",
        "EDI",
        "DEV",
        "Data Migration and Integrating",
        "Migrated",
        "Studio Informatica IDQ",
        "HIPAA",
        "Loading Data",
        "SVN",
        "Coordinated Sprint",
        "Oracle SSRS FTP VSS Responsibilities Designed",
        "ETL Development",
        "Software Engineer XLCareUnited Health Group",
        "Data",
        "Connectors",
        "B2B Data Exchange Repository",
        "Excel Spreadsheets",
        "Handle Team Foundation",
        "TOAD",
        "Waterfall AgileScrum",
        "EnvironmentsAtoms"
    ],
    "experience": "Experience in Creating new EnvironmentsAtoms and Deploying the processes to various AtomEnvironments Scheduling the processes Working knowledge on different data sources such as OLEDB Excel XML Flat Files PDF DB2 SQL Server X12 Experience in writing Oracle SQL Server MYSQL PLSQL queries query performance tuning and database mirroring Expertise in creatingmodifying Tables Views Stored Procedures Functions and indepth knowledge in query optimization performance tuning Knowledge of OLAP MultiDimensional Data Modeling Designing star snowflake schemas Data Marts Data Mining Data quality Analysis Data Integration Slowly Changing Dimensions SCD and creating job flow diagrams Working experience in Informatica B2B data exchange and B2B transformation Studio Informatica IDQ MDM Informatica ILM Implementation Informatica version upgradation and Data archivals Experience in SQL Server 00 OLAP database development including KPIs Data mining working with changing dimensions Experience in BI tools includes Cognos10 framework Manager and reports designer SSRS and Business Objects BOXIR2 Tableau Experience in ETL tools validation across MSBI IBM DataStage Jasper and Informatica Extensively worked on Waterfall AgileScrum methodologies Well experienced on all phases of Software Development Life Cycle SDLC of Data warehousing including functional requirements gathering from the business users requirement analysis specification writing design creation of mapping documents development testing and PostProduction Support Conductparticipate in IterationSprint planning Story point estimation and work on assigning the User stories for development and implementation Work Experience Principal Software Engineer IT DELL Round Rock TX July 2018 to Present Environment Salesforce Lightning DELL Boomi Integration Oracle SQL Developer Siebel CRM Salesforce Analytics Data Loader Salesforce Classic JavaScript Groovy Informatica 961 UNIX Putty Team Foundation ServerTFS Responsibilities Analyze and identify the Gaps in requirements coordinate with business users and convert the business requirements into technical specifications Track all the requirements using TFS and work with other interlock teams for continuous development Analyze the data migration requirements and design the data flow model with ER model DesignDevelop the DB system to store the data in accordance with business requirements Create necessary Tables stored procedures triggers and PLSQL Packages to extract and store the data for downstreamupstream systems with initial and incremental load Develop new processes to move the data from existing application to new CRM application using DELL Boomi cloud integration Write custom scripts using JavaScriptGroovy to fetch the process parameters inside the map for Data transformation Expertise in using environment extensions cross reference connections parameters to deploy the processes in to different molecules as required Implement the process as per DELL Boomi Coding standards using Maps Set Properties DecisionBusiness rules shapes Branch and Routing as required and tune the performance analyzing the flow control threads to balance the server load during real time executions Perform Unit testing to validate the development in accordance with functional requirements Build the process and deploy it to respective atomsenvironments for SIT UAT and Production environments in each phase Support data migration requests across other streams to provide continuity in interlock testing ondemand Prepare release instructions DBA procedures backout plan and post production validation steps during Production Implementation Work on Major Incident Management to resolve any issues based on severity Software Developer Indotronix International Corporation Poughkeepsie NY May 2018 to July 2018 Environment DELL Boomi Integration Informatica 951 102 UNIX Putty WINSCP SQL Developer Informatica B2B Data Transformation Studio TIDAL Scheduler ClearQuest Responsibilities Defines the scope and objectives and prepares technical functional requirements listing with impacted objects for reference Migrates the code from Informatica 95 to Informatica 102 validates the data in both the systems Creates Tidal jobs and deploys the code from DEV to QA and continues to provide support until post production Perform Gap analysis and reviews the implementation plan with the scrum team to ensure the transition is up to date as per the schedule Performs Code checkins in the SVN and reviews the test results maintains technical development environment Mentors others and may lead multiple or small to medium sized projects Facilitates group sessions to elicit complex information on requirements clarification design sessions code reviews and troubleshooting issues Technology Analyst Infosys Ltd Chennai Tamil Nadu November 2012 to August 2016 Environment DELL Boomi Integration Informatica 951 961 SSIS 2008 Cognos 10 TOAD DB2 UNIX Putty WINSCP SQL Developer Informatica B2B Data Transformation Studio TFS SharePoint Responsibilities Proactively interact and collaborate with stakeholdersArchitects to analyze business needs and create the Business Requirements Document and System requirement specifications for Data Migration and ETL Development Involved in implementation of HIPAA EDI Transactions in building EDIs 270 271 276 277 470 835 837 and 834 Performed GAP Analysis for HIPAA 4010 and 5010 transactions and Used EDI tools to verify mapping to X12 format Preparing technical specifications document ETL Mapping document and Metadata management for ETL load and extract processes Installation Configuration and Administration of Informatica Power Center on ClientServer Environment Worked on Informatica Power Center tools Designer Repository Manager Workflow Manager and Workflow Monitor Developed the ETLs to fetch the data from different source system and integrate Development of new ETLs for EDI gateway 5010 implementation to process HIPAA X12 files from various trading partners Transform X12 files through Data transformation studio and parse the data through Informatica transformations to process EDI data and load it into downstream systems Loading Data to the Interface tables from multiple data sources such as SQL server Text files and Excel Spreadsheets using SQL Loader Informatica and ODBC connections Createmodify the database tables stored procedures to accommodate new customer data as part of metadata management Developed ETL workflows to migrate existing trading partner set up in legacy mainframe system to B2B Data Exchange Repository Has worked on Informatica 91 to 95 upgrade handling multiple realtime and batch transactions code migration inclusive of environment and data testing throughout Designed and developed an approach to handle event creation with two layers of sequence numbers so that both the custom transformations and Informatica transformations can coexist in version 95 Creating necessary repositories to handle the metadata in the ETL process Designing the target warehouse using Star Schema Creating mappings to load data from various sources using different transformations like Source Qualifier Expression Lookup Aggregator Update Strategy Joiner Normalizer Filter and Router transformations Union transformations etc Simplified the data flow by using a Router transformation to check multiple conditions at the same time Creating sessions sequential and concurrent batches for proper execution of mappings using workflow manager Implemented ILM with a threetier architecture to store and manage transactional data This results in storing data segregated by retention period such as short medium and long term Providing technical guidance to the team and work on solution design Prepare Coding standards perform code reviews design review unit testing reviews for each environment Migrated data from Legacy DB2 environment to SQL Server 2005 with SQL Server Integrated Services SSIS Created ETL process using SSIS to transfer data from heterogeneous data sources Created logging for ETL load at package level and task level to log number of records processed by each package and each task in a package using SSIS Responsible for Deploying Scheduling Jobs Alerting and Maintaining SSIS packages Code Migrations to Main Development folders SIT and UAE repository Software Engineer Ascent Staffing Solutions Pvt Ltd Bengaluru Karnataka December 2010 to November 2012 Environment Informatica 8x MSBI Data Stage Net IIS SQL Server 08 Oracle TOAD DB2 UNIX WINSCP TFS 2010 SharePoint Responsibilities Convert business requirements into technical specifications create design and mapping documents with data modelling and database design Creating Sprints assigning enhancements bugs and user stories to the sprints seasons and work on implementation along with the team Involved and Coordinated Sprint meeting sprint review and Sprint Retrospective meeting Conducted the FRS and URS reviews and walkthroughs with designers developers and stakeholders Also conducted feasibility and adaptability study Develop ETLs to fetch the data from various data sources such as DB2 Mainframes excel OLEDB and load into various target systems Created multiple complex mappings using aggregators expressions joiners ranking filters and Lookup transformations Involved in tuning the mappings sessions and source qualifier queries Worked with different caches such as Index cache Data cache Lookup cache Static Dynamic and Persistent and join cache while creating the Mappings Worked on migrating the legacy aviation data from SQL Server 2000 to 2008 through new ETLs with no impact on application Created a new mappingworkflow to validate the daily counts and weekly counts for incremental load and full load jobs to notify the business users for application data validations Worked on multiple adhoc requests to create SSIS ETL creating Config files multiple data flow tasks and data transformations such as Derived Column Conditional Split Merge Joins and SCDs Worked on Code migration from DEV TEST UAT and PROD preparing technical and process documentation for each change object deployment Worked on developing UNIX scripts to move the files from Production to archival locations as part of production server management Worked on creating new Database Tables Indexes Stored Procedures Triggers and Cursors Worked on IIS Internet Information Services deployments as part of application changes during sprint releases Handle Team Foundation Server TFS 2010 for code checkin branchinglabelling the application code and ETL jobs and test cases test results Software Engineer XLCareUnited Health Group Bengaluru Karnataka December 2009 to December 2010 Environment SQL Server 20002005 DTS 2000 SSIS 2005 Oracle SSRS FTP VSS Responsibilities Designed and implemented new SSIS jobs for all the data load processes from various vendors to load the data into target data bases while retiring from DTS system and upgrading to SSIS 2005 Worked on SQL query performance tuning Stored procedures converting cursors into SPs and creating SSIS config files Designing Database creating tables Indexes etc as part of legacy system retirement from SQL 2000 to 2005 Analyzing the data files from Trizetto SFTP for Coordination of Benefits Member Enrollment Institutional and Professional Claims Paper claims Pharmacy data etc to develop the ETL coding templates and to design target database Work on Unit testing data validation of new SSIS jobs wrt legacy DTS jobs to ensure data accuracy in the new system Execute and monitor Replication system as part of Data warehouse refresh process and notify the DBAs in case of job failure Work on adhoc requests to pull the Pharmacy claims and member benefits data extracting from reporting database Skills Data modeling Database Db2 Ms access Sql server Mysql Oracle Plsql Sql Datastage Etl Informatica Mdm Sharepoint Ssrs Team foundation server Siebel Tableau Crm Groovy Additional Information TECHNICAL SKILLS ETLBI Tools DELL Boomi Informatica 102 Informatica PowerCenter 9x8x IDQ Informatica MDM SSIS 20052008 and DataStage Cognos10 Framework Manager and Report Studio SSRS and Business Objects Tableau CRM Salesforce Siebel Scripting JavaScript Groovy 15 Groovy 24 Operating System Windows UNIX Data Modeling Tools Erwin 40 ER Studio Database Oracle 9i10g11 g MSSQL Server   DB2 MYSQL MS Access 702000 SQL Server DTSSSISSSRS Tools PLSQL Developer TOAD SSMS MS Office Suite MS Visio TFSTeam Foundation Server SharePoint SVN sub versioning HPALM Clear Quest",
    "extracted_keywords": [
        "Principal",
        "Software",
        "Engineer",
        "IT",
        "Principal",
        "span",
        "lSoftwarespan",
        "Engineer",
        "IT",
        "Principal",
        "Software",
        "Engineer",
        "IT",
        "DELL",
        "years",
        "experience",
        "Data",
        "Migration",
        "CRM",
        "applications",
        "Salesforce",
        "Siebel",
        "platforms",
        "Cloud",
        "ETL",
        "technologies",
        "DELL",
        "Boomi",
        "Informatica",
        "MSBI",
        "Jaspersoft",
        "DataStage",
        "Expertise",
        "Business",
        "Data",
        "Analysis",
        "requirement",
        "development",
        "data",
        "IT",
        "Industries",
        "Product",
        "development",
        "Services",
        "Health",
        "Insurance",
        "Marketing",
        "Industries",
        "Well",
        "end",
        "ETL",
        "Development",
        "deployments",
        "deployment",
        "object",
        "creation",
        "labelling",
        "Production",
        "validation",
        "Data",
        "Validation",
        "Data",
        "Migration",
        "experience",
        "DELL",
        "Boomi",
        "Process",
        "data",
        "source",
        "systems",
        "CRM",
        "systems",
        "Connectors",
        "FTP",
        "Database",
        "Salesforce",
        "Disk",
        "Mail",
        "Connection",
        "Operators",
        "shapes",
        "Map",
        "Set",
        "Properties",
        "Program",
        "Command",
        "Process",
        "Call",
        "Data",
        "Process",
        "Cache",
        "Branch",
        "Route",
        "Decision",
        "Business",
        "Rules",
        "Flow",
        "Control",
        "data",
        "flow",
        "process",
        "business",
        "requirements",
        "error",
        "handling",
        "methodologies",
        "TryCatch",
        "exception",
        "shapes",
        "document",
        "process",
        "properties",
        "time",
        "parameters",
        "datasets",
        "volumes",
        "Experience",
        "EnvironmentsAtoms",
        "processes",
        "AtomEnvironments",
        "Scheduling",
        "processes",
        "knowledge",
        "data",
        "sources",
        "OLEDB",
        "Excel",
        "XML",
        "Flat",
        "Files",
        "PDF",
        "DB2",
        "SQL",
        "Server",
        "X12",
        "Experience",
        "Oracle",
        "SQL",
        "Server",
        "MYSQL",
        "PLSQL",
        "query",
        "performance",
        "tuning",
        "database",
        "Expertise",
        "Tables",
        "Views",
        "Stored",
        "Procedures",
        "Functions",
        "knowledge",
        "query",
        "optimization",
        "performance",
        "Knowledge",
        "OLAP",
        "MultiDimensional",
        "Data",
        "Modeling",
        "Designing",
        "star",
        "snowflake",
        "schemas",
        "Data",
        "Marts",
        "Data",
        "Mining",
        "Data",
        "quality",
        "Analysis",
        "Data",
        "Integration",
        "Dimensions",
        "SCD",
        "job",
        "flow",
        "diagrams",
        "Working",
        "experience",
        "Informatica",
        "B2B",
        "data",
        "exchange",
        "B2B",
        "transformation",
        "Studio",
        "Informatica",
        "IDQ",
        "MDM",
        "Informatica",
        "ILM",
        "Implementation",
        "Informatica",
        "version",
        "upgradation",
        "Data",
        "archivals",
        "Experience",
        "SQL",
        "Server",
        "OLAP",
        "database",
        "development",
        "KPIs",
        "Data",
        "mining",
        "dimensions",
        "Experience",
        "BI",
        "tools",
        "framework",
        "Manager",
        "designer",
        "SSRS",
        "Business",
        "BOXIR2",
        "Tableau",
        "Experience",
        "ETL",
        "tools",
        "validation",
        "MSBI",
        "IBM",
        "DataStage",
        "Jasper",
        "Informatica",
        "Waterfall",
        "AgileScrum",
        "methodologies",
        "phases",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "SDLC",
        "Data",
        "warehousing",
        "requirements",
        "business",
        "users",
        "requirement",
        "analysis",
        "specification",
        "design",
        "creation",
        "mapping",
        "documents",
        "development",
        "testing",
        "PostProduction",
        "Support",
        "Conductparticipate",
        "IterationSprint",
        "planning",
        "Story",
        "point",
        "estimation",
        "work",
        "User",
        "stories",
        "development",
        "implementation",
        "Work",
        "Experience",
        "Principal",
        "Software",
        "Engineer",
        "IT",
        "DELL",
        "Round",
        "Rock",
        "TX",
        "July",
        "Present",
        "Environment",
        "Salesforce",
        "Lightning",
        "DELL",
        "Boomi",
        "Integration",
        "Oracle",
        "SQL",
        "Developer",
        "Siebel",
        "CRM",
        "Salesforce",
        "Analytics",
        "Data",
        "Loader",
        "Salesforce",
        "Classic",
        "JavaScript",
        "Groovy",
        "Informatica",
        "UNIX",
        "Putty",
        "Team",
        "Foundation",
        "ServerTFS",
        "Responsibilities",
        "Analyze",
        "Gaps",
        "requirements",
        "business",
        "users",
        "business",
        "requirements",
        "specifications",
        "Track",
        "requirements",
        "TFS",
        "work",
        "teams",
        "development",
        "Analyze",
        "data",
        "migration",
        "requirements",
        "data",
        "flow",
        "model",
        "ER",
        "model",
        "DesignDevelop",
        "DB",
        "system",
        "data",
        "accordance",
        "business",
        "requirements",
        "Tables",
        "procedures",
        "triggers",
        "PLSQL",
        "Packages",
        "data",
        "downstreamupstream",
        "systems",
        "load",
        "processes",
        "data",
        "application",
        "CRM",
        "application",
        "DELL",
        "Boomi",
        "cloud",
        "integration",
        "custom",
        "scripts",
        "JavaScriptGroovy",
        "process",
        "parameters",
        "map",
        "Data",
        "transformation",
        "Expertise",
        "environment",
        "extensions",
        "cross",
        "reference",
        "connections",
        "parameters",
        "processes",
        "molecules",
        "Implement",
        "process",
        "DELL",
        "Boomi",
        "Coding",
        "standards",
        "Maps",
        "Set",
        "Properties",
        "DecisionBusiness",
        "rules",
        "Branch",
        "Routing",
        "performance",
        "flow",
        "control",
        "threads",
        "server",
        "load",
        "time",
        "executions",
        "Perform",
        "Unit",
        "testing",
        "development",
        "accordance",
        "requirements",
        "process",
        "atomsenvironments",
        "SIT",
        "UAT",
        "Production",
        "environments",
        "phase",
        "Support",
        "data",
        "migration",
        "requests",
        "streams",
        "continuity",
        "testing",
        "ondemand",
        "Prepare",
        "release",
        "instructions",
        "DBA",
        "procedures",
        "backout",
        "plan",
        "production",
        "validation",
        "steps",
        "Production",
        "Implementation",
        "Work",
        "Major",
        "Incident",
        "Management",
        "issues",
        "severity",
        "Software",
        "Developer",
        "Indotronix",
        "International",
        "Corporation",
        "Poughkeepsie",
        "NY",
        "May",
        "July",
        "Environment",
        "DELL",
        "Boomi",
        "Integration",
        "Informatica",
        "UNIX",
        "Putty",
        "WINSCP",
        "SQL",
        "Developer",
        "Informatica",
        "B2B",
        "Data",
        "Transformation",
        "Studio",
        "Scheduler",
        "ClearQuest",
        "Responsibilities",
        "scope",
        "objectives",
        "requirements",
        "objects",
        "reference",
        "code",
        "Informatica",
        "Informatica",
        "data",
        "systems",
        "jobs",
        "code",
        "DEV",
        "support",
        "post",
        "production",
        "Gap",
        "analysis",
        "implementation",
        "plan",
        "scrum",
        "team",
        "transition",
        "date",
        "schedule",
        "Code",
        "SVN",
        "test",
        "results",
        "development",
        "environment",
        "Mentors",
        "others",
        "projects",
        "Facilitates",
        "group",
        "sessions",
        "information",
        "requirements",
        "clarification",
        "design",
        "sessions",
        "code",
        "reviews",
        "troubleshooting",
        "issues",
        "Technology",
        "Analyst",
        "Infosys",
        "Ltd",
        "Chennai",
        "Tamil",
        "Nadu",
        "November",
        "August",
        "Environment",
        "DELL",
        "Boomi",
        "Integration",
        "Informatica",
        "SSIS",
        "Cognos",
        "TOAD",
        "DB2",
        "UNIX",
        "Putty",
        "WINSCP",
        "SQL",
        "Developer",
        "Informatica",
        "B2B",
        "Data",
        "Transformation",
        "Studio",
        "TFS",
        "SharePoint",
        "Responsibilities",
        "stakeholdersArchitects",
        "business",
        "needs",
        "Business",
        "Requirements",
        "Document",
        "System",
        "requirement",
        "specifications",
        "Data",
        "Migration",
        "ETL",
        "Development",
        "implementation",
        "HIPAA",
        "EDI",
        "Transactions",
        "EDIs",
        "Performed",
        "GAP",
        "Analysis",
        "HIPAA",
        "transactions",
        "EDI",
        "tools",
        "mapping",
        "X12",
        "format",
        "specifications",
        "document",
        "ETL",
        "Mapping",
        "document",
        "Metadata",
        "management",
        "ETL",
        "load",
        "Installation",
        "Configuration",
        "Administration",
        "Informatica",
        "Power",
        "Center",
        "ClientServer",
        "Environment",
        "Informatica",
        "Power",
        "Center",
        "tools",
        "Designer",
        "Repository",
        "Manager",
        "Workflow",
        "Manager",
        "Workflow",
        "Monitor",
        "ETLs",
        "data",
        "source",
        "system",
        "Development",
        "ETLs",
        "EDI",
        "gateway",
        "implementation",
        "X12",
        "files",
        "trading",
        "partners",
        "X12",
        "files",
        "Data",
        "transformation",
        "studio",
        "data",
        "Informatica",
        "transformations",
        "EDI",
        "data",
        "systems",
        "Loading",
        "Data",
        "Interface",
        "tables",
        "data",
        "sources",
        "SQL",
        "server",
        "Text",
        "files",
        "Excel",
        "Spreadsheets",
        "SQL",
        "Loader",
        "Informatica",
        "ODBC",
        "connections",
        "database",
        "procedures",
        "customer",
        "data",
        "part",
        "metadata",
        "management",
        "Developed",
        "ETL",
        "workflows",
        "trading",
        "partner",
        "legacy",
        "mainframe",
        "system",
        "B2B",
        "Data",
        "Exchange",
        "Repository",
        "Informatica",
        "upgrade",
        "realtime",
        "transactions",
        "code",
        "migration",
        "inclusive",
        "environment",
        "data",
        "testing",
        "approach",
        "event",
        "creation",
        "layers",
        "sequence",
        "numbers",
        "custom",
        "transformations",
        "Informatica",
        "transformations",
        "version",
        "repositories",
        "metadata",
        "ETL",
        "process",
        "target",
        "warehouse",
        "Star",
        "Schema",
        "mappings",
        "data",
        "sources",
        "transformations",
        "Source",
        "Qualifier",
        "Expression",
        "Lookup",
        "Aggregator",
        "Update",
        "Strategy",
        "Joiner",
        "Normalizer",
        "Filter",
        "Router",
        "transformations",
        "Union",
        "transformations",
        "data",
        "flow",
        "Router",
        "transformation",
        "conditions",
        "time",
        "sessions",
        "batches",
        "execution",
        "mappings",
        "manager",
        "ILM",
        "architecture",
        "data",
        "results",
        "data",
        "retention",
        "period",
        "term",
        "guidance",
        "team",
        "solution",
        "design",
        "Prepare",
        "Coding",
        "standards",
        "code",
        "reviews",
        "design",
        "review",
        "unit",
        "testing",
        "reviews",
        "environment",
        "data",
        "Legacy",
        "DB2",
        "environment",
        "SQL",
        "Server",
        "SQL",
        "Server",
        "Integrated",
        "Services",
        "SSIS",
        "Created",
        "ETL",
        "process",
        "SSIS",
        "data",
        "data",
        "sources",
        "ETL",
        "load",
        "package",
        "level",
        "task",
        "level",
        "number",
        "records",
        "package",
        "task",
        "package",
        "SSIS",
        "Deploying",
        "Scheduling",
        "Jobs",
        "Alerting",
        "SSIS",
        "packages",
        "Code",
        "Migrations",
        "Main",
        "Development",
        "folders",
        "SIT",
        "UAE",
        "Software",
        "Engineer",
        "Ascent",
        "Staffing",
        "Solutions",
        "Pvt",
        "Ltd",
        "Bengaluru",
        "Karnataka",
        "December",
        "November",
        "Environment",
        "Informatica",
        "8x",
        "MSBI",
        "Data",
        "Stage",
        "Net",
        "IIS",
        "SQL",
        "Server",
        "Oracle",
        "TOAD",
        "DB2",
        "UNIX",
        "WINSCP",
        "TFS",
        "SharePoint",
        "Responsibilities",
        "Convert",
        "business",
        "requirements",
        "specifications",
        "design",
        "mapping",
        "documents",
        "data",
        "modelling",
        "database",
        "design",
        "Sprints",
        "enhancements",
        "bugs",
        "user",
        "stories",
        "sprints",
        "seasons",
        "work",
        "implementation",
        "team",
        "Coordinated",
        "Sprint",
        "meeting",
        "sprint",
        "review",
        "Sprint",
        "Retrospective",
        "meeting",
        "FRS",
        "URS",
        "reviews",
        "walkthroughs",
        "designers",
        "developers",
        "stakeholders",
        "feasibility",
        "adaptability",
        "study",
        "Develop",
        "ETLs",
        "data",
        "data",
        "sources",
        "DB2",
        "Mainframes",
        "OLEDB",
        "target",
        "systems",
        "mappings",
        "aggregators",
        "expressions",
        "joiners",
        "filters",
        "Lookup",
        "transformations",
        "mappings",
        "sessions",
        "source",
        "qualifier",
        "queries",
        "caches",
        "Index",
        "cache",
        "Data",
        "cache",
        "Lookup",
        "cache",
        "Static",
        "Dynamic",
        "Persistent",
        "cache",
        "Mappings",
        "legacy",
        "aviation",
        "data",
        "SQL",
        "Server",
        "ETLs",
        "impact",
        "application",
        "mappingworkflow",
        "counts",
        "counts",
        "load",
        "load",
        "jobs",
        "business",
        "users",
        "application",
        "data",
        "validations",
        "requests",
        "SSIS",
        "ETL",
        "Config",
        "files",
        "data",
        "flow",
        "tasks",
        "data",
        "transformations",
        "Derived",
        "Column",
        "Conditional",
        "Split",
        "Merge",
        "Joins",
        "SCDs",
        "Code",
        "migration",
        "DEV",
        "TEST",
        "UAT",
        "process",
        "documentation",
        "change",
        "object",
        "deployment",
        "UNIX",
        "scripts",
        "files",
        "Production",
        "archival",
        "locations",
        "part",
        "production",
        "server",
        "management",
        "Database",
        "Tables",
        "Indexes",
        "Stored",
        "Procedures",
        "Triggers",
        "Cursors",
        "IIS",
        "Internet",
        "Information",
        "Services",
        "deployments",
        "part",
        "application",
        "changes",
        "sprint",
        "releases",
        "Handle",
        "Team",
        "Foundation",
        "Server",
        "TFS",
        "code",
        "checkin",
        "application",
        "code",
        "ETL",
        "jobs",
        "test",
        "cases",
        "test",
        "Software",
        "Engineer",
        "Health",
        "Group",
        "Bengaluru",
        "Karnataka",
        "December",
        "December",
        "Environment",
        "SQL",
        "Server",
        "DTS",
        "SSIS",
        "Oracle",
        "SSRS",
        "FTP",
        "VSS",
        "Responsibilities",
        "SSIS",
        "jobs",
        "data",
        "load",
        "processes",
        "vendors",
        "data",
        "target",
        "data",
        "bases",
        "DTS",
        "system",
        "upgrading",
        "SSIS",
        "SQL",
        "query",
        "performance",
        "procedures",
        "cursors",
        "SPs",
        "SSIS",
        "config",
        "Designing",
        "Database",
        "tables",
        "Indexes",
        "part",
        "legacy",
        "system",
        "retirement",
        "SQL",
        "data",
        "files",
        "Trizetto",
        "SFTP",
        "Coordination",
        "Benefits",
        "Member",
        "Enrollment",
        "Institutional",
        "Professional",
        "Claims",
        "Paper",
        "Pharmacy",
        "data",
        "ETL",
        "templates",
        "target",
        "database",
        "Work",
        "Unit",
        "testing",
        "data",
        "validation",
        "SSIS",
        "jobs",
        "DTS",
        "jobs",
        "data",
        "accuracy",
        "system",
        "Replication",
        "system",
        "part",
        "Data",
        "warehouse",
        "refresh",
        "process",
        "DBAs",
        "case",
        "job",
        "failure",
        "requests",
        "Pharmacy",
        "claims",
        "member",
        "benefits",
        "data",
        "database",
        "Skills",
        "Data",
        "Database",
        "Ms",
        "access",
        "Sql",
        "server",
        "Mysql",
        "Oracle",
        "Plsql",
        "Sql",
        "Datastage",
        "Etl",
        "Informatica",
        "Mdm",
        "Sharepoint",
        "Ssrs",
        "Team",
        "foundation",
        "server",
        "Siebel",
        "Tableau",
        "Crm",
        "Groovy",
        "Additional",
        "Information",
        "TECHNICAL",
        "SKILLS",
        "ETLBI",
        "Tools",
        "DELL",
        "Boomi",
        "Informatica",
        "Informatica",
        "PowerCenter",
        "9x8x",
        "IDQ",
        "Informatica",
        "MDM",
        "SSIS",
        "DataStage",
        "Cognos10",
        "Framework",
        "Manager",
        "Report",
        "Studio",
        "SSRS",
        "Business",
        "Tableau",
        "CRM",
        "Salesforce",
        "Siebel",
        "Scripting",
        "JavaScript",
        "System",
        "UNIX",
        "Data",
        "Modeling",
        "Tools",
        "Erwin",
        "ER",
        "Studio",
        "Database",
        "Oracle",
        "9i10g11",
        "g",
        "MSSQL",
        "Server",
        "DB2",
        "MYSQL",
        "MS",
        "Access",
        "SQL",
        "Server",
        "DTSSSISSSRS",
        "Tools",
        "PLSQL",
        "Developer",
        "TOAD",
        "SSMS",
        "MS",
        "Office",
        "Suite",
        "MS",
        "Visio",
        "TFSTeam",
        "Foundation",
        "Server",
        "SharePoint",
        "SVN",
        "sub",
        "HPALM",
        "Clear",
        "Quest"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T20:06:06.394150",
    "resume_data": "Principal Software Engineer IT Principal span lSoftwarespan Engineer IT Principal Software Engineer IT DELL More than 8 years of extensive experience in Data Migration and Integrating it with CRM applications such as Salesforce and Siebel platforms using Cloud and ETL technologies such as DELL Boomi Informatica MSBI Jaspersoft and DataStage Expertise in Business and Data Analysis and requirement understanding development and data modeling across IT Industries such as Product development Services Health Insurance and Marketing Industries Well experienced in end to end ETL Development deployments deployment object creation labelling versioning Production validation Data Validation and Data Migration Extensive experience in developing the DELL Boomi Process to Migrate the data across various source systems to cloud CRM systems Using various Connectors such as FTP Database Salesforce Disk and Mail with respective Connection Operators Experienced in working with various shapes such as Map Set Properties Program Command Process Call Data Process Cache Branch Route Decision Business Rules Flow Control and notify to enhance the data flow process as per business requirements Well experienced in error handling methodologies using TryCatch and exception shapes Also worked on dynamic document process properties to get the run time parameters to process the datasets in larger volumes Experience in Creating new EnvironmentsAtoms and Deploying the processes to various AtomEnvironments Scheduling the processes Working knowledge on different data sources such as OLEDB Excel XML Flat Files PDF DB2 SQL Server X12 Experience in writing Oracle SQL Server MYSQL PLSQL queries query performance tuning and database mirroring Expertise in creatingmodifying Tables Views Stored Procedures Functions and indepth knowledge in query optimization performance tuning Knowledge of OLAP MultiDimensional Data Modeling Designing star snowflake schemas Data Marts Data Mining Data quality Analysis Data Integration Slowly Changing Dimensions SCD and creating job flow diagrams Working experience in Informatica B2B data exchange and B2B transformation Studio Informatica IDQ MDM Informatica ILM Implementation Informatica version upgradation and Data archivals Experience in SQL Server 200820052000 OLAP database development including KPIs Data mining working with changing dimensions Experience in BI tools includes Cognos10 framework Manager and reports designer SSRS and Business Objects BOXIR2 Tableau Experience in ETL tools validation across MSBI IBM DataStage Jasper and Informatica Extensively worked on Waterfall AgileScrum methodologies Well experienced on all phases of Software Development Life Cycle SDLC of Data warehousing including functional requirements gathering from the business users requirement analysis specification writing design creation of mapping documents development testing and PostProduction Support Conductparticipate in IterationSprint planning Story point estimation and work on assigning the User stories for development and implementation Work Experience Principal Software Engineer IT DELL Round Rock TX July 2018 to Present Environment Salesforce Lightning DELL Boomi Integration Oracle SQL Developer Siebel CRM Salesforce Analytics Data Loader Salesforce Classic JavaScript Groovy Informatica 961 UNIX Putty Team Foundation ServerTFS Responsibilities Analyze and identify the Gaps in requirements coordinate with business users and convert the business requirements into technical specifications Track all the requirements using TFS and work with other interlock teams for continuous development Analyze the data migration requirements and design the data flow model with ER model DesignDevelop the DB system to store the data in accordance with business requirements Create necessary Tables stored procedures triggers and PLSQL Packages to extract and store the data for downstreamupstream systems with initial and incremental load Develop new processes to move the data from existing application to new CRM application using DELL Boomi cloud integration Write custom scripts using JavaScriptGroovy to fetch the process parameters inside the map for Data transformation Expertise in using environment extensions cross reference connections parameters to deploy the processes in to different molecules as required Implement the process as per DELL Boomi Coding standards using Maps Set Properties DecisionBusiness rules shapes Branch and Routing as required and tune the performance analyzing the flow control threads to balance the server load during real time executions Perform Unit testing to validate the development in accordance with functional requirements Build the process and deploy it to respective atomsenvironments for SIT UAT and Production environments in each phase Support data migration requests across other streams to provide continuity in interlock testing ondemand Prepare release instructions DBA procedures backout plan and post production validation steps during Production Implementation Work on Major Incident Management to resolve any issues based on severity Software Developer Indotronix International Corporation Poughkeepsie NY May 2018 to July 2018 Environment DELL Boomi Integration Informatica 951 102 UNIX Putty WINSCP SQL Developer Informatica B2B Data Transformation Studio TIDAL Scheduler ClearQuest Responsibilities Defines the scope and objectives and prepares technical functional requirements listing with impacted objects for reference Migrates the code from Informatica 95 to Informatica 102 validates the data in both the systems Creates Tidal jobs and deploys the code from DEV to QA and continues to provide support until post production Perform Gap analysis and reviews the implementation plan with the scrum team to ensure the transition is up to date as per the schedule Performs Code checkins in the SVN and reviews the test results maintains technical development environment Mentors others and may lead multiple or small to medium sized projects Facilitates group sessions to elicit complex information on requirements clarification design sessions code reviews and troubleshooting issues Technology Analyst Infosys Ltd Chennai Tamil Nadu November 2012 to August 2016 Environment DELL Boomi Integration Informatica 951 961 SSIS 2008 Cognos 10 TOAD DB2 UNIX Putty WINSCP SQL Developer Informatica B2B Data Transformation Studio TFS SharePoint Responsibilities Proactively interact and collaborate with stakeholdersArchitects to analyze business needs and create the Business Requirements Document and System requirement specifications for Data Migration and ETL Development Involved in implementation of HIPAA EDI Transactions in building EDIs 270 271 276 277 470 835 837 and 834 Performed GAP Analysis for HIPAA 4010 and 5010 transactions and Used EDI tools to verify mapping to X12 format Preparing technical specifications document ETL Mapping document and Metadata management for ETL load and extract processes Installation Configuration and Administration of Informatica Power Center on ClientServer Environment Worked on Informatica Power Center tools Designer Repository Manager Workflow Manager and Workflow Monitor Developed the ETLs to fetch the data from different source system and integrate Development of new ETLs for EDI gateway 5010 implementation to process HIPAA X12 files from various trading partners Transform X12 files through Data transformation studio and parse the data through Informatica transformations to process EDI data and load it into downstream systems Loading Data to the Interface tables from multiple data sources such as SQL server Text files and Excel Spreadsheets using SQL Loader Informatica and ODBC connections Createmodify the database tables stored procedures to accommodate new customer data as part of metadata management Developed ETL workflows to migrate existing trading partner set up in legacy mainframe system to B2B Data Exchange Repository Has worked on Informatica 91 to 95 upgrade handling multiple realtime and batch transactions code migration inclusive of environment and data testing throughout Designed and developed an approach to handle event creation with two layers of sequence numbers so that both the custom transformations and Informatica transformations can coexist in version 95 Creating necessary repositories to handle the metadata in the ETL process Designing the target warehouse using Star Schema Creating mappings to load data from various sources using different transformations like Source Qualifier Expression Lookup Aggregator Update Strategy Joiner Normalizer Filter and Router transformations Union transformations etc Simplified the data flow by using a Router transformation to check multiple conditions at the same time Creating sessions sequential and concurrent batches for proper execution of mappings using workflow manager Implemented ILM with a threetier architecture to store and manage transactional data This results in storing data segregated by retention period such as short medium and long term Providing technical guidance to the team and work on solution design Prepare Coding standards perform code reviews design review unit testing reviews for each environment Migrated data from Legacy DB2 environment to SQL Server 2005 with SQL Server Integrated Services SSIS Created ETL process using SSIS to transfer data from heterogeneous data sources Created logging for ETL load at package level and task level to log number of records processed by each package and each task in a package using SSIS Responsible for Deploying Scheduling Jobs Alerting and Maintaining SSIS packages Code Migrations to Main Development folders SIT and UAE repository Software Engineer Ascent Staffing Solutions Pvt Ltd Bengaluru Karnataka December 2010 to November 2012 Environment Informatica 8x MSBI Data Stage Net IIS SQL Server 200020052008 Oracle TOAD DB2 UNIX WINSCP TFS 2010 SharePoint Responsibilities Convert business requirements into technical specifications create design and mapping documents with data modelling and database design Creating Sprints assigning enhancements bugs and user stories to the sprints seasons and work on implementation along with the team Involved and Coordinated Sprint meeting sprint review and Sprint Retrospective meeting Conducted the FRS and URS reviews and walkthroughs with designers developers and stakeholders Also conducted feasibility and adaptability study Develop ETLs to fetch the data from various data sources such as DB2 Mainframes excel OLEDB and load into various target systems Created multiple complex mappings using aggregators expressions joiners ranking filters and Lookup transformations Involved in tuning the mappings sessions and source qualifier queries Worked with different caches such as Index cache Data cache Lookup cache Static Dynamic and Persistent and join cache while creating the Mappings Worked on migrating the legacy aviation data from SQL Server 2000 to 2008 through new ETLs with no impact on application Created a new mappingworkflow to validate the daily counts and weekly counts for incremental load and full load jobs to notify the business users for application data validations Worked on multiple adhoc requests to create SSIS ETL creating Config files multiple data flow tasks and data transformations such as Derived Column Conditional Split Merge Joins and SCDs Worked on Code migration from DEV TEST UAT and PROD preparing technical and process documentation for each change object deployment Worked on developing UNIX scripts to move the files from Production to archival locations as part of production server management Worked on creating new Database Tables Indexes Stored Procedures Triggers and Cursors Worked on IIS Internet Information Services deployments as part of application changes during sprint releases Handle Team Foundation Server TFS 2010 for code checkin branchinglabelling the application code and ETL jobs and test cases test results Software Engineer XLCareUnited Health Group Bengaluru Karnataka December 2009 to December 2010 Environment SQL Server 20002005 DTS 2000 SSIS 2005 Oracle SSRS FTP VSS Responsibilities Designed and implemented new SSIS jobs for all the data load processes from various vendors to load the data into target data bases while retiring from DTS system and upgrading to SSIS 2005 Worked on SQL query performance tuning Stored procedures converting cursors into SPs and creating SSIS config files Designing Database creating tables Indexes etc as part of legacy system retirement from SQL 2000 to 2005 Analyzing the data files from Trizetto SFTP for Coordination of Benefits Member Enrollment Institutional and Professional Claims Paper claims Pharmacy data etc to develop the ETL coding templates and to design target database Work on Unit testing data validation of new SSIS jobs wrt legacy DTS jobs to ensure data accuracy in the new system Execute and monitor Replication system as part of Data warehouse refresh process and notify the DBAs in case of job failure Work on adhoc requests to pull the Pharmacy claims and member benefits data extracting from reporting database Skills Data modeling Database Db2 Ms access Sql server Mysql Oracle Plsql Sql Datastage Etl Informatica Mdm Sharepoint Ssrs Team foundation server Siebel Tableau Crm Groovy Additional Information TECHNICAL SKILLS ETLBI Tools DELL Boomi Informatica 102 Informatica PowerCenter 9x8x IDQ Informatica MDM SSIS 20052008 and DataStage Cognos10 Framework Manager and Report Studio SSRS and Business Objects Tableau CRM Salesforce Siebel Scripting JavaScript Groovy 15 Groovy 24 Operating System Windows UNIX Data Modeling Tools Erwin 40 ER Studio Database Oracle 9i10g11g MSSQL Server 2000050812 DB2 MYSQL MS Access 702000 SQL Server DTSSSISSSRS Tools PLSQL Developer TOAD SSMS MS Office Suite MS Visio TFSTeam Foundation Server SharePoint SVN sub versioning HPALM Clear Quest",
    "unique_id": "fe97fbf8-7538-40d6-b230-d0cc186821d1"
}