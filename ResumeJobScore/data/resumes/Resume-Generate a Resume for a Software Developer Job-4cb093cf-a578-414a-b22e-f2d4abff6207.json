{
    "clean_data": "Job Seeker Over 4 years of experience in configuring installing and maintenance Apache Hadoop cluster Hortonworks distribution and having good knowledge and experience on Hadoop and BigData Technologies Expertise in setting up fully distributed multi node Hadoop clusters with Hortonworks Ambari Good knowledge in installing configuring and using ecosystem components like Oozie Hive Spark Sqoop Yarn Zookeeper Zeppelin and Namenode High Availability Extensive experience on performing administration configuration management monitoring debugging in Hadoop Clusters Expertise in adding hadoop components using Ambari Good knowledge in ImportExport structured unstructured data from various data sources such as RDBMS Event logs Message queues into HDFS using a variety of tools such as Sqoop Daily ticket analysis of open and critical operations issues Experience in managing Hadoop infrastructure like commissioning and decommissioning of nodes Excellent Interpersonal Skills Communication skills documentation skills problem solving ability Quality consious and multitasked environment Having hands on experience in installation configuration supporting and managing Hadoop Clusters using Hortonworks Distribution Having hand on experience on upgradation of Ambari from 24 to 25 Having hand on experience on upgradation of HDP from 25 to 26 Having hands on experience in analyzing Log files for Hadoop and eco system services and finding root cause Hadoop Cluster capacity planning cluster Monitoring Troubleshooting Strong knowledge in configuring Namenode High Availability Having experience on creating read only users to access ambari server WEB UI Having hands on experience in installing kerberos create principals and keytabs for services and users level manually Having experience on generating users and services kerberos tickets for access Hadoop Cluster Having experience on Commissioning Decommissioning and Managing Nodes and tuning server for performance of the cluster Having experience in HDFS data storage and support for running PIG YARN Spark Hive and Oozie jobs Good knowledge on administrating Pivotal HAWQ and Hadoop echo system components Having experience on data migration from Hawq to GPDB Generating keytabs for Gpadmin users Preparing the list of activities for Restrospective meetings Work Experience Wissen Infotech April 2016 to Present Environment Hadoop GE Aviation is a worldleading provider of commercial military and business GE Aviation is a worldleading provider of commercial military and business GE Aviation is becoming a digital industrial business with its ability to harness large streams of data that are providing incredible insights and in turn real operational value for customers Roles and Responsibilities Involved in raising and closing tickets in service now and adding the assignment group Creating templates regarding outages and sending Notification Email to the users and also to the particular DLs Creating User Stories in Rally Kanban Dash Board and updating the tasks and also the Iteration status Involved in creating the databases and adding the NSGs in Ranger Monitored multiple hadoop clusters environments using Ambari Monitored workload CPU utilization YARN memory and RM Involved in Table creation and Data Migrations from one environment to another Worked on Upgradations of Ambari and HDP Reclaimed the disk usage spaces Hands on experience in Installing and configuring Kerberos for the authentication of users and hadoop services Involved in restarting the zeppelin service Preparing Retrospective meeting documents and list out the major activities and In progress Involved in webex sessions with Hortonworks team Involved in Daily stand up call regarding updates Involved in Cluster configuration change in order to add new NSGschanging the parameters based on the recommendations Database Administrator Wissen Infotech August 2015 to April 2016 Duration Aug 2015 Apr 2016 Environment Hadoop GE Healthcare is a subsidiary of General Electric Co that focuses on new developments in health information technology HIT such as more advanced medical imaging technology and patient monitoring systems Roles and Responsibilities Involved in start to end process of hadoop cluster setup where in installation configuration and monitoring the Hadoop Cluster Responsible for Cluster maintenance commissioning and decommissioning Data nodes Cluster Monitoring Troubleshooting Manage and review data backups Manage review Hadoop log files Installation of various Hadoop Ecosystems and Hadoop Daemons Experience in create users databases and grant permissions as per requirement Managed and reviewed Hadoop Log files as a part of administration for troubleshooting purposes Communicate and escalate issues appropriately Experience in Analyzing system failures identifying root causes and recommended course of actions Documented the systems processes and procedures for future references Involved in Package Installations Bringing back the Disk Mount mismatch Created cronjobs for kerberos ticket generation for services accessing without interruption Worked on Implementation of Druid for creation of the table in Hive PROJECT 3 Project Name GEA Role Database Administrator Organization Wissen Infotech Client GE Aviation Education GE Aviation Wissen Infotech September 2014 to July 2015 Skills DATABASES 3 years MYSQL HADOOP 3 years Hadoop 3 years Hive Less than 1 year Additional Information SKILLSET Big Data Ecosystems Hadoop HDFS Hive Sqoop Oozie Spark and YARN Databases Hawq Greenplum Postgres and MySQL Datawarehouse Hive Operating Systems Windows XP07 Linux Tools Pivotal Hadoop Monitoring Tools PCC PROJECT 1",
    "entities": [
        "Hawq",
        "Hadoop Ecosystems",
        "Installing",
        "Hadoop Clusters",
        "NSGschanging",
        "Present Environment Hadoop GE Aviation",
        "GE Aviation",
        "Kerberos",
        "Apache Hadoop",
        "Disk Mount",
        "UI Having",
        "Hadoop Clusters Expertise",
        "Hadoop Log",
        "Namenode High Availability Extensive",
        "ImportExport",
        "Commissioning Decommissioning and Managing Nodes",
        "Ranger Monitored",
        "Communicate",
        "Ambari",
        "Oozie Hive Spark",
        "Sqoop Daily",
        "HDP Reclaimed",
        "Excellent Interpersonal Skills Communication",
        "Namenode High Availability Having",
        "BigData Technologies Expertise",
        "another Worked on Upgradations of Ambari",
        "the Hadoop Cluster Responsible for Cluster",
        "Hadoop",
        "Ambari Monitored",
        "Data",
        "Hadoop GE Healthcare",
        "ambari",
        "CPU",
        "Hadoop Cluster",
        "RM Involved",
        "General Electric Co",
        "Creating User Stories",
        "Roles",
        "HDP",
        "Rally Kanban Dash Board",
        "Data Migrations",
        "Hive PROJECT 3 Project",
        "GE Aviation Education",
        "Cluster Monitoring Troubleshooting Manage"
    ],
    "experience": "Experience in managing Hadoop infrastructure like commissioning and decommissioning of nodes Excellent Interpersonal Skills Communication skills documentation skills problem solving ability Quality consious and multitasked environment Having hands on experience in installation configuration supporting and managing Hadoop Clusters using Hortonworks Distribution Having hand on experience on upgradation of Ambari from 24 to 25 Having hand on experience on upgradation of HDP from 25 to 26 Having hands on experience in analyzing Log files for Hadoop and eco system services and finding root cause Hadoop Cluster capacity planning cluster Monitoring Troubleshooting Strong knowledge in configuring Namenode High Availability Having experience on creating read only users to access ambari server WEB UI Having hands on experience in installing kerberos create principals and keytabs for services and users level manually Having experience on generating users and services kerberos tickets for access Hadoop Cluster Having experience on Commissioning Decommissioning and Managing Nodes and tuning server for performance of the cluster Having experience in HDFS data storage and support for running PIG YARN Spark Hive and Oozie jobs Good knowledge on administrating Pivotal HAWQ and Hadoop echo system components Having experience on data migration from Hawq to GPDB Generating keytabs for Gpadmin users Preparing the list of activities for Restrospective meetings Work Experience Wissen Infotech April 2016 to Present Environment Hadoop GE Aviation is a worldleading provider of commercial military and business GE Aviation is a worldleading provider of commercial military and business GE Aviation is becoming a digital industrial business with its ability to harness large streams of data that are providing incredible insights and in turn real operational value for customers Roles and Responsibilities Involved in raising and closing tickets in service now and adding the assignment group Creating templates regarding outages and sending Notification Email to the users and also to the particular DLs Creating User Stories in Rally Kanban Dash Board and updating the tasks and also the Iteration status Involved in creating the databases and adding the NSGs in Ranger Monitored multiple hadoop clusters environments using Ambari Monitored workload CPU utilization YARN memory and RM Involved in Table creation and Data Migrations from one environment to another Worked on Upgradations of Ambari and HDP Reclaimed the disk usage spaces Hands on experience in Installing and configuring Kerberos for the authentication of users and hadoop services Involved in restarting the zeppelin service Preparing Retrospective meeting documents and list out the major activities and In progress Involved in webex sessions with Hortonworks team Involved in Daily stand up call regarding updates Involved in Cluster configuration change in order to add new NSGschanging the parameters based on the recommendations Database Administrator Wissen Infotech August 2015 to April 2016 Duration Aug 2015 Apr 2016 Environment Hadoop GE Healthcare is a subsidiary of General Electric Co that focuses on new developments in health information technology HIT such as more advanced medical imaging technology and patient monitoring systems Roles and Responsibilities Involved in start to end process of hadoop cluster setup where in installation configuration and monitoring the Hadoop Cluster Responsible for Cluster maintenance commissioning and decommissioning Data nodes Cluster Monitoring Troubleshooting Manage and review data backups Manage review Hadoop log files Installation of various Hadoop Ecosystems and Hadoop Daemons Experience in create users databases and grant permissions as per requirement Managed and reviewed Hadoop Log files as a part of administration for troubleshooting purposes Communicate and escalate issues appropriately Experience in Analyzing system failures identifying root causes and recommended course of actions Documented the systems processes and procedures for future references Involved in Package Installations Bringing back the Disk Mount mismatch Created cronjobs for kerberos ticket generation for services accessing without interruption Worked on Implementation of Druid for creation of the table in Hive PROJECT 3 Project Name GEA Role Database Administrator Organization Wissen Infotech Client GE Aviation Education GE Aviation Wissen Infotech September 2014 to July 2015 Skills DATABASES 3 years MYSQL HADOOP 3 years Hadoop 3 years Hive Less than 1 year Additional Information SKILLSET Big Data Ecosystems Hadoop HDFS Hive Sqoop Oozie Spark and YARN Databases Hawq Greenplum Postgres and MySQL Datawarehouse Hive Operating Systems Windows XP07 Linux Tools Pivotal Hadoop Monitoring Tools PCC PROJECT 1",
    "extracted_keywords": [
        "Job",
        "Seeker",
        "years",
        "experience",
        "maintenance",
        "Apache",
        "Hadoop",
        "cluster",
        "Hortonworks",
        "distribution",
        "knowledge",
        "experience",
        "Hadoop",
        "BigData",
        "Technologies",
        "Expertise",
        "multi",
        "node",
        "Hadoop",
        "clusters",
        "Hortonworks",
        "Ambari",
        "knowledge",
        "configuring",
        "ecosystem",
        "components",
        "Oozie",
        "Hive",
        "Spark",
        "Sqoop",
        "Yarn",
        "Zookeeper",
        "Zeppelin",
        "Namenode",
        "High",
        "Availability",
        "experience",
        "administration",
        "configuration",
        "management",
        "monitoring",
        "debugging",
        "Hadoop",
        "Clusters",
        "Expertise",
        "hadoop",
        "components",
        "knowledge",
        "ImportExport",
        "data",
        "data",
        "sources",
        "RDBMS",
        "Event",
        "Message",
        "queues",
        "HDFS",
        "variety",
        "tools",
        "Sqoop",
        "Daily",
        "ticket",
        "analysis",
        "operations",
        "issues",
        "Experience",
        "Hadoop",
        "infrastructure",
        "commissioning",
        "decommissioning",
        "nodes",
        "Excellent",
        "Interpersonal",
        "Skills",
        "Communication",
        "documentation",
        "skills",
        "problem",
        "ability",
        "Quality",
        "environment",
        "hands",
        "experience",
        "installation",
        "configuration",
        "Hadoop",
        "Clusters",
        "Hortonworks",
        "Distribution",
        "hand",
        "experience",
        "upgradation",
        "Ambari",
        "hand",
        "experience",
        "upgradation",
        "HDP",
        "hands",
        "experience",
        "Log",
        "files",
        "Hadoop",
        "eco",
        "system",
        "services",
        "root",
        "Hadoop",
        "Cluster",
        "capacity",
        "cluster",
        "Monitoring",
        "Troubleshooting",
        "knowledge",
        "Namenode",
        "High",
        "Availability",
        "experience",
        "read",
        "users",
        "server",
        "WEB",
        "UI",
        "hands",
        "experience",
        "kerberos",
        "principals",
        "keytabs",
        "services",
        "users",
        "experience",
        "users",
        "services",
        "tickets",
        "access",
        "Hadoop",
        "Cluster",
        "experience",
        "Decommissioning",
        "Managing",
        "Nodes",
        "server",
        "performance",
        "cluster",
        "experience",
        "HDFS",
        "data",
        "storage",
        "support",
        "PIG",
        "YARN",
        "Spark",
        "Hive",
        "Oozie",
        "jobs",
        "knowledge",
        "HAWQ",
        "Hadoop",
        "echo",
        "system",
        "components",
        "experience",
        "data",
        "migration",
        "Hawq",
        "GPDB",
        "Generating",
        "keytabs",
        "Gpadmin",
        "users",
        "list",
        "activities",
        "meetings",
        "Work",
        "Experience",
        "Wissen",
        "Infotech",
        "April",
        "Present",
        "Environment",
        "Hadoop",
        "GE",
        "Aviation",
        "provider",
        "military",
        "business",
        "GE",
        "Aviation",
        "provider",
        "military",
        "business",
        "GE",
        "Aviation",
        "business",
        "ability",
        "streams",
        "data",
        "insights",
        "turn",
        "value",
        "customers",
        "Roles",
        "Responsibilities",
        "closing",
        "tickets",
        "service",
        "assignment",
        "group",
        "templates",
        "outages",
        "Notification",
        "Email",
        "users",
        "User",
        "Stories",
        "Rally",
        "Kanban",
        "Dash",
        "Board",
        "tasks",
        "Iteration",
        "status",
        "databases",
        "NSGs",
        "Ranger",
        "Monitored",
        "hadoop",
        "clusters",
        "environments",
        "workload",
        "CPU",
        "utilization",
        "YARN",
        "memory",
        "RM",
        "Table",
        "creation",
        "Data",
        "Migrations",
        "environment",
        "Worked",
        "Upgradations",
        "Ambari",
        "HDP",
        "Reclaimed",
        "disk",
        "usage",
        "Hands",
        "experience",
        "Kerberos",
        "authentication",
        "users",
        "hadoop",
        "services",
        "zeppelin",
        "service",
        "Retrospective",
        "meeting",
        "documents",
        "activities",
        "progress",
        "sessions",
        "Hortonworks",
        "team",
        "Daily",
        "call",
        "updates",
        "Cluster",
        "configuration",
        "change",
        "order",
        "parameters",
        "recommendations",
        "Database",
        "Administrator",
        "Wissen",
        "Infotech",
        "August",
        "April",
        "Duration",
        "Aug",
        "Apr",
        "Environment",
        "Hadoop",
        "GE",
        "Healthcare",
        "subsidiary",
        "General",
        "Electric",
        "Co",
        "developments",
        "health",
        "information",
        "technology",
        "HIT",
        "imaging",
        "technology",
        "monitoring",
        "systems",
        "Roles",
        "Responsibilities",
        "start",
        "process",
        "hadoop",
        "cluster",
        "setup",
        "installation",
        "configuration",
        "Hadoop",
        "Cluster",
        "Responsible",
        "Cluster",
        "maintenance",
        "Data",
        "nodes",
        "Cluster",
        "Monitoring",
        "Troubleshooting",
        "Manage",
        "data",
        "backups",
        "Manage",
        "review",
        "Hadoop",
        "log",
        "Installation",
        "Hadoop",
        "Ecosystems",
        "Hadoop",
        "Daemons",
        "Experience",
        "users",
        "databases",
        "permissions",
        "requirement",
        "Managed",
        "Hadoop",
        "Log",
        "files",
        "part",
        "administration",
        "troubleshooting",
        "purposes",
        "issues",
        "Experience",
        "system",
        "failures",
        "root",
        "causes",
        "course",
        "actions",
        "systems",
        "processes",
        "procedures",
        "references",
        "Package",
        "Installations",
        "Disk",
        "Mount",
        "cronjobs",
        "ticket",
        "generation",
        "services",
        "interruption",
        "Implementation",
        "Druid",
        "creation",
        "table",
        "Hive",
        "PROJECT",
        "Project",
        "Name",
        "GEA",
        "Role",
        "Database",
        "Administrator",
        "Organization",
        "Wissen",
        "Infotech",
        "Client",
        "GE",
        "Aviation",
        "Education",
        "GE",
        "Aviation",
        "Wissen",
        "Infotech",
        "September",
        "July",
        "Skills",
        "DATABASES",
        "years",
        "MYSQL",
        "HADOOP",
        "years",
        "Hadoop",
        "years",
        "Hive",
        "year",
        "Additional",
        "Information",
        "SKILLSET",
        "Big",
        "Data",
        "Ecosystems",
        "Hadoop",
        "HDFS",
        "Hive",
        "Sqoop",
        "Oozie",
        "Spark",
        "YARN",
        "Databases",
        "Hawq",
        "Greenplum",
        "Postgres",
        "MySQL",
        "Datawarehouse",
        "Hive",
        "Operating",
        "Systems",
        "Windows",
        "XP07",
        "Linux",
        "Tools",
        "Pivotal",
        "Hadoop",
        "Monitoring",
        "Tools",
        "PCC",
        "PROJECT"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T21:45:08.652903",
    "resume_data": "Job Seeker Over 4 years of experience in configuring installing and maintenance Apache Hadoop cluster Hortonworks distribution and having good knowledge and experience on Hadoop and BigData Technologies Expertise in setting up fully distributed multi node Hadoop clusters with Hortonworks Ambari Good knowledge in installing configuring and using ecosystem components like Oozie Hive Spark Sqoop Yarn Zookeeper Zeppelin and Namenode High Availability Extensive experience on performing administration configuration management monitoring debugging in Hadoop Clusters Expertise in adding hadoop components using Ambari Good knowledge in ImportExport structured unstructured data from various data sources such as RDBMS Event logs Message queues into HDFS using a variety of tools such as Sqoop Daily ticket analysis of open and critical operations issues Experience in managing Hadoop infrastructure like commissioning and decommissioning of nodes Excellent Interpersonal Skills Communication skills documentation skills problem solving ability Quality consious and multitasked environment Having hands on experience in installation configuration supporting and managing Hadoop Clusters using Hortonworks Distribution Having hand on experience on upgradation of Ambari from 24 to 25 Having hand on experience on upgradation of HDP from 25 to 26 Having hands on experience in analyzing Log files for Hadoop and eco system services and finding root cause Hadoop Cluster capacity planning cluster Monitoring Troubleshooting Strong knowledge in configuring Namenode High Availability Having experience on creating read only users to access ambari server WEB UI Having hands on experience in installing kerberos create principals and keytabs for services and users level manually Having experience on generating users and services kerberos tickets for access Hadoop Cluster Having experience on Commissioning Decommissioning and Managing Nodes and tuning server for performance of the cluster Having experience in HDFS data storage and support for running PIG YARN Spark Hive and Oozie jobs Good knowledge on administrating Pivotal HAWQ and Hadoop echo system components Having experience on data migration from Hawq to GPDB Generating keytabs for Gpadmin users Preparing the list of activities for Restrospective meetings Work Experience Wissen Infotech April 2016 to Present Environment Hadoop GE Aviation is a worldleading provider of commercial military and business GE Aviation is a worldleading provider of commercial military and business GE Aviation is becoming a digital industrial business with its ability to harness large streams of data that are providing incredible insights and in turn real operational value for customers Roles and Responsibilities Involved in raising and closing tickets in service now and adding the assignment group Creating templates regarding outages and sending Notification Email to the users and also to the particular DLs Creating User Stories in Rally Kanban Dash Board and updating the tasks and also the Iteration status Involved in creating the databases and adding the NSGs in Ranger Monitored multiple hadoop clusters environments using Ambari Monitored workload CPU utilization YARN memory and RM Involved in Table creation and Data Migrations from one environment to another Worked on Upgradations of Ambari and HDP Reclaimed the disk usage spaces Hands on experience in Installing and configuring Kerberos for the authentication of users and hadoop services Involved in restarting the zeppelin service Preparing Retrospective meeting documents and list out the major activities and In progress Involved in webex sessions with Hortonworks team Involved in Daily stand up call regarding updates Involved in Cluster configuration change in order to add new NSGschanging the parameters based on the recommendations Database Administrator Wissen Infotech August 2015 to April 2016 Duration Aug 2015 Apr 2016 Environment Hadoop GE Healthcare is a subsidiary of General Electric Co that focuses on new developments in health information technology HIT such as more advanced medical imaging technology and patient monitoring systems Roles and Responsibilities Involved in start to end process of hadoop cluster setup where in installation configuration and monitoring the Hadoop Cluster Responsible for Cluster maintenance commissioning and decommissioning Data nodes Cluster Monitoring Troubleshooting Manage and review data backups Manage review Hadoop log files Installation of various Hadoop Ecosystems and Hadoop Daemons Experience in create users databases and grant permissions as per requirement Managed and reviewed Hadoop Log files as a part of administration for troubleshooting purposes Communicate and escalate issues appropriately Experience in Analyzing system failures identifying root causes and recommended course of actions Documented the systems processes and procedures for future references Involved in Package Installations Bringing back the Disk Mount mismatch Created cronjobs for kerberos ticket generation for services accessing without interruption Worked on Implementation of Druid for creation of the table in Hive PROJECT 3 Project Name GEA Role Database Administrator Organization Wissen Infotech Client GE Aviation Education GE Aviation Wissen Infotech September 2014 to July 2015 Skills DATABASES 3 years MYSQL HADOOP 3 years Hadoop 3 years Hive Less than 1 year Additional Information SKILLSET Big Data Ecosystems Hadoop HDFS Hive Sqoop Oozie Spark and YARN Databases Hawq Greenplum Postgres and MySQL Datawarehouse Hive Operating Systems Windows XP07 Linux Tools Pivotal Hadoop Monitoring Tools PCC PROJECT 1",
    "unique_id": "4cb093cf-a578-414a-b22e-f2d4abff6207"
}