{
    "clean_data": "Data Scientist Data Scientist Data Scientist PPD Raleigh NC Around 6 years of experience in Data Science Data Analyst Python Developer and Project Management Involved in the entire data science project life cycle and actively involved in all the phases including data extraction data cleaning statistical modeling and data visualization with large data sets of structured and unstructured data created ER diagrams and schemas Proficient in process research which requires analytic models data inputs and output analytic metrics and user interface needs Developed predictive models using Decision Tree Random Forest Naive Bayes Logistic Regression Cluster Analysis and Artificial Neural Networks Experienced with machine learning algorithms such as Logistic Regression Random Forest KNN Support Vector Machines Neural Networks LinearNonLinear Regression and Kmeans Expertise in employing techniques for Supervised and Unsupervised learningClustering Classification PCA Decision trees KNN SVM Predictive Analytics Excellent understanding of Agile and Scrum development methodology Experienced in Python to manipulate data for data loading and extraction and worked with python libraries like Matplotlib Numpy and Pandas for data analysis Hands on experience of Data Science libraries in Python such as Pandas NumPy Scikitlearn Matplotlib Seaborn Keras Equipped with experience in utilizing statistical techniques which include Correlation Hypothesis modeling Inferential Statistics as well as data mining and modeling techniques using Linear and Logistic Regression Clustering Decision Trees and Kmean clustering Mitigated risk factors through careful analysis of financial and statistical data Transformed and processed raw data for further analysis visualization and modeling Experience in Big Data technologies like Spark 16 Spark SQL pySpark Hadoop 2X Hive 1X Experience in visualization tools like Tableau 9X 10X for creating dashboards Automated recurring reports using SQL and Python and visualized them on BI platform like Tableau Worked on Artificial Neural Networks and Deep Learning models using Theano and Keras packages using Python Worked with No SQL Database including Cassandra and Mongo DB Experienced in writing SQL queries working knowledge of RDBMS like SQL Server 2008 No SQL databases like Mongo DB 32 Experience working on Microsoft SQL Server Oracle HadoopHive Analytical performancefocused and detailoriented professional offering indepth knowledge of data analysis and statistics Utilized complex SQL queries for data manipulation Excellent Team player and selfstarter possess good communication skills Experience in various phases of Software Development life cycle Analysis Requirements gathering Designing with expertise in writingdocumenting Technical Design Document TDD Functional Specification Document FSD Test Plans GAP Analysis and Source to Target mapping documents Used the version control tools like Git 2X and build tools like Apache MavenAnt C C Java Python SQL programming skills with experience in working with functions packages and triggers Skilled in Advanced Regression Modeling Correlation Multivariate Analysis Model Building and application of Statistical Concepts Work Experience Data Scientist PPD Raleigh NC February 2018 to Present Responsibilities Responsible for predictive analysis of CRO trial data to predict patient yield and recruitment timeline for clinical trials across APAC EMEA regions Data was extracted extensively by using SQL queries and used python packages for the data mining tasks Performed Exploratory Data Analysis Data Wrangling and development of algorithms in Python for data mining and analysis Extensively used Pythons multiple data science packages like Pandas NumPy Matplotlib Scipy Scikitlearn Keras and Theano Ensure complete understanding for the broader team on the datasets and how they tie to clinical trial execution and thereby modeling analytics Identify and resolve contradictions in datasets develop effective validations and heuristicsEnsure data structure is appropriate for future complex analytics initiatives and not limited to a nearterm object Discuss alternative modeling approaches considerations limitations feature definition and develop strategy to ensure objectives are met in nearterm while also supporting longerterm increased sophistication and performance metrics Investigational sites chosen for clinical trials rarely meet enrollment goals leading to delays and high costs in conducting clinical trials We need to identify sites that have the potential to complete the clinical trial on time and under budget Site performance model outputs and resulting topline Trial performance summary based on site selection scenario Created and designed reports that will use gathered metrics to infer and draw logical conclusions from past and future behavior Stepbystep instructions for use of new features to facilitate verification of the new content Used Pythonbased data manipulation and visualization tools such as Pandas Matplotlib and Seaborn to clean corrupted data before generating business requested reports Developed extension models relying on but not limited to the Random forest logistic linear regression Support Vector Regression and boosting techniques like Gradient Boosting and XGBoost for Site Selection Used Python programming language to graphically analyze the data and perform data mining Performed extensive data mining to find out relevant features in an anonymized dataset using Python Explored supervised Machine Learning algorithms Decision Tree Regression Random Forest Regression SVM and used parameters such as Root Mean Squared Error and Mean Absolute Error to select the winning model Environment Python 3 SQL Pandas Seaborn Decision Tree Random Forest Support Vector Machines Gradient Boosting Tableau Data Scientist 7Eleven Irving TX April 2017 to January 2018 Responsibilities Implemented endtoend systems for Data Analytics Data Automation and customized visualization tools using Python Hadoop and MongoDB Used Pandas NumPy Seaborn Matplotlib scikitlearn in Python for developing various machine learning algorithms Worked on csv Json excel different types of files for the Data cleaning and Data analysis Used Python for statistical operations on the data and Matplotlib for the visualizing the data Ensured that the model has a low False Positive Rate Managed large datasets using Pandas data frames and MySQL Built various graphs for business decisionmaking using Python Matplotlib library Identified root causes of problems and facilitated the implementation of costeffective solutions with all levels of management Performed Data Cleaning handled missing data outliers feature scaling features engineering Application of various ML algorithms and statistical modeling like decision trees regression models random forest SVM clustering to identify Volume using different packages in python Performed data visualization with Tableau and generated dashboards to present the findings Created and designed reports that will use gathered metrics to infer and draw logical conclusions from past and future behavior Worked independently and collaboratively throughout the project lifecycle including data extractionpreparation design and implementation of scalable machine learning analysis and solutions and documentation of results Performed Classification using supervised algorithms like Logistic Regression Decision trees KNN Naive Bayes Performed data profiling to merge the data from multiple data sources Knowledge of other relational database platforms such as Oracle NoSQL Environment Python 3 MySQL Matplotlib Seaborn Linear Regression Logistic Regression Random Forest Support Vector Machines KNN Tableau Python Developer Zen3 Info Solutions Hyderabad Telangana August 2014 to December 2016 Involved in building database model APIs and views utilizing Python in order to build an interactive webbased solution Used data types like dictionaries tuples and object concepts based inheritance features for making complex algorithms of networks Designed and managed API system deployment using fast http server and Amazon AWS architecture Worked on Python Open stack APIs Carried out various mathematical operations for calculation purpose using python libraries Managed large datasets using Panda data frames and MySQL Worked with JSON based REST Web services Performed testing using Djangos Test Module Involved in Agile Methodologies and SCRUM Process Creating unit testregression test framework for workingnew code Using Subversion version control tool to coordinate teamdevelopment Developed SQL Queries Stored Procedures and Triggers Using Oracle SQL PLSQL Responsible for debugging and troubleshooting the web application Supported user groups by handling targetrelated software issuesservice requests identifyingfixing bugs Configured the Django admin site dashboard and created a custom Django dashboard for end users with custom look and feel Used Django APIs for database access Used Python for XML JSON processing data exchange and business logic implementation Used Python scripts to update the content in database and manipulate files Worked through the entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Environment Python Django JSP Oracle Java MySQL Linux HTML CSS Data Analyst HTC Global Services India Private Ltd September 2013 to July 2014 Responsibilities Communicated with business users data architects and developers to identify needs define project scope and detailed functional and nonfunctional requirements Gathered and documented requirements throughout the Software Development Life Cycle SDLC Prepared Data Mapping documents Use Cases Requirements Traceability Matrix and worked with the User experience team Wireframe preparing team Created requirement documentation reviews with user representatives recommended priorities gave presentations and walkthroughs and obtained user signoff Driven daily stand up meetings offshore iteration planning meetings and requirement gathering meetings Extracting data from different public data repositories and from different databases and creating datasets for statistical analysis Identified Multiple Dimensions and Fact tables Used advance data modeling concepts of degenerated dimension subdimension Factless fact table Aggregate fact tables in the Multidimensional model Extensively used Tab Admin and Tab Cmd commands in creating backups and restoring backups of Tableau repository Administered user user groups and scheduled instances for reports in Tableau Handson development in creating and modifying worksheets and data visualization dashboards Designed developed various analytical reports from multiple data sources by blending data on a single worksheet in Tableau Desktop Environment Windows 7 8 MS SQL Data Base MS Excel MS Word MS PowerPoint MS Outlook SharePoint MS Visio MS Project Oracle 11g Tableau Server and Tableau Desktop v8v9 MS Excel SQL ERWIN SSIS SSRS Java Developer Hyderabad Telangana May 2013 to August 2013 Responsibilities Developed web application using Struts JSP Servlets Java beans that uses MVC design pattern Created userfriendly GUI interface and Web pages using HTML CSS and JSP Used Eclipse as IDE tool for creating Servlets JSP and XML Implemented the Struts framework based on MVC design pattern Wrote SQL for JDBC prepared statements to retrieve the data from database Worked with Database Administrators to solve the problems generated while creating tables for application Developed and implemented customized maintenance plans to meet the needs and keep up to date with the glitches and fixes for performances issues Developed various UML diagrams like use cases class diagrams interaction diagrams sequence and collaboration and activity diagrams Involved in build and deploying the application using ANT Environment Java SQL XML HTML CSS JSP JDBC Eclipse IDE Education Bachelors in Computer Science in TOOLS AND TECHNOLOGIES JNTU",
    "entities": [
        "Use Cases Requirements Traceability Matrix",
        "Aggregate",
        "GUI",
        "Identify",
        "BI",
        "APAC",
        "Data Science",
        "Apache MavenAnt C C",
        "Artificial Neural Networks Experienced",
        "KNN Naive",
        "Oracle SQL PLSQL Responsible",
        "Statistical Concepts Work Experience Data Scientist PPD",
        "Panda",
        "ER",
        "Data Science Data Analyst Python Developer and Project Management Involved",
        "Design Development and Deployment Testing and Implementation",
        "Mitigated",
        "Telangana",
        "Python Hadoop",
        "MySQL Worked",
        "Data Scientist Data Scientist Data Scientist PPD Raleigh NC",
        "Technical Design Document TDD Functional Specification Document FSD Test",
        "Target",
        "Driven daily",
        "Decision Tree Random Forest Naive Bayes Logistic Regression Cluster Analysis",
        "SQL Server",
        "Performed Data Cleaning",
        "Performed Classification",
        "Present Responsibilities Responsible",
        "NC",
        "Django",
        "Utilized",
        "XML Implemented",
        "UML",
        "Tableau Worked",
        "Irving",
        "Oracle HadoopHive Analytical",
        "Tableau Server",
        "Multidimensional",
        "Oracle NoSQL Environment",
        "Global Services India Private Ltd",
        "JSP",
        "Tableau Desktop",
        "the Software Development Life Cycle SDLC Prepared Data Mapping",
        "IDE Education Bachelors",
        "Seaborn",
        "CRO",
        "Performed Exploratory Data Analysis Data Wrangling",
        "MVC",
        "Spark",
        "Djangos Test Module Involved",
        "Database Administrators",
        "Developed SQL Queries Stored Procedures",
        "Correlation Hypothesis",
        "HTML CSS",
        "API",
        "Linear",
        "Logistic Regression Random Forest KNN Support",
        "Random",
        "Tableau Desktop Environment Windows",
        "Created",
        "Vector Machines Neural Networks LinearNonLinear Regression",
        "Application of various",
        "schemas Proficient",
        "SQL",
        "Struts JSP Servlets Java",
        "Inferential Statistics",
        "Software Development",
        "PowerPoint MS",
        "Advanced Regression Modeling Correlation Multivariate Analysis Model Building",
        "Big Data",
        "Amazon AWS",
        "Identified Multiple Dimensions",
        "Pandas",
        "Pandas NumPy Scikitlearn",
        "Performed",
        "Tableau Handson",
        "ANT",
        "Logistic Regression Decision",
        "Microsoft",
        "Data Analytics Data Automation",
        "Deep Learning",
        "ML",
        "Data",
        "REST",
        "Gathered",
        "GAP Analysis",
        "Outlook SharePoint",
        "Support Vector Regression",
        "Tableau",
        "Machine Learning",
        "SQL ERWIN",
        "Artificial Neural Networks",
        "SVM"
    ],
    "experience": "Experience in Big Data technologies like Spark 16 Spark SQL pySpark Hadoop 2X Hive 1X Experience in visualization tools like Tableau 9X 10X for creating dashboards Automated recurring reports using SQL and Python and visualized them on BI platform like Tableau Worked on Artificial Neural Networks and Deep Learning models using Theano and Keras packages using Python Worked with No SQL Database including Cassandra and Mongo DB Experienced in writing SQL queries working knowledge of RDBMS like SQL Server 2008 No SQL databases like Mongo DB 32 Experience working on Microsoft SQL Server Oracle HadoopHive Analytical performancefocused and detailoriented professional offering indepth knowledge of data analysis and statistics Utilized complex SQL queries for data manipulation Excellent Team player and selfstarter possess good communication skills Experience in various phases of Software Development life cycle Analysis Requirements gathering Designing with expertise in writingdocumenting Technical Design Document TDD Functional Specification Document FSD Test Plans GAP Analysis and Source to Target mapping documents Used the version control tools like Git 2X and build tools like Apache MavenAnt C C Java Python SQL programming skills with experience in working with functions packages and triggers Skilled in Advanced Regression Modeling Correlation Multivariate Analysis Model Building and application of Statistical Concepts Work Experience Data Scientist PPD Raleigh NC February 2018 to Present Responsibilities Responsible for predictive analysis of CRO trial data to predict patient yield and recruitment timeline for clinical trials across APAC EMEA regions Data was extracted extensively by using SQL queries and used python packages for the data mining tasks Performed Exploratory Data Analysis Data Wrangling and development of algorithms in Python for data mining and analysis Extensively used Pythons multiple data science packages like Pandas NumPy Matplotlib Scipy Scikitlearn Keras and Theano Ensure complete understanding for the broader team on the datasets and how they tie to clinical trial execution and thereby modeling analytics Identify and resolve contradictions in datasets develop effective validations and heuristicsEnsure data structure is appropriate for future complex analytics initiatives and not limited to a nearterm object Discuss alternative modeling approaches considerations limitations feature definition and develop strategy to ensure objectives are met in nearterm while also supporting longerterm increased sophistication and performance metrics Investigational sites chosen for clinical trials rarely meet enrollment goals leading to delays and high costs in conducting clinical trials We need to identify sites that have the potential to complete the clinical trial on time and under budget Site performance model outputs and resulting topline Trial performance summary based on site selection scenario Created and designed reports that will use gathered metrics to infer and draw logical conclusions from past and future behavior Stepbystep instructions for use of new features to facilitate verification of the new content Used Pythonbased data manipulation and visualization tools such as Pandas Matplotlib and Seaborn to clean corrupted data before generating business requested reports Developed extension models relying on but not limited to the Random forest logistic linear regression Support Vector Regression and boosting techniques like Gradient Boosting and XGBoost for Site Selection Used Python programming language to graphically analyze the data and perform data mining Performed extensive data mining to find out relevant features in an anonymized dataset using Python Explored supervised Machine Learning algorithms Decision Tree Regression Random Forest Regression SVM and used parameters such as Root Mean Squared Error and Mean Absolute Error to select the winning model Environment Python 3 SQL Pandas Seaborn Decision Tree Random Forest Support Vector Machines Gradient Boosting Tableau Data Scientist 7Eleven Irving TX April 2017 to January 2018 Responsibilities Implemented endtoend systems for Data Analytics Data Automation and customized visualization tools using Python Hadoop and MongoDB Used Pandas NumPy Seaborn Matplotlib scikitlearn in Python for developing various machine learning algorithms Worked on csv Json excel different types of files for the Data cleaning and Data analysis Used Python for statistical operations on the data and Matplotlib for the visualizing the data Ensured that the model has a low False Positive Rate Managed large datasets using Pandas data frames and MySQL Built various graphs for business decisionmaking using Python Matplotlib library Identified root causes of problems and facilitated the implementation of costeffective solutions with all levels of management Performed Data Cleaning handled missing data outliers feature scaling features engineering Application of various ML algorithms and statistical modeling like decision trees regression models random forest SVM clustering to identify Volume using different packages in python Performed data visualization with Tableau and generated dashboards to present the findings Created and designed reports that will use gathered metrics to infer and draw logical conclusions from past and future behavior Worked independently and collaboratively throughout the project lifecycle including data extractionpreparation design and implementation of scalable machine learning analysis and solutions and documentation of results Performed Classification using supervised algorithms like Logistic Regression Decision trees KNN Naive Bayes Performed data profiling to merge the data from multiple data sources Knowledge of other relational database platforms such as Oracle NoSQL Environment Python 3 MySQL Matplotlib Seaborn Linear Regression Logistic Regression Random Forest Support Vector Machines KNN Tableau Python Developer Zen3 Info Solutions Hyderabad Telangana August 2014 to December 2016 Involved in building database model APIs and views utilizing Python in order to build an interactive webbased solution Used data types like dictionaries tuples and object concepts based inheritance features for making complex algorithms of networks Designed and managed API system deployment using fast http server and Amazon AWS architecture Worked on Python Open stack APIs Carried out various mathematical operations for calculation purpose using python libraries Managed large datasets using Panda data frames and MySQL Worked with JSON based REST Web services Performed testing using Djangos Test Module Involved in Agile Methodologies and SCRUM Process Creating unit testregression test framework for workingnew code Using Subversion version control tool to coordinate teamdevelopment Developed SQL Queries Stored Procedures and Triggers Using Oracle SQL PLSQL Responsible for debugging and troubleshooting the web application Supported user groups by handling targetrelated software issuesservice requests identifyingfixing bugs Configured the Django admin site dashboard and created a custom Django dashboard for end users with custom look and feel Used Django APIs for database access Used Python for XML JSON processing data exchange and business logic implementation Used Python scripts to update the content in database and manipulate files Worked through the entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Environment Python Django JSP Oracle Java MySQL Linux HTML CSS Data Analyst HTC Global Services India Private Ltd September 2013 to July 2014 Responsibilities Communicated with business users data architects and developers to identify needs define project scope and detailed functional and nonfunctional requirements Gathered and documented requirements throughout the Software Development Life Cycle SDLC Prepared Data Mapping documents Use Cases Requirements Traceability Matrix and worked with the User experience team Wireframe preparing team Created requirement documentation reviews with user representatives recommended priorities gave presentations and walkthroughs and obtained user signoff Driven daily stand up meetings offshore iteration planning meetings and requirement gathering meetings Extracting data from different public data repositories and from different databases and creating datasets for statistical analysis Identified Multiple Dimensions and Fact tables Used advance data modeling concepts of degenerated dimension subdimension Factless fact table Aggregate fact tables in the Multidimensional model Extensively used Tab Admin and Tab Cmd commands in creating backups and restoring backups of Tableau repository Administered user user groups and scheduled instances for reports in Tableau Handson development in creating and modifying worksheets and data visualization dashboards Designed developed various analytical reports from multiple data sources by blending data on a single worksheet in Tableau Desktop Environment Windows 7 8 MS SQL Data Base MS Excel MS Word MS PowerPoint MS Outlook SharePoint MS Visio MS Project Oracle 11 g Tableau Server and Tableau Desktop v8v9 MS Excel SQL ERWIN SSIS SSRS Java Developer Hyderabad Telangana May 2013 to August 2013 Responsibilities Developed web application using Struts JSP Servlets Java beans that uses MVC design pattern Created userfriendly GUI interface and Web pages using HTML CSS and JSP Used Eclipse as IDE tool for creating Servlets JSP and XML Implemented the Struts framework based on MVC design pattern Wrote SQL for JDBC prepared statements to retrieve the data from database Worked with Database Administrators to solve the problems generated while creating tables for application Developed and implemented customized maintenance plans to meet the needs and keep up to date with the glitches and fixes for performances issues Developed various UML diagrams like use cases class diagrams interaction diagrams sequence and collaboration and activity diagrams Involved in build and deploying the application using ANT Environment Java SQL XML HTML CSS JSP JDBC Eclipse IDE Education Bachelors in Computer Science in TOOLS AND TECHNOLOGIES JNTU",
    "extracted_keywords": [
        "Data",
        "Scientist",
        "Data",
        "Scientist",
        "Data",
        "Scientist",
        "PPD",
        "Raleigh",
        "NC",
        "years",
        "experience",
        "Data",
        "Science",
        "Data",
        "Analyst",
        "Python",
        "Developer",
        "Project",
        "Management",
        "data",
        "science",
        "project",
        "life",
        "cycle",
        "phases",
        "data",
        "extraction",
        "data",
        "modeling",
        "data",
        "visualization",
        "data",
        "sets",
        "data",
        "ER",
        "diagrams",
        "schemas",
        "Proficient",
        "process",
        "research",
        "models",
        "data",
        "inputs",
        "metrics",
        "user",
        "interface",
        "models",
        "Decision",
        "Tree",
        "Random",
        "Forest",
        "Naive",
        "Bayes",
        "Logistic",
        "Regression",
        "Cluster",
        "Analysis",
        "Artificial",
        "Neural",
        "Networks",
        "machine",
        "learning",
        "algorithms",
        "Logistic",
        "Regression",
        "Random",
        "Forest",
        "KNN",
        "Support",
        "Vector",
        "Machines",
        "Neural",
        "Networks",
        "Regression",
        "Kmeans",
        "Expertise",
        "techniques",
        "Classification",
        "PCA",
        "Decision",
        "trees",
        "KNN",
        "SVM",
        "Predictive",
        "Analytics",
        "Excellent",
        "understanding",
        "Agile",
        "Scrum",
        "development",
        "methodology",
        "Python",
        "data",
        "data",
        "loading",
        "extraction",
        "python",
        "libraries",
        "Matplotlib",
        "Numpy",
        "Pandas",
        "data",
        "analysis",
        "Hands",
        "experience",
        "Data",
        "Science",
        "Python",
        "Pandas",
        "NumPy",
        "Scikitlearn",
        "Matplotlib",
        "Seaborn",
        "Keras",
        "experience",
        "techniques",
        "Correlation",
        "Hypothesis",
        "Inferential",
        "Statistics",
        "data",
        "mining",
        "modeling",
        "techniques",
        "Linear",
        "Logistic",
        "Regression",
        "Clustering",
        "Decision",
        "Trees",
        "Kmean",
        "Mitigated",
        "risk",
        "factors",
        "analysis",
        "data",
        "Transformed",
        "data",
        "analysis",
        "visualization",
        "Experience",
        "Big",
        "Data",
        "technologies",
        "Spark",
        "Spark",
        "SQL",
        "pySpark",
        "Hadoop",
        "2X",
        "Hive",
        "1X",
        "Experience",
        "visualization",
        "tools",
        "Tableau",
        "9X",
        "dashboards",
        "reports",
        "SQL",
        "Python",
        "BI",
        "platform",
        "Tableau",
        "Artificial",
        "Neural",
        "Networks",
        "Deep",
        "Learning",
        "models",
        "Theano",
        "Keras",
        "packages",
        "Python",
        "Worked",
        "SQL",
        "Database",
        "Cassandra",
        "Mongo",
        "DB",
        "SQL",
        "knowledge",
        "RDBMS",
        "SQL",
        "Server",
        "SQL",
        "Mongo",
        "DB",
        "Experience",
        "Microsoft",
        "SQL",
        "Server",
        "Oracle",
        "HadoopHive",
        "Analytical",
        "offering",
        "knowledge",
        "data",
        "analysis",
        "statistics",
        "SQL",
        "data",
        "manipulation",
        "Excellent",
        "Team",
        "player",
        "selfstarter",
        "communication",
        "skills",
        "Experience",
        "phases",
        "Software",
        "Development",
        "life",
        "cycle",
        "Analysis",
        "Requirements",
        "Designing",
        "expertise",
        "Technical",
        "Design",
        "Document",
        "TDD",
        "Functional",
        "Specification",
        "Document",
        "FSD",
        "Test",
        "GAP",
        "Analysis",
        "Source",
        "mapping",
        "documents",
        "version",
        "control",
        "tools",
        "Git",
        "2X",
        "tools",
        "Apache",
        "MavenAnt",
        "C",
        "C",
        "Java",
        "Python",
        "SQL",
        "programming",
        "skills",
        "experience",
        "functions",
        "packages",
        "triggers",
        "Regression",
        "Modeling",
        "Correlation",
        "Multivariate",
        "Analysis",
        "Model",
        "Building",
        "application",
        "Statistical",
        "Concepts",
        "Work",
        "Experience",
        "Data",
        "Scientist",
        "PPD",
        "Raleigh",
        "NC",
        "February",
        "Present",
        "Responsibilities",
        "analysis",
        "CRO",
        "trial",
        "data",
        "yield",
        "recruitment",
        "timeline",
        "trials",
        "APAC",
        "EMEA",
        "regions",
        "Data",
        "SQL",
        "queries",
        "python",
        "packages",
        "data",
        "mining",
        "tasks",
        "Performed",
        "Exploratory",
        "Data",
        "Analysis",
        "Data",
        "Wrangling",
        "development",
        "algorithms",
        "Python",
        "data",
        "mining",
        "analysis",
        "Pythons",
        "data",
        "science",
        "packages",
        "Pandas",
        "NumPy",
        "Matplotlib",
        "Scipy",
        "Scikitlearn",
        "Keras",
        "Theano",
        "Ensure",
        "understanding",
        "team",
        "datasets",
        "trial",
        "execution",
        "analytics",
        "contradictions",
        "datasets",
        "validations",
        "heuristicsEnsure",
        "data",
        "structure",
        "analytics",
        "initiatives",
        "nearterm",
        "object",
        "Discuss",
        "alternative",
        "modeling",
        "approaches",
        "limitations",
        "definition",
        "strategy",
        "objectives",
        "nearterm",
        "longerterm",
        "sophistication",
        "performance",
        "metrics",
        "sites",
        "trials",
        "enrollment",
        "goals",
        "delays",
        "costs",
        "trials",
        "sites",
        "potential",
        "trial",
        "time",
        "budget",
        "Site",
        "performance",
        "model",
        "outputs",
        "topline",
        "Trial",
        "performance",
        "summary",
        "site",
        "selection",
        "scenario",
        "reports",
        "metrics",
        "conclusions",
        "behavior",
        "Stepbystep",
        "instructions",
        "use",
        "features",
        "verification",
        "content",
        "data",
        "manipulation",
        "visualization",
        "tools",
        "Pandas",
        "Matplotlib",
        "Seaborn",
        "data",
        "business",
        "reports",
        "extension",
        "models",
        "Random",
        "forest",
        "linear",
        "regression",
        "Support",
        "Vector",
        "Regression",
        "techniques",
        "Gradient",
        "Boosting",
        "XGBoost",
        "Site",
        "Selection",
        "Python",
        "programming",
        "language",
        "data",
        "data",
        "mining",
        "data",
        "mining",
        "features",
        "dataset",
        "Python",
        "Explored",
        "Machine",
        "Learning",
        "Decision",
        "Tree",
        "Regression",
        "Random",
        "Forest",
        "Regression",
        "SVM",
        "parameters",
        "Root",
        "Mean",
        "Squared",
        "Error",
        "Mean",
        "Absolute",
        "Error",
        "model",
        "Environment",
        "Python",
        "SQL",
        "Pandas",
        "Seaborn",
        "Decision",
        "Tree",
        "Random",
        "Forest",
        "Support",
        "Vector",
        "Machines",
        "Gradient",
        "Boosting",
        "Tableau",
        "Data",
        "Scientist",
        "7Eleven",
        "Irving",
        "TX",
        "April",
        "January",
        "Responsibilities",
        "endtoend",
        "systems",
        "Data",
        "Analytics",
        "Data",
        "Automation",
        "visualization",
        "tools",
        "Python",
        "Hadoop",
        "MongoDB",
        "Pandas",
        "NumPy",
        "Seaborn",
        "Matplotlib",
        "Python",
        "machine",
        "learning",
        "algorithms",
        "csv",
        "Json",
        "types",
        "files",
        "Data",
        "cleaning",
        "Data",
        "analysis",
        "Python",
        "operations",
        "data",
        "Matplotlib",
        "data",
        "model",
        "False",
        "Positive",
        "Rate",
        "datasets",
        "Pandas",
        "data",
        "frames",
        "MySQL",
        "graphs",
        "business",
        "Python",
        "Matplotlib",
        "library",
        "root",
        "causes",
        "problems",
        "implementation",
        "solutions",
        "levels",
        "management",
        "Performed",
        "Data",
        "Cleaning",
        "data",
        "outliers",
        "features",
        "engineering",
        "Application",
        "ML",
        "algorithms",
        "modeling",
        "decision",
        "trees",
        "regression",
        "models",
        "forest",
        "SVM",
        "Volume",
        "packages",
        "python",
        "Performed",
        "data",
        "visualization",
        "Tableau",
        "dashboards",
        "findings",
        "reports",
        "metrics",
        "conclusions",
        "behavior",
        "project",
        "lifecycle",
        "data",
        "extractionpreparation",
        "design",
        "implementation",
        "machine",
        "analysis",
        "solutions",
        "documentation",
        "results",
        "Performed",
        "Classification",
        "algorithms",
        "Logistic",
        "Regression",
        "Decision",
        "KNN",
        "Naive",
        "Bayes",
        "data",
        "profiling",
        "data",
        "data",
        "sources",
        "Knowledge",
        "database",
        "platforms",
        "Oracle",
        "NoSQL",
        "Environment",
        "Python",
        "MySQL",
        "Matplotlib",
        "Seaborn",
        "Linear",
        "Regression",
        "Logistic",
        "Regression",
        "Random",
        "Forest",
        "Support",
        "Vector",
        "Machines",
        "KNN",
        "Tableau",
        "Python",
        "Developer",
        "Zen3",
        "Info",
        "Solutions",
        "Hyderabad",
        "Telangana",
        "August",
        "December",
        "database",
        "model",
        "APIs",
        "views",
        "Python",
        "order",
        "solution",
        "data",
        "types",
        "dictionaries",
        "tuples",
        "object",
        "concepts",
        "inheritance",
        "algorithms",
        "networks",
        "API",
        "system",
        "deployment",
        "http",
        "server",
        "Amazon",
        "AWS",
        "architecture",
        "Python",
        "stack",
        "APIs",
        "operations",
        "calculation",
        "purpose",
        "python",
        "libraries",
        "datasets",
        "Panda",
        "data",
        "frames",
        "MySQL",
        "JSON",
        "REST",
        "Web",
        "services",
        "testing",
        "Djangos",
        "Test",
        "Module",
        "Agile",
        "Methodologies",
        "SCRUM",
        "Process",
        "unit",
        "testregression",
        "test",
        "framework",
        "code",
        "Subversion",
        "version",
        "control",
        "tool",
        "teamdevelopment",
        "Developed",
        "SQL",
        "Queries",
        "Stored",
        "Procedures",
        "Triggers",
        "Oracle",
        "SQL",
        "PLSQL",
        "web",
        "application",
        "user",
        "groups",
        "software",
        "issuesservice",
        "requests",
        "bugs",
        "Django",
        "admin",
        "site",
        "dashboard",
        "custom",
        "Django",
        "dashboard",
        "end",
        "users",
        "custom",
        "Django",
        "APIs",
        "database",
        "access",
        "Python",
        "XML",
        "processing",
        "data",
        "exchange",
        "business",
        "logic",
        "implementation",
        "Python",
        "scripts",
        "content",
        "database",
        "manipulate",
        "files",
        "lifecycle",
        "projects",
        "Design",
        "Development",
        "Deployment",
        "Testing",
        "Implementation",
        "support",
        "Environment",
        "Python",
        "Django",
        "JSP",
        "Oracle",
        "Java",
        "MySQL",
        "Linux",
        "HTML",
        "CSS",
        "Data",
        "Analyst",
        "HTC",
        "Global",
        "Services",
        "India",
        "Private",
        "Ltd",
        "September",
        "July",
        "Responsibilities",
        "business",
        "users",
        "data",
        "architects",
        "developers",
        "needs",
        "define",
        "project",
        "scope",
        "requirements",
        "requirements",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "SDLC",
        "Prepared",
        "Data",
        "Mapping",
        "documents",
        "Use",
        "Cases",
        "Requirements",
        "Traceability",
        "Matrix",
        "User",
        "experience",
        "team",
        "Wireframe",
        "team",
        "requirement",
        "documentation",
        "reviews",
        "user",
        "representatives",
        "priorities",
        "presentations",
        "walkthroughs",
        "user",
        "signoff",
        "Driven",
        "meetings",
        "iteration",
        "planning",
        "meetings",
        "requirement",
        "gathering",
        "meetings",
        "data",
        "data",
        "repositories",
        "databases",
        "datasets",
        "analysis",
        "Multiple",
        "Dimensions",
        "Fact",
        "tables",
        "advance",
        "data",
        "modeling",
        "concepts",
        "dimension",
        "subdimension",
        "Factless",
        "fact",
        "table",
        "fact",
        "tables",
        "Multidimensional",
        "model",
        "Tab",
        "Admin",
        "Tab",
        "Cmd",
        "backups",
        "backups",
        "Tableau",
        "repository",
        "user",
        "user",
        "groups",
        "instances",
        "reports",
        "Tableau",
        "Handson",
        "development",
        "worksheets",
        "data",
        "visualization",
        "dashboards",
        "reports",
        "data",
        "sources",
        "data",
        "worksheet",
        "Tableau",
        "Desktop",
        "Environment",
        "MS",
        "SQL",
        "Data",
        "Base",
        "MS",
        "Excel",
        "MS",
        "Word",
        "MS",
        "PowerPoint",
        "MS",
        "Outlook",
        "SharePoint",
        "MS",
        "Visio",
        "MS",
        "Project",
        "Oracle",
        "g",
        "Tableau",
        "Server",
        "Tableau",
        "Desktop",
        "v8v9",
        "MS",
        "Excel",
        "SQL",
        "ERWIN",
        "SSIS",
        "SSRS",
        "Java",
        "Developer",
        "Hyderabad",
        "Telangana",
        "May",
        "August",
        "Responsibilities",
        "web",
        "application",
        "Struts",
        "JSP",
        "Servlets",
        "Java",
        "beans",
        "MVC",
        "design",
        "pattern",
        "GUI",
        "interface",
        "Web",
        "pages",
        "HTML",
        "CSS",
        "JSP",
        "Eclipse",
        "IDE",
        "tool",
        "Servlets",
        "JSP",
        "XML",
        "Struts",
        "framework",
        "MVC",
        "design",
        "pattern",
        "SQL",
        "JDBC",
        "statements",
        "data",
        "database",
        "Database",
        "Administrators",
        "problems",
        "tables",
        "application",
        "maintenance",
        "plans",
        "needs",
        "date",
        "glitches",
        "fixes",
        "performances",
        "issues",
        "UML",
        "diagrams",
        "use",
        "cases",
        "class",
        "diagrams",
        "interaction",
        "diagrams",
        "sequence",
        "collaboration",
        "activity",
        "diagrams",
        "build",
        "application",
        "ANT",
        "Environment",
        "Java",
        "SQL",
        "XML",
        "HTML",
        "CSS",
        "JSP",
        "JDBC",
        "Eclipse",
        "IDE",
        "Education",
        "Bachelors",
        "Computer",
        "Science",
        "TOOLS",
        "TECHNOLOGIES",
        "JNTU"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T19:39:20.280233",
    "resume_data": "Data Scientist Data Scientist Data Scientist PPD Raleigh NC Around 6 years of experience in Data Science Data Analyst Python Developer and Project Management Involved in the entire data science project life cycle and actively involved in all the phases including data extraction data cleaning statistical modeling and data visualization with large data sets of structured and unstructured data created ER diagrams and schemas Proficient in process research which requires analytic models data inputs and output analytic metrics and user interface needs Developed predictive models using Decision Tree Random Forest Naive Bayes Logistic Regression Cluster Analysis and Artificial Neural Networks Experienced with machine learning algorithms such as Logistic Regression Random Forest KNN Support Vector Machines Neural Networks LinearNonLinear Regression and Kmeans Expertise in employing techniques for Supervised and Unsupervised learningClustering Classification PCA Decision trees KNN SVM Predictive Analytics Excellent understanding of Agile and Scrum development methodology Experienced in Python to manipulate data for data loading and extraction and worked with python libraries like Matplotlib Numpy and Pandas for data analysis Hands on experience of Data Science libraries in Python such as Pandas NumPy Scikitlearn Matplotlib Seaborn Keras Equipped with experience in utilizing statistical techniques which include Correlation Hypothesis modeling Inferential Statistics as well as data mining and modeling techniques using Linear and Logistic Regression Clustering Decision Trees and Kmean clustering Mitigated risk factors through careful analysis of financial and statistical data Transformed and processed raw data for further analysis visualization and modeling Experience in Big Data technologies like Spark 16 Spark SQL pySpark Hadoop 2X Hive 1X Experience in visualization tools like Tableau 9X 10X for creating dashboards Automated recurring reports using SQL and Python and visualized them on BI platform like Tableau Worked on Artificial Neural Networks and Deep Learning models using Theano and Keras packages using Python Worked with No SQL Database including Cassandra and Mongo DB Experienced in writing SQL queries working knowledge of RDBMS like SQL Server 2008 No SQL databases like Mongo DB 32 Experience working on Microsoft SQL Server Oracle HadoopHive Analytical performancefocused and detailoriented professional offering indepth knowledge of data analysis and statistics Utilized complex SQL queries for data manipulation Excellent Team player and selfstarter possess good communication skills Experience in various phases of Software Development life cycle Analysis Requirements gathering Designing with expertise in writingdocumenting Technical Design Document TDD Functional Specification Document FSD Test Plans GAP Analysis and Source to Target mapping documents Used the version control tools like Git 2X and build tools like Apache MavenAnt C C Java Python SQL programming skills with experience in working with functions packages and triggers Skilled in Advanced Regression Modeling Correlation Multivariate Analysis Model Building and application of Statistical Concepts Work Experience Data Scientist PPD Raleigh NC February 2018 to Present Responsibilities Responsible for predictive analysis of CRO trial data to predict patient yield and recruitment timeline for clinical trials across APAC EMEA regions Data was extracted extensively by using SQL queries and used python packages for the data mining tasks Performed Exploratory Data Analysis Data Wrangling and development of algorithms in Python for data mining and analysis Extensively used Pythons multiple data science packages like Pandas NumPy Matplotlib Scipy Scikitlearn Keras and Theano Ensure complete understanding for the broader team on the datasets and how they tie to clinical trial execution and thereby modeling analytics Identify and resolve contradictions in datasets develop effective validations and heuristicsEnsure data structure is appropriate for future complex analytics initiatives and not limited to a nearterm object Discuss alternative modeling approaches considerations limitations feature definition and develop strategy to ensure objectives are met in nearterm while also supporting longerterm increased sophistication and performance metrics Investigational sites chosen for clinical trials rarely meet enrollment goals leading to delays and high costs in conducting clinical trials We need to identify sites that have the potential to complete the clinical trial on time and under budget Site performance model outputs and resulting topline Trial performance summary based on site selection scenario Created and designed reports that will use gathered metrics to infer and draw logical conclusions from past and future behavior Stepbystep instructions for use of new features to facilitate verification of the new content Used Pythonbased data manipulation and visualization tools such as Pandas Matplotlib and Seaborn to clean corrupted data before generating business requested reports Developed extension models relying on but not limited to the Random forest logistic linear regression Support Vector Regression and boosting techniques like Gradient Boosting and XGBoost for Site Selection Used Python programming language to graphically analyze the data and perform data mining Performed extensive data mining to find out relevant features in an anonymized dataset using Python Explored supervised Machine Learning algorithms Decision Tree Regression Random Forest Regression SVM and used parameters such as Root Mean Squared Error and Mean Absolute Error to select the winning model Environment Python 3 SQL Pandas Seaborn Decision Tree Random Forest Support Vector Machines Gradient Boosting Tableau Data Scientist 7Eleven Irving TX April 2017 to January 2018 Responsibilities Implemented endtoend systems for Data Analytics Data Automation and customized visualization tools using Python Hadoop and MongoDB Used Pandas NumPy Seaborn Matplotlib scikitlearn in Python for developing various machine learning algorithms Worked on csv Json excel different types of files for the Data cleaning and Data analysis Used Python for statistical operations on the data and Matplotlib for the visualizing the data Ensured that the model has a low False Positive Rate Managed large datasets using Pandas data frames and MySQL Built various graphs for business decisionmaking using Python Matplotlib library Identified root causes of problems and facilitated the implementation of costeffective solutions with all levels of management Performed Data Cleaning handled missing data outliers feature scaling features engineering Application of various ML algorithms and statistical modeling like decision trees regression models random forest SVM clustering to identify Volume using different packages in python Performed data visualization with Tableau and generated dashboards to present the findings Created and designed reports that will use gathered metrics to infer and draw logical conclusions from past and future behavior Worked independently and collaboratively throughout the project lifecycle including data extractionpreparation design and implementation of scalable machine learning analysis and solutions and documentation of results Performed Classification using supervised algorithms like Logistic Regression Decision trees KNN Naive Bayes Performed data profiling to merge the data from multiple data sources Knowledge of other relational database platforms such as Oracle NoSQL Environment Python 3 MySQL Matplotlib Seaborn Linear Regression Logistic Regression Random Forest Support Vector Machines KNN Tableau Python Developer Zen3 Info Solutions Hyderabad Telangana August 2014 to December 2016 Involved in building database model APIs and views utilizing Python in order to build an interactive webbased solution Used data types like dictionaries tuples and object concepts based inheritance features for making complex algorithms of networks Designed and managed API system deployment using fast http server and Amazon AWS architecture Worked on Python Open stack APIs Carried out various mathematical operations for calculation purpose using python libraries Managed large datasets using Panda data frames and MySQL Worked with JSON based REST Web services Performed testing using Djangos Test Module Involved in Agile Methodologies and SCRUM Process Creating unit testregression test framework for workingnew code Using Subversion version control tool to coordinate teamdevelopment Developed SQL Queries Stored Procedures and Triggers Using Oracle SQL PLSQL Responsible for debugging and troubleshooting the web application Supported user groups by handling targetrelated software issuesservice requests identifyingfixing bugs Configured the Django admin site dashboard and created a custom Django dashboard for end users with custom look and feel Used Django APIs for database access Used Python for XML JSON processing data exchange and business logic implementation Used Python scripts to update the content in database and manipulate files Worked through the entire lifecycle of the projects including Design Development and Deployment Testing and Implementation and support Environment Python Django JSP Oracle Java MySQL Linux HTML CSS Data Analyst HTC Global Services India Private Ltd September 2013 to July 2014 Responsibilities Communicated with business users data architects and developers to identify needs define project scope and detailed functional and nonfunctional requirements Gathered and documented requirements throughout the Software Development Life Cycle SDLC Prepared Data Mapping documents Use Cases Requirements Traceability Matrix and worked with the User experience team Wireframe preparing team Created requirement documentation reviews with user representatives recommended priorities gave presentations and walkthroughs and obtained user signoff Driven daily stand up meetings offshore iteration planning meetings and requirement gathering meetings Extracting data from different public data repositories and from different databases and creating datasets for statistical analysis Identified Multiple Dimensions and Fact tables Used advance data modeling concepts of degenerated dimension subdimension Factless fact table Aggregate fact tables in the Multidimensional model Extensively used Tab Admin and Tab Cmd commands in creating backups and restoring backups of Tableau repository Administered user user groups and scheduled instances for reports in Tableau Handson development in creating and modifying worksheets and data visualization dashboards Designed developed various analytical reports from multiple data sources by blending data on a single worksheet in Tableau Desktop Environment Windows 7 8 MS SQL Data Base MS Excel MS Word MS PowerPoint MS Outlook SharePoint MS Visio MS Project Oracle 11g Tableau Server and Tableau Desktop v8v9 MS Excel SQL ERWIN SSIS SSRS Java Developer Hyderabad Telangana May 2013 to August 2013 Responsibilities Developed web application using Struts JSP Servlets Java beans that uses MVC design pattern Created userfriendly GUI interface and Web pages using HTML CSS and JSP Used Eclipse as IDE tool for creating Servlets JSP and XML Implemented the Struts framework based on MVC design pattern Wrote SQL for JDBC prepared statements to retrieve the data from database Worked with Database Administrators to solve the problems generated while creating tables for application Developed and implemented customized maintenance plans to meet the needs and keep up to date with the glitches and fixes for performances issues Developed various UML diagrams like use cases class diagrams interaction diagrams sequence and collaboration and activity diagrams Involved in build and deploying the application using ANT Environment Java SQL XML HTML CSS JSP JDBC Eclipse IDE Education Bachelors in Computer Science in TOOLS AND TECHNOLOGIES JNTU",
    "unique_id": "d98735f2-6f6a-49dd-8221-3867d002f23b"
}