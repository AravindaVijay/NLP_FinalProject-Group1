{
    "clean_data": "Senior Software DeveloperOnsite lead Senior span lSoftwarespan span lDeveloperspanOnsite lead Senior Software DeveloperOnsite lead CognizantAetna Hartford CT To pursue a career in an environment that allows use and expand my technical skills and expertise to introduce efficiency into the dataanaylsis and datamanipulation needs of my employer to support improved profitability and corporate growth Work Experience Senior Software DeveloperOnsite lead CognizantAetna 2013 to Present Involved in design and enhancement of the ingestion framework which sqoopingest the data from disparate data sources like RDBMS XML and flat files Developed XML parsing framework for ingestion team to handle massive survey XML data Automated the file extraction process from Amazon S3 to Hadoop to ingest files from external vendors Developed cost transparency framework using ScalaSpark to empower Aetna members by providing them cost estimation when they opt for a procedure or a service Involved in the entire DevOps cycle for the scalaspark applications Managed the setting up GitHub repository and performed the role of reviewerapprover Wrote test cases using ScalaTest to automate the testing in DevOps process Worked in setting up the Scala Build ToolSBT and educate team members about SBT to automate the build Worked with crossteams for scheduling the scala application through internal Workload framework Proposed Designed and developed Java Swing UI application which supports the business analyst who verifies the outcomes of the Cost transparency framework Built a Pig data pipeline to find out the prospect members who are currently eligible for medicare but not yet enrolled Built a Hive data pipeline which reports utilization parameters like continuous admissions and bed days calculation Designed and Developed J2EESpring based Web applications for manual repricing and network cascading arrangements Worked on prototyping approach where HTML prototypes will be presented to stakeholders in brainstorming sessions to gather requirements Wrote Junit test scripts using Mockito framework in order to automate the unit testing Software Engineer Vanenburg software India Pvt Ltd 2010 to 2013 Developed services for supporting Near Real Time search functionality using Solr Developed servlet filters at container level for filtering out Solr queries Developed custom XML response writers for Solr and custom data import handler for migrating the Solr indexes from Hbase Provided insights on developing Solr queries for the UI developers Worked on installation and deployment documentation of the Solr HA cloud set up for the beta release of the product Developed Lucene based APIs to process and index the structured data Developed the persistent mechanism of the indexes in Hbase Involved in the development of information retrieval from Hbase for search Contributed to the technical discussions for Hbase and Lucene integration for performance improvement and index sharding Associate Software Engineer Cordys software India Pvt Ltd 2009 to 2010 Developed a Netbeans platform based plugin for iReport designer which will allow a user to design the report by consuming the webservices and publish back the designed report to the Cordys Process Factory repository using iReport APIs Developed Swing user interfaces for establishing connection consuming webservices publish and import reports in iReport designer Created methodsets webservices for supporting the functions of the plugin using Cordys BOP4 Developed the execution layer of the reports using JasperReports APIs Documented on help pages in Cordys wiki about the iReport and plugin usage Education Master of Computer Applications in Computer Applications PSG College of Technology Coimbatore Tamil Nadu Academy of Healthcare Management Skills Hadoop Hbase Hive Json Lucene Pig Solr Svn Xml Sqoop Hbase Solr Hadoop Lucene Eclipse J2ee Java Spring jquery Jsp Links httpwwwlinkedincominjagadeshkumarbalasubramanian50801614 Additional Information TECHNICAL SKILLS Hadoop Ecosystem Hadoop 273 Hive 12 Scala 2118 Sqoop Shell Amazon S3 Spark 16 DistCp Pig Hbase 092 LanguagesTechnology Java J2EE XML JSON Swing JSP HTML5 JQuery CSS3 WebServices Frameworks Spring Junit Mockito ScalaTest Operating Systems Windows Linux RDBMS Libraries MySQL Solr 400 Lucene 400 JasperReports DevOps GitHub GitLab ScalaBuildTool SBT Tortoise SVN IBM ClearCase Platforms Cordys Process Factory Cordys BOP4 IDE Tools Eclipse ScalaIDE Netbeans Hue Aginity Workbench for Hadoop SecureCRT SecureFX JIRA HbaseExplorer iReport Jupyter Fiddler Luke",
    "entities": [
        "ScalaTest",
        "Associate Software Engineer Cordys",
        "Hue Aginity Workbench for",
        "Mockito",
        "IDE Tools",
        "Created",
        "Aetna",
        "UI",
        "CognizantAetna",
        "GitHub GitLab",
        "SBT",
        "medicare",
        "IBM",
        "SVN",
        "ScalaSpark",
        "iReport",
        "Software Engineer Vanenburg",
        "JSP",
        "India Pvt Ltd",
        "Solr",
        "JasperReports",
        "Hadoop",
        "XML",
        "GitHub",
        "Present Involved",
        "the Cordys Process Factory",
        "DevOps",
        "lSoftwarespan",
        "Amazon",
        "Workload",
        "Tamil Nadu Academy of Healthcare Management Skills Hadoop Hbase"
    ],
    "experience": "Experience Senior Software DeveloperOnsite lead CognizantAetna 2013 to Present Involved in design and enhancement of the ingestion framework which sqoopingest the data from disparate data sources like RDBMS XML and flat files Developed XML parsing framework for ingestion team to handle massive survey XML data Automated the file extraction process from Amazon S3 to Hadoop to ingest files from external vendors Developed cost transparency framework using ScalaSpark to empower Aetna members by providing them cost estimation when they opt for a procedure or a service Involved in the entire DevOps cycle for the scalaspark applications Managed the setting up GitHub repository and performed the role of reviewerapprover Wrote test cases using ScalaTest to automate the testing in DevOps process Worked in setting up the Scala Build ToolSBT and educate team members about SBT to automate the build Worked with crossteams for scheduling the scala application through internal Workload framework Proposed Designed and developed Java Swing UI application which supports the business analyst who verifies the outcomes of the Cost transparency framework Built a Pig data pipeline to find out the prospect members who are currently eligible for medicare but not yet enrolled Built a Hive data pipeline which reports utilization parameters like continuous admissions and bed days calculation Designed and Developed J2EESpring based Web applications for manual repricing and network cascading arrangements Worked on prototyping approach where HTML prototypes will be presented to stakeholders in brainstorming sessions to gather requirements Wrote Junit test scripts using Mockito framework in order to automate the unit testing Software Engineer Vanenburg software India Pvt Ltd 2010 to 2013 Developed services for supporting Near Real Time search functionality using Solr Developed servlet filters at container level for filtering out Solr queries Developed custom XML response writers for Solr and custom data import handler for migrating the Solr indexes from Hbase Provided insights on developing Solr queries for the UI developers Worked on installation and deployment documentation of the Solr HA cloud set up for the beta release of the product Developed Lucene based APIs to process and index the structured data Developed the persistent mechanism of the indexes in Hbase Involved in the development of information retrieval from Hbase for search Contributed to the technical discussions for Hbase and Lucene integration for performance improvement and index sharding Associate Software Engineer Cordys software India Pvt Ltd 2009 to 2010 Developed a Netbeans platform based plugin for iReport designer which will allow a user to design the report by consuming the webservices and publish back the designed report to the Cordys Process Factory repository using iReport APIs Developed Swing user interfaces for establishing connection consuming webservices publish and import reports in iReport designer Created methodsets webservices for supporting the functions of the plugin using Cordys BOP4 Developed the execution layer of the reports using JasperReports APIs Documented on help pages in Cordys wiki about the iReport and plugin usage Education Master of Computer Applications in Computer Applications PSG College of Technology Coimbatore Tamil Nadu Academy of Healthcare Management Skills Hadoop Hbase Hive Json Lucene Pig Solr Svn Xml Sqoop Hbase Solr Hadoop Lucene Eclipse J2ee Java Spring jquery Jsp Links httpwwwlinkedincominjagadeshkumarbalasubramanian50801614 Additional Information TECHNICAL SKILLS Hadoop Ecosystem Hadoop 273 Hive 12 Scala 2118 Sqoop Shell Amazon S3 Spark 16 DistCp Pig Hbase 092 LanguagesTechnology Java J2EE XML JSON Swing JSP HTML5 JQuery CSS3 WebServices Frameworks Spring Junit Mockito ScalaTest Operating Systems Windows Linux RDBMS Libraries MySQL Solr 400 Lucene 400 JasperReports DevOps GitHub GitLab ScalaBuildTool SBT Tortoise SVN IBM ClearCase Platforms Cordys Process Factory Cordys BOP4 IDE Tools Eclipse ScalaIDE Netbeans Hue Aginity Workbench for Hadoop SecureCRT SecureFX JIRA HbaseExplorer iReport Jupyter Fiddler Luke",
    "extracted_keywords": [
        "Senior",
        "Software",
        "DeveloperOnsite",
        "span",
        "lSoftwarespan",
        "span",
        "lDeveloperspanOnsite",
        "Senior",
        "Software",
        "DeveloperOnsite",
        "CognizantAetna",
        "Hartford",
        "CT",
        "career",
        "environment",
        "use",
        "skills",
        "expertise",
        "efficiency",
        "dataanaylsis",
        "datamanipulation",
        "needs",
        "employer",
        "profitability",
        "growth",
        "Work",
        "Experience",
        "Senior",
        "Software",
        "DeveloperOnsite",
        "CognizantAetna",
        "Present",
        "design",
        "enhancement",
        "ingestion",
        "framework",
        "data",
        "data",
        "sources",
        "RDBMS",
        "XML",
        "files",
        "Developed",
        "XML",
        "framework",
        "ingestion",
        "team",
        "survey",
        "XML",
        "data",
        "file",
        "extraction",
        "process",
        "Amazon",
        "S3",
        "Hadoop",
        "files",
        "vendors",
        "cost",
        "transparency",
        "framework",
        "ScalaSpark",
        "Aetna",
        "members",
        "cost",
        "estimation",
        "procedure",
        "service",
        "DevOps",
        "cycle",
        "scalaspark",
        "applications",
        "setting",
        "GitHub",
        "repository",
        "role",
        "reviewerapprover",
        "Wrote",
        "test",
        "cases",
        "ScalaTest",
        "testing",
        "DevOps",
        "process",
        "Scala",
        "Build",
        "ToolSBT",
        "team",
        "members",
        "SBT",
        "build",
        "crossteams",
        "scala",
        "application",
        "Workload",
        "framework",
        "Java",
        "Swing",
        "UI",
        "application",
        "business",
        "analyst",
        "outcomes",
        "Cost",
        "transparency",
        "framework",
        "Pig",
        "data",
        "pipeline",
        "prospect",
        "members",
        "medicare",
        "Hive",
        "data",
        "pipeline",
        "utilization",
        "parameters",
        "admissions",
        "bed",
        "days",
        "calculation",
        "Developed",
        "Web",
        "applications",
        "repricing",
        "network",
        "arrangements",
        "approach",
        "HTML",
        "prototypes",
        "stakeholders",
        "sessions",
        "requirements",
        "Wrote",
        "Junit",
        "test",
        "scripts",
        "Mockito",
        "framework",
        "order",
        "unit",
        "Software",
        "Engineer",
        "Vanenburg",
        "software",
        "India",
        "Pvt",
        "Ltd",
        "services",
        "Near",
        "Real",
        "Time",
        "search",
        "functionality",
        "Solr",
        "Developed",
        "servlet",
        "filters",
        "container",
        "level",
        "Solr",
        "custom",
        "XML",
        "response",
        "writers",
        "Solr",
        "custom",
        "data",
        "import",
        "handler",
        "Solr",
        "indexes",
        "Hbase",
        "insights",
        "Solr",
        "queries",
        "UI",
        "developers",
        "installation",
        "deployment",
        "documentation",
        "Solr",
        "HA",
        "cloud",
        "beta",
        "release",
        "product",
        "Lucene",
        "APIs",
        "data",
        "mechanism",
        "indexes",
        "Hbase",
        "development",
        "information",
        "retrieval",
        "Hbase",
        "search",
        "Contributed",
        "discussions",
        "Hbase",
        "Lucene",
        "integration",
        "performance",
        "improvement",
        "index",
        "Associate",
        "Software",
        "Engineer",
        "Cordys",
        "software",
        "India",
        "Pvt",
        "Ltd",
        "Netbeans",
        "platform",
        "plugin",
        "iReport",
        "designer",
        "user",
        "report",
        "webservices",
        "report",
        "Cordys",
        "Process",
        "Factory",
        "repository",
        "iReport",
        "APIs",
        "Developed",
        "Swing",
        "user",
        "interfaces",
        "connection",
        "webservices",
        "import",
        "reports",
        "iReport",
        "designer",
        "methodsets",
        "webservices",
        "functions",
        "plugin",
        "Cordys",
        "BOP4",
        "execution",
        "layer",
        "reports",
        "JasperReports",
        "APIs",
        "help",
        "pages",
        "Cordys",
        "wiki",
        "iReport",
        "usage",
        "Education",
        "Master",
        "Computer",
        "Applications",
        "Computer",
        "Applications",
        "PSG",
        "College",
        "Technology",
        "Coimbatore",
        "Tamil",
        "Nadu",
        "Academy",
        "Healthcare",
        "Management",
        "Skills",
        "Hadoop",
        "Hbase",
        "Hive",
        "Json",
        "Lucene",
        "Pig",
        "Solr",
        "Svn",
        "Xml",
        "Sqoop",
        "Hbase",
        "Solr",
        "Hadoop",
        "Lucene",
        "Eclipse",
        "J2ee",
        "Java",
        "Spring",
        "jquery",
        "Jsp",
        "Links",
        "httpwwwlinkedincominjagadeshkumarbalasubramanian50801614",
        "Information",
        "TECHNICAL",
        "SKILLS",
        "Hadoop",
        "Ecosystem",
        "Hadoop",
        "Hive",
        "Scala",
        "Sqoop",
        "Shell",
        "Amazon",
        "S3",
        "Spark",
        "Pig",
        "Hbase",
        "LanguagesTechnology",
        "Java",
        "J2EE",
        "XML",
        "JSON",
        "Swing",
        "JSP",
        "HTML5",
        "JQuery",
        "CSS3",
        "WebServices",
        "Frameworks",
        "Spring",
        "Junit",
        "Mockito",
        "ScalaTest",
        "Operating",
        "Systems",
        "Windows",
        "Linux",
        "RDBMS",
        "MySQL",
        "Solr",
        "Lucene",
        "JasperReports",
        "DevOps",
        "GitHub",
        "GitLab",
        "ScalaBuildTool",
        "SBT",
        "Tortoise",
        "SVN",
        "IBM",
        "ClearCase",
        "Platforms",
        "Cordys",
        "Process",
        "Factory",
        "Cordys",
        "BOP4",
        "IDE",
        "Tools",
        "Eclipse",
        "ScalaIDE",
        "Netbeans",
        "Hue",
        "Aginity",
        "Workbench",
        "Hadoop",
        "SecureCRT",
        "SecureFX",
        "JIRA",
        "HbaseExplorer",
        "iReport",
        "Jupyter",
        "Fiddler",
        "Luke"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T22:22:02.123971",
    "resume_data": "Senior Software DeveloperOnsite lead Senior span lSoftwarespan span lDeveloperspanOnsite lead Senior Software DeveloperOnsite lead CognizantAetna Hartford CT To pursue a career in an environment that allows use and expand my technical skills and expertise to introduce efficiency into the dataanaylsis and datamanipulation needs of my employer to support improved profitability and corporate growth Work Experience Senior Software DeveloperOnsite lead CognizantAetna 2013 to Present Involved in design and enhancement of the ingestion framework which sqoopingest the data from disparate data sources like RDBMS XML and flat files Developed XML parsing framework for ingestion team to handle massive survey XML data Automated the file extraction process from Amazon S3 to Hadoop to ingest files from external vendors Developed cost transparency framework using ScalaSpark to empower Aetna members by providing them cost estimation when they opt for a procedure or a service Involved in the entire DevOps cycle for the scalaspark applications Managed the setting up GitHub repository and performed the role of reviewerapprover Wrote test cases using ScalaTest to automate the testing in DevOps process Worked in setting up the Scala Build ToolSBT and educate team members about SBT to automate the build Worked with crossteams for scheduling the scala application through internal Workload framework Proposed Designed and developed Java Swing UI application which supports the business analyst who verifies the outcomes of the Cost transparency framework Built a Pig data pipeline to find out the prospect members who are currently eligible for medicare but not yet enrolled Built a Hive data pipeline which reports utilization parameters like continuous admissions and bed days calculation Designed and Developed J2EESpring based Web applications for manual repricing and network cascading arrangements Worked on prototyping approach where HTML prototypes will be presented to stakeholders in brainstorming sessions to gather requirements Wrote Junit test scripts using Mockito framework in order to automate the unit testing Software Engineer Vanenburg software India Pvt Ltd 2010 to 2013 Developed services for supporting Near Real Time search functionality using Solr Developed servlet filters at container level for filtering out Solr queries Developed custom XML response writers for Solr and custom data import handler for migrating the Solr indexes from Hbase Provided insights on developing Solr queries for the UI developers Worked on installation and deployment documentation of the Solr HA cloud set up for the beta release of the product Developed Lucene based APIs to process and index the structured data Developed the persistent mechanism of the indexes in Hbase Involved in the development of information retrieval from Hbase for search Contributed to the technical discussions for Hbase and Lucene integration for performance improvement and index sharding Associate Software Engineer Cordys software India Pvt Ltd 2009 to 2010 Developed a Netbeans platform based plugin for iReport designer which will allow a user to design the report by consuming the webservices and publish back the designed report to the Cordys Process Factory repository using iReport APIs Developed Swing user interfaces for establishing connection consuming webservices publish and import reports in iReport designer Created methodsets webservices for supporting the functions of the plugin using Cordys BOP4 Developed the execution layer of the reports using JasperReports APIs Documented on help pages in Cordys wiki about the iReport and plugin usage Education Master of Computer Applications in Computer Applications PSG College of Technology Coimbatore Tamil Nadu Academy of Healthcare Management Skills Hadoop Hbase Hive Json Lucene Pig Solr Svn Xml Sqoop Hbase Solr Hadoop Lucene Eclipse J2ee Java Spring jquery Jsp Links httpwwwlinkedincominjagadeshkumarbalasubramanian50801614 Additional Information TECHNICAL SKILLS Hadoop Ecosystem Hadoop 273 Hive 12 Scala 2118 Sqoop Shell Amazon S3 Spark 16 DistCp Pig Hbase 092 LanguagesTechnology Java J2EE XML JSON Swing JSP HTML5 JQuery CSS3 WebServices Frameworks Spring Junit Mockito ScalaTest Operating Systems Windows Linux RDBMS Libraries MySQL Solr 400 Lucene 400 JasperReports DevOps GitHub GitLab ScalaBuildTool SBT Tortoise SVN IBM ClearCase Platforms Cordys Process Factory Cordys BOP4 IDE Tools Eclipse ScalaIDE Netbeans Hue Aginity Workbench for Hadoop SecureCRT SecureFX JIRA HbaseExplorer iReport Jupyter Fiddler Luke",
    "unique_id": "e088741c-edb6-45ce-9660-b4a19f43d0a9"
}