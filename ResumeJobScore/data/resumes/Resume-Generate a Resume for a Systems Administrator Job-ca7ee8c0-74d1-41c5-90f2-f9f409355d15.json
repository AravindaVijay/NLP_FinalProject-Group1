{
    "clean_data": "HADOOP DEVELOPER HADOOP span lDEVELOPERspan HADOOP DEVELOPER American Express Work Experience HADOOP DEVELOPER American Express Phoenix AZ March 2018 to Present Design develop and implement enterprise data warehouse and create DataMart models Physical and logical data models Build the Hive Query Language code Build Spark Query Language code and unit testing the code Also create partitions dynamic partitions Develop Magellan maps and assist in deployment and provide technical and operational support during the install Involved in hive coding by using Magellan tool transform the data from SORs to ODL tables Review the Hive QL code Spark code UNIX scripts Magellan code and other deliverables with ODL technical panel Work closely with team and close all issues identified during the technical panel review Prepare installation manual and implement the project and provide post installation support Update the project documentations with the installed project changes Perform all the activities related to release such as preparing the metadata Jenkin job configurations and RFC creations All followups related to the RFC and managing service now tickets and Jira tickets Worked on scheduling mapsnodes in event engine and implement different proactive steps for monitoring scheduled jobs on regular basis Provide production support for the existing ODL variables in production This includes any defects fixing and implementing changes with respect to any existing ODL variables in production Creating activity reports with risks issues causes resolutions and provide status reports to American Express end users on daily or weekly basis Conduct knowledge sharing and best practice sessions to educate the team for better quality deliverables for future Environment Hive HDFS MapReduce Flume Spark SQL Oozie Oracle Jenkins Yarn Netezza GitHub Junit Linux Hbase sqoop HDFS Event Engine Maven and Splunk Eclipse Big Data Developer Citi Bank Irving TX March 2016 to February 2018 Updating details in Rally for all assigned user stories and reported the status in daily standup meetings and also involved in sprint planning Grooming show tell and retrospective calls Analyze the reported issues during UAT and coordinate with the business users for the resolutions Implemented multiple Map Reduce Jobs in java for data cleaning and preprocessing Created the external tables in Hive to store information from different sources for testing needs Configured the Sqoop jobs to load the data from Netezza database and other sources into Hive Tables Extensively Used Sqoop to importexport data from Netezza and Hive tables incremental imports and created Sqoop jobs for last saved value Collected logs data from webservers and integrated into HDFS using Flume Created Hive tables to store the processed results in a tabular format Used Maven extensively for building jar files of MapReduce programs and deployed to Cluster Good experience in importing other enterprise data from different data sources into HDFS using Sqoop and Flume and also performing transformations using Hive and PIG and then loading into HBase tables Configured Oozie workflow engine to run multiple Map Reduce HiveQL and Pig jobs Loaded the customer profiles data customer spending data credit from legacy warehouse onto HDFS using Sqoop Used Oozie to orchestrate the map reduce jobs that extract the data on a timely manner Involved in loading data from one Environment to other environment in Hadoop Platform Developed multiple Map Reduce jobs in java for data cleaning Involved in creating Hive tables loading with data and writing hive queries that will run internally in Map Reduce way Design and develop oozie workflows for timely data loading into Hadoop ecosystems from other data sources Environment Hive HDFS MapReduce Flume Pig Spark Core Spark SQL Oozie Oracle Yarn Netezza GitHub Junit Linux Hbase sqoop HDFS Java Scala Maven and Splunk Eclipse JAVA DEVELOPER Hibu Cedar Rapids IA August 2014 to February 2016 Involved in all phases of Software Development Life Cycle and in Analysis designed applications using agile methodology Created dynamic HTML pages using JavaScript jQuery RESTful Web Services and AJAX to create interactive FrontEnd GUI Used synchronous and asynchronous MultiThreading and Lambdas Expressions Implemented J2EE design patterns such as Session Facade Factory DAO DTO and Proxy Involved in Coding based on the spring framework Implemented several components using Spring IOCDependency Injection Consumed RESTful Web services provided by different vendor to use for Address verification and validation Used REST services along with UI built on Angular20 to perform CRUD operations on the database server over HTTP with GET POST PUT DELETE to the Web service Used JIRA ticketing system to keep track of issues and tasks on individuals Created new tables Stored Procedures functions views indexes and constraints triggers and required SQL tuning to reduce the response time in the application Used NoSQL DB like Mongo DB for the proof of concept Migrating existing legacy java services into Micro Services Architecture with Spring Boot Optimized the full text search function by connecting to MongoDB Created data model and generated Hibernate mappings and domain objects using Hibernate tools Interfaced with the MySQL backend database by integrating Spring with Hibernate Maintaining production critical servers running Unix Linux supporting database and Web services Providing 24x7 supports Used Spring Core annotations for Spring Dependency Injection Spring MVC for Rest APIs and Spring Boot for microservices Installed the WebSphere MQ and involved in configuring MDB listeners JMS resources and queues and integrating with the WebSphere Application Server Used log4j to print the logging debugging warning info statements Used Maven for build cruise control is used continuous building Used SVN as version control system for source code and project documents Environment Java8 Spring Frameworks Spring Boot Micro services JPA Hibernate AWS RESTfulSOAP Web Services HTML CSS JavaScript jQuery Angular 2 Maven WebSphere Application Server Mongo DB Log4j Jenkins JIRA GIT JAVA DEVELOPER Walmart Inc Bentonville AR November 2013 to July 2014 Involved in Analyzing preparing technical design specification documents as per the Requirements Architecture Development and Maintenance of high traffic application built in JavaJ2EE Designed application modules base classes and utility classes using core java Used SAX for XML parsing specifically for JAXB marshaling and unmarshaling Involved in development performance testing defects fixing Developed SOAP Web Services Contract First for pricing of the claims Organized daily agile meetings to interact with the development team Expertise in understanding and preparation of WSDL XSLT and XML schemas definitions Designed the project using Business Delegate Singleton Service Locator and DAO Patterns Involved in making the necessary changes for the entire work flow from Action classes to the backend database in Placement Quote Creation module Implemented Hibernate ORM Mapping tool framework to interact with the database to update retrieve insert and delete values effectively JSF was used as the data interchange format between the browser and server In the Front end of the application designed and implemented a publishing framework and reusable UI component library based on Angular JS and jQuery Developed weblayer using Spring MVC Framework with JSP CSS3 AJAX and JavaScript Worked within SOA based enterprise framework to build web services The RESTful web services have been used to retrieve and update the data which is populated in view using Angular JS model Developed Messaging framework for Asynchronous messaging service using JMS and MQseries Extensively used JSON object data in the model as from RESTful web services Developed Restful web services using JERSEY to sendreceive data tofrom various systems Performed Test Driven Development TDD using JUnit Used Jenkins for Continuous Integration and Continuous Delivery Environment Java J2EE HTML5 CSS3 AJAX JavaScript jQuery Spring 40 Tiles SOA Hibernate 40 JMS 20 JNDI JTA XML JSON JAXB JAXWS REST WS SOAP WSDL JUnit Log4J Maven JSP JSF Oracle Servlets Jenkins Eclipse SVN Design Patterns Agile WebSphere Skills HDFS OOZIE SQOOP HBASE KAFKA FLUME JMS MAP REDUCE CODING Git HBase Hive HTML JENKINS Pig SVN XML ZooKeeper ECLIPSE EJB Additional Information Technical Skills Big Data Technologies HDFS Map Reduce Hive Pig Hbase Sqoop Zookeeper Oozie Flume Kafka Databases Oracle 9i 10g 11g MySQL SQL Server Hbase JavaJ2EE Technologies JDBC Servlets JSP OAuth2 JMS EJB JNDI Selenium OWB LDAP Log4j ANT Maven RDS SNS Chef JIRA Confluence JMeter Programming Languages Java JDK 1718 SQL PLSQL IDEs Eclipse NetBeans IntelliJ IBM RAD Oracle WebLogic Studio 8x7x Sublime text Brackets Hive Connecter Frameworks Struts 2x1x Spring 2x Hibernate 3x Mockito PowerMockito Coding Languages Java 678 PLSQL XML HTML CSS Java Script UML Bug Tracking or other Tools Jira Bugzilla Junit Putty WinScp FileZilla Operating Systems Windows and Linux Environments Web Services SOAP JAXB JAXWS RESTful Web services UDDI Micro services Sub Version Control Tool SVN CVS Git Bit Bucket Jenkins JIRA",
    "entities": [
        "Developed Messaging",
        "JERSEY",
        "UDDI Micro services",
        "Hibernate Maintaining",
        "Sub Version Control Tool",
        "Business Delegate Singleton Service Locator",
        "AJAX",
        "Present Design",
        "Stored Procedures",
        "ODL",
        "CRUD",
        "Micro Services Architecture",
        "Sqoop",
        "WebSphere Application",
        "Maven",
        "Performed Test Driven Development TDD",
        "American Express Work Experience HADOOP",
        "RFC",
        "XSLT",
        "JPA Hibernate AWS RESTfulSOAP Web Services HTML CSS JavaScript jQuery Angular",
        "EJB Additional Information Technical Skills Big Data Technologies",
        "UNIX",
        "Created",
        "DAO Patterns Involved",
        "MDB",
        "JMS",
        "Placement Quote Creation",
        "UI",
        "Coding",
        "JSF",
        "WebLogic Studio",
        "PIG",
        "Linux Environments Web Services SOAP",
        "IBM",
        "Flume Created Hive",
        "SVN",
        "SAX",
        "Netezza",
        "java",
        "SOA",
        "Build the Hive Query Language",
        "the Requirements Architecture Development",
        "jQuery Developed",
        "Update",
        "JSP",
        "JNDI",
        "ANT Maven RDS SNS Chef JIRA Confluence JMeter Programming",
        "SQL",
        "Prepare",
        "American Express",
        "Hadoop",
        "REST",
        "UAT",
        "Spring Core",
        "XML",
        "Developed SOAP Web Services",
        "Spring MVC Framework",
        "MapReduce",
        "Installed the WebSphere MQ",
        "FrontEnd",
        "NetBeans",
        "Boot Micro",
        "JUnit",
        "Software Development Life Cycle",
        "JSP JSF Oracle Servlets Jenkins",
        "HBase",
        "the WebSphere Application",
        "GET POST PUT DELETE",
        "Hive",
        "JavaJ2EE",
        "Rally",
        "Spark",
        "Build Spark Query Language"
    ],
    "experience": "Experience HADOOP DEVELOPER American Express Phoenix AZ March 2018 to Present Design develop and implement enterprise data warehouse and create DataMart models Physical and logical data models Build the Hive Query Language code Build Spark Query Language code and unit testing the code Also create partitions dynamic partitions Develop Magellan maps and assist in deployment and provide technical and operational support during the install Involved in hive coding by using Magellan tool transform the data from SORs to ODL tables Review the Hive QL code Spark code UNIX scripts Magellan code and other deliverables with ODL technical panel Work closely with team and close all issues identified during the technical panel review Prepare installation manual and implement the project and provide post installation support Update the project documentations with the installed project changes Perform all the activities related to release such as preparing the metadata Jenkin job configurations and RFC creations All followups related to the RFC and managing service now tickets and Jira tickets Worked on scheduling mapsnodes in event engine and implement different proactive steps for monitoring scheduled jobs on regular basis Provide production support for the existing ODL variables in production This includes any defects fixing and implementing changes with respect to any existing ODL variables in production Creating activity reports with risks issues causes resolutions and provide status reports to American Express end users on daily or weekly basis Conduct knowledge sharing and best practice sessions to educate the team for better quality deliverables for future Environment Hive HDFS MapReduce Flume Spark SQL Oozie Oracle Jenkins Yarn Netezza GitHub Junit Linux Hbase sqoop HDFS Event Engine Maven and Splunk Eclipse Big Data Developer Citi Bank Irving TX March 2016 to February 2018 Updating details in Rally for all assigned user stories and reported the status in daily standup meetings and also involved in sprint planning Grooming show tell and retrospective calls Analyze the reported issues during UAT and coordinate with the business users for the resolutions Implemented multiple Map Reduce Jobs in java for data cleaning and preprocessing Created the external tables in Hive to store information from different sources for testing needs Configured the Sqoop jobs to load the data from Netezza database and other sources into Hive Tables Extensively Used Sqoop to importexport data from Netezza and Hive tables incremental imports and created Sqoop jobs for last saved value Collected logs data from webservers and integrated into HDFS using Flume Created Hive tables to store the processed results in a tabular format Used Maven extensively for building jar files of MapReduce programs and deployed to Cluster Good experience in importing other enterprise data from different data sources into HDFS using Sqoop and Flume and also performing transformations using Hive and PIG and then loading into HBase tables Configured Oozie workflow engine to run multiple Map Reduce HiveQL and Pig jobs Loaded the customer profiles data customer spending data credit from legacy warehouse onto HDFS using Sqoop Used Oozie to orchestrate the map reduce jobs that extract the data on a timely manner Involved in loading data from one Environment to other environment in Hadoop Platform Developed multiple Map Reduce jobs in java for data cleaning Involved in creating Hive tables loading with data and writing hive queries that will run internally in Map Reduce way Design and develop oozie workflows for timely data loading into Hadoop ecosystems from other data sources Environment Hive HDFS MapReduce Flume Pig Spark Core Spark SQL Oozie Oracle Yarn Netezza GitHub Junit Linux Hbase sqoop HDFS Java Scala Maven and Splunk Eclipse JAVA DEVELOPER Hibu Cedar Rapids IA August 2014 to February 2016 Involved in all phases of Software Development Life Cycle and in Analysis designed applications using agile methodology Created dynamic HTML pages using JavaScript jQuery RESTful Web Services and AJAX to create interactive FrontEnd GUI Used synchronous and asynchronous MultiThreading and Lambdas Expressions Implemented J2EE design patterns such as Session Facade Factory DAO DTO and Proxy Involved in Coding based on the spring framework Implemented several components using Spring IOCDependency Injection Consumed RESTful Web services provided by different vendor to use for Address verification and validation Used REST services along with UI built on Angular20 to perform CRUD operations on the database server over HTTP with GET POST PUT DELETE to the Web service Used JIRA ticketing system to keep track of issues and tasks on individuals Created new tables Stored Procedures functions views indexes and constraints triggers and required SQL tuning to reduce the response time in the application Used NoSQL DB like Mongo DB for the proof of concept Migrating existing legacy java services into Micro Services Architecture with Spring Boot Optimized the full text search function by connecting to MongoDB Created data model and generated Hibernate mappings and domain objects using Hibernate tools Interfaced with the MySQL backend database by integrating Spring with Hibernate Maintaining production critical servers running Unix Linux supporting database and Web services Providing 24x7 supports Used Spring Core annotations for Spring Dependency Injection Spring MVC for Rest APIs and Spring Boot for microservices Installed the WebSphere MQ and involved in configuring MDB listeners JMS resources and queues and integrating with the WebSphere Application Server Used log4j to print the logging debugging warning info statements Used Maven for build cruise control is used continuous building Used SVN as version control system for source code and project documents Environment Java8 Spring Frameworks Spring Boot Micro services JPA Hibernate AWS RESTfulSOAP Web Services HTML CSS JavaScript jQuery Angular 2 Maven WebSphere Application Server Mongo DB Log4j Jenkins JIRA GIT JAVA DEVELOPER Walmart Inc Bentonville AR November 2013 to July 2014 Involved in Analyzing preparing technical design specification documents as per the Requirements Architecture Development and Maintenance of high traffic application built in JavaJ2EE Designed application modules base classes and utility classes using core java Used SAX for XML parsing specifically for JAXB marshaling and unmarshaling Involved in development performance testing defects fixing Developed SOAP Web Services Contract First for pricing of the claims Organized daily agile meetings to interact with the development team Expertise in understanding and preparation of WSDL XSLT and XML schemas definitions Designed the project using Business Delegate Singleton Service Locator and DAO Patterns Involved in making the necessary changes for the entire work flow from Action classes to the backend database in Placement Quote Creation module Implemented Hibernate ORM Mapping tool framework to interact with the database to update retrieve insert and delete values effectively JSF was used as the data interchange format between the browser and server In the Front end of the application designed and implemented a publishing framework and reusable UI component library based on Angular JS and jQuery Developed weblayer using Spring MVC Framework with JSP CSS3 AJAX and JavaScript Worked within SOA based enterprise framework to build web services The RESTful web services have been used to retrieve and update the data which is populated in view using Angular JS model Developed Messaging framework for Asynchronous messaging service using JMS and MQseries Extensively used JSON object data in the model as from RESTful web services Developed Restful web services using JERSEY to sendreceive data tofrom various systems Performed Test Driven Development TDD using JUnit Used Jenkins for Continuous Integration and Continuous Delivery Environment Java J2EE HTML5 CSS3 AJAX JavaScript jQuery Spring 40 Tiles SOA Hibernate 40 JMS 20 JNDI JTA XML JSON JAXB JAXWS REST WS SOAP WSDL JUnit Log4J Maven JSP JSF Oracle Servlets Jenkins Eclipse SVN Design Patterns Agile WebSphere Skills HDFS OOZIE SQOOP HBASE KAFKA FLUME JMS MAP REDUCE CODING Git HBase Hive HTML JENKINS Pig SVN XML ZooKeeper ECLIPSE EJB Additional Information Technical Skills Big Data Technologies HDFS Map Reduce Hive Pig Hbase Sqoop Zookeeper Oozie Flume Kafka Databases Oracle 9i 10 g 11 g MySQL SQL Server Hbase JavaJ2EE Technologies JDBC Servlets JSP OAuth2 JMS EJB JNDI Selenium OWB LDAP Log4j ANT Maven RDS SNS Chef JIRA Confluence JMeter Programming Languages Java JDK 1718 SQL PLSQL IDEs Eclipse NetBeans IntelliJ IBM RAD Oracle WebLogic Studio 8x7x Sublime text Brackets Hive Connecter Frameworks Struts 2x1x Spring 2x Hibernate 3x Mockito PowerMockito Coding Languages Java 678 PLSQL XML HTML CSS Java Script UML Bug Tracking or other Tools Jira Bugzilla Junit Putty WinScp FileZilla Operating Systems Windows and Linux Environments Web Services SOAP JAXB JAXWS RESTful Web services UDDI Micro services Sub Version Control Tool SVN CVS Git Bit Bucket Jenkins JIRA",
    "extracted_keywords": [
        "HADOOP",
        "DEVELOPER",
        "HADOOP",
        "span",
        "lDEVELOPERspan",
        "HADOOP",
        "DEVELOPER",
        "American",
        "Express",
        "Work",
        "Experience",
        "HADOOP",
        "DEVELOPER",
        "American",
        "Express",
        "Phoenix",
        "AZ",
        "March",
        "Present",
        "Design",
        "enterprise",
        "data",
        "warehouse",
        "DataMart",
        "models",
        "data",
        "models",
        "Hive",
        "Query",
        "Language",
        "code",
        "Build",
        "Spark",
        "Query",
        "Language",
        "code",
        "unit",
        "code",
        "partitions",
        "partitions",
        "Develop",
        "Magellan",
        "maps",
        "deployment",
        "support",
        "install",
        "hive",
        "Magellan",
        "tool",
        "data",
        "SORs",
        "ODL",
        "tables",
        "Review",
        "Hive",
        "QL",
        "code",
        "Spark",
        "code",
        "UNIX",
        "scripts",
        "Magellan",
        "code",
        "deliverables",
        "ODL",
        "panel",
        "team",
        "issues",
        "panel",
        "review",
        "Prepare",
        "installation",
        "manual",
        "project",
        "post",
        "installation",
        "support",
        "project",
        "documentations",
        "project",
        "changes",
        "activities",
        "metadata",
        "Jenkin",
        "job",
        "configurations",
        "RFC",
        "followups",
        "RFC",
        "service",
        "tickets",
        "Jira",
        "tickets",
        "scheduling",
        "mapsnodes",
        "event",
        "engine",
        "steps",
        "jobs",
        "basis",
        "Provide",
        "production",
        "support",
        "ODL",
        "variables",
        "production",
        "defects",
        "changes",
        "respect",
        "ODL",
        "variables",
        "production",
        "activity",
        "reports",
        "risks",
        "issues",
        "resolutions",
        "status",
        "reports",
        "American",
        "Express",
        "users",
        "basis",
        "Conduct",
        "knowledge",
        "sharing",
        "practice",
        "sessions",
        "team",
        "quality",
        "deliverables",
        "Environment",
        "Hive",
        "HDFS",
        "MapReduce",
        "Flume",
        "Spark",
        "SQL",
        "Oozie",
        "Oracle",
        "Jenkins",
        "Yarn",
        "Netezza",
        "GitHub",
        "Junit",
        "Linux",
        "Hbase",
        "sqoop",
        "HDFS",
        "Event",
        "Engine",
        "Maven",
        "Splunk",
        "Eclipse",
        "Big",
        "Data",
        "Developer",
        "Citi",
        "Bank",
        "Irving",
        "TX",
        "March",
        "February",
        "details",
        "Rally",
        "user",
        "stories",
        "status",
        "standup",
        "meetings",
        "sprint",
        "planning",
        "Grooming",
        "show",
        "tell",
        "calls",
        "Analyze",
        "issues",
        "UAT",
        "business",
        "users",
        "resolutions",
        "Map",
        "Reduce",
        "Jobs",
        "java",
        "data",
        "cleaning",
        "tables",
        "Hive",
        "information",
        "sources",
        "testing",
        "Sqoop",
        "jobs",
        "data",
        "Netezza",
        "database",
        "sources",
        "Hive",
        "Tables",
        "Sqoop",
        "data",
        "Netezza",
        "Hive",
        "imports",
        "Sqoop",
        "jobs",
        "value",
        "Collected",
        "logs",
        "data",
        "webservers",
        "HDFS",
        "Flume",
        "Created",
        "Hive",
        "tables",
        "results",
        "format",
        "Maven",
        "jar",
        "files",
        "MapReduce",
        "programs",
        "Cluster",
        "Good",
        "experience",
        "enterprise",
        "data",
        "data",
        "sources",
        "HDFS",
        "Sqoop",
        "Flume",
        "transformations",
        "Hive",
        "PIG",
        "HBase",
        "tables",
        "Configured",
        "Oozie",
        "workflow",
        "engine",
        "Map",
        "Reduce",
        "HiveQL",
        "Pig",
        "jobs",
        "customer",
        "profiles",
        "data",
        "customer",
        "data",
        "credit",
        "warehouse",
        "HDFS",
        "Sqoop",
        "Oozie",
        "map",
        "jobs",
        "data",
        "manner",
        "loading",
        "data",
        "Environment",
        "environment",
        "Hadoop",
        "Platform",
        "Map",
        "Reduce",
        "jobs",
        "java",
        "data",
        "cleaning",
        "Hive",
        "tables",
        "data",
        "hive",
        "queries",
        "Map",
        "Reduce",
        "way",
        "Design",
        "workflows",
        "data",
        "loading",
        "Hadoop",
        "ecosystems",
        "data",
        "sources",
        "Environment",
        "Hive",
        "HDFS",
        "MapReduce",
        "Flume",
        "Pig",
        "Spark",
        "Core",
        "Spark",
        "SQL",
        "Oozie",
        "Oracle",
        "Yarn",
        "Netezza",
        "GitHub",
        "Junit",
        "Linux",
        "Hbase",
        "sqoop",
        "HDFS",
        "Java",
        "Scala",
        "Maven",
        "Splunk",
        "Eclipse",
        "DEVELOPER",
        "Hibu",
        "Cedar",
        "Rapids",
        "IA",
        "August",
        "February",
        "phases",
        "Software",
        "Development",
        "Life",
        "Cycle",
        "Analysis",
        "applications",
        "methodology",
        "HTML",
        "pages",
        "JavaScript",
        "jQuery",
        "RESTful",
        "Web",
        "Services",
        "AJAX",
        "FrontEnd",
        "GUI",
        "MultiThreading",
        "Lambdas",
        "Expressions",
        "J2EE",
        "design",
        "patterns",
        "Session",
        "Facade",
        "Factory",
        "DAO",
        "DTO",
        "Proxy",
        "Coding",
        "spring",
        "framework",
        "components",
        "Spring",
        "IOCDependency",
        "Injection",
        "Consumed",
        "Web",
        "services",
        "vendor",
        "Address",
        "verification",
        "validation",
        "REST",
        "services",
        "UI",
        "Angular20",
        "CRUD",
        "operations",
        "database",
        "server",
        "HTTP",
        "GET",
        "POST",
        "DELETE",
        "Web",
        "service",
        "JIRA",
        "system",
        "track",
        "issues",
        "tasks",
        "individuals",
        "tables",
        "Stored",
        "Procedures",
        "functions",
        "views",
        "indexes",
        "constraints",
        "triggers",
        "SQL",
        "response",
        "time",
        "application",
        "NoSQL",
        "DB",
        "Mongo",
        "DB",
        "proof",
        "concept",
        "legacy",
        "services",
        "Micro",
        "Services",
        "Architecture",
        "Spring",
        "Boot",
        "text",
        "search",
        "function",
        "data",
        "model",
        "Hibernate",
        "mappings",
        "domain",
        "objects",
        "Hibernate",
        "tools",
        "MySQL",
        "database",
        "Spring",
        "Hibernate",
        "production",
        "servers",
        "Unix",
        "Linux",
        "database",
        "Web",
        "services",
        "Spring",
        "Core",
        "annotations",
        "Spring",
        "Dependency",
        "Injection",
        "Spring",
        "MVC",
        "Rest",
        "APIs",
        "Spring",
        "Boot",
        "microservices",
        "WebSphere",
        "MQ",
        "MDB",
        "listeners",
        "JMS",
        "resources",
        "queues",
        "WebSphere",
        "Application",
        "Server",
        "log4j",
        "warning",
        "info",
        "statements",
        "Maven",
        "build",
        "cruise",
        "control",
        "building",
        "SVN",
        "version",
        "control",
        "system",
        "source",
        "code",
        "project",
        "documents",
        "Environment",
        "Java8",
        "Spring",
        "Frameworks",
        "Spring",
        "Boot",
        "Micro",
        "JPA",
        "Hibernate",
        "AWS",
        "RESTfulSOAP",
        "Web",
        "Services",
        "HTML",
        "CSS",
        "JavaScript",
        "jQuery",
        "Angular",
        "Maven",
        "WebSphere",
        "Application",
        "Server",
        "Mongo",
        "DB",
        "Log4j",
        "Jenkins",
        "JIRA",
        "GIT",
        "JAVA",
        "DEVELOPER",
        "Walmart",
        "Inc",
        "Bentonville",
        "AR",
        "November",
        "July",
        "Analyzing",
        "design",
        "specification",
        "documents",
        "Requirements",
        "Architecture",
        "Development",
        "Maintenance",
        "traffic",
        "application",
        "JavaJ2EE",
        "application",
        "modules",
        "base",
        "classes",
        "utility",
        "classes",
        "core",
        "SAX",
        "XML",
        "JAXB",
        "unmarshaling",
        "development",
        "performance",
        "testing",
        "defects",
        "SOAP",
        "Web",
        "Services",
        "Contract",
        "First",
        "pricing",
        "claims",
        "meetings",
        "development",
        "team",
        "Expertise",
        "understanding",
        "preparation",
        "WSDL",
        "XSLT",
        "XML",
        "schemas",
        "definitions",
        "project",
        "Business",
        "Delegate",
        "Singleton",
        "Service",
        "Locator",
        "DAO",
        "Patterns",
        "changes",
        "work",
        "flow",
        "Action",
        "classes",
        "database",
        "Placement",
        "Quote",
        "Creation",
        "module",
        "Hibernate",
        "ORM",
        "Mapping",
        "tool",
        "framework",
        "database",
        "retrieve",
        "values",
        "JSF",
        "data",
        "interchange",
        "format",
        "browser",
        "server",
        "end",
        "application",
        "publishing",
        "framework",
        "UI",
        "component",
        "library",
        "Angular",
        "JS",
        "jQuery",
        "Developed",
        "weblayer",
        "Spring",
        "MVC",
        "Framework",
        "JSP",
        "CSS3",
        "AJAX",
        "JavaScript",
        "SOA",
        "enterprise",
        "framework",
        "web",
        "services",
        "web",
        "services",
        "data",
        "view",
        "Angular",
        "JS",
        "model",
        "Developed",
        "framework",
        "messaging",
        "service",
        "JMS",
        "MQseries",
        "object",
        "data",
        "model",
        "web",
        "services",
        "web",
        "services",
        "JERSEY",
        "data",
        "systems",
        "Performed",
        "Test",
        "Driven",
        "Development",
        "TDD",
        "JUnit",
        "Jenkins",
        "Continuous",
        "Integration",
        "Continuous",
        "Delivery",
        "Environment",
        "Java",
        "J2EE",
        "HTML5",
        "CSS3",
        "AJAX",
        "JavaScript",
        "jQuery",
        "Spring",
        "Tiles",
        "SOA",
        "Hibernate",
        "JMS",
        "JNDI",
        "JTA",
        "JSON",
        "JAXB",
        "JAXWS",
        "REST",
        "WS",
        "SOAP",
        "WSDL",
        "JUnit",
        "Log4J",
        "Maven",
        "JSP",
        "JSF",
        "Oracle",
        "Servlets",
        "Jenkins",
        "Eclipse",
        "SVN",
        "Design",
        "Patterns",
        "Agile",
        "WebSphere",
        "Skills",
        "HDFS",
        "OOZIE",
        "SQOOP",
        "HBASE",
        "KAFKA",
        "JMS",
        "MAP",
        "REDUCE",
        "CODING",
        "Git",
        "HBase",
        "Hive",
        "HTML",
        "JENKINS",
        "Pig",
        "SVN",
        "XML",
        "ZooKeeper",
        "ECLIPSE",
        "EJB",
        "Additional",
        "Information",
        "Technical",
        "Skills",
        "Big",
        "Data",
        "Technologies",
        "HDFS",
        "Map",
        "Reduce",
        "Hive",
        "Pig",
        "Hbase",
        "Sqoop",
        "Zookeeper",
        "Oozie",
        "Flume",
        "Kafka",
        "Oracle",
        "9i",
        "g",
        "g",
        "MySQL",
        "SQL",
        "Server",
        "Hbase",
        "JavaJ2EE",
        "Technologies",
        "JDBC",
        "Servlets",
        "JSP",
        "OAuth2",
        "JMS",
        "EJB",
        "JNDI",
        "Selenium",
        "OWB",
        "LDAP",
        "Log4j",
        "ANT",
        "Maven",
        "RDS",
        "SNS",
        "Chef",
        "JIRA",
        "Confluence",
        "JMeter",
        "Programming",
        "Languages",
        "Java",
        "JDK",
        "SQL",
        "PLSQL",
        "Eclipse",
        "NetBeans",
        "IBM",
        "RAD",
        "Oracle",
        "WebLogic",
        "Studio",
        "8x7x",
        "text",
        "Brackets",
        "Hive",
        "Connecter",
        "Frameworks",
        "Struts",
        "2x1x",
        "Spring",
        "Hibernate",
        "Mockito",
        "PowerMockito",
        "Coding",
        "Languages",
        "Java",
        "PLSQL",
        "XML",
        "HTML",
        "CSS",
        "Java",
        "Script",
        "UML",
        "Bug",
        "Tracking",
        "Tools",
        "Jira",
        "Bugzilla",
        "Junit",
        "Putty",
        "WinScp",
        "FileZilla",
        "Operating",
        "Systems",
        "Windows",
        "Linux",
        "Environments",
        "Web",
        "Services",
        "SOAP",
        "JAXB",
        "JAXWS",
        "Web",
        "services",
        "UDDI",
        "Micro",
        "services",
        "Sub",
        "Version",
        "Control",
        "Tool",
        "SVN",
        "CVS",
        "Git",
        "Bit",
        "Bucket",
        "Jenkins",
        "JIRA"
    ],
    "input_field": null,
    "instruction": "",
    "processed_at": "2024-11-24T22:42:52.443281",
    "resume_data": "HADOOP DEVELOPER HADOOP span lDEVELOPERspan HADOOP DEVELOPER American Express Work Experience HADOOP DEVELOPER American Express Phoenix AZ March 2018 to Present Design develop and implement enterprise data warehouse and create DataMart models Physical and logical data models Build the Hive Query Language code Build Spark Query Language code and unit testing the code Also create partitions dynamic partitions Develop Magellan maps and assist in deployment and provide technical and operational support during the install Involved in hive coding by using Magellan tool transform the data from SORs to ODL tables Review the Hive QL code Spark code UNIX scripts Magellan code and other deliverables with ODL technical panel Work closely with team and close all issues identified during the technical panel review Prepare installation manual and implement the project and provide post installation support Update the project documentations with the installed project changes Perform all the activities related to release such as preparing the metadata Jenkin job configurations and RFC creations All followups related to the RFC and managing service now tickets and Jira tickets Worked on scheduling mapsnodes in event engine and implement different proactive steps for monitoring scheduled jobs on regular basis Provide production support for the existing ODL variables in production This includes any defects fixing and implementing changes with respect to any existing ODL variables in production Creating activity reports with risks issues causes resolutions and provide status reports to American Express end users on daily or weekly basis Conduct knowledge sharing and best practice sessions to educate the team for better quality deliverables for future Environment Hive HDFS MapReduce Flume Spark SQL Oozie Oracle Jenkins Yarn Netezza GitHub Junit Linux Hbase sqoop HDFS Event Engine Maven and Splunk Eclipse Big Data Developer Citi Bank Irving TX March 2016 to February 2018 Updating details in Rally for all assigned user stories and reported the status in daily standup meetings and also involved in sprint planning Grooming show tell and retrospective calls Analyze the reported issues during UAT and coordinate with the business users for the resolutions Implemented multiple Map Reduce Jobs in java for data cleaning and preprocessing Created the external tables in Hive to store information from different sources for testing needs Configured the Sqoop jobs to load the data from Netezza database and other sources into Hive Tables Extensively Used Sqoop to importexport data from Netezza and Hive tables incremental imports and created Sqoop jobs for last saved value Collected logs data from webservers and integrated into HDFS using Flume Created Hive tables to store the processed results in a tabular format Used Maven extensively for building jar files of MapReduce programs and deployed to Cluster Good experience in importing other enterprise data from different data sources into HDFS using Sqoop and Flume and also performing transformations using Hive and PIG and then loading into HBase tables Configured Oozie workflow engine to run multiple Map Reduce HiveQL and Pig jobs Loaded the customer profiles data customer spending data credit from legacy warehouse onto HDFS using Sqoop Used Oozie to orchestrate the map reduce jobs that extract the data on a timely manner Involved in loading data from one Environment to other environment in Hadoop Platform Developed multiple Map Reduce jobs in java for data cleaning Involved in creating Hive tables loading with data and writing hive queries that will run internally in Map Reduce way Design and develop oozie workflows for timely data loading into Hadoop ecosystems from other data sources Environment Hive HDFS MapReduce Flume Pig Spark Core Spark SQL Oozie Oracle Yarn Netezza GitHub Junit Linux Hbase sqoop HDFS Java Scala Maven and Splunk Eclipse JAVA DEVELOPER Hibu Cedar Rapids IA August 2014 to February 2016 Involved in all phases of Software Development Life Cycle and in Analysis designed applications using agile methodology Created dynamic HTML pages using JavaScript jQuery RESTful Web Services and AJAX to create interactive FrontEnd GUI Used synchronous and asynchronous MultiThreading and Lambdas Expressions Implemented J2EE design patterns such as Session Facade Factory DAO DTO and Proxy Involved in Coding based on the spring framework Implemented several components using Spring IOCDependency Injection Consumed RESTful Web services provided by different vendor to use for Address verification and validation Used REST services along with UI built on Angular20 to perform CRUD operations on the database server over HTTP with GET POST PUT DELETE to the Web service Used JIRA ticketing system to keep track of issues and tasks on individuals Created new tables Stored Procedures functions views indexes and constraints triggers and required SQL tuning to reduce the response time in the application Used NoSQL DB like Mongo DB for the proof of concept Migrating existing legacy java services into Micro Services Architecture with Spring Boot Optimized the full text search function by connecting to MongoDB Created data model and generated Hibernate mappings and domain objects using Hibernate tools Interfaced with the MySQL backend database by integrating Spring with Hibernate Maintaining production critical servers running Unix Linux supporting database and Web services Providing 24x7 supports Used Spring Core annotations for Spring Dependency Injection Spring MVC for Rest APIs and Spring Boot for microservices Installed the WebSphere MQ and involved in configuring MDB listeners JMS resources and queues and integrating with the WebSphere Application Server Used log4j to print the logging debugging warning info statements Used Maven for build cruise control is used continuous building Used SVN as version control system for source code and project documents Environment Java8 Spring Frameworks Spring Boot Micro services JPA Hibernate AWS RESTfulSOAP Web Services HTML CSS JavaScript jQuery Angular 2 Maven WebSphere Application Server Mongo DB Log4j Jenkins JIRA GIT JAVA DEVELOPER Walmart Inc Bentonville AR November 2013 to July 2014 Involved in Analyzing preparing technical design specification documents as per the Requirements Architecture Development and Maintenance of high traffic application built in JavaJ2EE Designed application modules base classes and utility classes using core java Used SAX for XML parsing specifically for JAXB marshaling and unmarshaling Involved in development performance testing defects fixing Developed SOAP Web Services Contract First for pricing of the claims Organized daily agile meetings to interact with the development team Expertise in understanding and preparation of WSDL XSLT and XML schemas definitions Designed the project using Business Delegate Singleton Service Locator and DAO Patterns Involved in making the necessary changes for the entire work flow from Action classes to the backend database in Placement Quote Creation module Implemented Hibernate ORM Mapping tool framework to interact with the database to update retrieve insert and delete values effectively JSF was used as the data interchange format between the browser and server In the Front end of the application designed and implemented a publishing framework and reusable UI component library based on Angular JS and jQuery Developed weblayer using Spring MVC Framework with JSP CSS3 AJAX and JavaScript Worked within SOA based enterprise framework to build web services The RESTful web services have been used to retrieve and update the data which is populated in view using Angular JS model Developed Messaging framework for Asynchronous messaging service using JMS and MQseries Extensively used JSON object data in the model as from RESTful web services Developed Restful web services using JERSEY to sendreceive data tofrom various systems Performed Test Driven Development TDD using JUnit Used Jenkins for Continuous Integration and Continuous Delivery Environment Java J2EE HTML5 CSS3 AJAX JavaScript jQuery Spring 40 Tiles SOA Hibernate 40 JMS 20 JNDI JTA XML JSON JAXB JAXWS REST WS SOAP WSDL JUnit Log4J Maven JSP JSF Oracle Servlets Jenkins Eclipse SVN Design Patterns Agile WebSphere Skills HDFS OOZIE SQOOP HBASE KAFKA FLUME JMS MAP REDUCE CODING Git HBase Hive HTML JENKINS Pig SVN XML ZooKeeper ECLIPSE EJB Additional Information Technical Skills Big Data Technologies HDFS Map Reduce Hive Pig Hbase Sqoop Zookeeper Oozie Flume Kafka Databases Oracle 9i 10g 11g MySQL SQL Server Hbase JavaJ2EE Technologies JDBC Servlets JSP OAuth2 JMS EJB JNDI Selenium OWB LDAP Log4j ANT Maven RDS SNS Chef JIRA Confluence JMeter Programming Languages Java JDK 1718 SQL PLSQL IDEs Eclipse NetBeans IntelliJ IBM RAD Oracle WebLogic Studio 8x7x Sublime text Brackets Hive Connecter Frameworks Struts 2x1x Spring 2x Hibernate 3x Mockito PowerMockito Coding Languages Java 678 PLSQL XML HTML CSS Java Script UML Bug Tracking or other Tools Jira Bugzilla Junit Putty WinScp FileZilla Operating Systems Windows and Linux Environments Web Services SOAP JAXB JAXWS RESTful Web services UDDI Micro services Sub Version Control Tool SVN CVS Git Bit Bucket Jenkins JIRA",
    "unique_id": "ca7ee8c0-74d1-41c5-90f2-f9f409355d15"
}